schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

# columns and relationships of "achievement_property"
type achievement_property {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!

  # An array relationship
  listings(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): [achievement_property_listing!]!

  # An aggregated array relationship
  listings_aggregate(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): achievement_property_listing_aggregate!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  oldType: String
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  sameAsField: String
  singleValue: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "achievement_property"
type achievement_property_aggregate {
  aggregate: achievement_property_aggregate_fields
  nodes: [achievement_property!]!
}

# aggregate fields of "achievement_property"
type achievement_property_aggregate_fields {
  avg: achievement_property_avg_fields
  count(columns: [achievement_property_select_column!], distinct: Boolean): Int
  max: achievement_property_max_fields
  min: achievement_property_min_fields
  stddev: achievement_property_stddev_fields
  stddev_pop: achievement_property_stddev_pop_fields
  stddev_samp: achievement_property_stddev_samp_fields
  sum: achievement_property_sum_fields
  var_pop: achievement_property_var_pop_fields
  var_samp: achievement_property_var_samp_fields
  variance: achievement_property_variance_fields
}

# order by aggregate values of table "achievement_property"
input achievement_property_aggregate_order_by {
  avg: achievement_property_avg_order_by
  count: order_by
  max: achievement_property_max_order_by
  min: achievement_property_min_order_by
  stddev: achievement_property_stddev_order_by
  stddev_pop: achievement_property_stddev_pop_order_by
  stddev_samp: achievement_property_stddev_samp_order_by
  sum: achievement_property_sum_order_by
  var_pop: achievement_property_var_pop_order_by
  var_samp: achievement_property_var_samp_order_by
  variance: achievement_property_variance_order_by
}

# input type for inserting array relation for remote table "achievement_property"
input achievement_property_arr_rel_insert_input {
  data: [achievement_property_insert_input!]!
  on_conflict: achievement_property_on_conflict
}

# aggregate avg on columns
type achievement_property_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "achievement_property"
input achievement_property_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "achievement_property". All fields are combined with a logical 'AND'.
input achievement_property_bool_exp {
  _and: [achievement_property_bool_exp]
  _not: achievement_property_bool_exp
  _or: [achievement_property_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  listings: achievement_property_listing_bool_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  oldType: String_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  sameAsField: String_comparison_exp
  singleValue: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "achievement_property"
enum achievement_property_constraint {
  # unique or primary key constraint
  achievement_property_pkey
}

# input type for incrementing integer column in table "achievement_property"
input achievement_property_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "achievement_property"
input achievement_property_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  listings: achievement_property_listing_arr_rel_insert_input
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  oldType: String
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  sameAsField: String
  singleValue: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# columns and relationships of "achievement_property_listing"
type achievement_property_listing {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  connectedPropertyId: bigint
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp

  # An object relationship
  docType: publication_type
  docTypeMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint

  # An object relationship
  property: achievement_property
  propertyMtid: bigint
  published: Boolean!
  refreshed: Boolean!
  required: Boolean!
  status: Int

  # An object relationship
  subType: sub_type
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "achievement_property_listing"
type achievement_property_listing_aggregate {
  aggregate: achievement_property_listing_aggregate_fields
  nodes: [achievement_property_listing!]!
}

# aggregate fields of "achievement_property_listing"
type achievement_property_listing_aggregate_fields {
  avg: achievement_property_listing_avg_fields
  count(columns: [achievement_property_listing_select_column!], distinct: Boolean): Int
  max: achievement_property_listing_max_fields
  min: achievement_property_listing_min_fields
  stddev: achievement_property_listing_stddev_fields
  stddev_pop: achievement_property_listing_stddev_pop_fields
  stddev_samp: achievement_property_listing_stddev_samp_fields
  sum: achievement_property_listing_sum_fields
  var_pop: achievement_property_listing_var_pop_fields
  var_samp: achievement_property_listing_var_samp_fields
  variance: achievement_property_listing_variance_fields
}

# order by aggregate values of table "achievement_property_listing"
input achievement_property_listing_aggregate_order_by {
  avg: achievement_property_listing_avg_order_by
  count: order_by
  max: achievement_property_listing_max_order_by
  min: achievement_property_listing_min_order_by
  stddev: achievement_property_listing_stddev_order_by
  stddev_pop: achievement_property_listing_stddev_pop_order_by
  stddev_samp: achievement_property_listing_stddev_samp_order_by
  sum: achievement_property_listing_sum_order_by
  var_pop: achievement_property_listing_var_pop_order_by
  var_samp: achievement_property_listing_var_samp_order_by
  variance: achievement_property_listing_variance_order_by
}

# input type for inserting array relation for remote table "achievement_property_listing"
input achievement_property_listing_arr_rel_insert_input {
  data: [achievement_property_listing_insert_input!]!
  on_conflict: achievement_property_listing_on_conflict
}

# aggregate avg on columns
type achievement_property_listing_avg_fields {
  approverMtid: Float
  connectedPropertyId: Float
  creator: Float
  docTypeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  status: Float
  subTypeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "achievement_property_listing"
input achievement_property_listing_avg_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "achievement_property_listing".
# All fields are combined with a logical 'AND'.
input achievement_property_listing_bool_exp {
  _and: [achievement_property_listing_bool_exp]
  _not: achievement_property_listing_bool_exp
  _or: [achievement_property_listing_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  connectedPropertyId: bigint_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  docType: publication_type_bool_exp
  docTypeMtid: bigint_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  property: achievement_property_bool_exp
  propertyMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  required: Boolean_comparison_exp
  status: Int_comparison_exp
  subType: sub_type_bool_exp
  subTypeMtid: bigint_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "achievement_property_listing"
enum achievement_property_listing_constraint {
  # unique or primary key constraint
  achievement_property_listing_pkey
}

# input type for incrementing integer column in table "achievement_property_listing"
input achievement_property_listing_inc_input {
  approverMtid: bigint
  connectedPropertyId: bigint
  creator: bigint
  docTypeMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  propertyMtid: bigint
  status: Int
  subTypeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "achievement_property_listing"
input achievement_property_listing_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  connectedPropertyId: bigint
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  docType: publication_type_obj_rel_insert_input
  docTypeMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  property: achievement_property_obj_rel_insert_input
  propertyMtid: bigint
  published: Boolean
  refreshed: Boolean
  required: Boolean
  status: Int
  subType: sub_type_obj_rel_insert_input
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type achievement_property_listing_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  connectedPropertyId: bigint
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  docTypeMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  propertyMtid: bigint
  status: Int
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "achievement_property_listing"
input achievement_property_listing_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  connectedPropertyId: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  docTypeMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type achievement_property_listing_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  connectedPropertyId: bigint
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  docTypeMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  propertyMtid: bigint
  status: Int
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "achievement_property_listing"
input achievement_property_listing_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  connectedPropertyId: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  docTypeMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "achievement_property_listing"
type achievement_property_listing_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [achievement_property_listing!]!
}

# input type for inserting object relation for remote table "achievement_property_listing"
input achievement_property_listing_obj_rel_insert_input {
  data: achievement_property_listing_insert_input!
  on_conflict: achievement_property_listing_on_conflict
}

# on conflict condition type for table "achievement_property_listing"
input achievement_property_listing_on_conflict {
  constraint: achievement_property_listing_constraint!
  update_columns: [achievement_property_listing_update_column!]!
  where: achievement_property_listing_bool_exp
}

# ordering options when selecting data from "achievement_property_listing"
input achievement_property_listing_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  connectedPropertyId: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  docType: publication_type_order_by
  docTypeMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  property: achievement_property_order_by
  propertyMtid: order_by
  published: order_by
  refreshed: order_by
  required: order_by
  status: order_by
  subType: sub_type_order_by
  subTypeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "achievement_property_listing"
input achievement_property_listing_pk_columns_input {
  mtid: bigint!
}

# select columns of table "achievement_property_listing"
enum achievement_property_listing_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  connectedPropertyId

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  docTypeMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  propertyMtid

  # column name
  published

  # column name
  refreshed

  # column name
  required

  # column name
  status

  # column name
  subTypeMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "achievement_property_listing"
input achievement_property_listing_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  connectedPropertyId: bigint
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  docTypeMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  propertyMtid: bigint
  published: Boolean
  refreshed: Boolean
  required: Boolean
  status: Int
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type achievement_property_listing_stddev_fields {
  approverMtid: Float
  connectedPropertyId: Float
  creator: Float
  docTypeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  status: Float
  subTypeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "achievement_property_listing"
input achievement_property_listing_stddev_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type achievement_property_listing_stddev_pop_fields {
  approverMtid: Float
  connectedPropertyId: Float
  creator: Float
  docTypeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  status: Float
  subTypeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "achievement_property_listing"
input achievement_property_listing_stddev_pop_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type achievement_property_listing_stddev_samp_fields {
  approverMtid: Float
  connectedPropertyId: Float
  creator: Float
  docTypeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  status: Float
  subTypeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "achievement_property_listing"
input achievement_property_listing_stddev_samp_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type achievement_property_listing_sum_fields {
  approverMtid: bigint
  connectedPropertyId: bigint
  creator: bigint
  docTypeMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  propertyMtid: bigint
  status: Int
  subTypeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "achievement_property_listing"
input achievement_property_listing_sum_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "achievement_property_listing"
enum achievement_property_listing_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  connectedPropertyId

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  docTypeMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  propertyMtid

  # column name
  published

  # column name
  refreshed

  # column name
  required

  # column name
  status

  # column name
  subTypeMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type achievement_property_listing_var_pop_fields {
  approverMtid: Float
  connectedPropertyId: Float
  creator: Float
  docTypeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  status: Float
  subTypeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "achievement_property_listing"
input achievement_property_listing_var_pop_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type achievement_property_listing_var_samp_fields {
  approverMtid: Float
  connectedPropertyId: Float
  creator: Float
  docTypeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  status: Float
  subTypeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "achievement_property_listing"
input achievement_property_listing_var_samp_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type achievement_property_listing_variance_fields {
  approverMtid: Float
  connectedPropertyId: Float
  creator: Float
  docTypeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  status: Float
  subTypeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "achievement_property_listing"
input achievement_property_listing_variance_order_by {
  approverMtid: order_by
  connectedPropertyId: order_by
  creator: order_by
  docTypeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  status: order_by
  subTypeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate max on columns
type achievement_property_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  oldType: String
  otype: String
  prevValid: bigint
  sameAsField: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "achievement_property"
input achievement_property_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  oldType: order_by
  otype: order_by
  prevValid: order_by
  sameAsField: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type achievement_property_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  oldType: String
  otype: String
  prevValid: bigint
  sameAsField: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "achievement_property"
input achievement_property_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  oldType: order_by
  otype: order_by
  prevValid: order_by
  sameAsField: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "achievement_property"
type achievement_property_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [achievement_property!]!
}

# input type for inserting object relation for remote table "achievement_property"
input achievement_property_obj_rel_insert_input {
  data: achievement_property_insert_input!
  on_conflict: achievement_property_on_conflict
}

# on conflict condition type for table "achievement_property"
input achievement_property_on_conflict {
  constraint: achievement_property_constraint!
  update_columns: [achievement_property_update_column!]!
  where: achievement_property_bool_exp
}

# ordering options when selecting data from "achievement_property"
input achievement_property_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  listings_aggregate: achievement_property_listing_aggregate_order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  oldType: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  sameAsField: order_by
  singleValue: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "achievement_property"
input achievement_property_pk_columns_input {
  mtid: bigint!
}

# select columns of table "achievement_property"
enum achievement_property_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  oldType

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sameAsField

  # column name
  singleValue

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "achievement_property"
input achievement_property_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  oldType: String
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  sameAsField: String
  singleValue: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type achievement_property_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "achievement_property"
input achievement_property_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type achievement_property_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "achievement_property"
input achievement_property_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type achievement_property_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "achievement_property"
input achievement_property_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type achievement_property_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "achievement_property"
input achievement_property_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "achievement_property"
enum achievement_property_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  oldType

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sameAsField

  # column name
  singleValue

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# columns and relationships of "achievement_property_value"
type achievement_property_value {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  dateValue: timestamp
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  idValue: Int
  idValues: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  newIdValue: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint

  # An object relationship
  property: achievement_property
  propertyMtid: bigint

  # An object relationship
  publication: publication
  publicationMtid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "achievement_property_value"
type achievement_property_value_aggregate {
  aggregate: achievement_property_value_aggregate_fields
  nodes: [achievement_property_value!]!
}

# aggregate fields of "achievement_property_value"
type achievement_property_value_aggregate_fields {
  avg: achievement_property_value_avg_fields
  count(columns: [achievement_property_value_select_column!], distinct: Boolean): Int
  max: achievement_property_value_max_fields
  min: achievement_property_value_min_fields
  stddev: achievement_property_value_stddev_fields
  stddev_pop: achievement_property_value_stddev_pop_fields
  stddev_samp: achievement_property_value_stddev_samp_fields
  sum: achievement_property_value_sum_fields
  var_pop: achievement_property_value_var_pop_fields
  var_samp: achievement_property_value_var_samp_fields
  variance: achievement_property_value_variance_fields
}

# order by aggregate values of table "achievement_property_value"
input achievement_property_value_aggregate_order_by {
  avg: achievement_property_value_avg_order_by
  count: order_by
  max: achievement_property_value_max_order_by
  min: achievement_property_value_min_order_by
  stddev: achievement_property_value_stddev_order_by
  stddev_pop: achievement_property_value_stddev_pop_order_by
  stddev_samp: achievement_property_value_stddev_samp_order_by
  sum: achievement_property_value_sum_order_by
  var_pop: achievement_property_value_var_pop_order_by
  var_samp: achievement_property_value_var_samp_order_by
  variance: achievement_property_value_variance_order_by
}

# input type for inserting array relation for remote table "achievement_property_value"
input achievement_property_value_arr_rel_insert_input {
  data: [achievement_property_value_insert_input!]!
  on_conflict: achievement_property_value_on_conflict
}

# aggregate avg on columns
type achievement_property_value_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  idValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  newIdValue: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "achievement_property_value"
input achievement_property_value_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "achievement_property_value". All fields are combined with a logical 'AND'.
input achievement_property_value_bool_exp {
  _and: [achievement_property_value_bool_exp]
  _not: achievement_property_value_bool_exp
  _or: [achievement_property_value_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  dateValue: timestamp_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  idValue: Int_comparison_exp
  idValues: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  newIdValue: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  property: achievement_property_bool_exp
  propertyMtid: bigint_comparison_exp
  publication: publication_bool_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  stringValue: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "achievement_property_value"
enum achievement_property_value_constraint {
  # unique or primary key constraint
  achievement_property_value_pkey
}

# input type for incrementing integer column in table "achievement_property_value"
input achievement_property_value_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  idValue: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  newIdValue: bigint
  oldId: Int
  prevValid: bigint
  propertyMtid: bigint
  publicationMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "achievement_property_value"
input achievement_property_value_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  dateValue: timestamp
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: Int
  idValues: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  newIdValue: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  property: achievement_property_obj_rel_insert_input
  propertyMtid: bigint
  publication: publication_obj_rel_insert_input
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type achievement_property_value_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dateValue: timestamp
  deletedDate: timestamp
  error: Int
  idValue: Int
  idValues: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  newIdValue: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  propertyMtid: bigint
  publicationMtid: bigint
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "achievement_property_value"
input achievement_property_value_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dateValue: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  idValues: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  stringValue: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type achievement_property_value_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dateValue: timestamp
  deletedDate: timestamp
  error: Int
  idValue: Int
  idValues: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  newIdValue: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  propertyMtid: bigint
  publicationMtid: bigint
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "achievement_property_value"
input achievement_property_value_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dateValue: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  idValues: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  stringValue: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "achievement_property_value"
type achievement_property_value_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [achievement_property_value!]!
}

# input type for inserting object relation for remote table "achievement_property_value"
input achievement_property_value_obj_rel_insert_input {
  data: achievement_property_value_insert_input!
  on_conflict: achievement_property_value_on_conflict
}

# on conflict condition type for table "achievement_property_value"
input achievement_property_value_on_conflict {
  constraint: achievement_property_value_constraint!
  update_columns: [achievement_property_value_update_column!]!
  where: achievement_property_value_bool_exp
}

# ordering options when selecting data from "achievement_property_value"
input achievement_property_value_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  dateValue: order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  idValues: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  property: achievement_property_order_by
  propertyMtid: order_by
  publication: publication_order_by
  publicationMtid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  stringValue: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "achievement_property_value"
input achievement_property_value_pk_columns_input {
  mtid: bigint!
}

# select columns of table "achievement_property_value"
enum achievement_property_value_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dateValue

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  idValues

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  newIdValue

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  propertyMtid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  stringValue

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "achievement_property_value"
input achievement_property_value_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dateValue: timestamp
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: Int
  idValues: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  newIdValue: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  propertyMtid: bigint
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type achievement_property_value_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  idValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  newIdValue: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "achievement_property_value"
input achievement_property_value_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type achievement_property_value_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  idValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  newIdValue: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "achievement_property_value"
input achievement_property_value_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type achievement_property_value_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  idValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  newIdValue: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "achievement_property_value"
input achievement_property_value_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type achievement_property_value_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  idValue: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  newIdValue: bigint
  oldId: Int
  prevValid: bigint
  propertyMtid: bigint
  publicationMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "achievement_property_value"
input achievement_property_value_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "achievement_property_value"
enum achievement_property_value_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dateValue

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  idValues

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  newIdValue

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  propertyMtid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  stringValue

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type achievement_property_value_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  idValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  newIdValue: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "achievement_property_value"
input achievement_property_value_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type achievement_property_value_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  idValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  newIdValue: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "achievement_property_value"
input achievement_property_value_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type achievement_property_value_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  idValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  newIdValue: Float
  oldId: Float
  prevValid: Float
  propertyMtid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "achievement_property_value"
input achievement_property_value_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  idValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  newIdValue: order_by
  oldId: order_by
  prevValid: order_by
  propertyMtid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_pop on columns
type achievement_property_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "achievement_property"
input achievement_property_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type achievement_property_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "achievement_property"
input achievement_property_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type achievement_property_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "achievement_property"
input achievement_property_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "activity_log"
type activity_log {
  fieldsChanged: String
  id: bigint!
  inetAddress: String
  json: String
  mtid: bigint
  objectType: String
  operation: Int
  request: String
  supervisor: String
  switchedUserid: bigint
  timestamp: timestamp
  userid: bigint
  username: String
}

# aggregated selection of "activity_log"
type activity_log_aggregate {
  aggregate: activity_log_aggregate_fields
  nodes: [activity_log!]!
}

# aggregate fields of "activity_log"
type activity_log_aggregate_fields {
  avg: activity_log_avg_fields
  count(columns: [activity_log_select_column!], distinct: Boolean): Int
  max: activity_log_max_fields
  min: activity_log_min_fields
  stddev: activity_log_stddev_fields
  stddev_pop: activity_log_stddev_pop_fields
  stddev_samp: activity_log_stddev_samp_fields
  sum: activity_log_sum_fields
  var_pop: activity_log_var_pop_fields
  var_samp: activity_log_var_samp_fields
  variance: activity_log_variance_fields
}

# order by aggregate values of table "activity_log"
input activity_log_aggregate_order_by {
  avg: activity_log_avg_order_by
  count: order_by
  max: activity_log_max_order_by
  min: activity_log_min_order_by
  stddev: activity_log_stddev_order_by
  stddev_pop: activity_log_stddev_pop_order_by
  stddev_samp: activity_log_stddev_samp_order_by
  sum: activity_log_sum_order_by
  var_pop: activity_log_var_pop_order_by
  var_samp: activity_log_var_samp_order_by
  variance: activity_log_variance_order_by
}

# input type for inserting array relation for remote table "activity_log"
input activity_log_arr_rel_insert_input {
  data: [activity_log_insert_input!]!
  on_conflict: activity_log_on_conflict
}

# aggregate avg on columns
type activity_log_avg_fields {
  id: Float
  mtid: Float
  operation: Float
  switchedUserid: Float
  userid: Float
}

# order by avg() on columns of table "activity_log"
input activity_log_avg_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# Boolean expression to filter rows from the table "activity_log". All fields are combined with a logical 'AND'.
input activity_log_bool_exp {
  _and: [activity_log_bool_exp]
  _not: activity_log_bool_exp
  _or: [activity_log_bool_exp]
  fieldsChanged: String_comparison_exp
  id: bigint_comparison_exp
  inetAddress: String_comparison_exp
  json: String_comparison_exp
  mtid: bigint_comparison_exp
  objectType: String_comparison_exp
  operation: Int_comparison_exp
  request: String_comparison_exp
  supervisor: String_comparison_exp
  switchedUserid: bigint_comparison_exp
  timestamp: timestamp_comparison_exp
  userid: bigint_comparison_exp
  username: String_comparison_exp
}

# unique or primary key constraints on table "activity_log"
enum activity_log_constraint {
  # unique or primary key constraint
  activity_log_pkey
}

# input type for incrementing integer column in table "activity_log"
input activity_log_inc_input {
  id: bigint
  mtid: bigint
  operation: Int
  switchedUserid: bigint
  userid: bigint
}

# input type for inserting data into table "activity_log"
input activity_log_insert_input {
  fieldsChanged: String
  id: bigint
  inetAddress: String
  json: String
  mtid: bigint
  objectType: String
  operation: Int
  request: String
  supervisor: String
  switchedUserid: bigint
  timestamp: timestamp
  userid: bigint
  username: String
}

# aggregate max on columns
type activity_log_max_fields {
  fieldsChanged: String
  id: bigint
  inetAddress: String
  json: String
  mtid: bigint
  objectType: String
  operation: Int
  request: String
  supervisor: String
  switchedUserid: bigint
  timestamp: timestamp
  userid: bigint
  username: String
}

# order by max() on columns of table "activity_log"
input activity_log_max_order_by {
  fieldsChanged: order_by
  id: order_by
  inetAddress: order_by
  json: order_by
  mtid: order_by
  objectType: order_by
  operation: order_by
  request: order_by
  supervisor: order_by
  switchedUserid: order_by
  timestamp: order_by
  userid: order_by
  username: order_by
}

# aggregate min on columns
type activity_log_min_fields {
  fieldsChanged: String
  id: bigint
  inetAddress: String
  json: String
  mtid: bigint
  objectType: String
  operation: Int
  request: String
  supervisor: String
  switchedUserid: bigint
  timestamp: timestamp
  userid: bigint
  username: String
}

# order by min() on columns of table "activity_log"
input activity_log_min_order_by {
  fieldsChanged: order_by
  id: order_by
  inetAddress: order_by
  json: order_by
  mtid: order_by
  objectType: order_by
  operation: order_by
  request: order_by
  supervisor: order_by
  switchedUserid: order_by
  timestamp: order_by
  userid: order_by
  username: order_by
}

# response of any mutation on the table "activity_log"
type activity_log_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [activity_log!]!
}

# input type for inserting object relation for remote table "activity_log"
input activity_log_obj_rel_insert_input {
  data: activity_log_insert_input!
  on_conflict: activity_log_on_conflict
}

# on conflict condition type for table "activity_log"
input activity_log_on_conflict {
  constraint: activity_log_constraint!
  update_columns: [activity_log_update_column!]!
  where: activity_log_bool_exp
}

# ordering options when selecting data from "activity_log"
input activity_log_order_by {
  fieldsChanged: order_by
  id: order_by
  inetAddress: order_by
  json: order_by
  mtid: order_by
  objectType: order_by
  operation: order_by
  request: order_by
  supervisor: order_by
  switchedUserid: order_by
  timestamp: order_by
  userid: order_by
  username: order_by
}

# primary key columns input for table: "activity_log"
input activity_log_pk_columns_input {
  id: bigint!
}

# select columns of table "activity_log"
enum activity_log_select_column {
  # column name
  fieldsChanged

  # column name
  id

  # column name
  inetAddress

  # column name
  json

  # column name
  mtid

  # column name
  objectType

  # column name
  operation

  # column name
  request

  # column name
  supervisor

  # column name
  switchedUserid

  # column name
  timestamp

  # column name
  userid

  # column name
  username
}

# input type for updating data in table "activity_log"
input activity_log_set_input {
  fieldsChanged: String
  id: bigint
  inetAddress: String
  json: String
  mtid: bigint
  objectType: String
  operation: Int
  request: String
  supervisor: String
  switchedUserid: bigint
  timestamp: timestamp
  userid: bigint
  username: String
}

# aggregate stddev on columns
type activity_log_stddev_fields {
  id: Float
  mtid: Float
  operation: Float
  switchedUserid: Float
  userid: Float
}

# order by stddev() on columns of table "activity_log"
input activity_log_stddev_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# aggregate stddev_pop on columns
type activity_log_stddev_pop_fields {
  id: Float
  mtid: Float
  operation: Float
  switchedUserid: Float
  userid: Float
}

# order by stddev_pop() on columns of table "activity_log"
input activity_log_stddev_pop_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# aggregate stddev_samp on columns
type activity_log_stddev_samp_fields {
  id: Float
  mtid: Float
  operation: Float
  switchedUserid: Float
  userid: Float
}

# order by stddev_samp() on columns of table "activity_log"
input activity_log_stddev_samp_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# aggregate sum on columns
type activity_log_sum_fields {
  id: bigint
  mtid: bigint
  operation: Int
  switchedUserid: bigint
  userid: bigint
}

# order by sum() on columns of table "activity_log"
input activity_log_sum_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# update columns of table "activity_log"
enum activity_log_update_column {
  # column name
  fieldsChanged

  # column name
  id

  # column name
  inetAddress

  # column name
  json

  # column name
  mtid

  # column name
  objectType

  # column name
  operation

  # column name
  request

  # column name
  supervisor

  # column name
  switchedUserid

  # column name
  timestamp

  # column name
  userid

  # column name
  username
}

# aggregate var_pop on columns
type activity_log_var_pop_fields {
  id: Float
  mtid: Float
  operation: Float
  switchedUserid: Float
  userid: Float
}

# order by var_pop() on columns of table "activity_log"
input activity_log_var_pop_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# aggregate var_samp on columns
type activity_log_var_samp_fields {
  id: Float
  mtid: Float
  operation: Float
  switchedUserid: Float
  userid: Float
}

# order by var_samp() on columns of table "activity_log"
input activity_log_var_samp_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# aggregate variance on columns
type activity_log_variance_fields {
  id: Float
  mtid: Float
  operation: Float
  switchedUserid: Float
  userid: Float
}

# order by variance() on columns of table "activity_log"
input activity_log_variance_order_by {
  id: order_by
  mtid: order_by
  operation: order_by
  switchedUserid: order_by
  userid: order_by
}

# columns and relationships of "address"
type address {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  city: location
  cityMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp

  # An object relationship
  organization: organization
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  streetAndNumber: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  zipCode: String
}

# aggregated selection of "address"
type address_aggregate {
  aggregate: address_aggregate_fields
  nodes: [address!]!
}

# aggregate fields of "address"
type address_aggregate_fields {
  avg: address_avg_fields
  count(columns: [address_select_column!], distinct: Boolean): Int
  max: address_max_fields
  min: address_min_fields
  stddev: address_stddev_fields
  stddev_pop: address_stddev_pop_fields
  stddev_samp: address_stddev_samp_fields
  sum: address_sum_fields
  var_pop: address_var_pop_fields
  var_samp: address_var_samp_fields
  variance: address_variance_fields
}

# order by aggregate values of table "address"
input address_aggregate_order_by {
  avg: address_avg_order_by
  count: order_by
  max: address_max_order_by
  min: address_min_order_by
  stddev: address_stddev_order_by
  stddev_pop: address_stddev_pop_order_by
  stddev_samp: address_stddev_samp_order_by
  sum: address_sum_order_by
  var_pop: address_var_pop_order_by
  var_samp: address_var_samp_order_by
  variance: address_variance_order_by
}

# input type for inserting array relation for remote table "address"
input address_arr_rel_insert_input {
  data: [address_insert_input!]!
  on_conflict: address_on_conflict
}

# aggregate avg on columns
type address_avg_fields {
  approverMtid: Float
  cityMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "address"
input address_avg_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "address". All fields are combined with a logical 'AND'.
input address_bool_exp {
  _and: [address_bool_exp]
  _not: address_bool_exp
  _or: [address_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  city: location_bool_exp
  cityMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  organization: organization_bool_exp
  organizationMtid: bigint_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  streetAndNumber: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  zipCode: String_comparison_exp
}

# unique or primary key constraints on table "address"
enum address_constraint {
  # unique or primary key constraint
  address_pkey
}

# input type for incrementing integer column in table "address"
input address_inc_input {
  approverMtid: bigint
  cityMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  organizationMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "address"
input address_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  city: location_obj_rel_insert_input
  cityMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organization: organization_obj_rel_insert_input
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  streetAndNumber: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  zipCode: String
}

# aggregate max on columns
type address_max_fields {
  approved: timestamp
  approverMtid: bigint
  cityMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  status: Int
  streetAndNumber: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  zipCode: String
}

# order by max() on columns of table "address"
input address_max_order_by {
  approved: order_by
  approverMtid: order_by
  cityMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  streetAndNumber: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  zipCode: order_by
}

# aggregate min on columns
type address_min_fields {
  approved: timestamp
  approverMtid: bigint
  cityMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  status: Int
  streetAndNumber: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  zipCode: String
}

# order by min() on columns of table "address"
input address_min_order_by {
  approved: order_by
  approverMtid: order_by
  cityMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  streetAndNumber: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  zipCode: order_by
}

# response of any mutation on the table "address"
type address_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [address!]!
}

# input type for inserting object relation for remote table "address"
input address_obj_rel_insert_input {
  data: address_insert_input!
  on_conflict: address_on_conflict
}

# on conflict condition type for table "address"
input address_on_conflict {
  constraint: address_constraint!
  update_columns: [address_update_column!]!
  where: address_bool_exp
}

# ordering options when selecting data from "address"
input address_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  city: location_order_by
  cityMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  organization: organization_order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  streetAndNumber: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  zipCode: order_by
}

# primary key columns input for table: "address"
input address_pk_columns_input {
  mtid: bigint!
}

# select columns of table "address"
enum address_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  cityMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  organizationMtid

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  streetAndNumber

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  zipCode
}

# input type for updating data in table "address"
input address_set_input {
  approved: timestamp
  approverMtid: bigint
  cityMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  streetAndNumber: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  zipCode: String
}

# aggregate stddev on columns
type address_stddev_fields {
  approverMtid: Float
  cityMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "address"
input address_stddev_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type address_stddev_pop_fields {
  approverMtid: Float
  cityMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "address"
input address_stddev_pop_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type address_stddev_samp_fields {
  approverMtid: Float
  cityMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "address"
input address_stddev_samp_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type address_sum_fields {
  approverMtid: bigint
  cityMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  organizationMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "address"
input address_sum_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "address"
enum address_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  cityMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  organizationMtid

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  streetAndNumber

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  zipCode
}

# aggregate var_pop on columns
type address_var_pop_fields {
  approverMtid: Float
  cityMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "address"
input address_var_pop_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type address_var_samp_fields {
  approverMtid: Float
  cityMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "address"
input address_var_samp_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type address_variance_fields {
  approverMtid: Float
  cityMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "address"
input address_variance_order_by {
  approverMtid: order_by
  cityMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "admin_role"
type admin_role {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  endDate: date
  error: Int
  handledObjectType: String

  # An object relationship
  institute: organization
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passive: Boolean!
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  rights: String
  roleType: Int
  startDate: date
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!

  # An object relationship
  user: users
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "admin_role"
type admin_role_aggregate {
  aggregate: admin_role_aggregate_fields
  nodes: [admin_role!]!
}

# aggregate fields of "admin_role"
type admin_role_aggregate_fields {
  avg: admin_role_avg_fields
  count(columns: [admin_role_select_column!], distinct: Boolean): Int
  max: admin_role_max_fields
  min: admin_role_min_fields
  stddev: admin_role_stddev_fields
  stddev_pop: admin_role_stddev_pop_fields
  stddev_samp: admin_role_stddev_samp_fields
  sum: admin_role_sum_fields
  var_pop: admin_role_var_pop_fields
  var_samp: admin_role_var_samp_fields
  variance: admin_role_variance_fields
}

# order by aggregate values of table "admin_role"
input admin_role_aggregate_order_by {
  avg: admin_role_avg_order_by
  count: order_by
  max: admin_role_max_order_by
  min: admin_role_min_order_by
  stddev: admin_role_stddev_order_by
  stddev_pop: admin_role_stddev_pop_order_by
  stddev_samp: admin_role_stddev_samp_order_by
  sum: admin_role_sum_order_by
  var_pop: admin_role_var_pop_order_by
  var_samp: admin_role_var_samp_order_by
  variance: admin_role_variance_order_by
}

# input type for inserting array relation for remote table "admin_role"
input admin_role_arr_rel_insert_input {
  data: [admin_role_insert_input!]!
  on_conflict: admin_role_on_conflict
}

# aggregate avg on columns
type admin_role_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  roleType: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "admin_role"
input admin_role_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "admin_role". All fields are combined with a logical 'AND'.
input admin_role_bool_exp {
  _and: [admin_role_bool_exp]
  _not: admin_role_bool_exp
  _or: [admin_role_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  endDate: date_comparison_exp
  error: Int_comparison_exp
  handledObjectType: String_comparison_exp
  institute: organization_bool_exp
  instituteMtid: bigint_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  passive: Boolean_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  rights: String_comparison_exp
  roleType: Int_comparison_exp
  startDate: date_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  user: users_bool_exp
  userMtid: bigint_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "admin_role"
enum admin_role_constraint {
  # unique or primary key constraint
  admin_role_pkey
}

# input type for incrementing integer column in table "admin_role"
input admin_role_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  roleType: Int
  status: Int
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "admin_role"
input admin_role_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  endDate: date
  error: Int
  handledObjectType: String
  institute: organization_obj_rel_insert_input
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passive: Boolean
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  rights: String
  roleType: Int
  startDate: date
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  user: users_obj_rel_insert_input
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type admin_role_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: date
  error: Int
  handledObjectType: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  rights: String
  roleType: Int
  startDate: date
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "admin_role"
input admin_role_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  handledObjectType: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  rights: order_by
  roleType: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type admin_role_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: date
  error: Int
  handledObjectType: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  rights: String
  roleType: Int
  startDate: date
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "admin_role"
input admin_role_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  handledObjectType: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  rights: order_by
  roleType: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "admin_role"
type admin_role_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [admin_role!]!
}

# input type for inserting object relation for remote table "admin_role"
input admin_role_obj_rel_insert_input {
  data: admin_role_insert_input!
  on_conflict: admin_role_on_conflict
}

# on conflict condition type for table "admin_role"
input admin_role_on_conflict {
  constraint: admin_role_constraint!
  update_columns: [admin_role_update_column!]!
  where: admin_role_bool_exp
}

# ordering options when selecting data from "admin_role"
input admin_role_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  handledObjectType: order_by
  institute: organization_order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  passive: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  rights: order_by
  roleType: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  user: users_order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "admin_role"
input admin_role_pk_columns_input {
  mtid: bigint!
}

# select columns of table "admin_role"
enum admin_role_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  handledObjectType

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  passive

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  rights

  # column name
  roleType

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  userMtid

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "admin_role"
input admin_role_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  endDate: date
  error: Int
  handledObjectType: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passive: Boolean
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  rights: String
  roleType: Int
  startDate: date
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type admin_role_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  roleType: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "admin_role"
input admin_role_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type admin_role_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  roleType: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "admin_role"
input admin_role_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type admin_role_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  roleType: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "admin_role"
input admin_role_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type admin_role_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  roleType: Int
  status: Int
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "admin_role"
input admin_role_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "admin_role"
enum admin_role_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  handledObjectType

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  passive

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  rights

  # column name
  roleType

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  userMtid

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type admin_role_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  roleType: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "admin_role"
input admin_role_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type admin_role_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  roleType: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "admin_role"
input admin_role_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type admin_role_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  roleType: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "admin_role"
input admin_role_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  roleType: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "affiliation"
type affiliation {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  author: users
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint

  # An object relationship
  worksFor: organization
  worksForMtid: bigint
}

# aggregated selection of "affiliation"
type affiliation_aggregate {
  aggregate: affiliation_aggregate_fields
  nodes: [affiliation!]!
}

# aggregate fields of "affiliation"
type affiliation_aggregate_fields {
  avg: affiliation_avg_fields
  count(columns: [affiliation_select_column!], distinct: Boolean): Int
  max: affiliation_max_fields
  min: affiliation_min_fields
  stddev: affiliation_stddev_fields
  stddev_pop: affiliation_stddev_pop_fields
  stddev_samp: affiliation_stddev_samp_fields
  sum: affiliation_sum_fields
  var_pop: affiliation_var_pop_fields
  var_samp: affiliation_var_samp_fields
  variance: affiliation_variance_fields
}

# order by aggregate values of table "affiliation"
input affiliation_aggregate_order_by {
  avg: affiliation_avg_order_by
  count: order_by
  max: affiliation_max_order_by
  min: affiliation_min_order_by
  stddev: affiliation_stddev_order_by
  stddev_pop: affiliation_stddev_pop_order_by
  stddev_samp: affiliation_stddev_samp_order_by
  sum: affiliation_sum_order_by
  var_pop: affiliation_var_pop_order_by
  var_samp: affiliation_var_samp_order_by
  variance: affiliation_variance_order_by
}

# input type for inserting array relation for remote table "affiliation"
input affiliation_arr_rel_insert_input {
  data: [affiliation_insert_input!]!
  on_conflict: affiliation_on_conflict
}

# aggregate avg on columns
type affiliation_avg_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  worksForMtid: Float
}

# order by avg() on columns of table "affiliation"
input affiliation_avg_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# Boolean expression to filter rows from the table "affiliation". All fields are combined with a logical 'AND'.
input affiliation_bool_exp {
  _and: [affiliation_bool_exp]
  _not: affiliation_bool_exp
  _or: [affiliation_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  author: users_bool_exp
  authorMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  endDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  startDate: timestamp_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  worksFor: organization_bool_exp
  worksForMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "affiliation"
enum affiliation_constraint {
  # unique or primary key constraint
  affiliation_pkey
}

# input type for incrementing integer column in table "affiliation"
input affiliation_inc_input {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  worksForMtid: bigint
}

# input type for inserting data into table "affiliation"
input affiliation_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  author: users_obj_rel_insert_input
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  worksFor: organization_obj_rel_insert_input
  worksForMtid: bigint
}

# aggregate max on columns
type affiliation_max_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  worksForMtid: bigint
}

# order by max() on columns of table "affiliation"
input affiliation_max_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# aggregate min on columns
type affiliation_min_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  worksForMtid: bigint
}

# order by min() on columns of table "affiliation"
input affiliation_min_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# response of any mutation on the table "affiliation"
type affiliation_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [affiliation!]!
}

# input type for inserting object relation for remote table "affiliation"
input affiliation_obj_rel_insert_input {
  data: affiliation_insert_input!
  on_conflict: affiliation_on_conflict
}

# on conflict condition type for table "affiliation"
input affiliation_on_conflict {
  constraint: affiliation_constraint!
  update_columns: [affiliation_update_column!]!
  where: affiliation_bool_exp
}

# ordering options when selecting data from "affiliation"
input affiliation_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  author: users_order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksFor: organization_order_by
  worksForMtid: order_by
}

# primary key columns input for table: "affiliation"
input affiliation_pk_columns_input {
  mtid: bigint!
}

# select columns of table "affiliation"
enum affiliation_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  worksForMtid
}

# input type for updating data in table "affiliation"
input affiliation_set_input {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  worksForMtid: bigint
}

# aggregate stddev on columns
type affiliation_stddev_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  worksForMtid: Float
}

# order by stddev() on columns of table "affiliation"
input affiliation_stddev_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# aggregate stddev_pop on columns
type affiliation_stddev_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  worksForMtid: Float
}

# order by stddev_pop() on columns of table "affiliation"
input affiliation_stddev_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# aggregate stddev_samp on columns
type affiliation_stddev_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  worksForMtid: Float
}

# order by stddev_samp() on columns of table "affiliation"
input affiliation_stddev_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# aggregate sum on columns
type affiliation_sum_fields {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  worksForMtid: bigint
}

# order by sum() on columns of table "affiliation"
input affiliation_sum_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# update columns of table "affiliation"
enum affiliation_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  worksForMtid
}

# aggregate var_pop on columns
type affiliation_var_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  worksForMtid: Float
}

# order by var_pop() on columns of table "affiliation"
input affiliation_var_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# aggregate var_samp on columns
type affiliation_var_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  worksForMtid: Float
}

# order by var_samp() on columns of table "affiliation"
input affiliation_var_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# aggregate variance on columns
type affiliation_variance_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  worksForMtid: Float
}

# order by variance() on columns of table "affiliation"
input affiliation_variance_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  worksForMtid: order_by
}

# columns and relationships of "appearance"
type appearance {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "appearance"
type appearance_aggregate {
  aggregate: appearance_aggregate_fields
  nodes: [appearance!]!
}

# aggregate fields of "appearance"
type appearance_aggregate_fields {
  avg: appearance_avg_fields
  count(columns: [appearance_select_column!], distinct: Boolean): Int
  max: appearance_max_fields
  min: appearance_min_fields
  stddev: appearance_stddev_fields
  stddev_pop: appearance_stddev_pop_fields
  stddev_samp: appearance_stddev_samp_fields
  sum: appearance_sum_fields
  var_pop: appearance_var_pop_fields
  var_samp: appearance_var_samp_fields
  variance: appearance_variance_fields
}

# order by aggregate values of table "appearance"
input appearance_aggregate_order_by {
  avg: appearance_avg_order_by
  count: order_by
  max: appearance_max_order_by
  min: appearance_min_order_by
  stddev: appearance_stddev_order_by
  stddev_pop: appearance_stddev_pop_order_by
  stddev_samp: appearance_stddev_samp_order_by
  sum: appearance_sum_order_by
  var_pop: appearance_var_pop_order_by
  var_samp: appearance_var_samp_order_by
  variance: appearance_variance_order_by
}

# input type for inserting array relation for remote table "appearance"
input appearance_arr_rel_insert_input {
  data: [appearance_insert_input!]!
  on_conflict: appearance_on_conflict
}

# aggregate avg on columns
type appearance_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "appearance"
input appearance_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "appearance". All fields are combined with a logical 'AND'.
input appearance_bool_exp {
  _and: [appearance_bool_exp]
  _not: appearance_bool_exp
  _or: [appearance_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "appearance"
enum appearance_constraint {
  # unique or primary key constraint
  appearance_pkey
}

# input type for incrementing integer column in table "appearance"
input appearance_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "appearance"
input appearance_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type appearance_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "appearance"
input appearance_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type appearance_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "appearance"
input appearance_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "appearance"
type appearance_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [appearance!]!
}

# input type for inserting object relation for remote table "appearance"
input appearance_obj_rel_insert_input {
  data: appearance_insert_input!
  on_conflict: appearance_on_conflict
}

# on conflict condition type for table "appearance"
input appearance_on_conflict {
  constraint: appearance_constraint!
  update_columns: [appearance_update_column!]!
  where: appearance_bool_exp
}

# ordering options when selecting data from "appearance"
input appearance_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "appearance"
input appearance_pk_columns_input {
  mtid: bigint!
}

# select columns of table "appearance"
enum appearance_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "appearance"
input appearance_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type appearance_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "appearance"
input appearance_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type appearance_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "appearance"
input appearance_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type appearance_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "appearance"
input appearance_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type appearance_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "appearance"
input appearance_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "appearance"
enum appearance_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type appearance_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "appearance"
input appearance_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type appearance_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "appearance"
input appearance_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type appearance_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "appearance"
input appearance_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "authentication_failure"
type authentication_failure {
  firstTry: timestamp
  id: bigint!
  inetAddress: String
  lastTry: timestamp
  lockedOutUntil: timestamp
  tries: Int!
  username: String
}

# aggregated selection of "authentication_failure"
type authentication_failure_aggregate {
  aggregate: authentication_failure_aggregate_fields
  nodes: [authentication_failure!]!
}

# aggregate fields of "authentication_failure"
type authentication_failure_aggregate_fields {
  avg: authentication_failure_avg_fields
  count(columns: [authentication_failure_select_column!], distinct: Boolean): Int
  max: authentication_failure_max_fields
  min: authentication_failure_min_fields
  stddev: authentication_failure_stddev_fields
  stddev_pop: authentication_failure_stddev_pop_fields
  stddev_samp: authentication_failure_stddev_samp_fields
  sum: authentication_failure_sum_fields
  var_pop: authentication_failure_var_pop_fields
  var_samp: authentication_failure_var_samp_fields
  variance: authentication_failure_variance_fields
}

# order by aggregate values of table "authentication_failure"
input authentication_failure_aggregate_order_by {
  avg: authentication_failure_avg_order_by
  count: order_by
  max: authentication_failure_max_order_by
  min: authentication_failure_min_order_by
  stddev: authentication_failure_stddev_order_by
  stddev_pop: authentication_failure_stddev_pop_order_by
  stddev_samp: authentication_failure_stddev_samp_order_by
  sum: authentication_failure_sum_order_by
  var_pop: authentication_failure_var_pop_order_by
  var_samp: authentication_failure_var_samp_order_by
  variance: authentication_failure_variance_order_by
}

# input type for inserting array relation for remote table "authentication_failure"
input authentication_failure_arr_rel_insert_input {
  data: [authentication_failure_insert_input!]!
  on_conflict: authentication_failure_on_conflict
}

# aggregate avg on columns
type authentication_failure_avg_fields {
  id: Float
  tries: Float
}

# order by avg() on columns of table "authentication_failure"
input authentication_failure_avg_order_by {
  id: order_by
  tries: order_by
}

# Boolean expression to filter rows from the table "authentication_failure". All fields are combined with a logical 'AND'.
input authentication_failure_bool_exp {
  _and: [authentication_failure_bool_exp]
  _not: authentication_failure_bool_exp
  _or: [authentication_failure_bool_exp]
  firstTry: timestamp_comparison_exp
  id: bigint_comparison_exp
  inetAddress: String_comparison_exp
  lastTry: timestamp_comparison_exp
  lockedOutUntil: timestamp_comparison_exp
  tries: Int_comparison_exp
  username: String_comparison_exp
}

# unique or primary key constraints on table "authentication_failure"
enum authentication_failure_constraint {
  # unique or primary key constraint
  authentication_failure_pkey
}

# input type for incrementing integer column in table "authentication_failure"
input authentication_failure_inc_input {
  id: bigint
  tries: Int
}

# input type for inserting data into table "authentication_failure"
input authentication_failure_insert_input {
  firstTry: timestamp
  id: bigint
  inetAddress: String
  lastTry: timestamp
  lockedOutUntil: timestamp
  tries: Int
  username: String
}

# aggregate max on columns
type authentication_failure_max_fields {
  firstTry: timestamp
  id: bigint
  inetAddress: String
  lastTry: timestamp
  lockedOutUntil: timestamp
  tries: Int
  username: String
}

# order by max() on columns of table "authentication_failure"
input authentication_failure_max_order_by {
  firstTry: order_by
  id: order_by
  inetAddress: order_by
  lastTry: order_by
  lockedOutUntil: order_by
  tries: order_by
  username: order_by
}

# aggregate min on columns
type authentication_failure_min_fields {
  firstTry: timestamp
  id: bigint
  inetAddress: String
  lastTry: timestamp
  lockedOutUntil: timestamp
  tries: Int
  username: String
}

# order by min() on columns of table "authentication_failure"
input authentication_failure_min_order_by {
  firstTry: order_by
  id: order_by
  inetAddress: order_by
  lastTry: order_by
  lockedOutUntil: order_by
  tries: order_by
  username: order_by
}

# response of any mutation on the table "authentication_failure"
type authentication_failure_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [authentication_failure!]!
}

# input type for inserting object relation for remote table "authentication_failure"
input authentication_failure_obj_rel_insert_input {
  data: authentication_failure_insert_input!
  on_conflict: authentication_failure_on_conflict
}

# on conflict condition type for table "authentication_failure"
input authentication_failure_on_conflict {
  constraint: authentication_failure_constraint!
  update_columns: [authentication_failure_update_column!]!
  where: authentication_failure_bool_exp
}

# ordering options when selecting data from "authentication_failure"
input authentication_failure_order_by {
  firstTry: order_by
  id: order_by
  inetAddress: order_by
  lastTry: order_by
  lockedOutUntil: order_by
  tries: order_by
  username: order_by
}

# primary key columns input for table: "authentication_failure"
input authentication_failure_pk_columns_input {
  id: bigint!
}

# select columns of table "authentication_failure"
enum authentication_failure_select_column {
  # column name
  firstTry

  # column name
  id

  # column name
  inetAddress

  # column name
  lastTry

  # column name
  lockedOutUntil

  # column name
  tries

  # column name
  username
}

# input type for updating data in table "authentication_failure"
input authentication_failure_set_input {
  firstTry: timestamp
  id: bigint
  inetAddress: String
  lastTry: timestamp
  lockedOutUntil: timestamp
  tries: Int
  username: String
}

# aggregate stddev on columns
type authentication_failure_stddev_fields {
  id: Float
  tries: Float
}

# order by stddev() on columns of table "authentication_failure"
input authentication_failure_stddev_order_by {
  id: order_by
  tries: order_by
}

# aggregate stddev_pop on columns
type authentication_failure_stddev_pop_fields {
  id: Float
  tries: Float
}

# order by stddev_pop() on columns of table "authentication_failure"
input authentication_failure_stddev_pop_order_by {
  id: order_by
  tries: order_by
}

# aggregate stddev_samp on columns
type authentication_failure_stddev_samp_fields {
  id: Float
  tries: Float
}

# order by stddev_samp() on columns of table "authentication_failure"
input authentication_failure_stddev_samp_order_by {
  id: order_by
  tries: order_by
}

# aggregate sum on columns
type authentication_failure_sum_fields {
  id: bigint
  tries: Int
}

# order by sum() on columns of table "authentication_failure"
input authentication_failure_sum_order_by {
  id: order_by
  tries: order_by
}

# update columns of table "authentication_failure"
enum authentication_failure_update_column {
  # column name
  firstTry

  # column name
  id

  # column name
  inetAddress

  # column name
  lastTry

  # column name
  lockedOutUntil

  # column name
  tries

  # column name
  username
}

# aggregate var_pop on columns
type authentication_failure_var_pop_fields {
  id: Float
  tries: Float
}

# order by var_pop() on columns of table "authentication_failure"
input authentication_failure_var_pop_order_by {
  id: order_by
  tries: order_by
}

# aggregate var_samp on columns
type authentication_failure_var_samp_fields {
  id: Float
  tries: Float
}

# order by var_samp() on columns of table "authentication_failure"
input authentication_failure_var_samp_order_by {
  id: order_by
  tries: order_by
}

# aggregate variance on columns
type authentication_failure_variance_fields {
  id: Float
  tries: Float
}

# order by variance() on columns of table "authentication_failure"
input authentication_failure_variance_order_by {
  id: order_by
  tries: order_by
}

# columns and relationships of "author_identifier"
type author_identifier {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  author: users
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  source: source
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "author_identifier"
type author_identifier_aggregate {
  aggregate: author_identifier_aggregate_fields
  nodes: [author_identifier!]!
}

# aggregate fields of "author_identifier"
type author_identifier_aggregate_fields {
  avg: author_identifier_avg_fields
  count(columns: [author_identifier_select_column!], distinct: Boolean): Int
  max: author_identifier_max_fields
  min: author_identifier_min_fields
  stddev: author_identifier_stddev_fields
  stddev_pop: author_identifier_stddev_pop_fields
  stddev_samp: author_identifier_stddev_samp_fields
  sum: author_identifier_sum_fields
  var_pop: author_identifier_var_pop_fields
  var_samp: author_identifier_var_samp_fields
  variance: author_identifier_variance_fields
}

# order by aggregate values of table "author_identifier"
input author_identifier_aggregate_order_by {
  avg: author_identifier_avg_order_by
  count: order_by
  max: author_identifier_max_order_by
  min: author_identifier_min_order_by
  stddev: author_identifier_stddev_order_by
  stddev_pop: author_identifier_stddev_pop_order_by
  stddev_samp: author_identifier_stddev_samp_order_by
  sum: author_identifier_sum_order_by
  var_pop: author_identifier_var_pop_order_by
  var_samp: author_identifier_var_samp_order_by
  variance: author_identifier_variance_order_by
}

# input type for inserting array relation for remote table "author_identifier"
input author_identifier_arr_rel_insert_input {
  data: [author_identifier_insert_input!]!
  on_conflict: author_identifier_on_conflict
}

# aggregate avg on columns
type author_identifier_avg_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "author_identifier"
input author_identifier_avg_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "author_identifier". All fields are combined with a logical 'AND'.
input author_identifier_bool_exp {
  _and: [author_identifier_bool_exp]
  _not: author_identifier_bool_exp
  _or: [author_identifier_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  author: users_bool_exp
  authorMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  idValue: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  source: source_bool_exp
  sourceMtid: bigint_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "author_identifier"
enum author_identifier_constraint {
  # unique or primary key constraint
  author_identifier_pkey
}

# input type for incrementing integer column in table "author_identifier"
input author_identifier_inc_input {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "author_identifier"
input author_identifier_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  author: users_obj_rel_insert_input
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  source: source_obj_rel_insert_input
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type author_identifier_max_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "author_identifier"
input author_identifier_max_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type author_identifier_min_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "author_identifier"
input author_identifier_min_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "author_identifier"
type author_identifier_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [author_identifier!]!
}

# input type for inserting object relation for remote table "author_identifier"
input author_identifier_obj_rel_insert_input {
  data: author_identifier_insert_input!
  on_conflict: author_identifier_on_conflict
}

# on conflict condition type for table "author_identifier"
input author_identifier_on_conflict {
  constraint: author_identifier_constraint!
  update_columns: [author_identifier_update_column!]!
  where: author_identifier_bool_exp
}

# ordering options when selecting data from "author_identifier"
input author_identifier_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  author: users_order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  source: source_order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "author_identifier"
input author_identifier_pk_columns_input {
  mtid: bigint!
}

# select columns of table "author_identifier"
enum author_identifier_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "author_identifier"
input author_identifier_set_input {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type author_identifier_stddev_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "author_identifier"
input author_identifier_stddev_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type author_identifier_stddev_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "author_identifier"
input author_identifier_stddev_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type author_identifier_stddev_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "author_identifier"
input author_identifier_stddev_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type author_identifier_sum_fields {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "author_identifier"
input author_identifier_sum_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "author_identifier"
enum author_identifier_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type author_identifier_var_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "author_identifier"
input author_identifier_var_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type author_identifier_var_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "author_identifier"
input author_identifier_var_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type author_identifier_variance_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "author_identifier"
input author_identifier_variance_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "author_name"
type author_name {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  author: users
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  familyName: String
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "author_name"
type author_name_aggregate {
  aggregate: author_name_aggregate_fields
  nodes: [author_name!]!
}

# aggregate fields of "author_name"
type author_name_aggregate_fields {
  avg: author_name_avg_fields
  count(columns: [author_name_select_column!], distinct: Boolean): Int
  max: author_name_max_fields
  min: author_name_min_fields
  stddev: author_name_stddev_fields
  stddev_pop: author_name_stddev_pop_fields
  stddev_samp: author_name_stddev_samp_fields
  sum: author_name_sum_fields
  var_pop: author_name_var_pop_fields
  var_samp: author_name_var_samp_fields
  variance: author_name_variance_fields
}

# order by aggregate values of table "author_name"
input author_name_aggregate_order_by {
  avg: author_name_avg_order_by
  count: order_by
  max: author_name_max_order_by
  min: author_name_min_order_by
  stddev: author_name_stddev_order_by
  stddev_pop: author_name_stddev_pop_order_by
  stddev_samp: author_name_stddev_samp_order_by
  sum: author_name_sum_order_by
  var_pop: author_name_var_pop_order_by
  var_samp: author_name_var_samp_order_by
  variance: author_name_variance_order_by
}

# input type for inserting array relation for remote table "author_name"
input author_name_arr_rel_insert_input {
  data: [author_name_insert_input!]!
  on_conflict: author_name_on_conflict
}

# aggregate avg on columns
type author_name_avg_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "author_name"
input author_name_avg_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "author_name". All fields are combined with a logical 'AND'.
input author_name_bool_exp {
  _and: [author_name_bool_exp]
  _not: author_name_bool_exp
  _or: [author_name_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  author: users_bool_exp
  authorMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  familyName: String_comparison_exp
  fullName: String_comparison_exp
  givenName: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "author_name"
enum author_name_constraint {
  # unique or primary key constraint
  author_name_pkey
}

# input type for incrementing integer column in table "author_name"
input author_name_inc_input {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "author_name"
input author_name_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  author: users_obj_rel_insert_input
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  familyName: String
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type author_name_max_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  familyName: String
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "author_name"
input author_name_max_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  familyName: order_by
  fullName: order_by
  givenName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type author_name_min_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  familyName: String
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "author_name"
input author_name_min_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  familyName: order_by
  fullName: order_by
  givenName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "author_name"
type author_name_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [author_name!]!
}

# input type for inserting object relation for remote table "author_name"
input author_name_obj_rel_insert_input {
  data: author_name_insert_input!
  on_conflict: author_name_on_conflict
}

# on conflict condition type for table "author_name"
input author_name_on_conflict {
  constraint: author_name_constraint!
  update_columns: [author_name_update_column!]!
  where: author_name_bool_exp
}

# ordering options when selecting data from "author_name"
input author_name_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  author: users_order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  familyName: order_by
  fullName: order_by
  givenName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "author_name"
input author_name_pk_columns_input {
  mtid: bigint!
}

# select columns of table "author_name"
enum author_name_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  familyName

  # column name
  fullName

  # column name
  givenName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "author_name"
input author_name_set_input {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  familyName: String
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type author_name_stddev_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "author_name"
input author_name_stddev_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type author_name_stddev_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "author_name"
input author_name_stddev_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type author_name_stddev_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "author_name"
input author_name_stddev_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type author_name_sum_fields {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "author_name"
input author_name_sum_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "author_name"
enum author_name_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  familyName

  # column name
  fullName

  # column name
  givenName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type author_name_var_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "author_name"
input author_name_var_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type author_name_var_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "author_name"
input author_name_var_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type author_name_variance_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "author_name"
input author_name_variance_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "authorship"
type authorship {
  affiliation: String
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  author: users
  authorMtid: bigint
  authorTyped: Boolean!
  comment: String
  comment2: String
  corresponding: Boolean
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  dtype: String!
  editorTyped: Boolean!
  error: Int
  familyName: String
  first: Boolean!
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  last: Boolean!
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldListPosition: Int!
  oldTimestamp: timestamp
  orcid: String

  # An array relationship
  organizations(
    # distinct select on columns
    distinct_on: [authorship_organizations_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_organizations_order_by!]

    # filter the rows returned
    where: authorship_organizations_bool_exp
  ): [authorship_organizations!]!

  # An aggregated array relationship
  organizations_aggregate(
    # distinct select on columns
    distinct_on: [authorship_organizations_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_organizations_order_by!]

    # filter the rows returned
    where: authorship_organizations_bool_exp
  ): authorship_organizations_aggregate!
  otherTyped: Boolean!
  otype: String
  prevValid: bigint

  # An object relationship
  publication: publication
  publicationMtid: bigint
  published: Boolean!
  refreshed: Boolean!
  share: Float!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An object relationship
  type: authorship_type
  typeMtid: bigint
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "authorship"
type authorship_aggregate {
  aggregate: authorship_aggregate_fields
  nodes: [authorship!]!
}

# aggregate fields of "authorship"
type authorship_aggregate_fields {
  avg: authorship_avg_fields
  count(columns: [authorship_select_column!], distinct: Boolean): Int
  max: authorship_max_fields
  min: authorship_min_fields
  stddev: authorship_stddev_fields
  stddev_pop: authorship_stddev_pop_fields
  stddev_samp: authorship_stddev_samp_fields
  sum: authorship_sum_fields
  var_pop: authorship_var_pop_fields
  var_samp: authorship_var_samp_fields
  variance: authorship_variance_fields
}

# order by aggregate values of table "authorship"
input authorship_aggregate_order_by {
  avg: authorship_avg_order_by
  count: order_by
  max: authorship_max_order_by
  min: authorship_min_order_by
  stddev: authorship_stddev_order_by
  stddev_pop: authorship_stddev_pop_order_by
  stddev_samp: authorship_stddev_samp_order_by
  sum: authorship_sum_order_by
  var_pop: authorship_var_pop_order_by
  var_samp: authorship_var_samp_order_by
  variance: authorship_variance_order_by
}

# input type for inserting array relation for remote table "authorship"
input authorship_arr_rel_insert_input {
  data: [authorship_insert_input!]!
  on_conflict: authorship_on_conflict
}

# aggregate avg on columns
type authorship_avg_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  oldListPosition: Float
  prevValid: Float
  publicationMtid: Float
  share: Float
  status: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "authorship"
input authorship_avg_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "authorship". All fields are combined with a logical 'AND'.
input authorship_bool_exp {
  _and: [authorship_bool_exp]
  _not: authorship_bool_exp
  _or: [authorship_bool_exp]
  affiliation: String_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  author: users_bool_exp
  authorMtid: bigint_comparison_exp
  authorTyped: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  corresponding: Boolean_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  dtype: String_comparison_exp
  editorTyped: Boolean_comparison_exp
  error: Int_comparison_exp
  familyName: String_comparison_exp
  first: Boolean_comparison_exp
  fullName: String_comparison_exp
  givenName: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  last: Boolean_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldListPosition: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  orcid: String_comparison_exp
  organizations: authorship_organizations_bool_exp
  otherTyped: Boolean_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  publication: publication_bool_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  share: Float_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: authorship_type_bool_exp
  typeMtid: bigint_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "authorship"
enum authorship_constraint {
  # unique or primary key constraint
  authorship_pkey
}

# input type for incrementing integer column in table "authorship"
input authorship_inc_input {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldListPosition: Int
  prevValid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "authorship"
input authorship_insert_input {
  affiliation: String
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  author: users_obj_rel_insert_input
  authorMtid: bigint
  authorTyped: Boolean
  comment: String
  comment2: String
  corresponding: Boolean
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  dtype: String
  editorTyped: Boolean
  error: Int
  familyName: String
  first: Boolean
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  last: Boolean
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldListPosition: Int
  oldTimestamp: timestamp
  orcid: String
  organizations: authorship_organizations_arr_rel_insert_input
  otherTyped: Boolean
  otype: String
  prevValid: bigint
  publication: publication_obj_rel_insert_input
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: authorship_type_obj_rel_insert_input
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type authorship_max_fields {
  affiliation: String
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  error: Int
  familyName: String
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldListPosition: Int
  oldTimestamp: timestamp
  orcid: String
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "authorship"
input authorship_max_order_by {
  affiliation: order_by
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  error: order_by
  familyName: order_by
  fullName: order_by
  givenName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  oldTimestamp: order_by
  orcid: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type authorship_min_fields {
  affiliation: String
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  error: Int
  familyName: String
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldListPosition: Int
  oldTimestamp: timestamp
  orcid: String
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "authorship"
input authorship_min_order_by {
  affiliation: order_by
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  error: order_by
  familyName: order_by
  fullName: order_by
  givenName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  oldTimestamp: order_by
  orcid: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "authorship"
type authorship_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [authorship!]!
}

# input type for inserting object relation for remote table "authorship"
input authorship_obj_rel_insert_input {
  data: authorship_insert_input!
  on_conflict: authorship_on_conflict
}

# on conflict condition type for table "authorship"
input authorship_on_conflict {
  constraint: authorship_constraint!
  update_columns: [authorship_update_column!]!
  where: authorship_bool_exp
}

# ordering options when selecting data from "authorship"
input authorship_order_by {
  affiliation: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  author: users_order_by
  authorMtid: order_by
  authorTyped: order_by
  comment: order_by
  comment2: order_by
  corresponding: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  dtype: order_by
  editorTyped: order_by
  error: order_by
  familyName: order_by
  first: order_by
  fullName: order_by
  givenName: order_by
  labelEng: order_by
  labelHun: order_by
  last: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  oldTimestamp: order_by
  orcid: order_by
  organizations_aggregate: authorship_organizations_aggregate_order_by
  otherTyped: order_by
  otype: order_by
  prevValid: order_by
  publication: publication_order_by
  publicationMtid: order_by
  published: order_by
  refreshed: order_by
  share: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: authorship_type_order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "authorship_organizations"
type authorship_organizations {
  authorshipMtid: bigint!

  # An object relationship
  organization: organization!
  organizationsMtid: bigint!
}

# aggregated selection of "authorship_organizations"
type authorship_organizations_aggregate {
  aggregate: authorship_organizations_aggregate_fields
  nodes: [authorship_organizations!]!
}

# aggregate fields of "authorship_organizations"
type authorship_organizations_aggregate_fields {
  avg: authorship_organizations_avg_fields
  count(columns: [authorship_organizations_select_column!], distinct: Boolean): Int
  max: authorship_organizations_max_fields
  min: authorship_organizations_min_fields
  stddev: authorship_organizations_stddev_fields
  stddev_pop: authorship_organizations_stddev_pop_fields
  stddev_samp: authorship_organizations_stddev_samp_fields
  sum: authorship_organizations_sum_fields
  var_pop: authorship_organizations_var_pop_fields
  var_samp: authorship_organizations_var_samp_fields
  variance: authorship_organizations_variance_fields
}

# order by aggregate values of table "authorship_organizations"
input authorship_organizations_aggregate_order_by {
  avg: authorship_organizations_avg_order_by
  count: order_by
  max: authorship_organizations_max_order_by
  min: authorship_organizations_min_order_by
  stddev: authorship_organizations_stddev_order_by
  stddev_pop: authorship_organizations_stddev_pop_order_by
  stddev_samp: authorship_organizations_stddev_samp_order_by
  sum: authorship_organizations_sum_order_by
  var_pop: authorship_organizations_var_pop_order_by
  var_samp: authorship_organizations_var_samp_order_by
  variance: authorship_organizations_variance_order_by
}

# input type for inserting array relation for remote table "authorship_organizations"
input authorship_organizations_arr_rel_insert_input {
  data: [authorship_organizations_insert_input!]!
}

# aggregate avg on columns
type authorship_organizations_avg_fields {
  authorshipMtid: Float
  organizationsMtid: Float
}

# order by avg() on columns of table "authorship_organizations"
input authorship_organizations_avg_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# Boolean expression to filter rows from the table "authorship_organizations". All fields are combined with a logical 'AND'.
input authorship_organizations_bool_exp {
  _and: [authorship_organizations_bool_exp]
  _not: authorship_organizations_bool_exp
  _or: [authorship_organizations_bool_exp]
  authorshipMtid: bigint_comparison_exp
  organization: organization_bool_exp
  organizationsMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "authorship_organizations"
input authorship_organizations_inc_input {
  authorshipMtid: bigint
  organizationsMtid: bigint
}

# input type for inserting data into table "authorship_organizations"
input authorship_organizations_insert_input {
  authorshipMtid: bigint
  organization: organization_obj_rel_insert_input
  organizationsMtid: bigint
}

# aggregate max on columns
type authorship_organizations_max_fields {
  authorshipMtid: bigint
  organizationsMtid: bigint
}

# order by max() on columns of table "authorship_organizations"
input authorship_organizations_max_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# aggregate min on columns
type authorship_organizations_min_fields {
  authorshipMtid: bigint
  organizationsMtid: bigint
}

# order by min() on columns of table "authorship_organizations"
input authorship_organizations_min_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# response of any mutation on the table "authorship_organizations"
type authorship_organizations_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [authorship_organizations!]!
}

# input type for inserting object relation for remote table "authorship_organizations"
input authorship_organizations_obj_rel_insert_input {
  data: authorship_organizations_insert_input!
}

# ordering options when selecting data from "authorship_organizations"
input authorship_organizations_order_by {
  authorshipMtid: order_by
  organization: organization_order_by
  organizationsMtid: order_by
}

# select columns of table "authorship_organizations"
enum authorship_organizations_select_column {
  # column name
  authorshipMtid

  # column name
  organizationsMtid
}

# input type for updating data in table "authorship_organizations"
input authorship_organizations_set_input {
  authorshipMtid: bigint
  organizationsMtid: bigint
}

# aggregate stddev on columns
type authorship_organizations_stddev_fields {
  authorshipMtid: Float
  organizationsMtid: Float
}

# order by stddev() on columns of table "authorship_organizations"
input authorship_organizations_stddev_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# aggregate stddev_pop on columns
type authorship_organizations_stddev_pop_fields {
  authorshipMtid: Float
  organizationsMtid: Float
}

# order by stddev_pop() on columns of table "authorship_organizations"
input authorship_organizations_stddev_pop_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# aggregate stddev_samp on columns
type authorship_organizations_stddev_samp_fields {
  authorshipMtid: Float
  organizationsMtid: Float
}

# order by stddev_samp() on columns of table "authorship_organizations"
input authorship_organizations_stddev_samp_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# aggregate sum on columns
type authorship_organizations_sum_fields {
  authorshipMtid: bigint
  organizationsMtid: bigint
}

# order by sum() on columns of table "authorship_organizations"
input authorship_organizations_sum_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# aggregate var_pop on columns
type authorship_organizations_var_pop_fields {
  authorshipMtid: Float
  organizationsMtid: Float
}

# order by var_pop() on columns of table "authorship_organizations"
input authorship_organizations_var_pop_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# aggregate var_samp on columns
type authorship_organizations_var_samp_fields {
  authorshipMtid: Float
  organizationsMtid: Float
}

# order by var_samp() on columns of table "authorship_organizations"
input authorship_organizations_var_samp_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# aggregate variance on columns
type authorship_organizations_variance_fields {
  authorshipMtid: Float
  organizationsMtid: Float
}

# order by variance() on columns of table "authorship_organizations"
input authorship_organizations_variance_order_by {
  authorshipMtid: order_by
  organizationsMtid: order_by
}

# primary key columns input for table: "authorship"
input authorship_pk_columns_input {
  mtid: bigint!
}

# select columns of table "authorship"
enum authorship_select_column {
  # column name
  affiliation

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  authorTyped

  # column name
  comment

  # column name
  comment2

  # column name
  corresponding

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  dtype

  # column name
  editorTyped

  # column name
  error

  # column name
  familyName

  # column name
  first

  # column name
  fullName

  # column name
  givenName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  last

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldListPosition

  # column name
  oldTimestamp

  # column name
  orcid

  # column name
  otherTyped

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  share

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  typeMtid

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "authorship"
input authorship_set_input {
  affiliation: String
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  authorTyped: Boolean
  comment: String
  comment2: String
  corresponding: Boolean
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  dtype: String
  editorTyped: Boolean
  error: Int
  familyName: String
  first: Boolean
  fullName: String
  givenName: String
  labelEng: String
  labelHun: String
  last: Boolean
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldListPosition: Int
  oldTimestamp: timestamp
  orcid: String
  otherTyped: Boolean
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type authorship_stddev_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  oldListPosition: Float
  prevValid: Float
  publicationMtid: Float
  share: Float
  status: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "authorship"
input authorship_stddev_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type authorship_stddev_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  oldListPosition: Float
  prevValid: Float
  publicationMtid: Float
  share: Float
  status: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "authorship"
input authorship_stddev_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type authorship_stddev_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  oldListPosition: Float
  prevValid: Float
  publicationMtid: Float
  share: Float
  status: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "authorship"
input authorship_stddev_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type authorship_sum_fields {
  approverMtid: bigint
  authorMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldListPosition: Int
  prevValid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "authorship"
input authorship_sum_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "authorship_type"
type authorship_type {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  code: Int!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int

  # An array relationship
  subTypesAllowed(
    # distinct select on columns
    distinct_on: [authorship_type_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_sub_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_sub_types_allowed_bool_exp
  ): [authorship_type_sub_types_allowed!]!

  # An aggregated array relationship
  subTypesAllowed_aggregate(
    # distinct select on columns
    distinct_on: [authorship_type_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_sub_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_sub_types_allowed_bool_exp
  ): authorship_type_sub_types_allowed_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An array relationship
  typesAllowed(
    # distinct select on columns
    distinct_on: [authorship_type_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_types_allowed_bool_exp
  ): [authorship_type_types_allowed!]!

  # An aggregated array relationship
  typesAllowed_aggregate(
    # distinct select on columns
    distinct_on: [authorship_type_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_types_allowed_bool_exp
  ): authorship_type_types_allowed_aggregate!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "authorship_type"
type authorship_type_aggregate {
  aggregate: authorship_type_aggregate_fields
  nodes: [authorship_type!]!
}

# aggregate fields of "authorship_type"
type authorship_type_aggregate_fields {
  avg: authorship_type_avg_fields
  count(columns: [authorship_type_select_column!], distinct: Boolean): Int
  max: authorship_type_max_fields
  min: authorship_type_min_fields
  stddev: authorship_type_stddev_fields
  stddev_pop: authorship_type_stddev_pop_fields
  stddev_samp: authorship_type_stddev_samp_fields
  sum: authorship_type_sum_fields
  var_pop: authorship_type_var_pop_fields
  var_samp: authorship_type_var_samp_fields
  variance: authorship_type_variance_fields
}

# order by aggregate values of table "authorship_type"
input authorship_type_aggregate_order_by {
  avg: authorship_type_avg_order_by
  count: order_by
  max: authorship_type_max_order_by
  min: authorship_type_min_order_by
  stddev: authorship_type_stddev_order_by
  stddev_pop: authorship_type_stddev_pop_order_by
  stddev_samp: authorship_type_stddev_samp_order_by
  sum: authorship_type_sum_order_by
  var_pop: authorship_type_var_pop_order_by
  var_samp: authorship_type_var_samp_order_by
  variance: authorship_type_variance_order_by
}

# input type for inserting array relation for remote table "authorship_type"
input authorship_type_arr_rel_insert_input {
  data: [authorship_type_insert_input!]!
  on_conflict: authorship_type_on_conflict
}

# aggregate avg on columns
type authorship_type_avg_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "authorship_type"
input authorship_type_avg_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "authorship_type". All fields are combined with a logical 'AND'.
input authorship_type_bool_exp {
  _and: [authorship_type_bool_exp]
  _not: authorship_type_bool_exp
  _or: [authorship_type_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  code: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  subTypesAllowed: authorship_type_sub_types_allowed_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  typesAllowed: authorship_type_types_allowed_bool_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "authorship_type"
enum authorship_type_constraint {
  # unique or primary key constraint
  authorship_type_pkey
}

# input type for incrementing integer column in table "authorship_type"
input authorship_type_inc_input {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "authorship_type"
input authorship_type_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  subTypesAllowed: authorship_type_sub_types_allowed_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typesAllowed: authorship_type_types_allowed_arr_rel_insert_input
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type authorship_type_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "authorship_type"
input authorship_type_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type authorship_type_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "authorship_type"
input authorship_type_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "authorship_type"
type authorship_type_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [authorship_type!]!
}

# input type for inserting object relation for remote table "authorship_type"
input authorship_type_obj_rel_insert_input {
  data: authorship_type_insert_input!
  on_conflict: authorship_type_on_conflict
}

# on conflict condition type for table "authorship_type"
input authorship_type_on_conflict {
  constraint: authorship_type_constraint!
  update_columns: [authorship_type_update_column!]!
  where: authorship_type_bool_exp
}

# ordering options when selecting data from "authorship_type"
input authorship_type_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  subTypesAllowed_aggregate: authorship_type_sub_types_allowed_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  typesAllowed_aggregate: authorship_type_types_allowed_aggregate_order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "authorship_type"
input authorship_type_pk_columns_input {
  mtid: bigint!
}

# select columns of table "authorship_type"
enum authorship_type_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "authorship_type"
input authorship_type_set_input {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type authorship_type_stddev_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "authorship_type"
input authorship_type_stddev_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type authorship_type_stddev_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "authorship_type"
input authorship_type_stddev_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type authorship_type_stddev_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "authorship_type"
input authorship_type_stddev_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "authorship_type_sub_types_allowed"
type authorship_type_sub_types_allowed {
  authorshipTypeMtid: bigint!

  # An object relationship
  subType: sub_type!
  subTypesAllowedMtid: bigint!
}

# aggregated selection of "authorship_type_sub_types_allowed"
type authorship_type_sub_types_allowed_aggregate {
  aggregate: authorship_type_sub_types_allowed_aggregate_fields
  nodes: [authorship_type_sub_types_allowed!]!
}

# aggregate fields of "authorship_type_sub_types_allowed"
type authorship_type_sub_types_allowed_aggregate_fields {
  avg: authorship_type_sub_types_allowed_avg_fields
  count(columns: [authorship_type_sub_types_allowed_select_column!], distinct: Boolean): Int
  max: authorship_type_sub_types_allowed_max_fields
  min: authorship_type_sub_types_allowed_min_fields
  stddev: authorship_type_sub_types_allowed_stddev_fields
  stddev_pop: authorship_type_sub_types_allowed_stddev_pop_fields
  stddev_samp: authorship_type_sub_types_allowed_stddev_samp_fields
  sum: authorship_type_sub_types_allowed_sum_fields
  var_pop: authorship_type_sub_types_allowed_var_pop_fields
  var_samp: authorship_type_sub_types_allowed_var_samp_fields
  variance: authorship_type_sub_types_allowed_variance_fields
}

# order by aggregate values of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_aggregate_order_by {
  avg: authorship_type_sub_types_allowed_avg_order_by
  count: order_by
  max: authorship_type_sub_types_allowed_max_order_by
  min: authorship_type_sub_types_allowed_min_order_by
  stddev: authorship_type_sub_types_allowed_stddev_order_by
  stddev_pop: authorship_type_sub_types_allowed_stddev_pop_order_by
  stddev_samp: authorship_type_sub_types_allowed_stddev_samp_order_by
  sum: authorship_type_sub_types_allowed_sum_order_by
  var_pop: authorship_type_sub_types_allowed_var_pop_order_by
  var_samp: authorship_type_sub_types_allowed_var_samp_order_by
  variance: authorship_type_sub_types_allowed_variance_order_by
}

# input type for inserting array relation for remote table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_arr_rel_insert_input {
  data: [authorship_type_sub_types_allowed_insert_input!]!
}

# aggregate avg on columns
type authorship_type_sub_types_allowed_avg_fields {
  authorshipTypeMtid: Float
  subTypesAllowedMtid: Float
}

# order by avg() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_avg_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# Boolean expression to filter rows from the table
# "authorship_type_sub_types_allowed". All fields are combined with a logical 'AND'.
input authorship_type_sub_types_allowed_bool_exp {
  _and: [authorship_type_sub_types_allowed_bool_exp]
  _not: authorship_type_sub_types_allowed_bool_exp
  _or: [authorship_type_sub_types_allowed_bool_exp]
  authorshipTypeMtid: bigint_comparison_exp
  subType: sub_type_bool_exp
  subTypesAllowedMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_inc_input {
  authorshipTypeMtid: bigint
  subTypesAllowedMtid: bigint
}

# input type for inserting data into table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_insert_input {
  authorshipTypeMtid: bigint
  subType: sub_type_obj_rel_insert_input
  subTypesAllowedMtid: bigint
}

# aggregate max on columns
type authorship_type_sub_types_allowed_max_fields {
  authorshipTypeMtid: bigint
  subTypesAllowedMtid: bigint
}

# order by max() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_max_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate min on columns
type authorship_type_sub_types_allowed_min_fields {
  authorshipTypeMtid: bigint
  subTypesAllowedMtid: bigint
}

# order by min() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_min_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# response of any mutation on the table "authorship_type_sub_types_allowed"
type authorship_type_sub_types_allowed_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [authorship_type_sub_types_allowed!]!
}

# input type for inserting object relation for remote table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_obj_rel_insert_input {
  data: authorship_type_sub_types_allowed_insert_input!
}

# ordering options when selecting data from "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_order_by {
  authorshipTypeMtid: order_by
  subType: sub_type_order_by
  subTypesAllowedMtid: order_by
}

# select columns of table "authorship_type_sub_types_allowed"
enum authorship_type_sub_types_allowed_select_column {
  # column name
  authorshipTypeMtid

  # column name
  subTypesAllowedMtid
}

# input type for updating data in table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_set_input {
  authorshipTypeMtid: bigint
  subTypesAllowedMtid: bigint
}

# aggregate stddev on columns
type authorship_type_sub_types_allowed_stddev_fields {
  authorshipTypeMtid: Float
  subTypesAllowedMtid: Float
}

# order by stddev() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_stddev_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate stddev_pop on columns
type authorship_type_sub_types_allowed_stddev_pop_fields {
  authorshipTypeMtid: Float
  subTypesAllowedMtid: Float
}

# order by stddev_pop() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_stddev_pop_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate stddev_samp on columns
type authorship_type_sub_types_allowed_stddev_samp_fields {
  authorshipTypeMtid: Float
  subTypesAllowedMtid: Float
}

# order by stddev_samp() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_stddev_samp_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate sum on columns
type authorship_type_sub_types_allowed_sum_fields {
  authorshipTypeMtid: bigint
  subTypesAllowedMtid: bigint
}

# order by sum() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_sum_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate var_pop on columns
type authorship_type_sub_types_allowed_var_pop_fields {
  authorshipTypeMtid: Float
  subTypesAllowedMtid: Float
}

# order by var_pop() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_var_pop_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate var_samp on columns
type authorship_type_sub_types_allowed_var_samp_fields {
  authorshipTypeMtid: Float
  subTypesAllowedMtid: Float
}

# order by var_samp() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_var_samp_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate variance on columns
type authorship_type_sub_types_allowed_variance_fields {
  authorshipTypeMtid: Float
  subTypesAllowedMtid: Float
}

# order by variance() on columns of table "authorship_type_sub_types_allowed"
input authorship_type_sub_types_allowed_variance_order_by {
  authorshipTypeMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate sum on columns
type authorship_type_sum_fields {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "authorship_type"
input authorship_type_sum_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "authorship_type_types_allowed"
type authorship_type_types_allowed {
  authorshipTypeMtid: bigint!

  # An object relationship
  publicationType: publication_type!
  typesAllowedMtid: bigint!
}

# aggregated selection of "authorship_type_types_allowed"
type authorship_type_types_allowed_aggregate {
  aggregate: authorship_type_types_allowed_aggregate_fields
  nodes: [authorship_type_types_allowed!]!
}

# aggregate fields of "authorship_type_types_allowed"
type authorship_type_types_allowed_aggregate_fields {
  avg: authorship_type_types_allowed_avg_fields
  count(columns: [authorship_type_types_allowed_select_column!], distinct: Boolean): Int
  max: authorship_type_types_allowed_max_fields
  min: authorship_type_types_allowed_min_fields
  stddev: authorship_type_types_allowed_stddev_fields
  stddev_pop: authorship_type_types_allowed_stddev_pop_fields
  stddev_samp: authorship_type_types_allowed_stddev_samp_fields
  sum: authorship_type_types_allowed_sum_fields
  var_pop: authorship_type_types_allowed_var_pop_fields
  var_samp: authorship_type_types_allowed_var_samp_fields
  variance: authorship_type_types_allowed_variance_fields
}

# order by aggregate values of table "authorship_type_types_allowed"
input authorship_type_types_allowed_aggregate_order_by {
  avg: authorship_type_types_allowed_avg_order_by
  count: order_by
  max: authorship_type_types_allowed_max_order_by
  min: authorship_type_types_allowed_min_order_by
  stddev: authorship_type_types_allowed_stddev_order_by
  stddev_pop: authorship_type_types_allowed_stddev_pop_order_by
  stddev_samp: authorship_type_types_allowed_stddev_samp_order_by
  sum: authorship_type_types_allowed_sum_order_by
  var_pop: authorship_type_types_allowed_var_pop_order_by
  var_samp: authorship_type_types_allowed_var_samp_order_by
  variance: authorship_type_types_allowed_variance_order_by
}

# input type for inserting array relation for remote table "authorship_type_types_allowed"
input authorship_type_types_allowed_arr_rel_insert_input {
  data: [authorship_type_types_allowed_insert_input!]!
}

# aggregate avg on columns
type authorship_type_types_allowed_avg_fields {
  authorshipTypeMtid: Float
  typesAllowedMtid: Float
}

# order by avg() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_avg_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# Boolean expression to filter rows from the table
# "authorship_type_types_allowed". All fields are combined with a logical 'AND'.
input authorship_type_types_allowed_bool_exp {
  _and: [authorship_type_types_allowed_bool_exp]
  _not: authorship_type_types_allowed_bool_exp
  _or: [authorship_type_types_allowed_bool_exp]
  authorshipTypeMtid: bigint_comparison_exp
  publicationType: publication_type_bool_exp
  typesAllowedMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "authorship_type_types_allowed"
input authorship_type_types_allowed_inc_input {
  authorshipTypeMtid: bigint
  typesAllowedMtid: bigint
}

# input type for inserting data into table "authorship_type_types_allowed"
input authorship_type_types_allowed_insert_input {
  authorshipTypeMtid: bigint
  publicationType: publication_type_obj_rel_insert_input
  typesAllowedMtid: bigint
}

# aggregate max on columns
type authorship_type_types_allowed_max_fields {
  authorshipTypeMtid: bigint
  typesAllowedMtid: bigint
}

# order by max() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_max_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate min on columns
type authorship_type_types_allowed_min_fields {
  authorshipTypeMtid: bigint
  typesAllowedMtid: bigint
}

# order by min() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_min_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# response of any mutation on the table "authorship_type_types_allowed"
type authorship_type_types_allowed_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [authorship_type_types_allowed!]!
}

# input type for inserting object relation for remote table "authorship_type_types_allowed"
input authorship_type_types_allowed_obj_rel_insert_input {
  data: authorship_type_types_allowed_insert_input!
}

# ordering options when selecting data from "authorship_type_types_allowed"
input authorship_type_types_allowed_order_by {
  authorshipTypeMtid: order_by
  publicationType: publication_type_order_by
  typesAllowedMtid: order_by
}

# select columns of table "authorship_type_types_allowed"
enum authorship_type_types_allowed_select_column {
  # column name
  authorshipTypeMtid

  # column name
  typesAllowedMtid
}

# input type for updating data in table "authorship_type_types_allowed"
input authorship_type_types_allowed_set_input {
  authorshipTypeMtid: bigint
  typesAllowedMtid: bigint
}

# aggregate stddev on columns
type authorship_type_types_allowed_stddev_fields {
  authorshipTypeMtid: Float
  typesAllowedMtid: Float
}

# order by stddev() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_stddev_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate stddev_pop on columns
type authorship_type_types_allowed_stddev_pop_fields {
  authorshipTypeMtid: Float
  typesAllowedMtid: Float
}

# order by stddev_pop() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_stddev_pop_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate stddev_samp on columns
type authorship_type_types_allowed_stddev_samp_fields {
  authorshipTypeMtid: Float
  typesAllowedMtid: Float
}

# order by stddev_samp() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_stddev_samp_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate sum on columns
type authorship_type_types_allowed_sum_fields {
  authorshipTypeMtid: bigint
  typesAllowedMtid: bigint
}

# order by sum() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_sum_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate var_pop on columns
type authorship_type_types_allowed_var_pop_fields {
  authorshipTypeMtid: Float
  typesAllowedMtid: Float
}

# order by var_pop() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_var_pop_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate var_samp on columns
type authorship_type_types_allowed_var_samp_fields {
  authorshipTypeMtid: Float
  typesAllowedMtid: Float
}

# order by var_samp() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_var_samp_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate variance on columns
type authorship_type_types_allowed_variance_fields {
  authorshipTypeMtid: Float
  typesAllowedMtid: Float
}

# order by variance() on columns of table "authorship_type_types_allowed"
input authorship_type_types_allowed_variance_order_by {
  authorshipTypeMtid: order_by
  typesAllowedMtid: order_by
}

# update columns of table "authorship_type"
enum authorship_type_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type authorship_type_var_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "authorship_type"
input authorship_type_var_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type authorship_type_var_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "authorship_type"
input authorship_type_var_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type authorship_type_variance_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "authorship_type"
input authorship_type_variance_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "authorship"
enum authorship_update_column {
  # column name
  affiliation

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  authorTyped

  # column name
  comment

  # column name
  comment2

  # column name
  corresponding

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  dtype

  # column name
  editorTyped

  # column name
  error

  # column name
  familyName

  # column name
  first

  # column name
  fullName

  # column name
  givenName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  last

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldListPosition

  # column name
  oldTimestamp

  # column name
  orcid

  # column name
  otherTyped

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  share

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  typeMtid

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type authorship_var_pop_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  oldListPosition: Float
  prevValid: Float
  publicationMtid: Float
  share: Float
  status: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "authorship"
input authorship_var_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type authorship_var_samp_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  oldListPosition: Float
  prevValid: Float
  publicationMtid: Float
  share: Float
  status: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "authorship"
input authorship_var_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type authorship_variance_fields {
  approverMtid: Float
  authorMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  oldListPosition: Float
  prevValid: Float
  publicationMtid: Float
  share: Float
  status: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "authorship"
input authorship_variance_order_by {
  approverMtid: order_by
  authorMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldListPosition: order_by
  prevValid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

scalar bigint

# expression to compare columns of type bigint. All fields are combined with logical 'AND'.
input bigint_comparison_exp {
  _eq: bigint
  _gt: bigint
  _gte: bigint
  _in: [bigint!]
  _is_null: Boolean
  _lt: bigint
  _lte: bigint
  _neq: bigint
  _nin: [bigint!]
}

# columns and relationships of "binary_content"
type binary_content {
  content: oid
  id: bigint!
}

# aggregated selection of "binary_content"
type binary_content_aggregate {
  aggregate: binary_content_aggregate_fields
  nodes: [binary_content!]!
}

# aggregate fields of "binary_content"
type binary_content_aggregate_fields {
  avg: binary_content_avg_fields
  count(columns: [binary_content_select_column!], distinct: Boolean): Int
  max: binary_content_max_fields
  min: binary_content_min_fields
  stddev: binary_content_stddev_fields
  stddev_pop: binary_content_stddev_pop_fields
  stddev_samp: binary_content_stddev_samp_fields
  sum: binary_content_sum_fields
  var_pop: binary_content_var_pop_fields
  var_samp: binary_content_var_samp_fields
  variance: binary_content_variance_fields
}

# order by aggregate values of table "binary_content"
input binary_content_aggregate_order_by {
  avg: binary_content_avg_order_by
  count: order_by
  max: binary_content_max_order_by
  min: binary_content_min_order_by
  stddev: binary_content_stddev_order_by
  stddev_pop: binary_content_stddev_pop_order_by
  stddev_samp: binary_content_stddev_samp_order_by
  sum: binary_content_sum_order_by
  var_pop: binary_content_var_pop_order_by
  var_samp: binary_content_var_samp_order_by
  variance: binary_content_variance_order_by
}

# input type for inserting array relation for remote table "binary_content"
input binary_content_arr_rel_insert_input {
  data: [binary_content_insert_input!]!
  on_conflict: binary_content_on_conflict
}

# aggregate avg on columns
type binary_content_avg_fields {
  id: Float
}

# order by avg() on columns of table "binary_content"
input binary_content_avg_order_by {
  id: order_by
}

# Boolean expression to filter rows from the table "binary_content". All fields are combined with a logical 'AND'.
input binary_content_bool_exp {
  _and: [binary_content_bool_exp]
  _not: binary_content_bool_exp
  _or: [binary_content_bool_exp]
  content: oid_comparison_exp
  id: bigint_comparison_exp
}

# unique or primary key constraints on table "binary_content"
enum binary_content_constraint {
  # unique or primary key constraint
  binary_content_pkey
}

# input type for incrementing integer column in table "binary_content"
input binary_content_inc_input {
  id: bigint
}

# input type for inserting data into table "binary_content"
input binary_content_insert_input {
  content: oid
  id: bigint
}

# aggregate max on columns
type binary_content_max_fields {
  id: bigint
}

# order by max() on columns of table "binary_content"
input binary_content_max_order_by {
  id: order_by
}

# aggregate min on columns
type binary_content_min_fields {
  id: bigint
}

# order by min() on columns of table "binary_content"
input binary_content_min_order_by {
  id: order_by
}

# response of any mutation on the table "binary_content"
type binary_content_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [binary_content!]!
}

# input type for inserting object relation for remote table "binary_content"
input binary_content_obj_rel_insert_input {
  data: binary_content_insert_input!
  on_conflict: binary_content_on_conflict
}

# on conflict condition type for table "binary_content"
input binary_content_on_conflict {
  constraint: binary_content_constraint!
  update_columns: [binary_content_update_column!]!
  where: binary_content_bool_exp
}

# ordering options when selecting data from "binary_content"
input binary_content_order_by {
  content: order_by
  id: order_by
}

# primary key columns input for table: "binary_content"
input binary_content_pk_columns_input {
  id: bigint!
}

# select columns of table "binary_content"
enum binary_content_select_column {
  # column name
  content

  # column name
  id
}

# input type for updating data in table "binary_content"
input binary_content_set_input {
  content: oid
  id: bigint
}

# aggregate stddev on columns
type binary_content_stddev_fields {
  id: Float
}

# order by stddev() on columns of table "binary_content"
input binary_content_stddev_order_by {
  id: order_by
}

# aggregate stddev_pop on columns
type binary_content_stddev_pop_fields {
  id: Float
}

# order by stddev_pop() on columns of table "binary_content"
input binary_content_stddev_pop_order_by {
  id: order_by
}

# aggregate stddev_samp on columns
type binary_content_stddev_samp_fields {
  id: Float
}

# order by stddev_samp() on columns of table "binary_content"
input binary_content_stddev_samp_order_by {
  id: order_by
}

# aggregate sum on columns
type binary_content_sum_fields {
  id: bigint
}

# order by sum() on columns of table "binary_content"
input binary_content_sum_order_by {
  id: order_by
}

# update columns of table "binary_content"
enum binary_content_update_column {
  # column name
  content

  # column name
  id
}

# aggregate var_pop on columns
type binary_content_var_pop_fields {
  id: Float
}

# order by var_pop() on columns of table "binary_content"
input binary_content_var_pop_order_by {
  id: order_by
}

# aggregate var_samp on columns
type binary_content_var_samp_fields {
  id: Float
}

# order by var_samp() on columns of table "binary_content"
input binary_content_var_samp_order_by {
  id: order_by
}

# aggregate variance on columns
type binary_content_variance_fields {
  id: Float
}

# order by variance() on columns of table "binary_content"
input binary_content_variance_order_by {
  id: order_by
}

# expression to compare columns of type Boolean. All fields are combined with logical 'AND'.
input Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

# columns and relationships of "bulk_duplum_merge_request"
type bulk_duplum_merge_request {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  beforeDate: timestamp
  citationsOnly: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  finder: Int
  instituteId: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  markNonMergeable: Boolean
  maxResults: Int
  mergeAll: Boolean
  mergeSub: Boolean
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  pubIds: String
  published: Boolean!
  queued: Boolean!
  refreshed: Boolean!

  # An object relationship
  resultList: named_list
  resultListMtid: bigint
  seen: Boolean
  sourceFilters: String
  sourceIds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  typeId: smallint
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "bulk_duplum_merge_request"
type bulk_duplum_merge_request_aggregate {
  aggregate: bulk_duplum_merge_request_aggregate_fields
  nodes: [bulk_duplum_merge_request!]!
}

# aggregate fields of "bulk_duplum_merge_request"
type bulk_duplum_merge_request_aggregate_fields {
  avg: bulk_duplum_merge_request_avg_fields
  count(columns: [bulk_duplum_merge_request_select_column!], distinct: Boolean): Int
  max: bulk_duplum_merge_request_max_fields
  min: bulk_duplum_merge_request_min_fields
  stddev: bulk_duplum_merge_request_stddev_fields
  stddev_pop: bulk_duplum_merge_request_stddev_pop_fields
  stddev_samp: bulk_duplum_merge_request_stddev_samp_fields
  sum: bulk_duplum_merge_request_sum_fields
  var_pop: bulk_duplum_merge_request_var_pop_fields
  var_samp: bulk_duplum_merge_request_var_samp_fields
  variance: bulk_duplum_merge_request_variance_fields
}

# order by aggregate values of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_aggregate_order_by {
  avg: bulk_duplum_merge_request_avg_order_by
  count: order_by
  max: bulk_duplum_merge_request_max_order_by
  min: bulk_duplum_merge_request_min_order_by
  stddev: bulk_duplum_merge_request_stddev_order_by
  stddev_pop: bulk_duplum_merge_request_stddev_pop_order_by
  stddev_samp: bulk_duplum_merge_request_stddev_samp_order_by
  sum: bulk_duplum_merge_request_sum_order_by
  var_pop: bulk_duplum_merge_request_var_pop_order_by
  var_samp: bulk_duplum_merge_request_var_samp_order_by
  variance: bulk_duplum_merge_request_variance_order_by
}

# input type for inserting array relation for remote table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_arr_rel_insert_input {
  data: [bulk_duplum_merge_request_insert_input!]!
  on_conflict: bulk_duplum_merge_request_on_conflict
}

# aggregate avg on columns
type bulk_duplum_merge_request_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  finder: Float
  instituteId: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxResults: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  typeId: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "bulk_duplum_merge_request". All fields are combined with a logical 'AND'.
input bulk_duplum_merge_request_bool_exp {
  _and: [bulk_duplum_merge_request_bool_exp]
  _not: bulk_duplum_merge_request_bool_exp
  _or: [bulk_duplum_merge_request_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  beforeDate: timestamp_comparison_exp
  citationsOnly: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  finder: Int_comparison_exp
  instituteId: bigint_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  markNonMergeable: Boolean_comparison_exp
  maxResults: Int_comparison_exp
  mergeAll: Boolean_comparison_exp
  mergeSub: Boolean_comparison_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  pubIds: String_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  resultList: named_list_bool_exp
  resultListMtid: bigint_comparison_exp
  seen: Boolean_comparison_exp
  sourceFilters: String_comparison_exp
  sourceIds: String_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  typeId: smallint_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "bulk_duplum_merge_request"
enum bulk_duplum_merge_request_constraint {
  # unique or primary key constraint
  bulk_duplum_merge_request_pkey
}

# input type for incrementing integer column in table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  finder: Int
  instituteId: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  maxResults: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  resultListMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  typeId: smallint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  beforeDate: timestamp
  citationsOnly: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  finder: Int
  instituteId: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  markNonMergeable: Boolean
  maxResults: Int
  mergeAll: Boolean
  mergeSub: Boolean
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  pubIds: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  resultList: named_list_obj_rel_insert_input
  resultListMtid: bigint
  seen: Boolean
  sourceFilters: String
  sourceIds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  typeId: smallint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type bulk_duplum_merge_request_max_fields {
  approved: timestamp
  approverMtid: bigint
  beforeDate: timestamp
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  finder: Int
  instituteId: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  maxResults: Int
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  pubIds: String
  resultListMtid: bigint
  sourceFilters: String
  sourceIds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  typeId: smallint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_max_order_by {
  approved: order_by
  approverMtid: order_by
  beforeDate: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  pubIds: order_by
  resultListMtid: order_by
  sourceFilters: order_by
  sourceIds: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type bulk_duplum_merge_request_min_fields {
  approved: timestamp
  approverMtid: bigint
  beforeDate: timestamp
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  finder: Int
  instituteId: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  maxResults: Int
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  pubIds: String
  resultListMtid: bigint
  sourceFilters: String
  sourceIds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  typeId: smallint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_min_order_by {
  approved: order_by
  approverMtid: order_by
  beforeDate: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  pubIds: order_by
  resultListMtid: order_by
  sourceFilters: order_by
  sourceIds: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "bulk_duplum_merge_request"
type bulk_duplum_merge_request_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [bulk_duplum_merge_request!]!
}

# input type for inserting object relation for remote table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_obj_rel_insert_input {
  data: bulk_duplum_merge_request_insert_input!
  on_conflict: bulk_duplum_merge_request_on_conflict
}

# on conflict condition type for table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_on_conflict {
  constraint: bulk_duplum_merge_request_constraint!
  update_columns: [bulk_duplum_merge_request_update_column!]!
  where: bulk_duplum_merge_request_bool_exp
}

# ordering options when selecting data from "bulk_duplum_merge_request"
input bulk_duplum_merge_request_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  beforeDate: order_by
  citationsOnly: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  markNonMergeable: order_by
  maxResults: order_by
  mergeAll: order_by
  mergeSub: order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  pubIds: order_by
  published: order_by
  queued: order_by
  refreshed: order_by
  resultList: named_list_order_by
  resultListMtid: order_by
  seen: order_by
  sourceFilters: order_by
  sourceIds: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "bulk_duplum_merge_request"
input bulk_duplum_merge_request_pk_columns_input {
  mtid: bigint!
}

# select columns of table "bulk_duplum_merge_request"
enum bulk_duplum_merge_request_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  beforeDate

  # column name
  citationsOnly

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  finder

  # column name
  instituteId

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  markNonMergeable

  # column name
  maxResults

  # column name
  mergeAll

  # column name
  mergeSub

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  pubIds

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  resultListMtid

  # column name
  seen

  # column name
  sourceFilters

  # column name
  sourceIds

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  typeId

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_set_input {
  approved: timestamp
  approverMtid: bigint
  beforeDate: timestamp
  citationsOnly: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  finder: Int
  instituteId: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  markNonMergeable: Boolean
  maxResults: Int
  mergeAll: Boolean
  mergeSub: Boolean
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  pubIds: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  resultListMtid: bigint
  seen: Boolean
  sourceFilters: String
  sourceIds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  typeId: smallint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type bulk_duplum_merge_request_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  finder: Float
  instituteId: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxResults: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  typeId: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type bulk_duplum_merge_request_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  finder: Float
  instituteId: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxResults: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  typeId: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type bulk_duplum_merge_request_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  finder: Float
  instituteId: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxResults: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  typeId: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type bulk_duplum_merge_request_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  finder: Int
  instituteId: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  maxResults: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  resultListMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  typeId: smallint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "bulk_duplum_merge_request"
enum bulk_duplum_merge_request_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  beforeDate

  # column name
  citationsOnly

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  finder

  # column name
  instituteId

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  markNonMergeable

  # column name
  maxResults

  # column name
  mergeAll

  # column name
  mergeSub

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  pubIds

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  resultListMtid

  # column name
  seen

  # column name
  sourceFilters

  # column name
  sourceIds

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  typeId

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type bulk_duplum_merge_request_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  finder: Float
  instituteId: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxResults: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  typeId: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type bulk_duplum_merge_request_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  finder: Float
  instituteId: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxResults: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  typeId: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type bulk_duplum_merge_request_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  finder: Float
  instituteId: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxResults: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  typeId: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "bulk_duplum_merge_request"
input bulk_duplum_merge_request_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  finder: order_by
  instituteId: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxResults: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  typeId: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

scalar bytea

# expression to compare columns of type bytea. All fields are combined with logical 'AND'.
input bytea_comparison_exp {
  _eq: bytea
  _gt: bytea
  _gte: bytea
  _in: [bytea!]
  _is_null: Boolean
  _lt: bytea
  _lte: bytea
  _neq: bytea
  _nin: [bytea!]
}

# columns and relationships of "category"
type category {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean!
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  scientific: Boolean!
  status: Int

  # An array relationship
  subTypesAllowed(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): [category_sub_types_allowed!]!

  # An aggregated array relationship
  subTypesAllowed_aggregate(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): category_sub_types_allowed_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An array relationship
  typesAllowed(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): [category_types_allowed!]!

  # An aggregated array relationship
  typesAllowed_aggregate(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): category_types_allowed_aggregate!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "category"
type category_aggregate {
  aggregate: category_aggregate_fields
  nodes: [category!]!
}

# aggregate fields of "category"
type category_aggregate_fields {
  avg: category_avg_fields
  count(columns: [category_select_column!], distinct: Boolean): Int
  max: category_max_fields
  min: category_min_fields
  stddev: category_stddev_fields
  stddev_pop: category_stddev_pop_fields
  stddev_samp: category_stddev_samp_fields
  sum: category_sum_fields
  var_pop: category_var_pop_fields
  var_samp: category_var_samp_fields
  variance: category_variance_fields
}

# order by aggregate values of table "category"
input category_aggregate_order_by {
  avg: category_avg_order_by
  count: order_by
  max: category_max_order_by
  min: category_min_order_by
  stddev: category_stddev_order_by
  stddev_pop: category_stddev_pop_order_by
  stddev_samp: category_stddev_samp_order_by
  sum: category_sum_order_by
  var_pop: category_var_pop_order_by
  var_samp: category_var_samp_order_by
  variance: category_variance_order_by
}

# input type for inserting array relation for remote table "category"
input category_arr_rel_insert_input {
  data: [category_insert_input!]!
  on_conflict: category_on_conflict
}

# aggregate avg on columns
type category_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "category"
input category_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "category". All fields are combined with a logical 'AND'.
input category_bool_exp {
  _and: [category_bool_exp]
  _not: category_bool_exp
  _or: [category_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  excludeFromOaStats: Boolean_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  scientific: Boolean_comparison_exp
  status: Int_comparison_exp
  subTypesAllowed: category_sub_types_allowed_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  typesAllowed: category_types_allowed_bool_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "category"
enum category_constraint {
  # unique or primary key constraint
  category_pkey
}

# input type for incrementing integer column in table "category"
input category_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "category"
input category_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  scientific: Boolean
  status: Int
  subTypesAllowed: category_sub_types_allowed_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typesAllowed: category_types_allowed_arr_rel_insert_input
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type category_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "category"
input category_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type category_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "category"
input category_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "category"
type category_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [category!]!
}

# input type for inserting object relation for remote table "category"
input category_obj_rel_insert_input {
  data: category_insert_input!
  on_conflict: category_on_conflict
}

# on conflict condition type for table "category"
input category_on_conflict {
  constraint: category_constraint!
  update_columns: [category_update_column!]!
  where: category_bool_exp
}

# ordering options when selecting data from "category"
input category_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  excludeFromOaStats: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  scientific: order_by
  status: order_by
  subTypesAllowed_aggregate: category_sub_types_allowed_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  typesAllowed_aggregate: category_types_allowed_aggregate_order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "category"
input category_pk_columns_input {
  mtid: bigint!
}

# select columns of table "category"
enum category_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  excludeFromOaStats

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  scientific

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "category"
input category_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  scientific: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type category_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "category"
input category_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type category_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "category"
input category_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type category_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "category"
input category_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "category_sub_types_allowed"
type category_sub_types_allowed {
  # An object relationship
  category: category!
  categoryMtid: bigint!

  # An object relationship
  subType: sub_type!
  subTypesAllowedMtid: bigint!
}

# aggregated selection of "category_sub_types_allowed"
type category_sub_types_allowed_aggregate {
  aggregate: category_sub_types_allowed_aggregate_fields
  nodes: [category_sub_types_allowed!]!
}

# aggregate fields of "category_sub_types_allowed"
type category_sub_types_allowed_aggregate_fields {
  avg: category_sub_types_allowed_avg_fields
  count(columns: [category_sub_types_allowed_select_column!], distinct: Boolean): Int
  max: category_sub_types_allowed_max_fields
  min: category_sub_types_allowed_min_fields
  stddev: category_sub_types_allowed_stddev_fields
  stddev_pop: category_sub_types_allowed_stddev_pop_fields
  stddev_samp: category_sub_types_allowed_stddev_samp_fields
  sum: category_sub_types_allowed_sum_fields
  var_pop: category_sub_types_allowed_var_pop_fields
  var_samp: category_sub_types_allowed_var_samp_fields
  variance: category_sub_types_allowed_variance_fields
}

# order by aggregate values of table "category_sub_types_allowed"
input category_sub_types_allowed_aggregate_order_by {
  avg: category_sub_types_allowed_avg_order_by
  count: order_by
  max: category_sub_types_allowed_max_order_by
  min: category_sub_types_allowed_min_order_by
  stddev: category_sub_types_allowed_stddev_order_by
  stddev_pop: category_sub_types_allowed_stddev_pop_order_by
  stddev_samp: category_sub_types_allowed_stddev_samp_order_by
  sum: category_sub_types_allowed_sum_order_by
  var_pop: category_sub_types_allowed_var_pop_order_by
  var_samp: category_sub_types_allowed_var_samp_order_by
  variance: category_sub_types_allowed_variance_order_by
}

# input type for inserting array relation for remote table "category_sub_types_allowed"
input category_sub_types_allowed_arr_rel_insert_input {
  data: [category_sub_types_allowed_insert_input!]!
}

# aggregate avg on columns
type category_sub_types_allowed_avg_fields {
  categoryMtid: Float
  subTypesAllowedMtid: Float
}

# order by avg() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_avg_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# Boolean expression to filter rows from the table "category_sub_types_allowed". All fields are combined with a logical 'AND'.
input category_sub_types_allowed_bool_exp {
  _and: [category_sub_types_allowed_bool_exp]
  _not: category_sub_types_allowed_bool_exp
  _or: [category_sub_types_allowed_bool_exp]
  category: category_bool_exp
  categoryMtid: bigint_comparison_exp
  subType: sub_type_bool_exp
  subTypesAllowedMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "category_sub_types_allowed"
input category_sub_types_allowed_inc_input {
  categoryMtid: bigint
  subTypesAllowedMtid: bigint
}

# input type for inserting data into table "category_sub_types_allowed"
input category_sub_types_allowed_insert_input {
  category: category_obj_rel_insert_input
  categoryMtid: bigint
  subType: sub_type_obj_rel_insert_input
  subTypesAllowedMtid: bigint
}

# aggregate max on columns
type category_sub_types_allowed_max_fields {
  categoryMtid: bigint
  subTypesAllowedMtid: bigint
}

# order by max() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_max_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate min on columns
type category_sub_types_allowed_min_fields {
  categoryMtid: bigint
  subTypesAllowedMtid: bigint
}

# order by min() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_min_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# response of any mutation on the table "category_sub_types_allowed"
type category_sub_types_allowed_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [category_sub_types_allowed!]!
}

# input type for inserting object relation for remote table "category_sub_types_allowed"
input category_sub_types_allowed_obj_rel_insert_input {
  data: category_sub_types_allowed_insert_input!
}

# ordering options when selecting data from "category_sub_types_allowed"
input category_sub_types_allowed_order_by {
  category: category_order_by
  categoryMtid: order_by
  subType: sub_type_order_by
  subTypesAllowedMtid: order_by
}

# select columns of table "category_sub_types_allowed"
enum category_sub_types_allowed_select_column {
  # column name
  categoryMtid

  # column name
  subTypesAllowedMtid
}

# input type for updating data in table "category_sub_types_allowed"
input category_sub_types_allowed_set_input {
  categoryMtid: bigint
  subTypesAllowedMtid: bigint
}

# aggregate stddev on columns
type category_sub_types_allowed_stddev_fields {
  categoryMtid: Float
  subTypesAllowedMtid: Float
}

# order by stddev() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_stddev_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate stddev_pop on columns
type category_sub_types_allowed_stddev_pop_fields {
  categoryMtid: Float
  subTypesAllowedMtid: Float
}

# order by stddev_pop() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_stddev_pop_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate stddev_samp on columns
type category_sub_types_allowed_stddev_samp_fields {
  categoryMtid: Float
  subTypesAllowedMtid: Float
}

# order by stddev_samp() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_stddev_samp_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate sum on columns
type category_sub_types_allowed_sum_fields {
  categoryMtid: bigint
  subTypesAllowedMtid: bigint
}

# order by sum() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_sum_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate var_pop on columns
type category_sub_types_allowed_var_pop_fields {
  categoryMtid: Float
  subTypesAllowedMtid: Float
}

# order by var_pop() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_var_pop_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate var_samp on columns
type category_sub_types_allowed_var_samp_fields {
  categoryMtid: Float
  subTypesAllowedMtid: Float
}

# order by var_samp() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_var_samp_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate variance on columns
type category_sub_types_allowed_variance_fields {
  categoryMtid: Float
  subTypesAllowedMtid: Float
}

# order by variance() on columns of table "category_sub_types_allowed"
input category_sub_types_allowed_variance_order_by {
  categoryMtid: order_by
  subTypesAllowedMtid: order_by
}

# aggregate sum on columns
type category_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "category"
input category_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "category_types_allowed"
type category_types_allowed {
  # An object relationship
  category: category!
  categoryMtid: bigint!

  # An object relationship
  publicationType: publication_type!
  typesAllowedMtid: bigint!
}

# aggregated selection of "category_types_allowed"
type category_types_allowed_aggregate {
  aggregate: category_types_allowed_aggregate_fields
  nodes: [category_types_allowed!]!
}

# aggregate fields of "category_types_allowed"
type category_types_allowed_aggregate_fields {
  avg: category_types_allowed_avg_fields
  count(columns: [category_types_allowed_select_column!], distinct: Boolean): Int
  max: category_types_allowed_max_fields
  min: category_types_allowed_min_fields
  stddev: category_types_allowed_stddev_fields
  stddev_pop: category_types_allowed_stddev_pop_fields
  stddev_samp: category_types_allowed_stddev_samp_fields
  sum: category_types_allowed_sum_fields
  var_pop: category_types_allowed_var_pop_fields
  var_samp: category_types_allowed_var_samp_fields
  variance: category_types_allowed_variance_fields
}

# order by aggregate values of table "category_types_allowed"
input category_types_allowed_aggregate_order_by {
  avg: category_types_allowed_avg_order_by
  count: order_by
  max: category_types_allowed_max_order_by
  min: category_types_allowed_min_order_by
  stddev: category_types_allowed_stddev_order_by
  stddev_pop: category_types_allowed_stddev_pop_order_by
  stddev_samp: category_types_allowed_stddev_samp_order_by
  sum: category_types_allowed_sum_order_by
  var_pop: category_types_allowed_var_pop_order_by
  var_samp: category_types_allowed_var_samp_order_by
  variance: category_types_allowed_variance_order_by
}

# input type for inserting array relation for remote table "category_types_allowed"
input category_types_allowed_arr_rel_insert_input {
  data: [category_types_allowed_insert_input!]!
}

# aggregate avg on columns
type category_types_allowed_avg_fields {
  categoryMtid: Float
  typesAllowedMtid: Float
}

# order by avg() on columns of table "category_types_allowed"
input category_types_allowed_avg_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# Boolean expression to filter rows from the table "category_types_allowed". All fields are combined with a logical 'AND'.
input category_types_allowed_bool_exp {
  _and: [category_types_allowed_bool_exp]
  _not: category_types_allowed_bool_exp
  _or: [category_types_allowed_bool_exp]
  category: category_bool_exp
  categoryMtid: bigint_comparison_exp
  publicationType: publication_type_bool_exp
  typesAllowedMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "category_types_allowed"
input category_types_allowed_inc_input {
  categoryMtid: bigint
  typesAllowedMtid: bigint
}

# input type for inserting data into table "category_types_allowed"
input category_types_allowed_insert_input {
  category: category_obj_rel_insert_input
  categoryMtid: bigint
  publicationType: publication_type_obj_rel_insert_input
  typesAllowedMtid: bigint
}

# aggregate max on columns
type category_types_allowed_max_fields {
  categoryMtid: bigint
  typesAllowedMtid: bigint
}

# order by max() on columns of table "category_types_allowed"
input category_types_allowed_max_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate min on columns
type category_types_allowed_min_fields {
  categoryMtid: bigint
  typesAllowedMtid: bigint
}

# order by min() on columns of table "category_types_allowed"
input category_types_allowed_min_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# response of any mutation on the table "category_types_allowed"
type category_types_allowed_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [category_types_allowed!]!
}

# input type for inserting object relation for remote table "category_types_allowed"
input category_types_allowed_obj_rel_insert_input {
  data: category_types_allowed_insert_input!
}

# ordering options when selecting data from "category_types_allowed"
input category_types_allowed_order_by {
  category: category_order_by
  categoryMtid: order_by
  publicationType: publication_type_order_by
  typesAllowedMtid: order_by
}

# select columns of table "category_types_allowed"
enum category_types_allowed_select_column {
  # column name
  categoryMtid

  # column name
  typesAllowedMtid
}

# input type for updating data in table "category_types_allowed"
input category_types_allowed_set_input {
  categoryMtid: bigint
  typesAllowedMtid: bigint
}

# aggregate stddev on columns
type category_types_allowed_stddev_fields {
  categoryMtid: Float
  typesAllowedMtid: Float
}

# order by stddev() on columns of table "category_types_allowed"
input category_types_allowed_stddev_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate stddev_pop on columns
type category_types_allowed_stddev_pop_fields {
  categoryMtid: Float
  typesAllowedMtid: Float
}

# order by stddev_pop() on columns of table "category_types_allowed"
input category_types_allowed_stddev_pop_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate stddev_samp on columns
type category_types_allowed_stddev_samp_fields {
  categoryMtid: Float
  typesAllowedMtid: Float
}

# order by stddev_samp() on columns of table "category_types_allowed"
input category_types_allowed_stddev_samp_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate sum on columns
type category_types_allowed_sum_fields {
  categoryMtid: bigint
  typesAllowedMtid: bigint
}

# order by sum() on columns of table "category_types_allowed"
input category_types_allowed_sum_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate var_pop on columns
type category_types_allowed_var_pop_fields {
  categoryMtid: Float
  typesAllowedMtid: Float
}

# order by var_pop() on columns of table "category_types_allowed"
input category_types_allowed_var_pop_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate var_samp on columns
type category_types_allowed_var_samp_fields {
  categoryMtid: Float
  typesAllowedMtid: Float
}

# order by var_samp() on columns of table "category_types_allowed"
input category_types_allowed_var_samp_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# aggregate variance on columns
type category_types_allowed_variance_fields {
  categoryMtid: Float
  typesAllowedMtid: Float
}

# order by variance() on columns of table "category_types_allowed"
input category_types_allowed_variance_order_by {
  categoryMtid: order_by
  typesAllowedMtid: order_by
}

# update columns of table "category"
enum category_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  excludeFromOaStats

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  scientific

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type category_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "category"
input category_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type category_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "category"
input category_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type category_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "category"
input category_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "citation"
type citation {
  adminApproved: timestamp

  # An object relationship
  adminApprover: users
  adminApproverForSort: String
  adminApproverMtid: bigint
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  checked: timestamp

  # An object relationship
  checker: users
  checkerMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  externalCitation: Boolean
  externalCitationOK: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mentionCount: Int

  # An array relationship
  mentions(
    # distinct select on columns
    distinct_on: [mention_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mention_order_by!]

    # filter the rows returned
    where: mention_bool_exp
  ): [mention!]!

  # An aggregated array relationship
  mentions_aggregate(
    # distinct select on columns
    distinct_on: [mention_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mention_order_by!]

    # filter the rows returned
    where: mention_bool_exp
  ): mention_aggregate!
  mtid: bigint!
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint

  # An object relationship
  publication: publication
  publicationForSort: String
  publicationMtid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  related: publication
  relatedForSort: String
  relatedMtid: bigint
  source: String
  status: Int
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp

  # An object relationship
  validator: users
  validatorForSort: String
  validatorMtid: bigint
}

# aggregated selection of "citation"
type citation_aggregate {
  aggregate: citation_aggregate_fields
  nodes: [citation!]!
}

# aggregate fields of "citation"
type citation_aggregate_fields {
  avg: citation_avg_fields
  count(columns: [citation_select_column!], distinct: Boolean): Int
  max: citation_max_fields
  min: citation_min_fields
  stddev: citation_stddev_fields
  stddev_pop: citation_stddev_pop_fields
  stddev_samp: citation_stddev_samp_fields
  sum: citation_sum_fields
  var_pop: citation_var_pop_fields
  var_samp: citation_var_samp_fields
  variance: citation_variance_fields
}

# order by aggregate values of table "citation"
input citation_aggregate_order_by {
  avg: citation_avg_order_by
  count: order_by
  max: citation_max_order_by
  min: citation_min_order_by
  stddev: citation_stddev_order_by
  stddev_pop: citation_stddev_pop_order_by
  stddev_samp: citation_stddev_samp_order_by
  sum: citation_sum_order_by
  var_pop: citation_var_pop_order_by
  var_samp: citation_var_samp_order_by
  variance: citation_variance_order_by
}

# input type for inserting array relation for remote table "citation"
input citation_arr_rel_insert_input {
  data: [citation_insert_input!]!
  on_conflict: citation_on_conflict
}

# aggregate avg on columns
type citation_avg_fields {
  adminApproverMtid: Float
  approverMtid: Float
  checkerMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mentionCount: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  relatedMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
}

# order by avg() on columns of table "citation"
input citation_avg_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# Boolean expression to filter rows from the table "citation". All fields are combined with a logical 'AND'.
input citation_bool_exp {
  _and: [citation_bool_exp]
  _not: citation_bool_exp
  _or: [citation_bool_exp]
  adminApproved: timestamp_comparison_exp
  adminApprover: users_bool_exp
  adminApproverForSort: String_comparison_exp
  adminApproverMtid: bigint_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  checked: timestamp_comparison_exp
  checker: users_bool_exp
  checkerMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  context: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  externalCitation: Boolean_comparison_exp
  externalCitationOK: Boolean_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mentionCount: Int_comparison_exp
  mentions: mention_bool_exp
  mtid: bigint_comparison_exp
  note: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  page: String_comparison_exp
  prevValid: bigint_comparison_exp
  publication: publication_bool_exp
  publicationForSort: String_comparison_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  related: publication_bool_exp
  relatedForSort: String_comparison_exp
  relatedMtid: bigint_comparison_exp
  source: String_comparison_exp
  status: Int_comparison_exp
  tempLocked: timestamp_comparison_exp
  tempLockerIdString: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  validated: timestamp_comparison_exp
  validator: users_bool_exp
  validatorForSort: String_comparison_exp
  validatorMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "citation"
enum citation_constraint {
  # unique or primary key constraint
  citation_pkey
}

# input type for incrementing integer column in table "citation"
input citation_inc_input {
  adminApproverMtid: bigint
  approverMtid: bigint
  checkerMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mentionCount: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  relatedMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validatorMtid: bigint
}

# input type for inserting data into table "citation"
input citation_insert_input {
  adminApproved: timestamp
  adminApprover: users_obj_rel_insert_input
  adminApproverForSort: String
  adminApproverMtid: bigint
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  checked: timestamp
  checker: users_obj_rel_insert_input
  checkerMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  externalCitation: Boolean
  externalCitationOK: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mentionCount: Int
  mentions: mention_arr_rel_insert_input
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  publication: publication_obj_rel_insert_input
  publicationForSort: String
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  related: publication_obj_rel_insert_input
  relatedForSort: String
  relatedMtid: bigint
  source: String
  status: Int
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validator: users_obj_rel_insert_input
  validatorForSort: String
  validatorMtid: bigint
}

# aggregate max on columns
type citation_max_fields {
  adminApproved: timestamp
  adminApproverForSort: String
  adminApproverMtid: bigint
  approved: timestamp
  approverMtid: bigint
  checked: timestamp
  checkerMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mentionCount: Int
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  publicationForSort: String
  publicationMtid: bigint
  relatedForSort: String
  relatedMtid: bigint
  source: String
  status: Int
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validatorForSort: String
  validatorMtid: bigint
}

# order by max() on columns of table "citation"
input citation_max_order_by {
  adminApproved: order_by
  adminApproverForSort: order_by
  adminApproverMtid: order_by
  approved: order_by
  approverMtid: order_by
  checked: order_by
  checkerMtid: order_by
  comment: order_by
  comment2: order_by
  context: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  note: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  page: order_by
  prevValid: order_by
  publicationForSort: order_by
  publicationMtid: order_by
  relatedForSort: order_by
  relatedMtid: order_by
  source: order_by
  status: order_by
  tempLocked: order_by
  tempLockerIdString: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validated: order_by
  validatorForSort: order_by
  validatorMtid: order_by
}

# aggregate min on columns
type citation_min_fields {
  adminApproved: timestamp
  adminApproverForSort: String
  adminApproverMtid: bigint
  approved: timestamp
  approverMtid: bigint
  checked: timestamp
  checkerMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mentionCount: Int
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  publicationForSort: String
  publicationMtid: bigint
  relatedForSort: String
  relatedMtid: bigint
  source: String
  status: Int
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validatorForSort: String
  validatorMtid: bigint
}

# order by min() on columns of table "citation"
input citation_min_order_by {
  adminApproved: order_by
  adminApproverForSort: order_by
  adminApproverMtid: order_by
  approved: order_by
  approverMtid: order_by
  checked: order_by
  checkerMtid: order_by
  comment: order_by
  comment2: order_by
  context: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  note: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  page: order_by
  prevValid: order_by
  publicationForSort: order_by
  publicationMtid: order_by
  relatedForSort: order_by
  relatedMtid: order_by
  source: order_by
  status: order_by
  tempLocked: order_by
  tempLockerIdString: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validated: order_by
  validatorForSort: order_by
  validatorMtid: order_by
}

# response of any mutation on the table "citation"
type citation_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [citation!]!
}

# input type for inserting object relation for remote table "citation"
input citation_obj_rel_insert_input {
  data: citation_insert_input!
  on_conflict: citation_on_conflict
}

# on conflict condition type for table "citation"
input citation_on_conflict {
  constraint: citation_constraint!
  update_columns: [citation_update_column!]!
  where: citation_bool_exp
}

# ordering options when selecting data from "citation"
input citation_order_by {
  adminApproved: order_by
  adminApprover: users_order_by
  adminApproverForSort: order_by
  adminApproverMtid: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  checked: order_by
  checker: users_order_by
  checkerMtid: order_by
  comment: order_by
  comment2: order_by
  context: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  externalCitation: order_by
  externalCitationOK: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mentionCount: order_by
  mentions_aggregate: mention_aggregate_order_by
  mtid: order_by
  note: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  page: order_by
  prevValid: order_by
  publication: publication_order_by
  publicationForSort: order_by
  publicationMtid: order_by
  published: order_by
  refreshed: order_by
  related: publication_order_by
  relatedForSort: order_by
  relatedMtid: order_by
  source: order_by
  status: order_by
  tempLocked: order_by
  tempLockerIdString: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validated: order_by
  validator: users_order_by
  validatorForSort: order_by
  validatorMtid: order_by
}

# primary key columns input for table: "citation"
input citation_pk_columns_input {
  mtid: bigint!
}

# select columns of table "citation"
enum citation_select_column {
  # column name
  adminApproved

  # column name
  adminApproverForSort

  # column name
  adminApproverMtid

  # column name
  approved

  # column name
  approverMtid

  # column name
  checked

  # column name
  checkerMtid

  # column name
  comment

  # column name
  comment2

  # column name
  context

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  externalCitation

  # column name
  externalCitationOK

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mentionCount

  # column name
  mtid

  # column name
  note

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  page

  # column name
  prevValid

  # column name
  publicationForSort

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  relatedForSort

  # column name
  relatedMtid

  # column name
  source

  # column name
  status

  # column name
  tempLocked

  # column name
  tempLockerIdString

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  validated

  # column name
  validatorForSort

  # column name
  validatorMtid
}

# input type for updating data in table "citation"
input citation_set_input {
  adminApproved: timestamp
  adminApproverForSort: String
  adminApproverMtid: bigint
  approved: timestamp
  approverMtid: bigint
  checked: timestamp
  checkerMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  externalCitation: Boolean
  externalCitationOK: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mentionCount: Int
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  publicationForSort: String
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  relatedForSort: String
  relatedMtid: bigint
  source: String
  status: Int
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validatorForSort: String
  validatorMtid: bigint
}

# aggregate stddev on columns
type citation_stddev_fields {
  adminApproverMtid: Float
  approverMtid: Float
  checkerMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mentionCount: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  relatedMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
}

# order by stddev() on columns of table "citation"
input citation_stddev_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate stddev_pop on columns
type citation_stddev_pop_fields {
  adminApproverMtid: Float
  approverMtid: Float
  checkerMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mentionCount: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  relatedMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
}

# order by stddev_pop() on columns of table "citation"
input citation_stddev_pop_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate stddev_samp on columns
type citation_stddev_samp_fields {
  adminApproverMtid: Float
  approverMtid: Float
  checkerMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mentionCount: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  relatedMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
}

# order by stddev_samp() on columns of table "citation"
input citation_stddev_samp_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate sum on columns
type citation_sum_fields {
  adminApproverMtid: bigint
  approverMtid: bigint
  checkerMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mentionCount: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  relatedMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validatorMtid: bigint
}

# order by sum() on columns of table "citation"
input citation_sum_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# update columns of table "citation"
enum citation_update_column {
  # column name
  adminApproved

  # column name
  adminApproverForSort

  # column name
  adminApproverMtid

  # column name
  approved

  # column name
  approverMtid

  # column name
  checked

  # column name
  checkerMtid

  # column name
  comment

  # column name
  comment2

  # column name
  context

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  externalCitation

  # column name
  externalCitationOK

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mentionCount

  # column name
  mtid

  # column name
  note

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  page

  # column name
  prevValid

  # column name
  publicationForSort

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  relatedForSort

  # column name
  relatedMtid

  # column name
  source

  # column name
  status

  # column name
  tempLocked

  # column name
  tempLockerIdString

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  validated

  # column name
  validatorForSort

  # column name
  validatorMtid
}

# aggregate var_pop on columns
type citation_var_pop_fields {
  adminApproverMtid: Float
  approverMtid: Float
  checkerMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mentionCount: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  relatedMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
}

# order by var_pop() on columns of table "citation"
input citation_var_pop_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate var_samp on columns
type citation_var_samp_fields {
  adminApproverMtid: Float
  approverMtid: Float
  checkerMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mentionCount: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  relatedMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
}

# order by var_samp() on columns of table "citation"
input citation_var_samp_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate variance on columns
type citation_variance_fields {
  adminApproverMtid: Float
  approverMtid: Float
  checkerMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mentionCount: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  relatedMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
}

# order by variance() on columns of table "citation"
input citation_variance_order_by {
  adminApproverMtid: order_by
  approverMtid: order_by
  checkerMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mentionCount: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  relatedMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# columns and relationships of "classification"
type classification {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An array relationship
  children(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): [classification_parents!]!

  # An aggregated array relationship
  children_aggregate(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): classification_parents_aggregate!
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  fid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int!
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users

  # An array relationship
  mappedFrom(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): [classification_external_mapped_to!]!

  # An aggregated array relationship
  mappedFrom_aggregate(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): classification_external_mapped_to_aggregate!
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent_mtid: bigint

  # An array relationship
  parents(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): [classification_parents!]!

  # An aggregated array relationship
  parents_aggregate(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): classification_parents_aggregate!
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "classification"
type classification_aggregate {
  aggregate: classification_aggregate_fields
  nodes: [classification!]!
}

# aggregate fields of "classification"
type classification_aggregate_fields {
  avg: classification_avg_fields
  count(columns: [classification_select_column!], distinct: Boolean): Int
  max: classification_max_fields
  min: classification_min_fields
  stddev: classification_stddev_fields
  stddev_pop: classification_stddev_pop_fields
  stddev_samp: classification_stddev_samp_fields
  sum: classification_sum_fields
  var_pop: classification_var_pop_fields
  var_samp: classification_var_samp_fields
  variance: classification_variance_fields
}

# order by aggregate values of table "classification"
input classification_aggregate_order_by {
  avg: classification_avg_order_by
  count: order_by
  max: classification_max_order_by
  min: classification_min_order_by
  stddev: classification_stddev_order_by
  stddev_pop: classification_stddev_pop_order_by
  stddev_samp: classification_stddev_samp_order_by
  sum: classification_sum_order_by
  var_pop: classification_var_pop_order_by
  var_samp: classification_var_samp_order_by
  variance: classification_variance_order_by
}

# input type for inserting array relation for remote table "classification"
input classification_arr_rel_insert_input {
  data: [classification_insert_input!]!
  on_conflict: classification_on_conflict
}

# aggregate avg on columns
type classification_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  fid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parent_mtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "classification"
input classification_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "classification". All fields are combined with a logical 'AND'.
input classification_bool_exp {
  _and: [classification_bool_exp]
  _not: classification_bool_exp
  _or: [classification_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  children: classification_parents_bool_exp
  code: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  fid: bigint_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  level: Int_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mappedFrom: classification_external_mapped_to_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parent_mtid: bigint_comparison_exp
  parents: classification_parents_bool_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  useCount: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "classification"
enum classification_constraint {
  # unique or primary key constraint
  classification_pkey
}

# columns and relationships of "classification_external"
type classification_external {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An array relationship
  children(
    # distinct select on columns
    distinct_on: [classification_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_order_by!]

    # filter the rows returned
    where: classification_external_bool_exp
  ): [classification_external!]!

  # An aggregated array relationship
  children_aggregate(
    # distinct select on columns
    distinct_on: [classification_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_order_by!]

    # filter the rows returned
    where: classification_external_bool_exp
  ): classification_external_aggregate!
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int!
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users

  # An array relationship
  mappedTo(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): [classification_external_mapped_to!]!

  # An aggregated array relationship
  mappedTo_aggregate(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): classification_external_mapped_to_aggregate!
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An object relationship
  parent: classification_external
  parentMtid: bigint
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An object relationship
  tree: classification_tree
  treeMtid: bigint
  unhandledTickets: Int!
  useCount: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "classification_external"
type classification_external_aggregate {
  aggregate: classification_external_aggregate_fields
  nodes: [classification_external!]!
}

# aggregate fields of "classification_external"
type classification_external_aggregate_fields {
  avg: classification_external_avg_fields
  count(columns: [classification_external_select_column!], distinct: Boolean): Int
  max: classification_external_max_fields
  min: classification_external_min_fields
  stddev: classification_external_stddev_fields
  stddev_pop: classification_external_stddev_pop_fields
  stddev_samp: classification_external_stddev_samp_fields
  sum: classification_external_sum_fields
  var_pop: classification_external_var_pop_fields
  var_samp: classification_external_var_samp_fields
  variance: classification_external_variance_fields
}

# order by aggregate values of table "classification_external"
input classification_external_aggregate_order_by {
  avg: classification_external_avg_order_by
  count: order_by
  max: classification_external_max_order_by
  min: classification_external_min_order_by
  stddev: classification_external_stddev_order_by
  stddev_pop: classification_external_stddev_pop_order_by
  stddev_samp: classification_external_stddev_samp_order_by
  sum: classification_external_sum_order_by
  var_pop: classification_external_var_pop_order_by
  var_samp: classification_external_var_samp_order_by
  variance: classification_external_variance_order_by
}

# input type for inserting array relation for remote table "classification_external"
input classification_external_arr_rel_insert_input {
  data: [classification_external_insert_input!]!
  on_conflict: classification_external_on_conflict
}

# aggregate avg on columns
type classification_external_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  treeMtid: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "classification_external"
input classification_external_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "classification_external". All fields are combined with a logical 'AND'.
input classification_external_bool_exp {
  _and: [classification_external_bool_exp]
  _not: classification_external_bool_exp
  _or: [classification_external_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  children: classification_external_bool_exp
  code: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  level: Int_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mappedTo: classification_external_mapped_to_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parent: classification_external_bool_exp
  parentMtid: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  tree: classification_tree_bool_exp
  treeMtid: bigint_comparison_exp
  unhandledTickets: Int_comparison_exp
  useCount: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "classification_external"
enum classification_external_constraint {
  # unique or primary key constraint
  classification_external_pkey
}

# input type for incrementing integer column in table "classification_external"
input classification_external_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  level: Int
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentMtid: bigint
  prevValid: bigint
  status: Int
  treeMtid: bigint
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "classification_external"
input classification_external_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  children: classification_external_arr_rel_insert_input
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mappedTo: classification_external_mapped_to_arr_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent: classification_external_obj_rel_insert_input
  parentMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  tree: classification_tree_obj_rel_insert_input
  treeMtid: bigint
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# columns and relationships of "classification_external_mapped_to"
type classification_external_mapped_to {
  # An object relationship
  classification: classification!

  # An object relationship
  classificationExternal: classification_external!
  mappedFromMtid: bigint!
  mappedToMtid: bigint!
}

# aggregated selection of "classification_external_mapped_to"
type classification_external_mapped_to_aggregate {
  aggregate: classification_external_mapped_to_aggregate_fields
  nodes: [classification_external_mapped_to!]!
}

# aggregate fields of "classification_external_mapped_to"
type classification_external_mapped_to_aggregate_fields {
  avg: classification_external_mapped_to_avg_fields
  count(columns: [classification_external_mapped_to_select_column!], distinct: Boolean): Int
  max: classification_external_mapped_to_max_fields
  min: classification_external_mapped_to_min_fields
  stddev: classification_external_mapped_to_stddev_fields
  stddev_pop: classification_external_mapped_to_stddev_pop_fields
  stddev_samp: classification_external_mapped_to_stddev_samp_fields
  sum: classification_external_mapped_to_sum_fields
  var_pop: classification_external_mapped_to_var_pop_fields
  var_samp: classification_external_mapped_to_var_samp_fields
  variance: classification_external_mapped_to_variance_fields
}

# order by aggregate values of table "classification_external_mapped_to"
input classification_external_mapped_to_aggregate_order_by {
  avg: classification_external_mapped_to_avg_order_by
  count: order_by
  max: classification_external_mapped_to_max_order_by
  min: classification_external_mapped_to_min_order_by
  stddev: classification_external_mapped_to_stddev_order_by
  stddev_pop: classification_external_mapped_to_stddev_pop_order_by
  stddev_samp: classification_external_mapped_to_stddev_samp_order_by
  sum: classification_external_mapped_to_sum_order_by
  var_pop: classification_external_mapped_to_var_pop_order_by
  var_samp: classification_external_mapped_to_var_samp_order_by
  variance: classification_external_mapped_to_variance_order_by
}

# input type for inserting array relation for remote table "classification_external_mapped_to"
input classification_external_mapped_to_arr_rel_insert_input {
  data: [classification_external_mapped_to_insert_input!]!
}

# aggregate avg on columns
type classification_external_mapped_to_avg_fields {
  mappedFromMtid: Float
  mappedToMtid: Float
}

# order by avg() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_avg_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# Boolean expression to filter rows from the table
# "classification_external_mapped_to". All fields are combined with a logical 'AND'.
input classification_external_mapped_to_bool_exp {
  _and: [classification_external_mapped_to_bool_exp]
  _not: classification_external_mapped_to_bool_exp
  _or: [classification_external_mapped_to_bool_exp]
  classification: classification_bool_exp
  classificationExternal: classification_external_bool_exp
  mappedFromMtid: bigint_comparison_exp
  mappedToMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "classification_external_mapped_to"
input classification_external_mapped_to_inc_input {
  mappedFromMtid: bigint
  mappedToMtid: bigint
}

# input type for inserting data into table "classification_external_mapped_to"
input classification_external_mapped_to_insert_input {
  classification: classification_obj_rel_insert_input
  classificationExternal: classification_external_obj_rel_insert_input
  mappedFromMtid: bigint
  mappedToMtid: bigint
}

# aggregate max on columns
type classification_external_mapped_to_max_fields {
  mappedFromMtid: bigint
  mappedToMtid: bigint
}

# order by max() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_max_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate min on columns
type classification_external_mapped_to_min_fields {
  mappedFromMtid: bigint
  mappedToMtid: bigint
}

# order by min() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_min_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# response of any mutation on the table "classification_external_mapped_to"
type classification_external_mapped_to_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [classification_external_mapped_to!]!
}

# input type for inserting object relation for remote table "classification_external_mapped_to"
input classification_external_mapped_to_obj_rel_insert_input {
  data: classification_external_mapped_to_insert_input!
}

# ordering options when selecting data from "classification_external_mapped_to"
input classification_external_mapped_to_order_by {
  classification: classification_order_by
  classificationExternal: classification_external_order_by
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# select columns of table "classification_external_mapped_to"
enum classification_external_mapped_to_select_column {
  # column name
  mappedFromMtid

  # column name
  mappedToMtid
}

# input type for updating data in table "classification_external_mapped_to"
input classification_external_mapped_to_set_input {
  mappedFromMtid: bigint
  mappedToMtid: bigint
}

# aggregate stddev on columns
type classification_external_mapped_to_stddev_fields {
  mappedFromMtid: Float
  mappedToMtid: Float
}

# order by stddev() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_stddev_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate stddev_pop on columns
type classification_external_mapped_to_stddev_pop_fields {
  mappedFromMtid: Float
  mappedToMtid: Float
}

# order by stddev_pop() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_stddev_pop_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate stddev_samp on columns
type classification_external_mapped_to_stddev_samp_fields {
  mappedFromMtid: Float
  mappedToMtid: Float
}

# order by stddev_samp() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_stddev_samp_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate sum on columns
type classification_external_mapped_to_sum_fields {
  mappedFromMtid: bigint
  mappedToMtid: bigint
}

# order by sum() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_sum_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate var_pop on columns
type classification_external_mapped_to_var_pop_fields {
  mappedFromMtid: Float
  mappedToMtid: Float
}

# order by var_pop() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_var_pop_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate var_samp on columns
type classification_external_mapped_to_var_samp_fields {
  mappedFromMtid: Float
  mappedToMtid: Float
}

# order by var_samp() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_var_samp_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate variance on columns
type classification_external_mapped_to_variance_fields {
  mappedFromMtid: Float
  mappedToMtid: Float
}

# order by variance() on columns of table "classification_external_mapped_to"
input classification_external_mapped_to_variance_order_by {
  mappedFromMtid: order_by
  mappedToMtid: order_by
}

# aggregate max on columns
type classification_external_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  treeMtid: bigint
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "classification_external"
input classification_external_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type classification_external_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  treeMtid: bigint
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "classification_external"
input classification_external_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "classification_external"
type classification_external_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [classification_external!]!
}

# input type for inserting object relation for remote table "classification_external"
input classification_external_obj_rel_insert_input {
  data: classification_external_insert_input!
  on_conflict: classification_external_on_conflict
}

# on conflict condition type for table "classification_external"
input classification_external_on_conflict {
  constraint: classification_external_constraint!
  update_columns: [classification_external_update_column!]!
  where: classification_external_bool_exp
}

# ordering options when selecting data from "classification_external"
input classification_external_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  children_aggregate: classification_external_aggregate_order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mappedTo_aggregate: classification_external_mapped_to_aggregate_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parent: classification_external_order_by
  parentMtid: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  tree: classification_tree_order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "classification_external"
input classification_external_pk_columns_input {
  mtid: bigint!
}

# select columns of table "classification_external"
enum classification_external_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  level

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  treeMtid

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "classification_external"
input classification_external_set_input {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  treeMtid: bigint
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type classification_external_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  treeMtid: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "classification_external"
input classification_external_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type classification_external_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  treeMtid: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "classification_external"
input classification_external_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type classification_external_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  treeMtid: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "classification_external"
input classification_external_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type classification_external_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  level: Int
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentMtid: bigint
  prevValid: bigint
  status: Int
  treeMtid: bigint
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "classification_external"
input classification_external_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "classification_external"
enum classification_external_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  level

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  treeMtid

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type classification_external_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  treeMtid: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "classification_external"
input classification_external_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type classification_external_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  treeMtid: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "classification_external"
input classification_external_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type classification_external_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  treeMtid: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "classification_external"
input classification_external_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  treeMtid: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# input type for incrementing integer column in table "classification"
input classification_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  level: Int
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parent_mtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "classification"
input classification_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  children: classification_parents_arr_rel_insert_input
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  fid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mappedFrom: classification_external_mapped_to_arr_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent_mtid: bigint
  parents: classification_parents_arr_rel_insert_input
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type classification_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent_mtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "classification"
input classification_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type classification_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent_mtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "classification"
input classification_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "classification"
type classification_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [classification!]!
}

# input type for inserting object relation for remote table "classification"
input classification_obj_rel_insert_input {
  data: classification_insert_input!
  on_conflict: classification_on_conflict
}

# on conflict condition type for table "classification"
input classification_on_conflict {
  constraint: classification_constraint!
  update_columns: [classification_update_column!]!
  where: classification_bool_exp
}

# ordering options when selecting data from "classification"
input classification_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  children_aggregate: classification_parents_aggregate_order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mappedFrom_aggregate: classification_external_mapped_to_aggregate_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parent_mtid: order_by
  parents_aggregate: classification_parents_aggregate_order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "classification_parents"
type classification_parents {
  # An object relationship
  child: classification!
  childrenMtid: bigint!

  # An object relationship
  parent: classification!
  parentsMtid: bigint!
}

# aggregated selection of "classification_parents"
type classification_parents_aggregate {
  aggregate: classification_parents_aggregate_fields
  nodes: [classification_parents!]!
}

# aggregate fields of "classification_parents"
type classification_parents_aggregate_fields {
  avg: classification_parents_avg_fields
  count(columns: [classification_parents_select_column!], distinct: Boolean): Int
  max: classification_parents_max_fields
  min: classification_parents_min_fields
  stddev: classification_parents_stddev_fields
  stddev_pop: classification_parents_stddev_pop_fields
  stddev_samp: classification_parents_stddev_samp_fields
  sum: classification_parents_sum_fields
  var_pop: classification_parents_var_pop_fields
  var_samp: classification_parents_var_samp_fields
  variance: classification_parents_variance_fields
}

# order by aggregate values of table "classification_parents"
input classification_parents_aggregate_order_by {
  avg: classification_parents_avg_order_by
  count: order_by
  max: classification_parents_max_order_by
  min: classification_parents_min_order_by
  stddev: classification_parents_stddev_order_by
  stddev_pop: classification_parents_stddev_pop_order_by
  stddev_samp: classification_parents_stddev_samp_order_by
  sum: classification_parents_sum_order_by
  var_pop: classification_parents_var_pop_order_by
  var_samp: classification_parents_var_samp_order_by
  variance: classification_parents_variance_order_by
}

# input type for inserting array relation for remote table "classification_parents"
input classification_parents_arr_rel_insert_input {
  data: [classification_parents_insert_input!]!
}

# aggregate avg on columns
type classification_parents_avg_fields {
  childrenMtid: Float
  parentsMtid: Float
}

# order by avg() on columns of table "classification_parents"
input classification_parents_avg_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# Boolean expression to filter rows from the table "classification_parents". All fields are combined with a logical 'AND'.
input classification_parents_bool_exp {
  _and: [classification_parents_bool_exp]
  _not: classification_parents_bool_exp
  _or: [classification_parents_bool_exp]
  child: classification_bool_exp
  childrenMtid: bigint_comparison_exp
  parent: classification_bool_exp
  parentsMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "classification_parents"
input classification_parents_inc_input {
  childrenMtid: bigint
  parentsMtid: bigint
}

# input type for inserting data into table "classification_parents"
input classification_parents_insert_input {
  child: classification_obj_rel_insert_input
  childrenMtid: bigint
  parent: classification_obj_rel_insert_input
  parentsMtid: bigint
}

# aggregate max on columns
type classification_parents_max_fields {
  childrenMtid: bigint
  parentsMtid: bigint
}

# order by max() on columns of table "classification_parents"
input classification_parents_max_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# aggregate min on columns
type classification_parents_min_fields {
  childrenMtid: bigint
  parentsMtid: bigint
}

# order by min() on columns of table "classification_parents"
input classification_parents_min_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# response of any mutation on the table "classification_parents"
type classification_parents_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [classification_parents!]!
}

# input type for inserting object relation for remote table "classification_parents"
input classification_parents_obj_rel_insert_input {
  data: classification_parents_insert_input!
}

# ordering options when selecting data from "classification_parents"
input classification_parents_order_by {
  child: classification_order_by
  childrenMtid: order_by
  parent: classification_order_by
  parentsMtid: order_by
}

# select columns of table "classification_parents"
enum classification_parents_select_column {
  # column name
  childrenMtid

  # column name
  parentsMtid
}

# input type for updating data in table "classification_parents"
input classification_parents_set_input {
  childrenMtid: bigint
  parentsMtid: bigint
}

# aggregate stddev on columns
type classification_parents_stddev_fields {
  childrenMtid: Float
  parentsMtid: Float
}

# order by stddev() on columns of table "classification_parents"
input classification_parents_stddev_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# aggregate stddev_pop on columns
type classification_parents_stddev_pop_fields {
  childrenMtid: Float
  parentsMtid: Float
}

# order by stddev_pop() on columns of table "classification_parents"
input classification_parents_stddev_pop_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# aggregate stddev_samp on columns
type classification_parents_stddev_samp_fields {
  childrenMtid: Float
  parentsMtid: Float
}

# order by stddev_samp() on columns of table "classification_parents"
input classification_parents_stddev_samp_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# aggregate sum on columns
type classification_parents_sum_fields {
  childrenMtid: bigint
  parentsMtid: bigint
}

# order by sum() on columns of table "classification_parents"
input classification_parents_sum_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# aggregate var_pop on columns
type classification_parents_var_pop_fields {
  childrenMtid: Float
  parentsMtid: Float
}

# order by var_pop() on columns of table "classification_parents"
input classification_parents_var_pop_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# aggregate var_samp on columns
type classification_parents_var_samp_fields {
  childrenMtid: Float
  parentsMtid: Float
}

# order by var_samp() on columns of table "classification_parents"
input classification_parents_var_samp_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# aggregate variance on columns
type classification_parents_variance_fields {
  childrenMtid: Float
  parentsMtid: Float
}

# order by variance() on columns of table "classification_parents"
input classification_parents_variance_order_by {
  childrenMtid: order_by
  parentsMtid: order_by
}

# primary key columns input for table: "classification"
input classification_pk_columns_input {
  mtid: bigint!
}

# select columns of table "classification"
enum classification_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  level

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parent_mtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "classification"
input classification_set_input {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent_mtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type classification_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  fid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parent_mtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "classification"
input classification_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type classification_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  fid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parent_mtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "classification"
input classification_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type classification_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  fid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parent_mtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "classification"
input classification_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type classification_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  level: Int
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parent_mtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "classification"
input classification_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "classification_tree"
type classification_tree {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "classification_tree"
type classification_tree_aggregate {
  aggregate: classification_tree_aggregate_fields
  nodes: [classification_tree!]!
}

# aggregate fields of "classification_tree"
type classification_tree_aggregate_fields {
  avg: classification_tree_avg_fields
  count(columns: [classification_tree_select_column!], distinct: Boolean): Int
  max: classification_tree_max_fields
  min: classification_tree_min_fields
  stddev: classification_tree_stddev_fields
  stddev_pop: classification_tree_stddev_pop_fields
  stddev_samp: classification_tree_stddev_samp_fields
  sum: classification_tree_sum_fields
  var_pop: classification_tree_var_pop_fields
  var_samp: classification_tree_var_samp_fields
  variance: classification_tree_variance_fields
}

# order by aggregate values of table "classification_tree"
input classification_tree_aggregate_order_by {
  avg: classification_tree_avg_order_by
  count: order_by
  max: classification_tree_max_order_by
  min: classification_tree_min_order_by
  stddev: classification_tree_stddev_order_by
  stddev_pop: classification_tree_stddev_pop_order_by
  stddev_samp: classification_tree_stddev_samp_order_by
  sum: classification_tree_sum_order_by
  var_pop: classification_tree_var_pop_order_by
  var_samp: classification_tree_var_samp_order_by
  variance: classification_tree_variance_order_by
}

# input type for inserting array relation for remote table "classification_tree"
input classification_tree_arr_rel_insert_input {
  data: [classification_tree_insert_input!]!
  on_conflict: classification_tree_on_conflict
}

# aggregate avg on columns
type classification_tree_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "classification_tree"
input classification_tree_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "classification_tree". All fields are combined with a logical 'AND'.
input classification_tree_bool_exp {
  _and: [classification_tree_bool_exp]
  _not: classification_tree_bool_exp
  _or: [classification_tree_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "classification_tree"
enum classification_tree_constraint {
  # unique or primary key constraint
  classification_tree_pkey
}

# input type for incrementing integer column in table "classification_tree"
input classification_tree_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "classification_tree"
input classification_tree_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type classification_tree_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "classification_tree"
input classification_tree_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type classification_tree_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "classification_tree"
input classification_tree_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "classification_tree"
type classification_tree_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [classification_tree!]!
}

# input type for inserting object relation for remote table "classification_tree"
input classification_tree_obj_rel_insert_input {
  data: classification_tree_insert_input!
  on_conflict: classification_tree_on_conflict
}

# on conflict condition type for table "classification_tree"
input classification_tree_on_conflict {
  constraint: classification_tree_constraint!
  update_columns: [classification_tree_update_column!]!
  where: classification_tree_bool_exp
}

# ordering options when selecting data from "classification_tree"
input classification_tree_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "classification_tree"
input classification_tree_pk_columns_input {
  mtid: bigint!
}

# select columns of table "classification_tree"
enum classification_tree_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "classification_tree"
input classification_tree_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type classification_tree_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "classification_tree"
input classification_tree_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type classification_tree_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "classification_tree"
input classification_tree_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type classification_tree_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "classification_tree"
input classification_tree_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type classification_tree_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "classification_tree"
input classification_tree_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "classification_tree"
enum classification_tree_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type classification_tree_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "classification_tree"
input classification_tree_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type classification_tree_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "classification_tree"
input classification_tree_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type classification_tree_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "classification_tree"
input classification_tree_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "classification"
enum classification_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  level

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parent_mtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type classification_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  fid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parent_mtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "classification"
input classification_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type classification_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  fid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parent_mtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "classification"
input classification_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type classification_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  fid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parent_mtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "classification"
input classification_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parent_mtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "conference"
type conference {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  collaboration: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  endDate: timestamp
  error: Int
  fromCitation: Boolean!
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp

  # An array relationship
  location(
    # distinct select on columns
    distinct_on: [conference_location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_location_order_by!]

    # filter the rows returned
    where: conference_location_bool_exp
  ): [conference_location!]!

  # An aggregated array relationship
  location_aggregate(
    # distinct select on columns
    distinct_on: [conference_location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_location_order_by!]

    # filter the rows returned
    where: conference_location_bool_exp
  ): conference_location_aggregate!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  oldId: Int
  oldTimestamp: timestamp

  # An array relationship
  organizers(
    # distinct select on columns
    distinct_on: [conference_organizers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_organizers_order_by!]

    # filter the rows returned
    where: conference_organizers_bool_exp
  ): [conference_organizers!]!

  # An aggregated array relationship
  organizers_aggregate(
    # distinct select on columns
    distinct_on: [conference_organizers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_organizers_order_by!]

    # filter the rows returned
    where: conference_organizers_bool_exp
  ): conference_organizers_aggregate!
  otype: String

  # An array relationship
  papers(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): [publication!]!

  # An aggregated array relationship
  papers_aggregate(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): publication_aggregate!
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "conference"
type conference_aggregate {
  aggregate: conference_aggregate_fields
  nodes: [conference!]!
}

# aggregate fields of "conference"
type conference_aggregate_fields {
  avg: conference_avg_fields
  count(columns: [conference_select_column!], distinct: Boolean): Int
  max: conference_max_fields
  min: conference_min_fields
  stddev: conference_stddev_fields
  stddev_pop: conference_stddev_pop_fields
  stddev_samp: conference_stddev_samp_fields
  sum: conference_sum_fields
  var_pop: conference_var_pop_fields
  var_samp: conference_var_samp_fields
  variance: conference_variance_fields
}

# order by aggregate values of table "conference"
input conference_aggregate_order_by {
  avg: conference_avg_order_by
  count: order_by
  max: conference_max_order_by
  min: conference_min_order_by
  stddev: conference_stddev_order_by
  stddev_pop: conference_stddev_pop_order_by
  stddev_samp: conference_stddev_samp_order_by
  sum: conference_sum_order_by
  var_pop: conference_var_pop_order_by
  var_samp: conference_var_samp_order_by
  variance: conference_variance_order_by
}

# input type for inserting array relation for remote table "conference"
input conference_arr_rel_insert_input {
  data: [conference_insert_input!]!
  on_conflict: conference_on_conflict
}

# aggregate avg on columns
type conference_avg_fields {
  approverMtid: Float
  collaboration: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "conference"
input conference_avg_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "conference". All fields are combined with a logical 'AND'.
input conference_bool_exp {
  _and: [conference_bool_exp]
  _not: conference_bool_exp
  _or: [conference_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  collaboration: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  endDate: timestamp_comparison_exp
  error: Int_comparison_exp
  fromCitation: Boolean_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  location: conference_location_bool_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  organizers: conference_organizers_bool_exp
  otype: String_comparison_exp
  papers: publication_bool_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  startDate: timestamp_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "conference"
enum conference_constraint {
  # unique or primary key constraint
  conference_pkey
}

# input type for incrementing integer column in table "conference"
input conference_inc_input {
  approverMtid: bigint
  collaboration: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "conference"
input conference_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  collaboration: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  endDate: timestamp
  error: Int
  fromCitation: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  location: conference_location_arr_rel_insert_input
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  organizers: conference_organizers_arr_rel_insert_input
  otype: String
  papers: publication_arr_rel_insert_input
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# columns and relationships of "conference_location"
type conference_location {
  conferenceMtid: bigint!

  # An object relationship
  location: location!
  locationMtid: bigint!
}

# aggregated selection of "conference_location"
type conference_location_aggregate {
  aggregate: conference_location_aggregate_fields
  nodes: [conference_location!]!
}

# aggregate fields of "conference_location"
type conference_location_aggregate_fields {
  avg: conference_location_avg_fields
  count(columns: [conference_location_select_column!], distinct: Boolean): Int
  max: conference_location_max_fields
  min: conference_location_min_fields
  stddev: conference_location_stddev_fields
  stddev_pop: conference_location_stddev_pop_fields
  stddev_samp: conference_location_stddev_samp_fields
  sum: conference_location_sum_fields
  var_pop: conference_location_var_pop_fields
  var_samp: conference_location_var_samp_fields
  variance: conference_location_variance_fields
}

# order by aggregate values of table "conference_location"
input conference_location_aggregate_order_by {
  avg: conference_location_avg_order_by
  count: order_by
  max: conference_location_max_order_by
  min: conference_location_min_order_by
  stddev: conference_location_stddev_order_by
  stddev_pop: conference_location_stddev_pop_order_by
  stddev_samp: conference_location_stddev_samp_order_by
  sum: conference_location_sum_order_by
  var_pop: conference_location_var_pop_order_by
  var_samp: conference_location_var_samp_order_by
  variance: conference_location_variance_order_by
}

# input type for inserting array relation for remote table "conference_location"
input conference_location_arr_rel_insert_input {
  data: [conference_location_insert_input!]!
}

# aggregate avg on columns
type conference_location_avg_fields {
  conferenceMtid: Float
  locationMtid: Float
}

# order by avg() on columns of table "conference_location"
input conference_location_avg_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# Boolean expression to filter rows from the table "conference_location". All fields are combined with a logical 'AND'.
input conference_location_bool_exp {
  _and: [conference_location_bool_exp]
  _not: conference_location_bool_exp
  _or: [conference_location_bool_exp]
  conferenceMtid: bigint_comparison_exp
  location: location_bool_exp
  locationMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "conference_location"
input conference_location_inc_input {
  conferenceMtid: bigint
  locationMtid: bigint
}

# input type for inserting data into table "conference_location"
input conference_location_insert_input {
  conferenceMtid: bigint
  location: location_obj_rel_insert_input
  locationMtid: bigint
}

# aggregate max on columns
type conference_location_max_fields {
  conferenceMtid: bigint
  locationMtid: bigint
}

# order by max() on columns of table "conference_location"
input conference_location_max_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate min on columns
type conference_location_min_fields {
  conferenceMtid: bigint
  locationMtid: bigint
}

# order by min() on columns of table "conference_location"
input conference_location_min_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# response of any mutation on the table "conference_location"
type conference_location_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [conference_location!]!
}

# input type for inserting object relation for remote table "conference_location"
input conference_location_obj_rel_insert_input {
  data: conference_location_insert_input!
}

# ordering options when selecting data from "conference_location"
input conference_location_order_by {
  conferenceMtid: order_by
  location: location_order_by
  locationMtid: order_by
}

# select columns of table "conference_location"
enum conference_location_select_column {
  # column name
  conferenceMtid

  # column name
  locationMtid
}

# input type for updating data in table "conference_location"
input conference_location_set_input {
  conferenceMtid: bigint
  locationMtid: bigint
}

# aggregate stddev on columns
type conference_location_stddev_fields {
  conferenceMtid: Float
  locationMtid: Float
}

# order by stddev() on columns of table "conference_location"
input conference_location_stddev_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate stddev_pop on columns
type conference_location_stddev_pop_fields {
  conferenceMtid: Float
  locationMtid: Float
}

# order by stddev_pop() on columns of table "conference_location"
input conference_location_stddev_pop_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate stddev_samp on columns
type conference_location_stddev_samp_fields {
  conferenceMtid: Float
  locationMtid: Float
}

# order by stddev_samp() on columns of table "conference_location"
input conference_location_stddev_samp_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate sum on columns
type conference_location_sum_fields {
  conferenceMtid: bigint
  locationMtid: bigint
}

# order by sum() on columns of table "conference_location"
input conference_location_sum_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate var_pop on columns
type conference_location_var_pop_fields {
  conferenceMtid: Float
  locationMtid: Float
}

# order by var_pop() on columns of table "conference_location"
input conference_location_var_pop_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate var_samp on columns
type conference_location_var_samp_fields {
  conferenceMtid: Float
  locationMtid: Float
}

# order by var_samp() on columns of table "conference_location"
input conference_location_var_samp_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate variance on columns
type conference_location_variance_fields {
  conferenceMtid: Float
  locationMtid: Float
}

# order by variance() on columns of table "conference_location"
input conference_location_variance_order_by {
  conferenceMtid: order_by
  locationMtid: order_by
}

# aggregate max on columns
type conference_max_fields {
  approved: timestamp
  approverMtid: bigint
  collaboration: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "conference"
input conference_max_order_by {
  approved: order_by
  approverMtid: order_by
  collaboration: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type conference_min_fields {
  approved: timestamp
  approverMtid: bigint
  collaboration: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "conference"
input conference_min_order_by {
  approved: order_by
  approverMtid: order_by
  collaboration: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "conference"
type conference_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [conference!]!
}

# input type for inserting object relation for remote table "conference"
input conference_obj_rel_insert_input {
  data: conference_insert_input!
  on_conflict: conference_on_conflict
}

# on conflict condition type for table "conference"
input conference_on_conflict {
  constraint: conference_constraint!
  update_columns: [conference_update_column!]!
  where: conference_bool_exp
}

# ordering options when selecting data from "conference"
input conference_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  collaboration: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  endDate: order_by
  error: order_by
  fromCitation: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  location_aggregate: conference_location_aggregate_order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  organizers_aggregate: conference_organizers_aggregate_order_by
  otype: order_by
  papers_aggregate: publication_aggregate_order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "conference_organizers"
type conference_organizers {
  conferenceMtid: bigint!
  organizersMtid: bigint!

  # An object relationship
  publisher: publisher!
}

# aggregated selection of "conference_organizers"
type conference_organizers_aggregate {
  aggregate: conference_organizers_aggregate_fields
  nodes: [conference_organizers!]!
}

# aggregate fields of "conference_organizers"
type conference_organizers_aggregate_fields {
  avg: conference_organizers_avg_fields
  count(columns: [conference_organizers_select_column!], distinct: Boolean): Int
  max: conference_organizers_max_fields
  min: conference_organizers_min_fields
  stddev: conference_organizers_stddev_fields
  stddev_pop: conference_organizers_stddev_pop_fields
  stddev_samp: conference_organizers_stddev_samp_fields
  sum: conference_organizers_sum_fields
  var_pop: conference_organizers_var_pop_fields
  var_samp: conference_organizers_var_samp_fields
  variance: conference_organizers_variance_fields
}

# order by aggregate values of table "conference_organizers"
input conference_organizers_aggregate_order_by {
  avg: conference_organizers_avg_order_by
  count: order_by
  max: conference_organizers_max_order_by
  min: conference_organizers_min_order_by
  stddev: conference_organizers_stddev_order_by
  stddev_pop: conference_organizers_stddev_pop_order_by
  stddev_samp: conference_organizers_stddev_samp_order_by
  sum: conference_organizers_sum_order_by
  var_pop: conference_organizers_var_pop_order_by
  var_samp: conference_organizers_var_samp_order_by
  variance: conference_organizers_variance_order_by
}

# input type for inserting array relation for remote table "conference_organizers"
input conference_organizers_arr_rel_insert_input {
  data: [conference_organizers_insert_input!]!
}

# aggregate avg on columns
type conference_organizers_avg_fields {
  conferenceMtid: Float
  organizersMtid: Float
}

# order by avg() on columns of table "conference_organizers"
input conference_organizers_avg_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# Boolean expression to filter rows from the table "conference_organizers". All fields are combined with a logical 'AND'.
input conference_organizers_bool_exp {
  _and: [conference_organizers_bool_exp]
  _not: conference_organizers_bool_exp
  _or: [conference_organizers_bool_exp]
  conferenceMtid: bigint_comparison_exp
  organizersMtid: bigint_comparison_exp
  publisher: publisher_bool_exp
}

# input type for incrementing integer column in table "conference_organizers"
input conference_organizers_inc_input {
  conferenceMtid: bigint
  organizersMtid: bigint
}

# input type for inserting data into table "conference_organizers"
input conference_organizers_insert_input {
  conferenceMtid: bigint
  organizersMtid: bigint
  publisher: publisher_obj_rel_insert_input
}

# aggregate max on columns
type conference_organizers_max_fields {
  conferenceMtid: bigint
  organizersMtid: bigint
}

# order by max() on columns of table "conference_organizers"
input conference_organizers_max_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# aggregate min on columns
type conference_organizers_min_fields {
  conferenceMtid: bigint
  organizersMtid: bigint
}

# order by min() on columns of table "conference_organizers"
input conference_organizers_min_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# response of any mutation on the table "conference_organizers"
type conference_organizers_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [conference_organizers!]!
}

# input type for inserting object relation for remote table "conference_organizers"
input conference_organizers_obj_rel_insert_input {
  data: conference_organizers_insert_input!
}

# ordering options when selecting data from "conference_organizers"
input conference_organizers_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
  publisher: publisher_order_by
}

# select columns of table "conference_organizers"
enum conference_organizers_select_column {
  # column name
  conferenceMtid

  # column name
  organizersMtid
}

# input type for updating data in table "conference_organizers"
input conference_organizers_set_input {
  conferenceMtid: bigint
  organizersMtid: bigint
}

# aggregate stddev on columns
type conference_organizers_stddev_fields {
  conferenceMtid: Float
  organizersMtid: Float
}

# order by stddev() on columns of table "conference_organizers"
input conference_organizers_stddev_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# aggregate stddev_pop on columns
type conference_organizers_stddev_pop_fields {
  conferenceMtid: Float
  organizersMtid: Float
}

# order by stddev_pop() on columns of table "conference_organizers"
input conference_organizers_stddev_pop_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# aggregate stddev_samp on columns
type conference_organizers_stddev_samp_fields {
  conferenceMtid: Float
  organizersMtid: Float
}

# order by stddev_samp() on columns of table "conference_organizers"
input conference_organizers_stddev_samp_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# aggregate sum on columns
type conference_organizers_sum_fields {
  conferenceMtid: bigint
  organizersMtid: bigint
}

# order by sum() on columns of table "conference_organizers"
input conference_organizers_sum_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# aggregate var_pop on columns
type conference_organizers_var_pop_fields {
  conferenceMtid: Float
  organizersMtid: Float
}

# order by var_pop() on columns of table "conference_organizers"
input conference_organizers_var_pop_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# aggregate var_samp on columns
type conference_organizers_var_samp_fields {
  conferenceMtid: Float
  organizersMtid: Float
}

# order by var_samp() on columns of table "conference_organizers"
input conference_organizers_var_samp_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# aggregate variance on columns
type conference_organizers_variance_fields {
  conferenceMtid: Float
  organizersMtid: Float
}

# order by variance() on columns of table "conference_organizers"
input conference_organizers_variance_order_by {
  conferenceMtid: order_by
  organizersMtid: order_by
}

# primary key columns input for table: "conference"
input conference_pk_columns_input {
  mtid: bigint!
}

# select columns of table "conference"
enum conference_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  collaboration

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  endDate

  # column name
  error

  # column name
  fromCitation

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "conference"
input conference_set_input {
  approved: timestamp
  approverMtid: bigint
  collaboration: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  endDate: timestamp
  error: Int
  fromCitation: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type conference_stddev_fields {
  approverMtid: Float
  collaboration: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "conference"
input conference_stddev_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type conference_stddev_pop_fields {
  approverMtid: Float
  collaboration: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "conference"
input conference_stddev_pop_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type conference_stddev_samp_fields {
  approverMtid: Float
  collaboration: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "conference"
input conference_stddev_samp_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type conference_sum_fields {
  approverMtid: bigint
  collaboration: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "conference"
input conference_sum_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "conference"
enum conference_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  collaboration

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  endDate

  # column name
  error

  # column name
  fromCitation

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type conference_var_pop_fields {
  approverMtid: Float
  collaboration: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "conference"
input conference_var_pop_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type conference_var_samp_fields {
  approverMtid: Float
  collaboration: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "conference"
input conference_var_samp_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type conference_variance_fields {
  approverMtid: Float
  collaboration: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "conference"
input conference_variance_order_by {
  approverMtid: order_by
  collaboration: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "cron_job"
type cron_job {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  cronExpression: String
  deleted: Boolean!
  deletedDate: timestamp
  disabled: Boolean!
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastRun: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameter: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  runImmediately: Boolean!
  runnableClass: String
  running: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "cron_job"
type cron_job_aggregate {
  aggregate: cron_job_aggregate_fields
  nodes: [cron_job!]!
}

# aggregate fields of "cron_job"
type cron_job_aggregate_fields {
  avg: cron_job_avg_fields
  count(columns: [cron_job_select_column!], distinct: Boolean): Int
  max: cron_job_max_fields
  min: cron_job_min_fields
  stddev: cron_job_stddev_fields
  stddev_pop: cron_job_stddev_pop_fields
  stddev_samp: cron_job_stddev_samp_fields
  sum: cron_job_sum_fields
  var_pop: cron_job_var_pop_fields
  var_samp: cron_job_var_samp_fields
  variance: cron_job_variance_fields
}

# order by aggregate values of table "cron_job"
input cron_job_aggregate_order_by {
  avg: cron_job_avg_order_by
  count: order_by
  max: cron_job_max_order_by
  min: cron_job_min_order_by
  stddev: cron_job_stddev_order_by
  stddev_pop: cron_job_stddev_pop_order_by
  stddev_samp: cron_job_stddev_samp_order_by
  sum: cron_job_sum_order_by
  var_pop: cron_job_var_pop_order_by
  var_samp: cron_job_var_samp_order_by
  variance: cron_job_variance_order_by
}

# input type for inserting array relation for remote table "cron_job"
input cron_job_arr_rel_insert_input {
  data: [cron_job_insert_input!]!
  on_conflict: cron_job_on_conflict
}

# aggregate avg on columns
type cron_job_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "cron_job"
input cron_job_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "cron_job". All fields are combined with a logical 'AND'.
input cron_job_bool_exp {
  _and: [cron_job_bool_exp]
  _not: cron_job_bool_exp
  _or: [cron_job_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  cronExpression: String_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  disabled: Boolean_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastRun: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parameter: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  runImmediately: Boolean_comparison_exp
  runnableClass: String_comparison_exp
  running: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "cron_job"
enum cron_job_constraint {
  # unique or primary key constraint
  cron_job_pkey
}

# input type for incrementing integer column in table "cron_job"
input cron_job_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "cron_job"
input cron_job_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  cronExpression: String
  deleted: Boolean
  deletedDate: timestamp
  disabled: Boolean
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastRun: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameter: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  runImmediately: Boolean
  runnableClass: String
  running: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type cron_job_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronExpression: String
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastRun: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameter: String
  prevValid: bigint
  runnableClass: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "cron_job"
input cron_job_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronExpression: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastRun: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parameter: order_by
  prevValid: order_by
  runnableClass: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type cron_job_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronExpression: String
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastRun: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameter: String
  prevValid: bigint
  runnableClass: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "cron_job"
input cron_job_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronExpression: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastRun: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parameter: order_by
  prevValid: order_by
  runnableClass: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "cron_job"
type cron_job_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [cron_job!]!
}

# input type for inserting object relation for remote table "cron_job"
input cron_job_obj_rel_insert_input {
  data: cron_job_insert_input!
  on_conflict: cron_job_on_conflict
}

# on conflict condition type for table "cron_job"
input cron_job_on_conflict {
  constraint: cron_job_constraint!
  update_columns: [cron_job_update_column!]!
  where: cron_job_bool_exp
}

# ordering options when selecting data from "cron_job"
input cron_job_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  cronExpression: order_by
  deleted: order_by
  deletedDate: order_by
  disabled: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastRun: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parameter: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  runImmediately: order_by
  runnableClass: order_by
  running: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "cron_job"
input cron_job_pk_columns_input {
  mtid: bigint!
}

# columns and relationships of "cron_job_run_request"
type cron_job_run_request {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  cronJobName: String

  # An object relationship
  cronjob: cron_job
  cronjobMtid: bigint
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean!
  queued: Boolean!
  refreshed: Boolean!
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "cron_job_run_request"
type cron_job_run_request_aggregate {
  aggregate: cron_job_run_request_aggregate_fields
  nodes: [cron_job_run_request!]!
}

# aggregate fields of "cron_job_run_request"
type cron_job_run_request_aggregate_fields {
  avg: cron_job_run_request_avg_fields
  count(columns: [cron_job_run_request_select_column!], distinct: Boolean): Int
  max: cron_job_run_request_max_fields
  min: cron_job_run_request_min_fields
  stddev: cron_job_run_request_stddev_fields
  stddev_pop: cron_job_run_request_stddev_pop_fields
  stddev_samp: cron_job_run_request_stddev_samp_fields
  sum: cron_job_run_request_sum_fields
  var_pop: cron_job_run_request_var_pop_fields
  var_samp: cron_job_run_request_var_samp_fields
  variance: cron_job_run_request_variance_fields
}

# order by aggregate values of table "cron_job_run_request"
input cron_job_run_request_aggregate_order_by {
  avg: cron_job_run_request_avg_order_by
  count: order_by
  max: cron_job_run_request_max_order_by
  min: cron_job_run_request_min_order_by
  stddev: cron_job_run_request_stddev_order_by
  stddev_pop: cron_job_run_request_stddev_pop_order_by
  stddev_samp: cron_job_run_request_stddev_samp_order_by
  sum: cron_job_run_request_sum_order_by
  var_pop: cron_job_run_request_var_pop_order_by
  var_samp: cron_job_run_request_var_samp_order_by
  variance: cron_job_run_request_variance_order_by
}

# input type for inserting array relation for remote table "cron_job_run_request"
input cron_job_run_request_arr_rel_insert_input {
  data: [cron_job_run_request_insert_input!]!
  on_conflict: cron_job_run_request_on_conflict
}

# aggregate avg on columns
type cron_job_run_request_avg_fields {
  approverMtid: Float
  creator: Float
  cronjobMtid: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "cron_job_run_request"
input cron_job_run_request_avg_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "cron_job_run_request". All fields are combined with a logical 'AND'.
input cron_job_run_request_bool_exp {
  _and: [cron_job_run_request_bool_exp]
  _not: cron_job_run_request_bool_exp
  _or: [cron_job_run_request_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  cronJobName: String_comparison_exp
  cronjob: cron_job_bool_exp
  cronjobMtid: bigint_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  seen: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "cron_job_run_request"
enum cron_job_run_request_constraint {
  # unique or primary key constraint
  cron_job_run_request_pkey
}

# input type for incrementing integer column in table "cron_job_run_request"
input cron_job_run_request_inc_input {
  approverMtid: bigint
  creator: bigint
  cronjobMtid: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "cron_job_run_request"
input cron_job_run_request_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  cronJobName: String
  cronjob: cron_job_obj_rel_insert_input
  cronjobMtid: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type cron_job_run_request_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronJobName: String
  cronjobMtid: bigint
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "cron_job_run_request"
input cron_job_run_request_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronJobName: order_by
  cronjobMtid: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type cron_job_run_request_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronJobName: String
  cronjobMtid: bigint
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "cron_job_run_request"
input cron_job_run_request_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronJobName: order_by
  cronjobMtid: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "cron_job_run_request"
type cron_job_run_request_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [cron_job_run_request!]!
}

# input type for inserting object relation for remote table "cron_job_run_request"
input cron_job_run_request_obj_rel_insert_input {
  data: cron_job_run_request_insert_input!
  on_conflict: cron_job_run_request_on_conflict
}

# on conflict condition type for table "cron_job_run_request"
input cron_job_run_request_on_conflict {
  constraint: cron_job_run_request_constraint!
  update_columns: [cron_job_run_request_update_column!]!
  where: cron_job_run_request_bool_exp
}

# ordering options when selecting data from "cron_job_run_request"
input cron_job_run_request_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  cronJobName: order_by
  cronjob: cron_job_order_by
  cronjobMtid: order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  queued: order_by
  refreshed: order_by
  seen: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "cron_job_run_request"
input cron_job_run_request_pk_columns_input {
  mtid: bigint!
}

# select columns of table "cron_job_run_request"
enum cron_job_run_request_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronJobName

  # column name
  cronjobMtid

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "cron_job_run_request"
input cron_job_run_request_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronJobName: String
  cronjobMtid: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type cron_job_run_request_stddev_fields {
  approverMtid: Float
  creator: Float
  cronjobMtid: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "cron_job_run_request"
input cron_job_run_request_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type cron_job_run_request_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  cronjobMtid: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "cron_job_run_request"
input cron_job_run_request_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type cron_job_run_request_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  cronjobMtid: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "cron_job_run_request"
input cron_job_run_request_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type cron_job_run_request_sum_fields {
  approverMtid: bigint
  creator: bigint
  cronjobMtid: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "cron_job_run_request"
input cron_job_run_request_sum_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "cron_job_run_request"
enum cron_job_run_request_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronJobName

  # column name
  cronjobMtid

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type cron_job_run_request_var_pop_fields {
  approverMtid: Float
  creator: Float
  cronjobMtid: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "cron_job_run_request"
input cron_job_run_request_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type cron_job_run_request_var_samp_fields {
  approverMtid: Float
  creator: Float
  cronjobMtid: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "cron_job_run_request"
input cron_job_run_request_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type cron_job_run_request_variance_fields {
  approverMtid: Float
  creator: Float
  cronjobMtid: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "cron_job_run_request"
input cron_job_run_request_variance_order_by {
  approverMtid: order_by
  creator: order_by
  cronjobMtid: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# select columns of table "cron_job"
enum cron_job_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronExpression

  # column name
  deleted

  # column name
  deletedDate

  # column name
  disabled

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastRun

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parameter

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  runImmediately

  # column name
  runnableClass

  # column name
  running

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "cron_job"
input cron_job_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronExpression: String
  deleted: Boolean
  deletedDate: timestamp
  disabled: Boolean
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastRun: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameter: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  runImmediately: Boolean
  runnableClass: String
  running: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type cron_job_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "cron_job"
input cron_job_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type cron_job_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "cron_job"
input cron_job_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type cron_job_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "cron_job"
input cron_job_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type cron_job_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "cron_job"
input cron_job_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "cron_job"
enum cron_job_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronExpression

  # column name
  deleted

  # column name
  deletedDate

  # column name
  disabled

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastRun

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parameter

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  runImmediately

  # column name
  runnableClass

  # column name
  running

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type cron_job_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "cron_job"
input cron_job_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type cron_job_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "cron_job"
input cron_job_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type cron_job_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "cron_job"
input cron_job_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

scalar date

# expression to compare columns of type date. All fields are combined with logical 'AND'.
input date_comparison_exp {
  _eq: date
  _gt: date
  _gte: date
  _in: [date!]
  _is_null: Boolean
  _lt: date
  _lte: date
  _neq: date
  _nin: [date!]
}

# columns and relationships of "degree"
type degree {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "degree"
type degree_aggregate {
  aggregate: degree_aggregate_fields
  nodes: [degree!]!
}

# aggregate fields of "degree"
type degree_aggregate_fields {
  avg: degree_avg_fields
  count(columns: [degree_select_column!], distinct: Boolean): Int
  max: degree_max_fields
  min: degree_min_fields
  stddev: degree_stddev_fields
  stddev_pop: degree_stddev_pop_fields
  stddev_samp: degree_stddev_samp_fields
  sum: degree_sum_fields
  var_pop: degree_var_pop_fields
  var_samp: degree_var_samp_fields
  variance: degree_variance_fields
}

# order by aggregate values of table "degree"
input degree_aggregate_order_by {
  avg: degree_avg_order_by
  count: order_by
  max: degree_max_order_by
  min: degree_min_order_by
  stddev: degree_stddev_order_by
  stddev_pop: degree_stddev_pop_order_by
  stddev_samp: degree_stddev_samp_order_by
  sum: degree_sum_order_by
  var_pop: degree_var_pop_order_by
  var_samp: degree_var_samp_order_by
  variance: degree_variance_order_by
}

# input type for inserting array relation for remote table "degree"
input degree_arr_rel_insert_input {
  data: [degree_insert_input!]!
  on_conflict: degree_on_conflict
}

# aggregate avg on columns
type degree_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "degree"
input degree_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "degree". All fields are combined with a logical 'AND'.
input degree_bool_exp {
  _and: [degree_bool_exp]
  _not: degree_bool_exp
  _or: [degree_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "degree"
enum degree_constraint {
  # unique or primary key constraint
  degree_pkey
}

# columns and relationships of "degree_holder"
type degree_holder {
  applicationYear: Int
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  author: users
  authorMtid: bigint
  comment: String
  comment2: String

  # An object relationship
  consultant: users
  consultant2: String
  consultantMtid: bigint
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users

  # An object relationship
  degree: degree
  degreeMtid: bigint
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# aggregated selection of "degree_holder"
type degree_holder_aggregate {
  aggregate: degree_holder_aggregate_fields
  nodes: [degree_holder!]!
}

# aggregate fields of "degree_holder"
type degree_holder_aggregate_fields {
  avg: degree_holder_avg_fields
  count(columns: [degree_holder_select_column!], distinct: Boolean): Int
  max: degree_holder_max_fields
  min: degree_holder_min_fields
  stddev: degree_holder_stddev_fields
  stddev_pop: degree_holder_stddev_pop_fields
  stddev_samp: degree_holder_stddev_samp_fields
  sum: degree_holder_sum_fields
  var_pop: degree_holder_var_pop_fields
  var_samp: degree_holder_var_samp_fields
  variance: degree_holder_variance_fields
}

# order by aggregate values of table "degree_holder"
input degree_holder_aggregate_order_by {
  avg: degree_holder_avg_order_by
  count: order_by
  max: degree_holder_max_order_by
  min: degree_holder_min_order_by
  stddev: degree_holder_stddev_order_by
  stddev_pop: degree_holder_stddev_pop_order_by
  stddev_samp: degree_holder_stddev_samp_order_by
  sum: degree_holder_sum_order_by
  var_pop: degree_holder_var_pop_order_by
  var_samp: degree_holder_var_samp_order_by
  variance: degree_holder_variance_order_by
}

# input type for inserting array relation for remote table "degree_holder"
input degree_holder_arr_rel_insert_input {
  data: [degree_holder_insert_input!]!
  on_conflict: degree_holder_on_conflict
}

# aggregate avg on columns
type degree_holder_avg_fields {
  applicationYear: Float
  approverMtid: Float
  authorMtid: Float
  consultantMtid: Float
  creator: Float
  degreeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by avg() on columns of table "degree_holder"
input degree_holder_avg_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# Boolean expression to filter rows from the table "degree_holder". All fields are combined with a logical 'AND'.
input degree_holder_bool_exp {
  _and: [degree_holder_bool_exp]
  _not: degree_holder_bool_exp
  _or: [degree_holder_bool_exp]
  applicationYear: Int_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  author: users_bool_exp
  authorMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  consultant: users_bool_exp
  consultant2: String_comparison_exp
  consultantMtid: bigint_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  degree: degree_bool_exp
  degreeMtid: bigint_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  year: Int_comparison_exp
}

# unique or primary key constraints on table "degree_holder"
enum degree_holder_constraint {
  # unique or primary key constraint
  degree_holder_pkey
}

# input type for incrementing integer column in table "degree_holder"
input degree_holder_inc_input {
  applicationYear: Int
  approverMtid: bigint
  authorMtid: bigint
  consultantMtid: bigint
  creator: bigint
  degreeMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# input type for inserting data into table "degree_holder"
input degree_holder_insert_input {
  applicationYear: Int
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  author: users_obj_rel_insert_input
  authorMtid: bigint
  comment: String
  comment2: String
  consultant: users_obj_rel_insert_input
  consultant2: String
  consultantMtid: bigint
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  degree: degree_obj_rel_insert_input
  degreeMtid: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# aggregate max on columns
type degree_holder_max_fields {
  applicationYear: Int
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  consultant2: String
  consultantMtid: bigint
  created: timestamp
  creator: bigint
  degreeMtid: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# order by max() on columns of table "degree_holder"
input degree_holder_max_order_by {
  applicationYear: order_by
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  consultant2: order_by
  consultantMtid: order_by
  created: order_by
  creator: order_by
  degreeMtid: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate min on columns
type degree_holder_min_fields {
  applicationYear: Int
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  consultant2: String
  consultantMtid: bigint
  created: timestamp
  creator: bigint
  degreeMtid: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# order by min() on columns of table "degree_holder"
input degree_holder_min_order_by {
  applicationYear: order_by
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  consultant2: order_by
  consultantMtid: order_by
  created: order_by
  creator: order_by
  degreeMtid: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# response of any mutation on the table "degree_holder"
type degree_holder_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [degree_holder!]!
}

# input type for inserting object relation for remote table "degree_holder"
input degree_holder_obj_rel_insert_input {
  data: degree_holder_insert_input!
  on_conflict: degree_holder_on_conflict
}

# on conflict condition type for table "degree_holder"
input degree_holder_on_conflict {
  constraint: degree_holder_constraint!
  update_columns: [degree_holder_update_column!]!
  where: degree_holder_bool_exp
}

# ordering options when selecting data from "degree_holder"
input degree_holder_order_by {
  applicationYear: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  author: users_order_by
  authorMtid: order_by
  comment: order_by
  comment2: order_by
  consultant: users_order_by
  consultant2: order_by
  consultantMtid: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  degree: degree_order_by
  degreeMtid: order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# primary key columns input for table: "degree_holder"
input degree_holder_pk_columns_input {
  mtid: bigint!
}

# select columns of table "degree_holder"
enum degree_holder_select_column {
  # column name
  applicationYear

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  consultant2

  # column name
  consultantMtid

  # column name
  created

  # column name
  creator

  # column name
  degreeMtid

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  year
}

# input type for updating data in table "degree_holder"
input degree_holder_set_input {
  applicationYear: Int
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  comment: String
  comment2: String
  consultant2: String
  consultantMtid: bigint
  created: timestamp
  creator: bigint
  degreeMtid: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# aggregate stddev on columns
type degree_holder_stddev_fields {
  applicationYear: Float
  approverMtid: Float
  authorMtid: Float
  consultantMtid: Float
  creator: Float
  degreeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev() on columns of table "degree_holder"
input degree_holder_stddev_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate stddev_pop on columns
type degree_holder_stddev_pop_fields {
  applicationYear: Float
  approverMtid: Float
  authorMtid: Float
  consultantMtid: Float
  creator: Float
  degreeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev_pop() on columns of table "degree_holder"
input degree_holder_stddev_pop_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate stddev_samp on columns
type degree_holder_stddev_samp_fields {
  applicationYear: Float
  approverMtid: Float
  authorMtid: Float
  consultantMtid: Float
  creator: Float
  degreeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev_samp() on columns of table "degree_holder"
input degree_holder_stddev_samp_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate sum on columns
type degree_holder_sum_fields {
  applicationYear: Int
  approverMtid: bigint
  authorMtid: bigint
  consultantMtid: bigint
  creator: bigint
  degreeMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# order by sum() on columns of table "degree_holder"
input degree_holder_sum_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# update columns of table "degree_holder"
enum degree_holder_update_column {
  # column name
  applicationYear

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  comment

  # column name
  comment2

  # column name
  consultant2

  # column name
  consultantMtid

  # column name
  created

  # column name
  creator

  # column name
  degreeMtid

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  year
}

# aggregate var_pop on columns
type degree_holder_var_pop_fields {
  applicationYear: Float
  approverMtid: Float
  authorMtid: Float
  consultantMtid: Float
  creator: Float
  degreeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by var_pop() on columns of table "degree_holder"
input degree_holder_var_pop_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate var_samp on columns
type degree_holder_var_samp_fields {
  applicationYear: Float
  approverMtid: Float
  authorMtid: Float
  consultantMtid: Float
  creator: Float
  degreeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by var_samp() on columns of table "degree_holder"
input degree_holder_var_samp_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate variance on columns
type degree_holder_variance_fields {
  applicationYear: Float
  approverMtid: Float
  authorMtid: Float
  consultantMtid: Float
  creator: Float
  degreeMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by variance() on columns of table "degree_holder"
input degree_holder_variance_order_by {
  applicationYear: order_by
  approverMtid: order_by
  authorMtid: order_by
  consultantMtid: order_by
  creator: order_by
  degreeMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# input type for incrementing integer column in table "degree"
input degree_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "degree"
input degree_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type degree_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "degree"
input degree_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type degree_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "degree"
input degree_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "degree"
type degree_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [degree!]!
}

# input type for inserting object relation for remote table "degree"
input degree_obj_rel_insert_input {
  data: degree_insert_input!
  on_conflict: degree_on_conflict
}

# on conflict condition type for table "degree"
input degree_on_conflict {
  constraint: degree_constraint!
  update_columns: [degree_update_column!]!
  where: degree_bool_exp
}

# ordering options when selecting data from "degree"
input degree_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "degree"
input degree_pk_columns_input {
  mtid: bigint!
}

# select columns of table "degree"
enum degree_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "degree"
input degree_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type degree_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "degree"
input degree_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type degree_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "degree"
input degree_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type degree_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "degree"
input degree_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type degree_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "degree"
input degree_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "degree"
enum degree_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type degree_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "degree"
input degree_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type degree_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "degree"
input degree_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type degree_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "degree"
input degree_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "discipline"
type discipline {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An array relationship
  children(
    # distinct select on columns
    distinct_on: [discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [discipline_order_by!]

    # filter the rows returned
    where: discipline_bool_exp
  ): [discipline!]!

  # An aggregated array relationship
  children_aggregate(
    # distinct select on columns
    distinct_on: [discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [discipline_order_by!]

    # filter the rows returned
    where: discipline_bool_exp
  ): discipline_aggregate!
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An object relationship
  parent: discipline
  parentMtid: bigint
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "discipline"
type discipline_aggregate {
  aggregate: discipline_aggregate_fields
  nodes: [discipline!]!
}

# aggregate fields of "discipline"
type discipline_aggregate_fields {
  avg: discipline_avg_fields
  count(columns: [discipline_select_column!], distinct: Boolean): Int
  max: discipline_max_fields
  min: discipline_min_fields
  stddev: discipline_stddev_fields
  stddev_pop: discipline_stddev_pop_fields
  stddev_samp: discipline_stddev_samp_fields
  sum: discipline_sum_fields
  var_pop: discipline_var_pop_fields
  var_samp: discipline_var_samp_fields
  variance: discipline_variance_fields
}

# order by aggregate values of table "discipline"
input discipline_aggregate_order_by {
  avg: discipline_avg_order_by
  count: order_by
  max: discipline_max_order_by
  min: discipline_min_order_by
  stddev: discipline_stddev_order_by
  stddev_pop: discipline_stddev_pop_order_by
  stddev_samp: discipline_stddev_samp_order_by
  sum: discipline_sum_order_by
  var_pop: discipline_var_pop_order_by
  var_samp: discipline_var_samp_order_by
  variance: discipline_variance_order_by
}

# input type for inserting array relation for remote table "discipline"
input discipline_arr_rel_insert_input {
  data: [discipline_insert_input!]!
  on_conflict: discipline_on_conflict
}

# aggregate avg on columns
type discipline_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "discipline"
input discipline_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "discipline". All fields are combined with a logical 'AND'.
input discipline_bool_exp {
  _and: [discipline_bool_exp]
  _not: discipline_bool_exp
  _or: [discipline_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  children: discipline_bool_exp
  code: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  level: Int_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parent: discipline_bool_exp
  parentMtid: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  useCount: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "discipline"
enum discipline_constraint {
  # unique or primary key constraint
  discipline_pkey
}

# input type for incrementing integer column in table "discipline"
input discipline_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  level: Int
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "discipline"
input discipline_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  children: discipline_arr_rel_insert_input
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent: discipline_obj_rel_insert_input
  parentMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type discipline_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "discipline"
input discipline_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type discipline_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "discipline"
input discipline_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "discipline"
type discipline_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [discipline!]!
}

# input type for inserting object relation for remote table "discipline"
input discipline_obj_rel_insert_input {
  data: discipline_insert_input!
  on_conflict: discipline_on_conflict
}

# on conflict condition type for table "discipline"
input discipline_on_conflict {
  constraint: discipline_constraint!
  update_columns: [discipline_update_column!]!
  where: discipline_bool_exp
}

# ordering options when selecting data from "discipline"
input discipline_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  children_aggregate: discipline_aggregate_order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  level: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parent: discipline_order_by
  parentMtid: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "discipline"
input discipline_pk_columns_input {
  mtid: bigint!
}

# select columns of table "discipline"
enum discipline_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  level

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "discipline"
input discipline_set_input {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  level: Int
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type discipline_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "discipline"
input discipline_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type discipline_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "discipline"
input discipline_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type discipline_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "discipline"
input discipline_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type discipline_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  level: Int
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "discipline"
input discipline_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "discipline"
enum discipline_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  level

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type discipline_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "discipline"
input discipline_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type discipline_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "discipline"
input discipline_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type discipline_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  level: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "discipline"
input discipline_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  level: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "division_containment"
type division_containment {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  child: organization
  childMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An object relationship
  parent: organization
  parentMtid: bigint
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "division_containment"
type division_containment_aggregate {
  aggregate: division_containment_aggregate_fields
  nodes: [division_containment!]!
}

# aggregate fields of "division_containment"
type division_containment_aggregate_fields {
  avg: division_containment_avg_fields
  count(columns: [division_containment_select_column!], distinct: Boolean): Int
  max: division_containment_max_fields
  min: division_containment_min_fields
  stddev: division_containment_stddev_fields
  stddev_pop: division_containment_stddev_pop_fields
  stddev_samp: division_containment_stddev_samp_fields
  sum: division_containment_sum_fields
  var_pop: division_containment_var_pop_fields
  var_samp: division_containment_var_samp_fields
  variance: division_containment_variance_fields
}

# order by aggregate values of table "division_containment"
input division_containment_aggregate_order_by {
  avg: division_containment_avg_order_by
  count: order_by
  max: division_containment_max_order_by
  min: division_containment_min_order_by
  stddev: division_containment_stddev_order_by
  stddev_pop: division_containment_stddev_pop_order_by
  stddev_samp: division_containment_stddev_samp_order_by
  sum: division_containment_sum_order_by
  var_pop: division_containment_var_pop_order_by
  var_samp: division_containment_var_samp_order_by
  variance: division_containment_variance_order_by
}

# input type for inserting array relation for remote table "division_containment"
input division_containment_arr_rel_insert_input {
  data: [division_containment_insert_input!]!
  on_conflict: division_containment_on_conflict
}

# aggregate avg on columns
type division_containment_avg_fields {
  approverMtid: Float
  childMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "division_containment"
input division_containment_avg_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "division_containment". All fields are combined with a logical 'AND'.
input division_containment_bool_exp {
  _and: [division_containment_bool_exp]
  _not: division_containment_bool_exp
  _or: [division_containment_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  child: organization_bool_exp
  childMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  endDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parent: organization_bool_exp
  parentMtid: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  startDate: timestamp_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "division_containment"
enum division_containment_constraint {
  # unique or primary key constraint
  division_containment_pkey
}

# input type for incrementing integer column in table "division_containment"
input division_containment_inc_input {
  approverMtid: bigint
  childMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "division_containment"
input division_containment_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  child: organization_obj_rel_insert_input
  childMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent: organization_obj_rel_insert_input
  parentMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type division_containment_max_fields {
  approved: timestamp
  approverMtid: bigint
  childMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "division_containment"
input division_containment_max_order_by {
  approved: order_by
  approverMtid: order_by
  childMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentMtid: order_by
  prevValid: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type division_containment_min_fields {
  approved: timestamp
  approverMtid: bigint
  childMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "division_containment"
input division_containment_min_order_by {
  approved: order_by
  approverMtid: order_by
  childMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentMtid: order_by
  prevValid: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "division_containment"
type division_containment_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [division_containment!]!
}

# input type for inserting object relation for remote table "division_containment"
input division_containment_obj_rel_insert_input {
  data: division_containment_insert_input!
  on_conflict: division_containment_on_conflict
}

# on conflict condition type for table "division_containment"
input division_containment_on_conflict {
  constraint: division_containment_constraint!
  update_columns: [division_containment_update_column!]!
  where: division_containment_bool_exp
}

# ordering options when selecting data from "division_containment"
input division_containment_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  child: organization_order_by
  childMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parent: organization_order_by
  parentMtid: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  startDate: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "division_containment"
input division_containment_pk_columns_input {
  mtid: bigint!
}

# select columns of table "division_containment"
enum division_containment_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  childMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "division_containment"
input division_containment_set_input {
  approved: timestamp
  approverMtid: bigint
  childMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  startDate: timestamp
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type division_containment_stddev_fields {
  approverMtid: Float
  childMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "division_containment"
input division_containment_stddev_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type division_containment_stddev_pop_fields {
  approverMtid: Float
  childMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "division_containment"
input division_containment_stddev_pop_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type division_containment_stddev_samp_fields {
  approverMtid: Float
  childMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "division_containment"
input division_containment_stddev_samp_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type division_containment_sum_fields {
  approverMtid: bigint
  childMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "division_containment"
input division_containment_sum_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "division_containment"
enum division_containment_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  childMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  startDate

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type division_containment_var_pop_fields {
  approverMtid: Float
  childMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "division_containment"
input division_containment_var_pop_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type division_containment_var_samp_fields {
  approverMtid: Float
  childMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "division_containment"
input division_containment_var_samp_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type division_containment_variance_fields {
  approverMtid: Float
  childMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "division_containment"
input division_containment_variance_order_by {
  approverMtid: order_by
  childMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "duplum_desc"
type duplum_desc {
  # An array relationship
  bookChaptersMerged(
    # distinct select on columns
    distinct_on: [duplum_desc_book_chapters_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_book_chapters_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_book_chapters_merged_bool_exp
  ): [duplum_desc_book_chapters_merged!]!

  # An aggregated array relationship
  bookChaptersMerged_aggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_book_chapters_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_book_chapters_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_book_chapters_merged_bool_exp
  ): duplum_desc_book_chapters_merged_aggregate!

  # An array relationship
  citationsMerged(
    # distinct select on columns
    distinct_on: [duplum_desc_citations_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_citations_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_citations_merged_bool_exp
  ): [duplum_desc_citations_merged!]!

  # An aggregated array relationship
  citationsMerged_aggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_citations_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_citations_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_citations_merged_bool_exp
  ): duplum_desc_citations_merged_aggregate!
  created: timestamp

  # An object relationship
  creator: users
  creatorMtid: bigint
  descPos: Int
  duplumKeys: String

  # An object relationship
  duplumSearchResult: duplum_search_result
  explicitDuplum: Boolean!
  id: bigint!
  lastModified: timestamp

  # An object relationship
  lastModifier: users
  lastModifierMtid: bigint
  objectMtid: bigint
  resolveType: Int
  role: Int
  searchResult: bigint
}

# aggregated selection of "duplum_desc"
type duplum_desc_aggregate {
  aggregate: duplum_desc_aggregate_fields
  nodes: [duplum_desc!]!
}

# aggregate fields of "duplum_desc"
type duplum_desc_aggregate_fields {
  avg: duplum_desc_avg_fields
  count(columns: [duplum_desc_select_column!], distinct: Boolean): Int
  max: duplum_desc_max_fields
  min: duplum_desc_min_fields
  stddev: duplum_desc_stddev_fields
  stddev_pop: duplum_desc_stddev_pop_fields
  stddev_samp: duplum_desc_stddev_samp_fields
  sum: duplum_desc_sum_fields
  var_pop: duplum_desc_var_pop_fields
  var_samp: duplum_desc_var_samp_fields
  variance: duplum_desc_variance_fields
}

# order by aggregate values of table "duplum_desc"
input duplum_desc_aggregate_order_by {
  avg: duplum_desc_avg_order_by
  count: order_by
  max: duplum_desc_max_order_by
  min: duplum_desc_min_order_by
  stddev: duplum_desc_stddev_order_by
  stddev_pop: duplum_desc_stddev_pop_order_by
  stddev_samp: duplum_desc_stddev_samp_order_by
  sum: duplum_desc_sum_order_by
  var_pop: duplum_desc_var_pop_order_by
  var_samp: duplum_desc_var_samp_order_by
  variance: duplum_desc_variance_order_by
}

# input type for inserting array relation for remote table "duplum_desc"
input duplum_desc_arr_rel_insert_input {
  data: [duplum_desc_insert_input!]!
  on_conflict: duplum_desc_on_conflict
}

# aggregate avg on columns
type duplum_desc_avg_fields {
  creatorMtid: Float
  descPos: Float
  id: Float
  lastModifierMtid: Float
  objectMtid: Float
  resolveType: Float
  role: Float
  searchResult: Float
}

# order by avg() on columns of table "duplum_desc"
input duplum_desc_avg_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# columns and relationships of "duplum_desc_book_chapters_merged"
type duplum_desc_book_chapters_merged {
  bookChaptersMergedMtid: bigint!
  duplumDescId: bigint!

  # An object relationship
  publication: publication!
}

# aggregated selection of "duplum_desc_book_chapters_merged"
type duplum_desc_book_chapters_merged_aggregate {
  aggregate: duplum_desc_book_chapters_merged_aggregate_fields
  nodes: [duplum_desc_book_chapters_merged!]!
}

# aggregate fields of "duplum_desc_book_chapters_merged"
type duplum_desc_book_chapters_merged_aggregate_fields {
  avg: duplum_desc_book_chapters_merged_avg_fields
  count(columns: [duplum_desc_book_chapters_merged_select_column!], distinct: Boolean): Int
  max: duplum_desc_book_chapters_merged_max_fields
  min: duplum_desc_book_chapters_merged_min_fields
  stddev: duplum_desc_book_chapters_merged_stddev_fields
  stddev_pop: duplum_desc_book_chapters_merged_stddev_pop_fields
  stddev_samp: duplum_desc_book_chapters_merged_stddev_samp_fields
  sum: duplum_desc_book_chapters_merged_sum_fields
  var_pop: duplum_desc_book_chapters_merged_var_pop_fields
  var_samp: duplum_desc_book_chapters_merged_var_samp_fields
  variance: duplum_desc_book_chapters_merged_variance_fields
}

# order by aggregate values of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_aggregate_order_by {
  avg: duplum_desc_book_chapters_merged_avg_order_by
  count: order_by
  max: duplum_desc_book_chapters_merged_max_order_by
  min: duplum_desc_book_chapters_merged_min_order_by
  stddev: duplum_desc_book_chapters_merged_stddev_order_by
  stddev_pop: duplum_desc_book_chapters_merged_stddev_pop_order_by
  stddev_samp: duplum_desc_book_chapters_merged_stddev_samp_order_by
  sum: duplum_desc_book_chapters_merged_sum_order_by
  var_pop: duplum_desc_book_chapters_merged_var_pop_order_by
  var_samp: duplum_desc_book_chapters_merged_var_samp_order_by
  variance: duplum_desc_book_chapters_merged_variance_order_by
}

# input type for inserting array relation for remote table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_arr_rel_insert_input {
  data: [duplum_desc_book_chapters_merged_insert_input!]!
}

# aggregate avg on columns
type duplum_desc_book_chapters_merged_avg_fields {
  bookChaptersMergedMtid: Float
  duplumDescId: Float
}

# order by avg() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_avg_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# Boolean expression to filter rows from the table
# "duplum_desc_book_chapters_merged". All fields are combined with a logical 'AND'.
input duplum_desc_book_chapters_merged_bool_exp {
  _and: [duplum_desc_book_chapters_merged_bool_exp]
  _not: duplum_desc_book_chapters_merged_bool_exp
  _or: [duplum_desc_book_chapters_merged_bool_exp]
  bookChaptersMergedMtid: bigint_comparison_exp
  duplumDescId: bigint_comparison_exp
  publication: publication_bool_exp
}

# input type for incrementing integer column in table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_inc_input {
  bookChaptersMergedMtid: bigint
  duplumDescId: bigint
}

# input type for inserting data into table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_insert_input {
  bookChaptersMergedMtid: bigint
  duplumDescId: bigint
  publication: publication_obj_rel_insert_input
}

# aggregate max on columns
type duplum_desc_book_chapters_merged_max_fields {
  bookChaptersMergedMtid: bigint
  duplumDescId: bigint
}

# order by max() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_max_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate min on columns
type duplum_desc_book_chapters_merged_min_fields {
  bookChaptersMergedMtid: bigint
  duplumDescId: bigint
}

# order by min() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_min_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# response of any mutation on the table "duplum_desc_book_chapters_merged"
type duplum_desc_book_chapters_merged_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [duplum_desc_book_chapters_merged!]!
}

# input type for inserting object relation for remote table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_obj_rel_insert_input {
  data: duplum_desc_book_chapters_merged_insert_input!
}

# ordering options when selecting data from "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
  publication: publication_order_by
}

# select columns of table "duplum_desc_book_chapters_merged"
enum duplum_desc_book_chapters_merged_select_column {
  # column name
  bookChaptersMergedMtid

  # column name
  duplumDescId
}

# input type for updating data in table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_set_input {
  bookChaptersMergedMtid: bigint
  duplumDescId: bigint
}

# aggregate stddev on columns
type duplum_desc_book_chapters_merged_stddev_fields {
  bookChaptersMergedMtid: Float
  duplumDescId: Float
}

# order by stddev() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_stddev_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate stddev_pop on columns
type duplum_desc_book_chapters_merged_stddev_pop_fields {
  bookChaptersMergedMtid: Float
  duplumDescId: Float
}

# order by stddev_pop() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_stddev_pop_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate stddev_samp on columns
type duplum_desc_book_chapters_merged_stddev_samp_fields {
  bookChaptersMergedMtid: Float
  duplumDescId: Float
}

# order by stddev_samp() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_stddev_samp_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate sum on columns
type duplum_desc_book_chapters_merged_sum_fields {
  bookChaptersMergedMtid: bigint
  duplumDescId: bigint
}

# order by sum() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_sum_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate var_pop on columns
type duplum_desc_book_chapters_merged_var_pop_fields {
  bookChaptersMergedMtid: Float
  duplumDescId: Float
}

# order by var_pop() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_var_pop_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate var_samp on columns
type duplum_desc_book_chapters_merged_var_samp_fields {
  bookChaptersMergedMtid: Float
  duplumDescId: Float
}

# order by var_samp() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_var_samp_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate variance on columns
type duplum_desc_book_chapters_merged_variance_fields {
  bookChaptersMergedMtid: Float
  duplumDescId: Float
}

# order by variance() on columns of table "duplum_desc_book_chapters_merged"
input duplum_desc_book_chapters_merged_variance_order_by {
  bookChaptersMergedMtid: order_by
  duplumDescId: order_by
}

# Boolean expression to filter rows from the table "duplum_desc". All fields are combined with a logical 'AND'.
input duplum_desc_bool_exp {
  _and: [duplum_desc_bool_exp]
  _not: duplum_desc_bool_exp
  _or: [duplum_desc_bool_exp]
  bookChaptersMerged: duplum_desc_book_chapters_merged_bool_exp
  citationsMerged: duplum_desc_citations_merged_bool_exp
  created: timestamp_comparison_exp
  creator: users_bool_exp
  creatorMtid: bigint_comparison_exp
  descPos: Int_comparison_exp
  duplumKeys: String_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  explicitDuplum: Boolean_comparison_exp
  id: bigint_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: users_bool_exp
  lastModifierMtid: bigint_comparison_exp
  objectMtid: bigint_comparison_exp
  resolveType: Int_comparison_exp
  role: Int_comparison_exp
  searchResult: bigint_comparison_exp
}

# columns and relationships of "duplum_desc_citations_merged"
type duplum_desc_citations_merged {
  # An object relationship
  citation: citation!
  citationsMergedMtid: bigint!
  duplumDescId: bigint!
}

# aggregated selection of "duplum_desc_citations_merged"
type duplum_desc_citations_merged_aggregate {
  aggregate: duplum_desc_citations_merged_aggregate_fields
  nodes: [duplum_desc_citations_merged!]!
}

# aggregate fields of "duplum_desc_citations_merged"
type duplum_desc_citations_merged_aggregate_fields {
  avg: duplum_desc_citations_merged_avg_fields
  count(columns: [duplum_desc_citations_merged_select_column!], distinct: Boolean): Int
  max: duplum_desc_citations_merged_max_fields
  min: duplum_desc_citations_merged_min_fields
  stddev: duplum_desc_citations_merged_stddev_fields
  stddev_pop: duplum_desc_citations_merged_stddev_pop_fields
  stddev_samp: duplum_desc_citations_merged_stddev_samp_fields
  sum: duplum_desc_citations_merged_sum_fields
  var_pop: duplum_desc_citations_merged_var_pop_fields
  var_samp: duplum_desc_citations_merged_var_samp_fields
  variance: duplum_desc_citations_merged_variance_fields
}

# order by aggregate values of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_aggregate_order_by {
  avg: duplum_desc_citations_merged_avg_order_by
  count: order_by
  max: duplum_desc_citations_merged_max_order_by
  min: duplum_desc_citations_merged_min_order_by
  stddev: duplum_desc_citations_merged_stddev_order_by
  stddev_pop: duplum_desc_citations_merged_stddev_pop_order_by
  stddev_samp: duplum_desc_citations_merged_stddev_samp_order_by
  sum: duplum_desc_citations_merged_sum_order_by
  var_pop: duplum_desc_citations_merged_var_pop_order_by
  var_samp: duplum_desc_citations_merged_var_samp_order_by
  variance: duplum_desc_citations_merged_variance_order_by
}

# input type for inserting array relation for remote table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_arr_rel_insert_input {
  data: [duplum_desc_citations_merged_insert_input!]!
}

# aggregate avg on columns
type duplum_desc_citations_merged_avg_fields {
  citationsMergedMtid: Float
  duplumDescId: Float
}

# order by avg() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_avg_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# Boolean expression to filter rows from the table "duplum_desc_citations_merged".
# All fields are combined with a logical 'AND'.
input duplum_desc_citations_merged_bool_exp {
  _and: [duplum_desc_citations_merged_bool_exp]
  _not: duplum_desc_citations_merged_bool_exp
  _or: [duplum_desc_citations_merged_bool_exp]
  citation: citation_bool_exp
  citationsMergedMtid: bigint_comparison_exp
  duplumDescId: bigint_comparison_exp
}

# input type for incrementing integer column in table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_inc_input {
  citationsMergedMtid: bigint
  duplumDescId: bigint
}

# input type for inserting data into table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_insert_input {
  citation: citation_obj_rel_insert_input
  citationsMergedMtid: bigint
  duplumDescId: bigint
}

# aggregate max on columns
type duplum_desc_citations_merged_max_fields {
  citationsMergedMtid: bigint
  duplumDescId: bigint
}

# order by max() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_max_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate min on columns
type duplum_desc_citations_merged_min_fields {
  citationsMergedMtid: bigint
  duplumDescId: bigint
}

# order by min() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_min_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# response of any mutation on the table "duplum_desc_citations_merged"
type duplum_desc_citations_merged_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [duplum_desc_citations_merged!]!
}

# input type for inserting object relation for remote table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_obj_rel_insert_input {
  data: duplum_desc_citations_merged_insert_input!
}

# ordering options when selecting data from "duplum_desc_citations_merged"
input duplum_desc_citations_merged_order_by {
  citation: citation_order_by
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# select columns of table "duplum_desc_citations_merged"
enum duplum_desc_citations_merged_select_column {
  # column name
  citationsMergedMtid

  # column name
  duplumDescId
}

# input type for updating data in table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_set_input {
  citationsMergedMtid: bigint
  duplumDescId: bigint
}

# aggregate stddev on columns
type duplum_desc_citations_merged_stddev_fields {
  citationsMergedMtid: Float
  duplumDescId: Float
}

# order by stddev() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_stddev_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate stddev_pop on columns
type duplum_desc_citations_merged_stddev_pop_fields {
  citationsMergedMtid: Float
  duplumDescId: Float
}

# order by stddev_pop() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_stddev_pop_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate stddev_samp on columns
type duplum_desc_citations_merged_stddev_samp_fields {
  citationsMergedMtid: Float
  duplumDescId: Float
}

# order by stddev_samp() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_stddev_samp_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate sum on columns
type duplum_desc_citations_merged_sum_fields {
  citationsMergedMtid: bigint
  duplumDescId: bigint
}

# order by sum() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_sum_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate var_pop on columns
type duplum_desc_citations_merged_var_pop_fields {
  citationsMergedMtid: Float
  duplumDescId: Float
}

# order by var_pop() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_var_pop_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate var_samp on columns
type duplum_desc_citations_merged_var_samp_fields {
  citationsMergedMtid: Float
  duplumDescId: Float
}

# order by var_samp() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_var_samp_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# aggregate variance on columns
type duplum_desc_citations_merged_variance_fields {
  citationsMergedMtid: Float
  duplumDescId: Float
}

# order by variance() on columns of table "duplum_desc_citations_merged"
input duplum_desc_citations_merged_variance_order_by {
  citationsMergedMtid: order_by
  duplumDescId: order_by
}

# unique or primary key constraints on table "duplum_desc"
enum duplum_desc_constraint {
  # unique or primary key constraint
  duplum_desc_pkey
}

# input type for incrementing integer column in table "duplum_desc"
input duplum_desc_inc_input {
  creatorMtid: bigint
  descPos: Int
  id: bigint
  lastModifierMtid: bigint
  objectMtid: bigint
  resolveType: Int
  role: Int
  searchResult: bigint
}

# input type for inserting data into table "duplum_desc"
input duplum_desc_insert_input {
  bookChaptersMerged: duplum_desc_book_chapters_merged_arr_rel_insert_input
  citationsMerged: duplum_desc_citations_merged_arr_rel_insert_input
  created: timestamp
  creator: users_obj_rel_insert_input
  creatorMtid: bigint
  descPos: Int
  duplumKeys: String
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  explicitDuplum: Boolean
  id: bigint
  lastModified: timestamp
  lastModifier: users_obj_rel_insert_input
  lastModifierMtid: bigint
  objectMtid: bigint
  resolveType: Int
  role: Int
  searchResult: bigint
}

# aggregate max on columns
type duplum_desc_max_fields {
  created: timestamp
  creatorMtid: bigint
  descPos: Int
  duplumKeys: String
  id: bigint
  lastModified: timestamp
  lastModifierMtid: bigint
  objectMtid: bigint
  resolveType: Int
  role: Int
  searchResult: bigint
}

# order by max() on columns of table "duplum_desc"
input duplum_desc_max_order_by {
  created: order_by
  creatorMtid: order_by
  descPos: order_by
  duplumKeys: order_by
  id: order_by
  lastModified: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# aggregate min on columns
type duplum_desc_min_fields {
  created: timestamp
  creatorMtid: bigint
  descPos: Int
  duplumKeys: String
  id: bigint
  lastModified: timestamp
  lastModifierMtid: bigint
  objectMtid: bigint
  resolveType: Int
  role: Int
  searchResult: bigint
}

# order by min() on columns of table "duplum_desc"
input duplum_desc_min_order_by {
  created: order_by
  creatorMtid: order_by
  descPos: order_by
  duplumKeys: order_by
  id: order_by
  lastModified: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# response of any mutation on the table "duplum_desc"
type duplum_desc_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [duplum_desc!]!
}

# input type for inserting object relation for remote table "duplum_desc"
input duplum_desc_obj_rel_insert_input {
  data: duplum_desc_insert_input!
  on_conflict: duplum_desc_on_conflict
}

# on conflict condition type for table "duplum_desc"
input duplum_desc_on_conflict {
  constraint: duplum_desc_constraint!
  update_columns: [duplum_desc_update_column!]!
  where: duplum_desc_bool_exp
}

# ordering options when selecting data from "duplum_desc"
input duplum_desc_order_by {
  bookChaptersMerged_aggregate: duplum_desc_book_chapters_merged_aggregate_order_by
  citationsMerged_aggregate: duplum_desc_citations_merged_aggregate_order_by
  created: order_by
  creator: users_order_by
  creatorMtid: order_by
  descPos: order_by
  duplumKeys: order_by
  duplumSearchResult: duplum_search_result_order_by
  explicitDuplum: order_by
  id: order_by
  lastModified: order_by
  lastModifier: users_order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# primary key columns input for table: "duplum_desc"
input duplum_desc_pk_columns_input {
  id: bigint!
}

# select columns of table "duplum_desc"
enum duplum_desc_select_column {
  # column name
  created

  # column name
  creatorMtid

  # column name
  descPos

  # column name
  duplumKeys

  # column name
  explicitDuplum

  # column name
  id

  # column name
  lastModified

  # column name
  lastModifierMtid

  # column name
  objectMtid

  # column name
  resolveType

  # column name
  role

  # column name
  searchResult
}

# input type for updating data in table "duplum_desc"
input duplum_desc_set_input {
  created: timestamp
  creatorMtid: bigint
  descPos: Int
  duplumKeys: String
  explicitDuplum: Boolean
  id: bigint
  lastModified: timestamp
  lastModifierMtid: bigint
  objectMtid: bigint
  resolveType: Int
  role: Int
  searchResult: bigint
}

# aggregate stddev on columns
type duplum_desc_stddev_fields {
  creatorMtid: Float
  descPos: Float
  id: Float
  lastModifierMtid: Float
  objectMtid: Float
  resolveType: Float
  role: Float
  searchResult: Float
}

# order by stddev() on columns of table "duplum_desc"
input duplum_desc_stddev_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# aggregate stddev_pop on columns
type duplum_desc_stddev_pop_fields {
  creatorMtid: Float
  descPos: Float
  id: Float
  lastModifierMtid: Float
  objectMtid: Float
  resolveType: Float
  role: Float
  searchResult: Float
}

# order by stddev_pop() on columns of table "duplum_desc"
input duplum_desc_stddev_pop_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# aggregate stddev_samp on columns
type duplum_desc_stddev_samp_fields {
  creatorMtid: Float
  descPos: Float
  id: Float
  lastModifierMtid: Float
  objectMtid: Float
  resolveType: Float
  role: Float
  searchResult: Float
}

# order by stddev_samp() on columns of table "duplum_desc"
input duplum_desc_stddev_samp_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# aggregate sum on columns
type duplum_desc_sum_fields {
  creatorMtid: bigint
  descPos: Int
  id: bigint
  lastModifierMtid: bigint
  objectMtid: bigint
  resolveType: Int
  role: Int
  searchResult: bigint
}

# order by sum() on columns of table "duplum_desc"
input duplum_desc_sum_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# update columns of table "duplum_desc"
enum duplum_desc_update_column {
  # column name
  created

  # column name
  creatorMtid

  # column name
  descPos

  # column name
  duplumKeys

  # column name
  explicitDuplum

  # column name
  id

  # column name
  lastModified

  # column name
  lastModifierMtid

  # column name
  objectMtid

  # column name
  resolveType

  # column name
  role

  # column name
  searchResult
}

# aggregate var_pop on columns
type duplum_desc_var_pop_fields {
  creatorMtid: Float
  descPos: Float
  id: Float
  lastModifierMtid: Float
  objectMtid: Float
  resolveType: Float
  role: Float
  searchResult: Float
}

# order by var_pop() on columns of table "duplum_desc"
input duplum_desc_var_pop_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# aggregate var_samp on columns
type duplum_desc_var_samp_fields {
  creatorMtid: Float
  descPos: Float
  id: Float
  lastModifierMtid: Float
  objectMtid: Float
  resolveType: Float
  role: Float
  searchResult: Float
}

# order by var_samp() on columns of table "duplum_desc"
input duplum_desc_var_samp_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# aggregate variance on columns
type duplum_desc_variance_fields {
  creatorMtid: Float
  descPos: Float
  id: Float
  lastModifierMtid: Float
  objectMtid: Float
  resolveType: Float
  role: Float
  searchResult: Float
}

# order by variance() on columns of table "duplum_desc"
input duplum_desc_variance_order_by {
  creatorMtid: order_by
  descPos: order_by
  id: order_by
  lastModifierMtid: order_by
  objectMtid: order_by
  resolveType: order_by
  role: order_by
  searchResult: order_by
}

# columns and relationships of "duplum_search_request"
type duplum_search_request {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  chaptersOf: publication
  chaptersOfMtid: bigint

  # An object relationship
  citationsOf: publication
  citationsOfMtid: bigint

  # An object relationship
  citingPublicationsOf: publication
  citingPublicationsOfMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  forceSearch: Boolean!
  fullQuerySearch: Boolean!
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp

  # An object relationship
  list: named_list
  listMtid: bigint
  localSearch: Boolean!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean!

  # An object relationship
  query: smart_query
  queryMtid: bigint
  queued: Boolean!
  refreshed: Boolean!

  # An object relationship
  resultList: named_list
  resultListMtid: bigint
  seen: Boolean
  smartQueryConds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "duplum_search_request"
type duplum_search_request_aggregate {
  aggregate: duplum_search_request_aggregate_fields
  nodes: [duplum_search_request!]!
}

# aggregate fields of "duplum_search_request"
type duplum_search_request_aggregate_fields {
  avg: duplum_search_request_avg_fields
  count(columns: [duplum_search_request_select_column!], distinct: Boolean): Int
  max: duplum_search_request_max_fields
  min: duplum_search_request_min_fields
  stddev: duplum_search_request_stddev_fields
  stddev_pop: duplum_search_request_stddev_pop_fields
  stddev_samp: duplum_search_request_stddev_samp_fields
  sum: duplum_search_request_sum_fields
  var_pop: duplum_search_request_var_pop_fields
  var_samp: duplum_search_request_var_samp_fields
  variance: duplum_search_request_variance_fields
}

# order by aggregate values of table "duplum_search_request"
input duplum_search_request_aggregate_order_by {
  avg: duplum_search_request_avg_order_by
  count: order_by
  max: duplum_search_request_max_order_by
  min: duplum_search_request_min_order_by
  stddev: duplum_search_request_stddev_order_by
  stddev_pop: duplum_search_request_stddev_pop_order_by
  stddev_samp: duplum_search_request_stddev_samp_order_by
  sum: duplum_search_request_sum_order_by
  var_pop: duplum_search_request_var_pop_order_by
  var_samp: duplum_search_request_var_samp_order_by
  variance: duplum_search_request_variance_order_by
}

# input type for inserting array relation for remote table "duplum_search_request"
input duplum_search_request_arr_rel_insert_input {
  data: [duplum_search_request_insert_input!]!
  on_conflict: duplum_search_request_on_conflict
}

# aggregate avg on columns
type duplum_search_request_avg_fields {
  approverMtid: Float
  chaptersOfMtid: Float
  citationsOfMtid: Float
  citingPublicationsOfMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "duplum_search_request"
input duplum_search_request_avg_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "duplum_search_request". All fields are combined with a logical 'AND'.
input duplum_search_request_bool_exp {
  _and: [duplum_search_request_bool_exp]
  _not: duplum_search_request_bool_exp
  _or: [duplum_search_request_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  chaptersOf: publication_bool_exp
  chaptersOfMtid: bigint_comparison_exp
  citationsOf: publication_bool_exp
  citationsOfMtid: bigint_comparison_exp
  citingPublicationsOf: publication_bool_exp
  citingPublicationsOfMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  forceSearch: Boolean_comparison_exp
  fullQuerySearch: Boolean_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  list: named_list_bool_exp
  listMtid: bigint_comparison_exp
  localSearch: Boolean_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  query: smart_query_bool_exp
  queryMtid: bigint_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  resultList: named_list_bool_exp
  resultListMtid: bigint_comparison_exp
  seen: Boolean_comparison_exp
  smartQueryConds: String_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "duplum_search_request"
enum duplum_search_request_constraint {
  # unique or primary key constraint
  duplum_search_request_pkey
}

# input type for incrementing integer column in table "duplum_search_request"
input duplum_search_request_inc_input {
  approverMtid: bigint
  chaptersOfMtid: bigint
  citationsOfMtid: bigint
  citingPublicationsOfMtid: bigint
  creator: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listMtid: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  resultListMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "duplum_search_request"
input duplum_search_request_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  chaptersOf: publication_obj_rel_insert_input
  chaptersOfMtid: bigint
  citationsOf: publication_obj_rel_insert_input
  citationsOfMtid: bigint
  citingPublicationsOf: publication_obj_rel_insert_input
  citingPublicationsOfMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  forceSearch: Boolean
  fullQuerySearch: Boolean
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: named_list_obj_rel_insert_input
  listMtid: bigint
  localSearch: Boolean
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  query: smart_query_obj_rel_insert_input
  queryMtid: bigint
  queued: Boolean
  refreshed: Boolean
  resultList: named_list_obj_rel_insert_input
  resultListMtid: bigint
  seen: Boolean
  smartQueryConds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type duplum_search_request_max_fields {
  approved: timestamp
  approverMtid: bigint
  chaptersOfMtid: bigint
  citationsOfMtid: bigint
  citingPublicationsOfMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listMtid: bigint
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  queryMtid: bigint
  resultListMtid: bigint
  smartQueryConds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "duplum_search_request"
input duplum_search_request_max_order_by {
  approved: order_by
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listMtid: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  queryMtid: order_by
  resultListMtid: order_by
  smartQueryConds: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type duplum_search_request_min_fields {
  approved: timestamp
  approverMtid: bigint
  chaptersOfMtid: bigint
  citationsOfMtid: bigint
  citingPublicationsOfMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listMtid: bigint
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  queryMtid: bigint
  resultListMtid: bigint
  smartQueryConds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "duplum_search_request"
input duplum_search_request_min_order_by {
  approved: order_by
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listMtid: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  queryMtid: order_by
  resultListMtid: order_by
  smartQueryConds: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "duplum_search_request"
type duplum_search_request_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [duplum_search_request!]!
}

# input type for inserting object relation for remote table "duplum_search_request"
input duplum_search_request_obj_rel_insert_input {
  data: duplum_search_request_insert_input!
  on_conflict: duplum_search_request_on_conflict
}

# on conflict condition type for table "duplum_search_request"
input duplum_search_request_on_conflict {
  constraint: duplum_search_request_constraint!
  update_columns: [duplum_search_request_update_column!]!
  where: duplum_search_request_bool_exp
}

# ordering options when selecting data from "duplum_search_request"
input duplum_search_request_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  chaptersOf: publication_order_by
  chaptersOfMtid: order_by
  citationsOf: publication_order_by
  citationsOfMtid: order_by
  citingPublicationsOf: publication_order_by
  citingPublicationsOfMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  forceSearch: order_by
  fullQuerySearch: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: named_list_order_by
  listMtid: order_by
  localSearch: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  query: smart_query_order_by
  queryMtid: order_by
  queued: order_by
  refreshed: order_by
  resultList: named_list_order_by
  resultListMtid: order_by
  seen: order_by
  smartQueryConds: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "duplum_search_request"
input duplum_search_request_pk_columns_input {
  mtid: bigint!
}

# select columns of table "duplum_search_request"
enum duplum_search_request_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  chaptersOfMtid

  # column name
  citationsOfMtid

  # column name
  citingPublicationsOfMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  forceSearch

  # column name
  fullQuerySearch

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listMtid

  # column name
  localSearch

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queryMtid

  # column name
  queued

  # column name
  refreshed

  # column name
  resultListMtid

  # column name
  seen

  # column name
  smartQueryConds

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "duplum_search_request"
input duplum_search_request_set_input {
  approved: timestamp
  approverMtid: bigint
  chaptersOfMtid: bigint
  citationsOfMtid: bigint
  citingPublicationsOfMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  forceSearch: Boolean
  fullQuerySearch: Boolean
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listMtid: bigint
  localSearch: Boolean
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queryMtid: bigint
  queued: Boolean
  refreshed: Boolean
  resultListMtid: bigint
  seen: Boolean
  smartQueryConds: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type duplum_search_request_stddev_fields {
  approverMtid: Float
  chaptersOfMtid: Float
  citationsOfMtid: Float
  citingPublicationsOfMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "duplum_search_request"
input duplum_search_request_stddev_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type duplum_search_request_stddev_pop_fields {
  approverMtid: Float
  chaptersOfMtid: Float
  citationsOfMtid: Float
  citingPublicationsOfMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "duplum_search_request"
input duplum_search_request_stddev_pop_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type duplum_search_request_stddev_samp_fields {
  approverMtid: Float
  chaptersOfMtid: Float
  citationsOfMtid: Float
  citingPublicationsOfMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "duplum_search_request"
input duplum_search_request_stddev_samp_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type duplum_search_request_sum_fields {
  approverMtid: bigint
  chaptersOfMtid: bigint
  citationsOfMtid: bigint
  citingPublicationsOfMtid: bigint
  creator: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listMtid: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  resultListMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "duplum_search_request"
input duplum_search_request_sum_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "duplum_search_request"
enum duplum_search_request_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  chaptersOfMtid

  # column name
  citationsOfMtid

  # column name
  citingPublicationsOfMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  forceSearch

  # column name
  fullQuerySearch

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listMtid

  # column name
  localSearch

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queryMtid

  # column name
  queued

  # column name
  refreshed

  # column name
  resultListMtid

  # column name
  seen

  # column name
  smartQueryConds

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type duplum_search_request_var_pop_fields {
  approverMtid: Float
  chaptersOfMtid: Float
  citationsOfMtid: Float
  citingPublicationsOfMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "duplum_search_request"
input duplum_search_request_var_pop_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type duplum_search_request_var_samp_fields {
  approverMtid: Float
  chaptersOfMtid: Float
  citationsOfMtid: Float
  citingPublicationsOfMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "duplum_search_request"
input duplum_search_request_var_samp_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type duplum_search_request_variance_fields {
  approverMtid: Float
  chaptersOfMtid: Float
  citationsOfMtid: Float
  citingPublicationsOfMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  resultListMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "duplum_search_request"
input duplum_search_request_variance_order_by {
  approverMtid: order_by
  chaptersOfMtid: order_by
  citationsOfMtid: order_by
  citingPublicationsOfMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  resultListMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "duplum_search_result"
type duplum_search_result {
  adminComment: String
  creationDate: timestamp

  # An object relationship
  creator: users
  creatorMtid: bigint

  # An array relationship
  descs(
    # distinct select on columns
    distinct_on: [duplum_desc_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_order_by!]

    # filter the rows returned
    where: duplum_desc_bool_exp
  ): [duplum_desc!]!

  # An aggregated array relationship
  descs_aggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_order_by!]

    # filter the rows returned
    where: duplum_desc_bool_exp
  ): duplum_desc_aggregate!
  duration: bigint
  id: bigint!
  jobId: bigint
  multipleTypes: Boolean!
  objectType: String
  oldId: Int
  reporterComment: String
  resolveDate: timestamp

  # An object relationship
  resolver: users
  resolverMtid: bigint
  startDate: timestamp
  survivorMtid: bigint

  # An object relationship
  ticket: ticket
  ticketMtid: bigint
}

# aggregated selection of "duplum_search_result"
type duplum_search_result_aggregate {
  aggregate: duplum_search_result_aggregate_fields
  nodes: [duplum_search_result!]!
}

# aggregate fields of "duplum_search_result"
type duplum_search_result_aggregate_fields {
  avg: duplum_search_result_avg_fields
  count(columns: [duplum_search_result_select_column!], distinct: Boolean): Int
  max: duplum_search_result_max_fields
  min: duplum_search_result_min_fields
  stddev: duplum_search_result_stddev_fields
  stddev_pop: duplum_search_result_stddev_pop_fields
  stddev_samp: duplum_search_result_stddev_samp_fields
  sum: duplum_search_result_sum_fields
  var_pop: duplum_search_result_var_pop_fields
  var_samp: duplum_search_result_var_samp_fields
  variance: duplum_search_result_variance_fields
}

# order by aggregate values of table "duplum_search_result"
input duplum_search_result_aggregate_order_by {
  avg: duplum_search_result_avg_order_by
  count: order_by
  max: duplum_search_result_max_order_by
  min: duplum_search_result_min_order_by
  stddev: duplum_search_result_stddev_order_by
  stddev_pop: duplum_search_result_stddev_pop_order_by
  stddev_samp: duplum_search_result_stddev_samp_order_by
  sum: duplum_search_result_sum_order_by
  var_pop: duplum_search_result_var_pop_order_by
  var_samp: duplum_search_result_var_samp_order_by
  variance: duplum_search_result_variance_order_by
}

# input type for inserting array relation for remote table "duplum_search_result"
input duplum_search_result_arr_rel_insert_input {
  data: [duplum_search_result_insert_input!]!
  on_conflict: duplum_search_result_on_conflict
}

# aggregate avg on columns
type duplum_search_result_avg_fields {
  creatorMtid: Float
  duration: Float
  id: Float
  jobId: Float
  oldId: Float
  resolverMtid: Float
  survivorMtid: Float
  ticketMtid: Float
}

# order by avg() on columns of table "duplum_search_result"
input duplum_search_result_avg_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# Boolean expression to filter rows from the table "duplum_search_result". All fields are combined with a logical 'AND'.
input duplum_search_result_bool_exp {
  _and: [duplum_search_result_bool_exp]
  _not: duplum_search_result_bool_exp
  _or: [duplum_search_result_bool_exp]
  adminComment: String_comparison_exp
  creationDate: timestamp_comparison_exp
  creator: users_bool_exp
  creatorMtid: bigint_comparison_exp
  descs: duplum_desc_bool_exp
  duration: bigint_comparison_exp
  id: bigint_comparison_exp
  jobId: bigint_comparison_exp
  multipleTypes: Boolean_comparison_exp
  objectType: String_comparison_exp
  oldId: Int_comparison_exp
  reporterComment: String_comparison_exp
  resolveDate: timestamp_comparison_exp
  resolver: users_bool_exp
  resolverMtid: bigint_comparison_exp
  startDate: timestamp_comparison_exp
  survivorMtid: bigint_comparison_exp
  ticket: ticket_bool_exp
  ticketMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "duplum_search_result"
enum duplum_search_result_constraint {
  # unique or primary key constraint
  duplum_search_result_pkey
}

# input type for incrementing integer column in table "duplum_search_result"
input duplum_search_result_inc_input {
  creatorMtid: bigint
  duration: bigint
  id: bigint
  jobId: bigint
  oldId: Int
  resolverMtid: bigint
  survivorMtid: bigint
  ticketMtid: bigint
}

# input type for inserting data into table "duplum_search_result"
input duplum_search_result_insert_input {
  adminComment: String
  creationDate: timestamp
  creator: users_obj_rel_insert_input
  creatorMtid: bigint
  descs: duplum_desc_arr_rel_insert_input
  duration: bigint
  id: bigint
  jobId: bigint
  multipleTypes: Boolean
  objectType: String
  oldId: Int
  reporterComment: String
  resolveDate: timestamp
  resolver: users_obj_rel_insert_input
  resolverMtid: bigint
  startDate: timestamp
  survivorMtid: bigint
  ticket: ticket_obj_rel_insert_input
  ticketMtid: bigint
}

# aggregate max on columns
type duplum_search_result_max_fields {
  adminComment: String
  creationDate: timestamp
  creatorMtid: bigint
  duration: bigint
  id: bigint
  jobId: bigint
  objectType: String
  oldId: Int
  reporterComment: String
  resolveDate: timestamp
  resolverMtid: bigint
  startDate: timestamp
  survivorMtid: bigint
  ticketMtid: bigint
}

# order by max() on columns of table "duplum_search_result"
input duplum_search_result_max_order_by {
  adminComment: order_by
  creationDate: order_by
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  objectType: order_by
  oldId: order_by
  reporterComment: order_by
  resolveDate: order_by
  resolverMtid: order_by
  startDate: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# aggregate min on columns
type duplum_search_result_min_fields {
  adminComment: String
  creationDate: timestamp
  creatorMtid: bigint
  duration: bigint
  id: bigint
  jobId: bigint
  objectType: String
  oldId: Int
  reporterComment: String
  resolveDate: timestamp
  resolverMtid: bigint
  startDate: timestamp
  survivorMtid: bigint
  ticketMtid: bigint
}

# order by min() on columns of table "duplum_search_result"
input duplum_search_result_min_order_by {
  adminComment: order_by
  creationDate: order_by
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  objectType: order_by
  oldId: order_by
  reporterComment: order_by
  resolveDate: order_by
  resolverMtid: order_by
  startDate: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# response of any mutation on the table "duplum_search_result"
type duplum_search_result_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [duplum_search_result!]!
}

# input type for inserting object relation for remote table "duplum_search_result"
input duplum_search_result_obj_rel_insert_input {
  data: duplum_search_result_insert_input!
  on_conflict: duplum_search_result_on_conflict
}

# on conflict condition type for table "duplum_search_result"
input duplum_search_result_on_conflict {
  constraint: duplum_search_result_constraint!
  update_columns: [duplum_search_result_update_column!]!
  where: duplum_search_result_bool_exp
}

# ordering options when selecting data from "duplum_search_result"
input duplum_search_result_order_by {
  adminComment: order_by
  creationDate: order_by
  creator: users_order_by
  creatorMtid: order_by
  descs_aggregate: duplum_desc_aggregate_order_by
  duration: order_by
  id: order_by
  jobId: order_by
  multipleTypes: order_by
  objectType: order_by
  oldId: order_by
  reporterComment: order_by
  resolveDate: order_by
  resolver: users_order_by
  resolverMtid: order_by
  startDate: order_by
  survivorMtid: order_by
  ticket: ticket_order_by
  ticketMtid: order_by
}

# primary key columns input for table: "duplum_search_result"
input duplum_search_result_pk_columns_input {
  id: bigint!
}

# select columns of table "duplum_search_result"
enum duplum_search_result_select_column {
  # column name
  adminComment

  # column name
  creationDate

  # column name
  creatorMtid

  # column name
  duration

  # column name
  id

  # column name
  jobId

  # column name
  multipleTypes

  # column name
  objectType

  # column name
  oldId

  # column name
  reporterComment

  # column name
  resolveDate

  # column name
  resolverMtid

  # column name
  startDate

  # column name
  survivorMtid

  # column name
  ticketMtid
}

# input type for updating data in table "duplum_search_result"
input duplum_search_result_set_input {
  adminComment: String
  creationDate: timestamp
  creatorMtid: bigint
  duration: bigint
  id: bigint
  jobId: bigint
  multipleTypes: Boolean
  objectType: String
  oldId: Int
  reporterComment: String
  resolveDate: timestamp
  resolverMtid: bigint
  startDate: timestamp
  survivorMtid: bigint
  ticketMtid: bigint
}

# aggregate stddev on columns
type duplum_search_result_stddev_fields {
  creatorMtid: Float
  duration: Float
  id: Float
  jobId: Float
  oldId: Float
  resolverMtid: Float
  survivorMtid: Float
  ticketMtid: Float
}

# order by stddev() on columns of table "duplum_search_result"
input duplum_search_result_stddev_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# aggregate stddev_pop on columns
type duplum_search_result_stddev_pop_fields {
  creatorMtid: Float
  duration: Float
  id: Float
  jobId: Float
  oldId: Float
  resolverMtid: Float
  survivorMtid: Float
  ticketMtid: Float
}

# order by stddev_pop() on columns of table "duplum_search_result"
input duplum_search_result_stddev_pop_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# aggregate stddev_samp on columns
type duplum_search_result_stddev_samp_fields {
  creatorMtid: Float
  duration: Float
  id: Float
  jobId: Float
  oldId: Float
  resolverMtid: Float
  survivorMtid: Float
  ticketMtid: Float
}

# order by stddev_samp() on columns of table "duplum_search_result"
input duplum_search_result_stddev_samp_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# aggregate sum on columns
type duplum_search_result_sum_fields {
  creatorMtid: bigint
  duration: bigint
  id: bigint
  jobId: bigint
  oldId: Int
  resolverMtid: bigint
  survivorMtid: bigint
  ticketMtid: bigint
}

# order by sum() on columns of table "duplum_search_result"
input duplum_search_result_sum_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# update columns of table "duplum_search_result"
enum duplum_search_result_update_column {
  # column name
  adminComment

  # column name
  creationDate

  # column name
  creatorMtid

  # column name
  duration

  # column name
  id

  # column name
  jobId

  # column name
  multipleTypes

  # column name
  objectType

  # column name
  oldId

  # column name
  reporterComment

  # column name
  resolveDate

  # column name
  resolverMtid

  # column name
  startDate

  # column name
  survivorMtid

  # column name
  ticketMtid
}

# aggregate var_pop on columns
type duplum_search_result_var_pop_fields {
  creatorMtid: Float
  duration: Float
  id: Float
  jobId: Float
  oldId: Float
  resolverMtid: Float
  survivorMtid: Float
  ticketMtid: Float
}

# order by var_pop() on columns of table "duplum_search_result"
input duplum_search_result_var_pop_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# aggregate var_samp on columns
type duplum_search_result_var_samp_fields {
  creatorMtid: Float
  duration: Float
  id: Float
  jobId: Float
  oldId: Float
  resolverMtid: Float
  survivorMtid: Float
  ticketMtid: Float
}

# order by var_samp() on columns of table "duplum_search_result"
input duplum_search_result_var_samp_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# aggregate variance on columns
type duplum_search_result_variance_fields {
  creatorMtid: Float
  duration: Float
  id: Float
  jobId: Float
  oldId: Float
  resolverMtid: Float
  survivorMtid: Float
  ticketMtid: Float
}

# order by variance() on columns of table "duplum_search_result"
input duplum_search_result_variance_order_by {
  creatorMtid: order_by
  duration: order_by
  id: order_by
  jobId: order_by
  oldId: order_by
  resolverMtid: order_by
  survivorMtid: order_by
  ticketMtid: order_by
}

# columns and relationships of "error_log"
type error_log {
  c: String
  causeMessage: String
  causeStackTrace: String
  exceptionMessage: String
  id: bigint!
  json: String
  level: Int
  message: String
  method: String
  stackTrace: String
  timestamp: timestamp
  url: String
  username: String
}

# aggregated selection of "error_log"
type error_log_aggregate {
  aggregate: error_log_aggregate_fields
  nodes: [error_log!]!
}

# aggregate fields of "error_log"
type error_log_aggregate_fields {
  avg: error_log_avg_fields
  count(columns: [error_log_select_column!], distinct: Boolean): Int
  max: error_log_max_fields
  min: error_log_min_fields
  stddev: error_log_stddev_fields
  stddev_pop: error_log_stddev_pop_fields
  stddev_samp: error_log_stddev_samp_fields
  sum: error_log_sum_fields
  var_pop: error_log_var_pop_fields
  var_samp: error_log_var_samp_fields
  variance: error_log_variance_fields
}

# order by aggregate values of table "error_log"
input error_log_aggregate_order_by {
  avg: error_log_avg_order_by
  count: order_by
  max: error_log_max_order_by
  min: error_log_min_order_by
  stddev: error_log_stddev_order_by
  stddev_pop: error_log_stddev_pop_order_by
  stddev_samp: error_log_stddev_samp_order_by
  sum: error_log_sum_order_by
  var_pop: error_log_var_pop_order_by
  var_samp: error_log_var_samp_order_by
  variance: error_log_variance_order_by
}

# input type for inserting array relation for remote table "error_log"
input error_log_arr_rel_insert_input {
  data: [error_log_insert_input!]!
  on_conflict: error_log_on_conflict
}

# aggregate avg on columns
type error_log_avg_fields {
  id: Float
  level: Float
}

# order by avg() on columns of table "error_log"
input error_log_avg_order_by {
  id: order_by
  level: order_by
}

# Boolean expression to filter rows from the table "error_log". All fields are combined with a logical 'AND'.
input error_log_bool_exp {
  _and: [error_log_bool_exp]
  _not: error_log_bool_exp
  _or: [error_log_bool_exp]
  c: String_comparison_exp
  causeMessage: String_comparison_exp
  causeStackTrace: String_comparison_exp
  exceptionMessage: String_comparison_exp
  id: bigint_comparison_exp
  json: String_comparison_exp
  level: Int_comparison_exp
  message: String_comparison_exp
  method: String_comparison_exp
  stackTrace: String_comparison_exp
  timestamp: timestamp_comparison_exp
  url: String_comparison_exp
  username: String_comparison_exp
}

# unique or primary key constraints on table "error_log"
enum error_log_constraint {
  # unique or primary key constraint
  error_log_pkey
}

# input type for incrementing integer column in table "error_log"
input error_log_inc_input {
  id: bigint
  level: Int
}

# input type for inserting data into table "error_log"
input error_log_insert_input {
  c: String
  causeMessage: String
  causeStackTrace: String
  exceptionMessage: String
  id: bigint
  json: String
  level: Int
  message: String
  method: String
  stackTrace: String
  timestamp: timestamp
  url: String
  username: String
}

# aggregate max on columns
type error_log_max_fields {
  c: String
  causeMessage: String
  causeStackTrace: String
  exceptionMessage: String
  id: bigint
  json: String
  level: Int
  message: String
  method: String
  stackTrace: String
  timestamp: timestamp
  url: String
  username: String
}

# order by max() on columns of table "error_log"
input error_log_max_order_by {
  c: order_by
  causeMessage: order_by
  causeStackTrace: order_by
  exceptionMessage: order_by
  id: order_by
  json: order_by
  level: order_by
  message: order_by
  method: order_by
  stackTrace: order_by
  timestamp: order_by
  url: order_by
  username: order_by
}

# aggregate min on columns
type error_log_min_fields {
  c: String
  causeMessage: String
  causeStackTrace: String
  exceptionMessage: String
  id: bigint
  json: String
  level: Int
  message: String
  method: String
  stackTrace: String
  timestamp: timestamp
  url: String
  username: String
}

# order by min() on columns of table "error_log"
input error_log_min_order_by {
  c: order_by
  causeMessage: order_by
  causeStackTrace: order_by
  exceptionMessage: order_by
  id: order_by
  json: order_by
  level: order_by
  message: order_by
  method: order_by
  stackTrace: order_by
  timestamp: order_by
  url: order_by
  username: order_by
}

# response of any mutation on the table "error_log"
type error_log_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [error_log!]!
}

# input type for inserting object relation for remote table "error_log"
input error_log_obj_rel_insert_input {
  data: error_log_insert_input!
  on_conflict: error_log_on_conflict
}

# on conflict condition type for table "error_log"
input error_log_on_conflict {
  constraint: error_log_constraint!
  update_columns: [error_log_update_column!]!
  where: error_log_bool_exp
}

# ordering options when selecting data from "error_log"
input error_log_order_by {
  c: order_by
  causeMessage: order_by
  causeStackTrace: order_by
  exceptionMessage: order_by
  id: order_by
  json: order_by
  level: order_by
  message: order_by
  method: order_by
  stackTrace: order_by
  timestamp: order_by
  url: order_by
  username: order_by
}

# primary key columns input for table: "error_log"
input error_log_pk_columns_input {
  id: bigint!
}

# select columns of table "error_log"
enum error_log_select_column {
  # column name
  c

  # column name
  causeMessage

  # column name
  causeStackTrace

  # column name
  exceptionMessage

  # column name
  id

  # column name
  json

  # column name
  level

  # column name
  message

  # column name
  method

  # column name
  stackTrace

  # column name
  timestamp

  # column name
  url

  # column name
  username
}

# input type for updating data in table "error_log"
input error_log_set_input {
  c: String
  causeMessage: String
  causeStackTrace: String
  exceptionMessage: String
  id: bigint
  json: String
  level: Int
  message: String
  method: String
  stackTrace: String
  timestamp: timestamp
  url: String
  username: String
}

# aggregate stddev on columns
type error_log_stddev_fields {
  id: Float
  level: Float
}

# order by stddev() on columns of table "error_log"
input error_log_stddev_order_by {
  id: order_by
  level: order_by
}

# aggregate stddev_pop on columns
type error_log_stddev_pop_fields {
  id: Float
  level: Float
}

# order by stddev_pop() on columns of table "error_log"
input error_log_stddev_pop_order_by {
  id: order_by
  level: order_by
}

# aggregate stddev_samp on columns
type error_log_stddev_samp_fields {
  id: Float
  level: Float
}

# order by stddev_samp() on columns of table "error_log"
input error_log_stddev_samp_order_by {
  id: order_by
  level: order_by
}

# aggregate sum on columns
type error_log_sum_fields {
  id: bigint
  level: Int
}

# order by sum() on columns of table "error_log"
input error_log_sum_order_by {
  id: order_by
  level: order_by
}

# update columns of table "error_log"
enum error_log_update_column {
  # column name
  c

  # column name
  causeMessage

  # column name
  causeStackTrace

  # column name
  exceptionMessage

  # column name
  id

  # column name
  json

  # column name
  level

  # column name
  message

  # column name
  method

  # column name
  stackTrace

  # column name
  timestamp

  # column name
  url

  # column name
  username
}

# aggregate var_pop on columns
type error_log_var_pop_fields {
  id: Float
  level: Float
}

# order by var_pop() on columns of table "error_log"
input error_log_var_pop_order_by {
  id: order_by
  level: order_by
}

# aggregate var_samp on columns
type error_log_var_samp_fields {
  id: Float
  level: Float
}

# order by var_samp() on columns of table "error_log"
input error_log_var_samp_order_by {
  id: order_by
  level: order_by
}

# aggregate variance on columns
type error_log_variance_fields {
  id: Float
  level: Float
}

# order by variance() on columns of table "error_log"
input error_log_variance_order_by {
  id: order_by
  level: order_by
}

# columns and relationships of "export_format"
type export_format {
  applicableAnnotation: String
  applicableClass: String
  applicableView: Int
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  builtin: Boolean!
  calculatedApplicableClass: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  enabled: Boolean!
  error: Int
  extension: String
  global: Boolean!
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listOrder: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint!
  name: String
  nameEng: String
  notApplicableAnnotation: String
  notApplicableClass: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  parameters: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  specificVersionOf: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An object relationship
  theOwnerInstitute: organization
  type: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint

  # An object relationship
  xslFile: uploaded_file
  xslFileMtid: bigint
}

# aggregated selection of "export_format"
type export_format_aggregate {
  aggregate: export_format_aggregate_fields
  nodes: [export_format!]!
}

# aggregate fields of "export_format"
type export_format_aggregate_fields {
  avg: export_format_avg_fields
  count(columns: [export_format_select_column!], distinct: Boolean): Int
  max: export_format_max_fields
  min: export_format_min_fields
  stddev: export_format_stddev_fields
  stddev_pop: export_format_stddev_pop_fields
  stddev_samp: export_format_stddev_samp_fields
  sum: export_format_sum_fields
  var_pop: export_format_var_pop_fields
  var_samp: export_format_var_samp_fields
  variance: export_format_variance_fields
}

# order by aggregate values of table "export_format"
input export_format_aggregate_order_by {
  avg: export_format_avg_order_by
  count: order_by
  max: export_format_max_order_by
  min: export_format_min_order_by
  stddev: export_format_stddev_order_by
  stddev_pop: export_format_stddev_pop_order_by
  stddev_samp: export_format_stddev_samp_order_by
  sum: export_format_sum_order_by
  var_pop: export_format_var_pop_order_by
  var_samp: export_format_var_samp_order_by
  variance: export_format_variance_order_by
}

# input type for inserting array relation for remote table "export_format"
input export_format_arr_rel_insert_input {
  data: [export_format_insert_input!]!
  on_conflict: export_format_on_conflict
}

# aggregate avg on columns
type export_format_avg_fields {
  applicableView: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listOrder: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by avg() on columns of table "export_format"
input export_format_avg_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# Boolean expression to filter rows from the table "export_format". All fields are combined with a logical 'AND'.
input export_format_bool_exp {
  _and: [export_format_bool_exp]
  _not: export_format_bool_exp
  _or: [export_format_bool_exp]
  applicableAnnotation: String_comparison_exp
  applicableClass: String_comparison_exp
  applicableView: Int_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  builtin: Boolean_comparison_exp
  calculatedApplicableClass: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  enabled: Boolean_comparison_exp
  error: Int_comparison_exp
  extension: String_comparison_exp
  global: Boolean_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listOrder: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  maxDedicatedRole: Int_comparison_exp
  minDedicatedRole: Int_comparison_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  notApplicableAnnotation: String_comparison_exp
  notApplicableClass: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  ownerInstitute: bigint_comparison_exp
  parameters: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  specificVersionOf: String_comparison_exp
  status: Int_comparison_exp
  tag: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  theOwnerInstitute: organization_bool_exp
  type: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  xslFile: uploaded_file_bool_exp
  xslFileMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "export_format"
enum export_format_constraint {
  # unique or primary key constraint
  export_format_pkey
}

# input type for incrementing integer column in table "export_format"
input export_format_inc_input {
  applicableView: Int
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listOrder: Int
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# input type for inserting data into table "export_format"
input export_format_insert_input {
  applicableAnnotation: String
  applicableClass: String
  applicableView: Int
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  builtin: Boolean
  calculatedApplicableClass: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  enabled: Boolean
  error: Int
  extension: String
  global: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listOrder: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  notApplicableAnnotation: String
  notApplicableClass: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  parameters: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  specificVersionOf: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  theOwnerInstitute: organization_obj_rel_insert_input
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFile: uploaded_file_obj_rel_insert_input
  xslFileMtid: bigint
}

# aggregate max on columns
type export_format_max_fields {
  applicableAnnotation: String
  applicableClass: String
  applicableView: Int
  approved: timestamp
  approverMtid: bigint
  calculatedApplicableClass: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  extension: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listOrder: Int
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  notApplicableAnnotation: String
  notApplicableClass: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  parameters: String
  prevValid: bigint
  specificVersionOf: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# order by max() on columns of table "export_format"
input export_format_max_order_by {
  applicableAnnotation: order_by
  applicableClass: order_by
  applicableView: order_by
  approved: order_by
  approverMtid: order_by
  calculatedApplicableClass: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  extension: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listOrder: order_by
  locked: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  notApplicableAnnotation: order_by
  notApplicableClass: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  parameters: order_by
  prevValid: order_by
  specificVersionOf: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate min on columns
type export_format_min_fields {
  applicableAnnotation: String
  applicableClass: String
  applicableView: Int
  approved: timestamp
  approverMtid: bigint
  calculatedApplicableClass: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  extension: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listOrder: Int
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  notApplicableAnnotation: String
  notApplicableClass: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  parameters: String
  prevValid: bigint
  specificVersionOf: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# order by min() on columns of table "export_format"
input export_format_min_order_by {
  applicableAnnotation: order_by
  applicableClass: order_by
  applicableView: order_by
  approved: order_by
  approverMtid: order_by
  calculatedApplicableClass: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  extension: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listOrder: order_by
  locked: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  notApplicableAnnotation: order_by
  notApplicableClass: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  parameters: order_by
  prevValid: order_by
  specificVersionOf: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# response of any mutation on the table "export_format"
type export_format_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [export_format!]!
}

# input type for inserting object relation for remote table "export_format"
input export_format_obj_rel_insert_input {
  data: export_format_insert_input!
  on_conflict: export_format_on_conflict
}

# on conflict condition type for table "export_format"
input export_format_on_conflict {
  constraint: export_format_constraint!
  update_columns: [export_format_update_column!]!
  where: export_format_bool_exp
}

# ordering options when selecting data from "export_format"
input export_format_order_by {
  applicableAnnotation: order_by
  applicableClass: order_by
  applicableView: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  builtin: order_by
  calculatedApplicableClass: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  enabled: order_by
  error: order_by
  extension: order_by
  global: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listOrder: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  notApplicableAnnotation: order_by
  notApplicableClass: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  parameters: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  specificVersionOf: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  theOwnerInstitute: organization_order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFile: uploaded_file_order_by
  xslFileMtid: order_by
}

# primary key columns input for table: "export_format"
input export_format_pk_columns_input {
  mtid: bigint!
}

# select columns of table "export_format"
enum export_format_select_column {
  # column name
  applicableAnnotation

  # column name
  applicableClass

  # column name
  applicableView

  # column name
  approved

  # column name
  approverMtid

  # column name
  builtin

  # column name
  calculatedApplicableClass

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  enabled

  # column name
  error

  # column name
  extension

  # column name
  global

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listOrder

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxDedicatedRole

  # column name
  minDedicatedRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  notApplicableAnnotation

  # column name
  notApplicableClass

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerInstitute

  # column name
  parameters

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  specificVersionOf

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xslFileMtid
}

# input type for updating data in table "export_format"
input export_format_set_input {
  applicableAnnotation: String
  applicableClass: String
  applicableView: Int
  approved: timestamp
  approverMtid: bigint
  builtin: Boolean
  calculatedApplicableClass: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  enabled: Boolean
  error: Int
  extension: String
  global: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listOrder: Int
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  notApplicableAnnotation: String
  notApplicableClass: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  parameters: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  specificVersionOf: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# aggregate stddev on columns
type export_format_stddev_fields {
  applicableView: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listOrder: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by stddev() on columns of table "export_format"
input export_format_stddev_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate stddev_pop on columns
type export_format_stddev_pop_fields {
  applicableView: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listOrder: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by stddev_pop() on columns of table "export_format"
input export_format_stddev_pop_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate stddev_samp on columns
type export_format_stddev_samp_fields {
  applicableView: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listOrder: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by stddev_samp() on columns of table "export_format"
input export_format_stddev_samp_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate sum on columns
type export_format_sum_fields {
  applicableView: Int
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listOrder: Int
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# order by sum() on columns of table "export_format"
input export_format_sum_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# update columns of table "export_format"
enum export_format_update_column {
  # column name
  applicableAnnotation

  # column name
  applicableClass

  # column name
  applicableView

  # column name
  approved

  # column name
  approverMtid

  # column name
  builtin

  # column name
  calculatedApplicableClass

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  enabled

  # column name
  error

  # column name
  extension

  # column name
  global

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listOrder

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxDedicatedRole

  # column name
  minDedicatedRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  notApplicableAnnotation

  # column name
  notApplicableClass

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerInstitute

  # column name
  parameters

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  specificVersionOf

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xslFileMtid
}

# aggregate var_pop on columns
type export_format_var_pop_fields {
  applicableView: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listOrder: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by var_pop() on columns of table "export_format"
input export_format_var_pop_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate var_samp on columns
type export_format_var_samp_fields {
  applicableView: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listOrder: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by var_samp() on columns of table "export_format"
input export_format_var_samp_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate variance on columns
type export_format_variance_fields {
  applicableView: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listOrder: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by variance() on columns of table "export_format"
input export_format_variance_order_by {
  applicableView: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listOrder: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# columns and relationships of "export_request"
type export_request {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int

  # An object relationship
  file: uploaded_file
  fileMtid: bigint

  # An object relationship
  format: export_format
  formatMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean!
  queued: Boolean!
  refreshed: Boolean!
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "export_request"
type export_request_aggregate {
  aggregate: export_request_aggregate_fields
  nodes: [export_request!]!
}

# aggregate fields of "export_request"
type export_request_aggregate_fields {
  avg: export_request_avg_fields
  count(columns: [export_request_select_column!], distinct: Boolean): Int
  max: export_request_max_fields
  min: export_request_min_fields
  stddev: export_request_stddev_fields
  stddev_pop: export_request_stddev_pop_fields
  stddev_samp: export_request_stddev_samp_fields
  sum: export_request_sum_fields
  var_pop: export_request_var_pop_fields
  var_samp: export_request_var_samp_fields
  variance: export_request_variance_fields
}

# order by aggregate values of table "export_request"
input export_request_aggregate_order_by {
  avg: export_request_avg_order_by
  count: order_by
  max: export_request_max_order_by
  min: export_request_min_order_by
  stddev: export_request_stddev_order_by
  stddev_pop: export_request_stddev_pop_order_by
  stddev_samp: export_request_stddev_samp_order_by
  sum: export_request_sum_order_by
  var_pop: export_request_var_pop_order_by
  var_samp: export_request_var_samp_order_by
  variance: export_request_variance_order_by
}

# input type for inserting array relation for remote table "export_request"
input export_request_arr_rel_insert_input {
  data: [export_request_insert_input!]!
  on_conflict: export_request_on_conflict
}

# aggregate avg on columns
type export_request_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "export_request"
input export_request_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "export_request". All fields are combined with a logical 'AND'.
input export_request_bool_exp {
  _and: [export_request_bool_exp]
  _not: export_request_bool_exp
  _or: [export_request_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  file: uploaded_file_bool_exp
  fileMtid: bigint_comparison_exp
  format: export_format_bool_exp
  formatMtid: bigint_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  seen: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "export_request"
enum export_request_constraint {
  # unique or primary key constraint
  export_request_pkey
}

# input type for incrementing integer column in table "export_request"
input export_request_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  fileMtid: bigint
  formatMtid: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "export_request"
input export_request_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  file: uploaded_file_obj_rel_insert_input
  fileMtid: bigint
  format: export_format_obj_rel_insert_input
  formatMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type export_request_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  fileMtid: bigint
  formatMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "export_request"
input export_request_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type export_request_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  fileMtid: bigint
  formatMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "export_request"
input export_request_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "export_request"
type export_request_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [export_request!]!
}

# input type for inserting object relation for remote table "export_request"
input export_request_obj_rel_insert_input {
  data: export_request_insert_input!
  on_conflict: export_request_on_conflict
}

# on conflict condition type for table "export_request"
input export_request_on_conflict {
  constraint: export_request_constraint!
  update_columns: [export_request_update_column!]!
  where: export_request_bool_exp
}

# ordering options when selecting data from "export_request"
input export_request_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  file: uploaded_file_order_by
  fileMtid: order_by
  format: export_format_order_by
  formatMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  queued: order_by
  refreshed: order_by
  seen: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "export_request"
input export_request_pk_columns_input {
  mtid: bigint!
}

# select columns of table "export_request"
enum export_request_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  fileMtid

  # column name
  formatMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "export_request"
input export_request_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  fileMtid: bigint
  formatMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type export_request_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "export_request"
input export_request_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type export_request_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "export_request"
input export_request_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type export_request_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "export_request"
input export_request_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type export_request_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  fileMtid: bigint
  formatMtid: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "export_request"
input export_request_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "export_request"
enum export_request_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  fileMtid

  # column name
  formatMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type export_request_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "export_request"
input export_request_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type export_request_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "export_request"
input export_request_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type export_request_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "export_request"
input export_request_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# expression to compare columns of type Float. All fields are combined with logical 'AND'.
input Float_comparison_exp {
  _eq: Float
  _gt: Float
  _gte: Float
  _in: [Float!]
  _is_null: Boolean
  _lt: Float
  _lte: Float
  _neq: Float
  _nin: [Float!]
}

scalar float8

# expression to compare columns of type float8. All fields are combined with logical 'AND'.
input float8_comparison_exp {
  _eq: float8
  _gt: float8
  _gte: float8
  _in: [float8!]
  _is_null: Boolean
  _lt: float8
  _lte: float8
  _neq: float8
  _nin: [float8!]
}

# columns and relationships of "forum"
type forum {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String

  # An object relationship
  institute: organization
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  scope: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "forum"
type forum_aggregate {
  aggregate: forum_aggregate_fields
  nodes: [forum!]!
}

# aggregate fields of "forum"
type forum_aggregate_fields {
  avg: forum_avg_fields
  count(columns: [forum_select_column!], distinct: Boolean): Int
  max: forum_max_fields
  min: forum_min_fields
  stddev: forum_stddev_fields
  stddev_pop: forum_stddev_pop_fields
  stddev_samp: forum_stddev_samp_fields
  sum: forum_sum_fields
  var_pop: forum_var_pop_fields
  var_samp: forum_var_samp_fields
  variance: forum_variance_fields
}

# order by aggregate values of table "forum"
input forum_aggregate_order_by {
  avg: forum_avg_order_by
  count: order_by
  max: forum_max_order_by
  min: forum_min_order_by
  stddev: forum_stddev_order_by
  stddev_pop: forum_stddev_pop_order_by
  stddev_samp: forum_stddev_samp_order_by
  sum: forum_sum_order_by
  var_pop: forum_var_pop_order_by
  var_samp: forum_var_samp_order_by
  variance: forum_variance_order_by
}

# input type for inserting array relation for remote table "forum"
input forum_arr_rel_insert_input {
  data: [forum_insert_input!]!
  on_conflict: forum_on_conflict
}

# aggregate avg on columns
type forum_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  scope: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "forum"
input forum_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "forum". All fields are combined with a logical 'AND'.
input forum_bool_exp {
  _and: [forum_bool_exp]
  _not: forum_bool_exp
  _or: [forum_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  institute: organization_bool_exp
  instituteMtid: bigint_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  scope: Int_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "forum"
enum forum_constraint {
  # unique or primary key constraint
  forum_pkey
}

# input type for incrementing integer column in table "forum"
input forum_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  scope: Int
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "forum"
input forum_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  institute: organization_obj_rel_insert_input
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  scope: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type forum_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  scope: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "forum"
input forum_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type forum_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  scope: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "forum"
input forum_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "forum"
type forum_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [forum!]!
}

# input type for inserting object relation for remote table "forum"
input forum_obj_rel_insert_input {
  data: forum_insert_input!
  on_conflict: forum_on_conflict
}

# on conflict condition type for table "forum"
input forum_on_conflict {
  constraint: forum_constraint!
  update_columns: [forum_update_column!]!
  where: forum_bool_exp
}

# ordering options when selecting data from "forum"
input forum_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  institute: organization_order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  scope: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "forum"
input forum_pk_columns_input {
  mtid: bigint!
}

# select columns of table "forum"
enum forum_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  scope

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "forum"
input forum_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  scope: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type forum_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  scope: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "forum"
input forum_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type forum_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  scope: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "forum"
input forum_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type forum_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  scope: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "forum"
input forum_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type forum_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  scope: Int
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "forum"
input forum_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "forum"
enum forum_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  scope

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type forum_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  scope: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "forum"
input forum_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type forum_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  scope: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "forum"
input forum_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type forum_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  scope: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "forum"
input forum_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  scope: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "funding"
type funding {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint

  # An object relationship
  project: project
  projectMtid: bigint

  # An object relationship
  publication: publication
  publicationMtid: bigint
  published: Boolean!
  refreshed: Boolean!
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "funding"
type funding_aggregate {
  aggregate: funding_aggregate_fields
  nodes: [funding!]!
}

# aggregate fields of "funding"
type funding_aggregate_fields {
  avg: funding_avg_fields
  count(columns: [funding_select_column!], distinct: Boolean): Int
  max: funding_max_fields
  min: funding_min_fields
  stddev: funding_stddev_fields
  stddev_pop: funding_stddev_pop_fields
  stddev_samp: funding_stddev_samp_fields
  sum: funding_sum_fields
  var_pop: funding_var_pop_fields
  var_samp: funding_var_samp_fields
  variance: funding_variance_fields
}

# order by aggregate values of table "funding"
input funding_aggregate_order_by {
  avg: funding_avg_order_by
  count: order_by
  max: funding_max_order_by
  min: funding_min_order_by
  stddev: funding_stddev_order_by
  stddev_pop: funding_stddev_pop_order_by
  stddev_samp: funding_stddev_samp_order_by
  sum: funding_sum_order_by
  var_pop: funding_var_pop_order_by
  var_samp: funding_var_samp_order_by
  variance: funding_variance_order_by
}

# input type for inserting array relation for remote table "funding"
input funding_arr_rel_insert_input {
  data: [funding_insert_input!]!
  on_conflict: funding_on_conflict
}

# aggregate avg on columns
type funding_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  projectMtid: Float
  publicationMtid: Float
  share: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "funding"
input funding_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "funding". All fields are combined with a logical 'AND'.
input funding_bool_exp {
  _and: [funding_bool_exp]
  _not: funding_bool_exp
  _or: [funding_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  project: project_bool_exp
  projectMtid: bigint_comparison_exp
  publication: publication_bool_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  share: Float_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "funding"
enum funding_constraint {
  # unique or primary key constraint
  funding_pkey
}

# input type for incrementing integer column in table "funding"
input funding_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  projectMtid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "funding"
input funding_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  project: project_obj_rel_insert_input
  projectMtid: bigint
  publication: publication_obj_rel_insert_input
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type funding_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  projectMtid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "funding"
input funding_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type funding_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  projectMtid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "funding"
input funding_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "funding"
type funding_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [funding!]!
}

# input type for inserting object relation for remote table "funding"
input funding_obj_rel_insert_input {
  data: funding_insert_input!
  on_conflict: funding_on_conflict
}

# on conflict condition type for table "funding"
input funding_on_conflict {
  constraint: funding_constraint!
  update_columns: [funding_update_column!]!
  where: funding_bool_exp
}

# ordering options when selecting data from "funding"
input funding_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  project: project_order_by
  projectMtid: order_by
  publication: publication_order_by
  publicationMtid: order_by
  published: order_by
  refreshed: order_by
  share: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "funding"
input funding_pk_columns_input {
  mtid: bigint!
}

# select columns of table "funding"
enum funding_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  projectMtid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  share

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "funding"
input funding_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  projectMtid: bigint
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  share: Float
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type funding_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  projectMtid: Float
  publicationMtid: Float
  share: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "funding"
input funding_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type funding_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  projectMtid: Float
  publicationMtid: Float
  share: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "funding"
input funding_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type funding_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  projectMtid: Float
  publicationMtid: Float
  share: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "funding"
input funding_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type funding_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  projectMtid: bigint
  publicationMtid: bigint
  share: Float
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "funding"
input funding_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "funding"
enum funding_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  projectMtid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  share

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type funding_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  projectMtid: Float
  publicationMtid: Float
  share: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "funding"
input funding_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type funding_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  projectMtid: Float
  publicationMtid: Float
  share: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "funding"
input funding_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type funding_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  projectMtid: Float
  publicationMtid: Float
  share: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "funding"
input funding_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  projectMtid: order_by
  publicationMtid: order_by
  share: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "import_alias"
type import_alias {
  alias: String
  aliasMappedId: bigint!
  aliasMappedLabel: String
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int

  # An object relationship
  format: import_format
  formatMtid: bigint
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "import_alias"
type import_alias_aggregate {
  aggregate: import_alias_aggregate_fields
  nodes: [import_alias!]!
}

# aggregate fields of "import_alias"
type import_alias_aggregate_fields {
  avg: import_alias_avg_fields
  count(columns: [import_alias_select_column!], distinct: Boolean): Int
  max: import_alias_max_fields
  min: import_alias_min_fields
  stddev: import_alias_stddev_fields
  stddev_pop: import_alias_stddev_pop_fields
  stddev_samp: import_alias_stddev_samp_fields
  sum: import_alias_sum_fields
  var_pop: import_alias_var_pop_fields
  var_samp: import_alias_var_samp_fields
  variance: import_alias_variance_fields
}

# order by aggregate values of table "import_alias"
input import_alias_aggregate_order_by {
  avg: import_alias_avg_order_by
  count: order_by
  max: import_alias_max_order_by
  min: import_alias_min_order_by
  stddev: import_alias_stddev_order_by
  stddev_pop: import_alias_stddev_pop_order_by
  stddev_samp: import_alias_stddev_samp_order_by
  sum: import_alias_sum_order_by
  var_pop: import_alias_var_pop_order_by
  var_samp: import_alias_var_samp_order_by
  variance: import_alias_variance_order_by
}

# input type for inserting array relation for remote table "import_alias"
input import_alias_arr_rel_insert_input {
  data: [import_alias_insert_input!]!
  on_conflict: import_alias_on_conflict
}

# aggregate avg on columns
type import_alias_avg_fields {
  aliasMappedId: Float
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  formatMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "import_alias"
input import_alias_avg_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "import_alias". All fields are combined with a logical 'AND'.
input import_alias_bool_exp {
  _and: [import_alias_bool_exp]
  _not: import_alias_bool_exp
  _or: [import_alias_bool_exp]
  alias: String_comparison_exp
  aliasMappedId: bigint_comparison_exp
  aliasMappedLabel: String_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  format: import_format_bool_exp
  formatMtid: bigint_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  otypeName: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "import_alias"
enum import_alias_constraint {
  # unique or primary key constraint
  import_alias_pkey
}

# input type for incrementing integer column in table "import_alias"
input import_alias_inc_input {
  aliasMappedId: bigint
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  formatMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "import_alias"
input import_alias_insert_input {
  alias: String
  aliasMappedId: bigint
  aliasMappedLabel: String
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  format: import_format_obj_rel_insert_input
  formatMtid: bigint
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type import_alias_max_fields {
  alias: String
  aliasMappedId: bigint
  aliasMappedLabel: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  formatMtid: bigint
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "import_alias"
input import_alias_max_order_by {
  alias: order_by
  aliasMappedId: order_by
  aliasMappedLabel: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  otypeName: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type import_alias_min_fields {
  alias: String
  aliasMappedId: bigint
  aliasMappedLabel: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  formatMtid: bigint
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "import_alias"
input import_alias_min_order_by {
  alias: order_by
  aliasMappedId: order_by
  aliasMappedLabel: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  otypeName: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "import_alias"
type import_alias_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [import_alias!]!
}

# input type for inserting object relation for remote table "import_alias"
input import_alias_obj_rel_insert_input {
  data: import_alias_insert_input!
  on_conflict: import_alias_on_conflict
}

# on conflict condition type for table "import_alias"
input import_alias_on_conflict {
  constraint: import_alias_constraint!
  update_columns: [import_alias_update_column!]!
  where: import_alias_bool_exp
}

# ordering options when selecting data from "import_alias"
input import_alias_order_by {
  alias: order_by
  aliasMappedId: order_by
  aliasMappedLabel: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  format: import_format_order_by
  formatMtid: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  otypeName: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "import_alias"
input import_alias_pk_columns_input {
  mtid: bigint!
}

# select columns of table "import_alias"
enum import_alias_select_column {
  # column name
  alias

  # column name
  aliasMappedId

  # column name
  aliasMappedLabel

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  formatMtid

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  otypeName

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "import_alias"
input import_alias_set_input {
  alias: String
  aliasMappedId: bigint
  aliasMappedLabel: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  formatMtid: bigint
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type import_alias_stddev_fields {
  aliasMappedId: Float
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  formatMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "import_alias"
input import_alias_stddev_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type import_alias_stddev_pop_fields {
  aliasMappedId: Float
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  formatMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "import_alias"
input import_alias_stddev_pop_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type import_alias_stddev_samp_fields {
  aliasMappedId: Float
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  formatMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "import_alias"
input import_alias_stddev_samp_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type import_alias_sum_fields {
  aliasMappedId: bigint
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  formatMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "import_alias"
input import_alias_sum_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "import_alias"
enum import_alias_update_column {
  # column name
  alias

  # column name
  aliasMappedId

  # column name
  aliasMappedLabel

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  formatMtid

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  otypeName

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type import_alias_var_pop_fields {
  aliasMappedId: Float
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  formatMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "import_alias"
input import_alias_var_pop_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type import_alias_var_samp_fields {
  aliasMappedId: Float
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  formatMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "import_alias"
input import_alias_var_samp_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type import_alias_variance_fields {
  aliasMappedId: Float
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  formatMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "import_alias"
input import_alias_variance_order_by {
  aliasMappedId: order_by
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  formatMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "import_format"
type import_format {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  citation: Boolean!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  dataCol: Int!
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  enabled: Boolean!
  error: Int
  extension: String
  firstLine: String
  hint: String
  hintEng: String
  keyPhrases: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  sourceName: String
  status: Int
  tagWidth: Int!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint

  # An object relationship
  xslFile: uploaded_file
  xslFileMtid: bigint
}

# aggregated selection of "import_format"
type import_format_aggregate {
  aggregate: import_format_aggregate_fields
  nodes: [import_format!]!
}

# aggregate fields of "import_format"
type import_format_aggregate_fields {
  avg: import_format_avg_fields
  count(columns: [import_format_select_column!], distinct: Boolean): Int
  max: import_format_max_fields
  min: import_format_min_fields
  stddev: import_format_stddev_fields
  stddev_pop: import_format_stddev_pop_fields
  stddev_samp: import_format_stddev_samp_fields
  sum: import_format_sum_fields
  var_pop: import_format_var_pop_fields
  var_samp: import_format_var_samp_fields
  variance: import_format_variance_fields
}

# order by aggregate values of table "import_format"
input import_format_aggregate_order_by {
  avg: import_format_avg_order_by
  count: order_by
  max: import_format_max_order_by
  min: import_format_min_order_by
  stddev: import_format_stddev_order_by
  stddev_pop: import_format_stddev_pop_order_by
  stddev_samp: import_format_stddev_samp_order_by
  sum: import_format_sum_order_by
  var_pop: import_format_var_pop_order_by
  var_samp: import_format_var_samp_order_by
  variance: import_format_variance_order_by
}

# input type for inserting array relation for remote table "import_format"
input import_format_arr_rel_insert_input {
  data: [import_format_insert_input!]!
  on_conflict: import_format_on_conflict
}

# aggregate avg on columns
type import_format_avg_fields {
  approverMtid: Float
  creator: Float
  dataCol: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  tagWidth: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by avg() on columns of table "import_format"
input import_format_avg_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# Boolean expression to filter rows from the table "import_format". All fields are combined with a logical 'AND'.
input import_format_bool_exp {
  _and: [import_format_bool_exp]
  _not: import_format_bool_exp
  _or: [import_format_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  citation: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  dataCol: Int_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  enabled: Boolean_comparison_exp
  error: Int_comparison_exp
  extension: String_comparison_exp
  firstLine: String_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  keyPhrases: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  sourceName: String_comparison_exp
  status: Int_comparison_exp
  tagWidth: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  xslFile: uploaded_file_bool_exp
  xslFileMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "import_format"
enum import_format_constraint {
  # unique or primary key constraint
  import_format_pkey
}

# input type for incrementing integer column in table "import_format"
input import_format_inc_input {
  approverMtid: bigint
  creator: bigint
  dataCol: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  tagWidth: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# input type for inserting data into table "import_format"
input import_format_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  citation: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  dataCol: Int
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  enabled: Boolean
  error: Int
  extension: String
  firstLine: String
  hint: String
  hintEng: String
  keyPhrases: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  sourceName: String
  status: Int
  tagWidth: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFile: uploaded_file_obj_rel_insert_input
  xslFileMtid: bigint
}

# aggregate max on columns
type import_format_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dataCol: Int
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  extension: String
  firstLine: String
  hint: String
  hintEng: String
  keyPhrases: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  sourceName: String
  status: Int
  tagWidth: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# order by max() on columns of table "import_format"
input import_format_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dataCol: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  extension: order_by
  firstLine: order_by
  hint: order_by
  hintEng: order_by
  keyPhrases: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  sourceName: order_by
  status: order_by
  tagWidth: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate min on columns
type import_format_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dataCol: Int
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  extension: String
  firstLine: String
  hint: String
  hintEng: String
  keyPhrases: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  sourceName: String
  status: Int
  tagWidth: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# order by min() on columns of table "import_format"
input import_format_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dataCol: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  extension: order_by
  firstLine: order_by
  hint: order_by
  hintEng: order_by
  keyPhrases: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  sourceName: order_by
  status: order_by
  tagWidth: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# response of any mutation on the table "import_format"
type import_format_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [import_format!]!
}

# input type for inserting object relation for remote table "import_format"
input import_format_obj_rel_insert_input {
  data: import_format_insert_input!
  on_conflict: import_format_on_conflict
}

# on conflict condition type for table "import_format"
input import_format_on_conflict {
  constraint: import_format_constraint!
  update_columns: [import_format_update_column!]!
  where: import_format_bool_exp
}

# ordering options when selecting data from "import_format"
input import_format_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  citation: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  dataCol: order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  enabled: order_by
  error: order_by
  extension: order_by
  firstLine: order_by
  hint: order_by
  hintEng: order_by
  keyPhrases: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  sourceName: order_by
  status: order_by
  tagWidth: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFile: uploaded_file_order_by
  xslFileMtid: order_by
}

# primary key columns input for table: "import_format"
input import_format_pk_columns_input {
  mtid: bigint!
}

# select columns of table "import_format"
enum import_format_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  citation

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dataCol

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  enabled

  # column name
  error

  # column name
  extension

  # column name
  firstLine

  # column name
  hint

  # column name
  hintEng

  # column name
  keyPhrases

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceName

  # column name
  status

  # column name
  tagWidth

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xslFileMtid
}

# input type for updating data in table "import_format"
input import_format_set_input {
  approved: timestamp
  approverMtid: bigint
  citation: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dataCol: Int
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  enabled: Boolean
  error: Int
  extension: String
  firstLine: String
  hint: String
  hintEng: String
  keyPhrases: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  sourceName: String
  status: Int
  tagWidth: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# aggregate stddev on columns
type import_format_stddev_fields {
  approverMtid: Float
  creator: Float
  dataCol: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  tagWidth: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by stddev() on columns of table "import_format"
input import_format_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate stddev_pop on columns
type import_format_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  dataCol: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  tagWidth: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by stddev_pop() on columns of table "import_format"
input import_format_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate stddev_samp on columns
type import_format_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  dataCol: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  tagWidth: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by stddev_samp() on columns of table "import_format"
input import_format_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate sum on columns
type import_format_sum_fields {
  approverMtid: bigint
  creator: bigint
  dataCol: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  tagWidth: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xslFileMtid: bigint
}

# order by sum() on columns of table "import_format"
input import_format_sum_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# update columns of table "import_format"
enum import_format_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  citation

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dataCol

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  enabled

  # column name
  error

  # column name
  extension

  # column name
  firstLine

  # column name
  hint

  # column name
  hintEng

  # column name
  keyPhrases

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceName

  # column name
  status

  # column name
  tagWidth

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xslFileMtid
}

# aggregate var_pop on columns
type import_format_var_pop_fields {
  approverMtid: Float
  creator: Float
  dataCol: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  tagWidth: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by var_pop() on columns of table "import_format"
input import_format_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate var_samp on columns
type import_format_var_samp_fields {
  approverMtid: Float
  creator: Float
  dataCol: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  tagWidth: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by var_samp() on columns of table "import_format"
input import_format_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# aggregate variance on columns
type import_format_variance_fields {
  approverMtid: Float
  creator: Float
  dataCol: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  tagWidth: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xslFileMtid: Float
}

# order by variance() on columns of table "import_format"
input import_format_variance_order_by {
  approverMtid: order_by
  creator: order_by
  dataCol: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  tagWidth: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xslFileMtid: order_by
}

# columns and relationships of "import_log"
type import_log {
  WOSCitationCount: Int
  bibCheckNeeded: Boolean!
  downloaded: Int
  duration: bigint
  error: String
  errorIds: String
  extendedIds: String
  id: bigint!
  identifier: bigint
  jobId: bigint
  jsonText: String
  lastId: String
  maxYear: Int
  newIds: String
  oldId: Int
  oldIds: String
  publicationIdentifier: bigint

  # An object relationship
  request: import_request
  requestMtid: bigint
  sourceIncomplete: Boolean
  timestamp: timestamp
  title: String
  wosState: String
}

# aggregated selection of "import_log"
type import_log_aggregate {
  aggregate: import_log_aggregate_fields
  nodes: [import_log!]!
}

# aggregate fields of "import_log"
type import_log_aggregate_fields {
  avg: import_log_avg_fields
  count(columns: [import_log_select_column!], distinct: Boolean): Int
  max: import_log_max_fields
  min: import_log_min_fields
  stddev: import_log_stddev_fields
  stddev_pop: import_log_stddev_pop_fields
  stddev_samp: import_log_stddev_samp_fields
  sum: import_log_sum_fields
  var_pop: import_log_var_pop_fields
  var_samp: import_log_var_samp_fields
  variance: import_log_variance_fields
}

# order by aggregate values of table "import_log"
input import_log_aggregate_order_by {
  avg: import_log_avg_order_by
  count: order_by
  max: import_log_max_order_by
  min: import_log_min_order_by
  stddev: import_log_stddev_order_by
  stddev_pop: import_log_stddev_pop_order_by
  stddev_samp: import_log_stddev_samp_order_by
  sum: import_log_sum_order_by
  var_pop: import_log_var_pop_order_by
  var_samp: import_log_var_samp_order_by
  variance: import_log_variance_order_by
}

# input type for inserting array relation for remote table "import_log"
input import_log_arr_rel_insert_input {
  data: [import_log_insert_input!]!
  on_conflict: import_log_on_conflict
}

# aggregate avg on columns
type import_log_avg_fields {
  WOSCitationCount: Float
  downloaded: Float
  duration: Float
  id: Float
  identifier: Float
  jobId: Float
  maxYear: Float
  oldId: Float
  publicationIdentifier: Float
  requestMtid: Float
}

# order by avg() on columns of table "import_log"
input import_log_avg_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# Boolean expression to filter rows from the table "import_log". All fields are combined with a logical 'AND'.
input import_log_bool_exp {
  WOSCitationCount: Int_comparison_exp
  _and: [import_log_bool_exp]
  _not: import_log_bool_exp
  _or: [import_log_bool_exp]
  bibCheckNeeded: Boolean_comparison_exp
  downloaded: Int_comparison_exp
  duration: bigint_comparison_exp
  error: String_comparison_exp
  errorIds: String_comparison_exp
  extendedIds: String_comparison_exp
  id: bigint_comparison_exp
  identifier: bigint_comparison_exp
  jobId: bigint_comparison_exp
  jsonText: String_comparison_exp
  lastId: String_comparison_exp
  maxYear: Int_comparison_exp
  newIds: String_comparison_exp
  oldId: Int_comparison_exp
  oldIds: String_comparison_exp
  publicationIdentifier: bigint_comparison_exp
  request: import_request_bool_exp
  requestMtid: bigint_comparison_exp
  sourceIncomplete: Boolean_comparison_exp
  timestamp: timestamp_comparison_exp
  title: String_comparison_exp
  wosState: String_comparison_exp
}

# unique or primary key constraints on table "import_log"
enum import_log_constraint {
  # unique or primary key constraint
  import_log_pkey
}

# input type for incrementing integer column in table "import_log"
input import_log_inc_input {
  WOSCitationCount: Int
  downloaded: Int
  duration: bigint
  id: bigint
  identifier: bigint
  jobId: bigint
  maxYear: Int
  oldId: Int
  publicationIdentifier: bigint
  requestMtid: bigint
}

# input type for inserting data into table "import_log"
input import_log_insert_input {
  WOSCitationCount: Int
  bibCheckNeeded: Boolean
  downloaded: Int
  duration: bigint
  error: String
  errorIds: String
  extendedIds: String
  id: bigint
  identifier: bigint
  jobId: bigint
  jsonText: String
  lastId: String
  maxYear: Int
  newIds: String
  oldId: Int
  oldIds: String
  publicationIdentifier: bigint
  request: import_request_obj_rel_insert_input
  requestMtid: bigint
  sourceIncomplete: Boolean
  timestamp: timestamp
  title: String
  wosState: String
}

# aggregate max on columns
type import_log_max_fields {
  WOSCitationCount: Int
  downloaded: Int
  duration: bigint
  error: String
  errorIds: String
  extendedIds: String
  id: bigint
  identifier: bigint
  jobId: bigint
  jsonText: String
  lastId: String
  maxYear: Int
  newIds: String
  oldId: Int
  oldIds: String
  publicationIdentifier: bigint
  requestMtid: bigint
  timestamp: timestamp
  title: String
  wosState: String
}

# order by max() on columns of table "import_log"
input import_log_max_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  error: order_by
  errorIds: order_by
  extendedIds: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  jsonText: order_by
  lastId: order_by
  maxYear: order_by
  newIds: order_by
  oldId: order_by
  oldIds: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
  timestamp: order_by
  title: order_by
  wosState: order_by
}

# aggregate min on columns
type import_log_min_fields {
  WOSCitationCount: Int
  downloaded: Int
  duration: bigint
  error: String
  errorIds: String
  extendedIds: String
  id: bigint
  identifier: bigint
  jobId: bigint
  jsonText: String
  lastId: String
  maxYear: Int
  newIds: String
  oldId: Int
  oldIds: String
  publicationIdentifier: bigint
  requestMtid: bigint
  timestamp: timestamp
  title: String
  wosState: String
}

# order by min() on columns of table "import_log"
input import_log_min_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  error: order_by
  errorIds: order_by
  extendedIds: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  jsonText: order_by
  lastId: order_by
  maxYear: order_by
  newIds: order_by
  oldId: order_by
  oldIds: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
  timestamp: order_by
  title: order_by
  wosState: order_by
}

# response of any mutation on the table "import_log"
type import_log_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [import_log!]!
}

# input type for inserting object relation for remote table "import_log"
input import_log_obj_rel_insert_input {
  data: import_log_insert_input!
  on_conflict: import_log_on_conflict
}

# on conflict condition type for table "import_log"
input import_log_on_conflict {
  constraint: import_log_constraint!
  update_columns: [import_log_update_column!]!
  where: import_log_bool_exp
}

# ordering options when selecting data from "import_log"
input import_log_order_by {
  WOSCitationCount: order_by
  bibCheckNeeded: order_by
  downloaded: order_by
  duration: order_by
  error: order_by
  errorIds: order_by
  extendedIds: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  jsonText: order_by
  lastId: order_by
  maxYear: order_by
  newIds: order_by
  oldId: order_by
  oldIds: order_by
  publicationIdentifier: order_by
  request: import_request_order_by
  requestMtid: order_by
  sourceIncomplete: order_by
  timestamp: order_by
  title: order_by
  wosState: order_by
}

# primary key columns input for table: "import_log"
input import_log_pk_columns_input {
  id: bigint!
}

# select columns of table "import_log"
enum import_log_select_column {
  # column name
  WOSCitationCount

  # column name
  bibCheckNeeded

  # column name
  downloaded

  # column name
  duration

  # column name
  error

  # column name
  errorIds

  # column name
  extendedIds

  # column name
  id

  # column name
  identifier

  # column name
  jobId

  # column name
  jsonText

  # column name
  lastId

  # column name
  maxYear

  # column name
  newIds

  # column name
  oldId

  # column name
  oldIds

  # column name
  publicationIdentifier

  # column name
  requestMtid

  # column name
  sourceIncomplete

  # column name
  timestamp

  # column name
  title

  # column name
  wosState
}

# input type for updating data in table "import_log"
input import_log_set_input {
  WOSCitationCount: Int
  bibCheckNeeded: Boolean
  downloaded: Int
  duration: bigint
  error: String
  errorIds: String
  extendedIds: String
  id: bigint
  identifier: bigint
  jobId: bigint
  jsonText: String
  lastId: String
  maxYear: Int
  newIds: String
  oldId: Int
  oldIds: String
  publicationIdentifier: bigint
  requestMtid: bigint
  sourceIncomplete: Boolean
  timestamp: timestamp
  title: String
  wosState: String
}

# aggregate stddev on columns
type import_log_stddev_fields {
  WOSCitationCount: Float
  downloaded: Float
  duration: Float
  id: Float
  identifier: Float
  jobId: Float
  maxYear: Float
  oldId: Float
  publicationIdentifier: Float
  requestMtid: Float
}

# order by stddev() on columns of table "import_log"
input import_log_stddev_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# aggregate stddev_pop on columns
type import_log_stddev_pop_fields {
  WOSCitationCount: Float
  downloaded: Float
  duration: Float
  id: Float
  identifier: Float
  jobId: Float
  maxYear: Float
  oldId: Float
  publicationIdentifier: Float
  requestMtid: Float
}

# order by stddev_pop() on columns of table "import_log"
input import_log_stddev_pop_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# aggregate stddev_samp on columns
type import_log_stddev_samp_fields {
  WOSCitationCount: Float
  downloaded: Float
  duration: Float
  id: Float
  identifier: Float
  jobId: Float
  maxYear: Float
  oldId: Float
  publicationIdentifier: Float
  requestMtid: Float
}

# order by stddev_samp() on columns of table "import_log"
input import_log_stddev_samp_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# aggregate sum on columns
type import_log_sum_fields {
  WOSCitationCount: Int
  downloaded: Int
  duration: bigint
  id: bigint
  identifier: bigint
  jobId: bigint
  maxYear: Int
  oldId: Int
  publicationIdentifier: bigint
  requestMtid: bigint
}

# order by sum() on columns of table "import_log"
input import_log_sum_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# update columns of table "import_log"
enum import_log_update_column {
  # column name
  WOSCitationCount

  # column name
  bibCheckNeeded

  # column name
  downloaded

  # column name
  duration

  # column name
  error

  # column name
  errorIds

  # column name
  extendedIds

  # column name
  id

  # column name
  identifier

  # column name
  jobId

  # column name
  jsonText

  # column name
  lastId

  # column name
  maxYear

  # column name
  newIds

  # column name
  oldId

  # column name
  oldIds

  # column name
  publicationIdentifier

  # column name
  requestMtid

  # column name
  sourceIncomplete

  # column name
  timestamp

  # column name
  title

  # column name
  wosState
}

# aggregate var_pop on columns
type import_log_var_pop_fields {
  WOSCitationCount: Float
  downloaded: Float
  duration: Float
  id: Float
  identifier: Float
  jobId: Float
  maxYear: Float
  oldId: Float
  publicationIdentifier: Float
  requestMtid: Float
}

# order by var_pop() on columns of table "import_log"
input import_log_var_pop_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# aggregate var_samp on columns
type import_log_var_samp_fields {
  WOSCitationCount: Float
  downloaded: Float
  duration: Float
  id: Float
  identifier: Float
  jobId: Float
  maxYear: Float
  oldId: Float
  publicationIdentifier: Float
  requestMtid: Float
}

# order by var_samp() on columns of table "import_log"
input import_log_var_samp_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# aggregate variance on columns
type import_log_variance_fields {
  WOSCitationCount: Float
  downloaded: Float
  duration: Float
  id: Float
  identifier: Float
  jobId: Float
  maxYear: Float
  oldId: Float
  publicationIdentifier: Float
  requestMtid: Float
}

# order by variance() on columns of table "import_log"
input import_log_variance_order_by {
  WOSCitationCount: order_by
  downloaded: order_by
  duration: order_by
  id: order_by
  identifier: order_by
  jobId: order_by
  maxYear: order_by
  oldId: order_by
  publicationIdentifier: order_by
  requestMtid: order_by
}

# columns and relationships of "import_request"
type import_request {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  author: users
  authorMtid: bigint

  # An object relationship
  category: category
  categoryMtid: bigint
  citation: Boolean!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users

  # An object relationship
  cronJobRunRequest: cron_job_run_request
  cronJobRunRequestMtid: bigint
  deleted: Boolean!
  deletedDate: timestamp
  doDuplumSearch: Boolean!
  doFullDuplumSearch: Boolean!
  dtype: String!
  duration: bigint
  error: Int
  excludedIdentifiers: String

  # An object relationship
  file: uploaded_file
  fileMtid: bigint

  # An object relationship
  format: import_format
  formatMtid: bigint
  idList: String
  importErrors: Boolean!
  importFailed: Boolean!

  # An object relationship
  institute: organization
  instituteMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String

  # An object relationship
  language: language
  languageMtid: bigint
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users

  # An array relationship
  logs(
    # distinct select on columns
    distinct_on: [import_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_log_order_by!]

    # filter the rows returned
    where: import_log_bool_exp
  ): [import_log!]!

  # An aggregated array relationship
  logs_aggregate(
    # distinct select on columns
    distinct_on: [import_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_log_order_by!]

    # filter the rows returned
    where: import_log_bool_exp
  ): import_log_aggregate!
  mode: Int
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String

  # An object relationship
  publication: publication
  publicationMtid: bigint
  published: Boolean!
  queued: Boolean!
  recordType: Int
  records: String
  refreshed: Boolean!

  # An object relationship
  result: named_list
  resultName: String
  resultStatus: Int
  seen: Boolean
  selfCitationCheck: Boolean!
  status: Int

  # An object relationship
  subType: sub_type
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  toYear: Int
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# aggregated selection of "import_request"
type import_request_aggregate {
  aggregate: import_request_aggregate_fields
  nodes: [import_request!]!
}

# aggregate fields of "import_request"
type import_request_aggregate_fields {
  avg: import_request_avg_fields
  count(columns: [import_request_select_column!], distinct: Boolean): Int
  max: import_request_max_fields
  min: import_request_min_fields
  stddev: import_request_stddev_fields
  stddev_pop: import_request_stddev_pop_fields
  stddev_samp: import_request_stddev_samp_fields
  sum: import_request_sum_fields
  var_pop: import_request_var_pop_fields
  var_samp: import_request_var_samp_fields
  variance: import_request_variance_fields
}

# order by aggregate values of table "import_request"
input import_request_aggregate_order_by {
  avg: import_request_avg_order_by
  count: order_by
  max: import_request_max_order_by
  min: import_request_min_order_by
  stddev: import_request_stddev_order_by
  stddev_pop: import_request_stddev_pop_order_by
  stddev_samp: import_request_stddev_samp_order_by
  sum: import_request_sum_order_by
  var_pop: import_request_var_pop_order_by
  var_samp: import_request_var_samp_order_by
  variance: import_request_variance_order_by
}

# input type for inserting array relation for remote table "import_request"
input import_request_arr_rel_insert_input {
  data: [import_request_insert_input!]!
  on_conflict: import_request_on_conflict
}

# aggregate avg on columns
type import_request_avg_fields {
  approverMtid: Float
  authorMtid: Float
  categoryMtid: Float
  creator: Float
  cronJobRunRequestMtid: Float
  duration: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  instituteMtid: Float
  jobId: Float
  jobStatus: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mode: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  recordType: Float
  resultStatus: Float
  status: Float
  subTypeMtid: Float
  threadId: Float
  threadPriority: Float
  toYear: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by avg() on columns of table "import_request"
input import_request_avg_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# Boolean expression to filter rows from the table "import_request". All fields are combined with a logical 'AND'.
input import_request_bool_exp {
  _and: [import_request_bool_exp]
  _not: import_request_bool_exp
  _or: [import_request_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  author: users_bool_exp
  authorMtid: bigint_comparison_exp
  category: category_bool_exp
  categoryMtid: bigint_comparison_exp
  citation: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  cronJobRunRequest: cron_job_run_request_bool_exp
  cronJobRunRequestMtid: bigint_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  doDuplumSearch: Boolean_comparison_exp
  doFullDuplumSearch: Boolean_comparison_exp
  dtype: String_comparison_exp
  duration: bigint_comparison_exp
  error: Int_comparison_exp
  excludedIdentifiers: String_comparison_exp
  file: uploaded_file_bool_exp
  fileMtid: bigint_comparison_exp
  format: import_format_bool_exp
  formatMtid: bigint_comparison_exp
  idList: String_comparison_exp
  importErrors: Boolean_comparison_exp
  importFailed: Boolean_comparison_exp
  institute: organization_bool_exp
  instituteMtid: bigint_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  language: language_bool_exp
  languageMtid: bigint_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  logs: import_log_bool_exp
  mode: Int_comparison_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  publication: publication_bool_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  recordType: Int_comparison_exp
  records: String_comparison_exp
  refreshed: Boolean_comparison_exp
  result: named_list_bool_exp
  resultName: String_comparison_exp
  resultStatus: Int_comparison_exp
  seen: Boolean_comparison_exp
  selfCitationCheck: Boolean_comparison_exp
  status: Int_comparison_exp
  subType: sub_type_bool_exp
  subTypeMtid: bigint_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  toYear: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  year: Int_comparison_exp
}

# unique or primary key constraints on table "import_request"
enum import_request_constraint {
  # unique or primary key constraint
  import_request_pkey
}

# input type for incrementing integer column in table "import_request"
input import_request_inc_input {
  approverMtid: bigint
  authorMtid: bigint
  categoryMtid: bigint
  creator: bigint
  cronJobRunRequestMtid: bigint
  duration: bigint
  error: Int
  fileMtid: bigint
  formatMtid: bigint
  instituteMtid: bigint
  jobId: bigint
  jobStatus: Int
  languageMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mode: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  recordType: Int
  resultStatus: Int
  status: Int
  subTypeMtid: bigint
  threadId: bigint
  threadPriority: Int
  toYear: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# input type for inserting data into table "import_request"
input import_request_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  author: users_obj_rel_insert_input
  authorMtid: bigint
  category: category_obj_rel_insert_input
  categoryMtid: bigint
  citation: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  cronJobRunRequest: cron_job_run_request_obj_rel_insert_input
  cronJobRunRequestMtid: bigint
  deleted: Boolean
  deletedDate: timestamp
  doDuplumSearch: Boolean
  doFullDuplumSearch: Boolean
  dtype: String
  duration: bigint
  error: Int
  excludedIdentifiers: String
  file: uploaded_file_obj_rel_insert_input
  fileMtid: bigint
  format: import_format_obj_rel_insert_input
  formatMtid: bigint
  idList: String
  importErrors: Boolean
  importFailed: Boolean
  institute: organization_obj_rel_insert_input
  instituteMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: language_obj_rel_insert_input
  languageMtid: bigint
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  logs: import_log_arr_rel_insert_input
  mode: Int
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  publication: publication_obj_rel_insert_input
  publicationMtid: bigint
  published: Boolean
  queued: Boolean
  recordType: Int
  records: String
  refreshed: Boolean
  result: named_list_obj_rel_insert_input
  resultName: String
  resultStatus: Int
  seen: Boolean
  selfCitationCheck: Boolean
  status: Int
  subType: sub_type_obj_rel_insert_input
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  toYear: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# aggregate max on columns
type import_request_max_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  categoryMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronJobRunRequestMtid: bigint
  deletedDate: timestamp
  dtype: String
  duration: bigint
  error: Int
  excludedIdentifiers: String
  fileMtid: bigint
  formatMtid: bigint
  idList: String
  instituteMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  languageMtid: bigint
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mode: Int
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  publicationMtid: bigint
  recordType: Int
  records: String
  resultName: String
  resultStatus: Int
  status: Int
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  toYear: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# order by max() on columns of table "import_request"
input import_request_max_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  deletedDate: order_by
  dtype: order_by
  duration: order_by
  error: order_by
  excludedIdentifiers: order_by
  fileMtid: order_by
  formatMtid: order_by
  idList: order_by
  instituteMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  languageMtid: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  publicationMtid: order_by
  recordType: order_by
  records: order_by
  resultName: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate min on columns
type import_request_min_fields {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  categoryMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronJobRunRequestMtid: bigint
  deletedDate: timestamp
  dtype: String
  duration: bigint
  error: Int
  excludedIdentifiers: String
  fileMtid: bigint
  formatMtid: bigint
  idList: String
  instituteMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  languageMtid: bigint
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mode: Int
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  publicationMtid: bigint
  recordType: Int
  records: String
  resultName: String
  resultStatus: Int
  status: Int
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  toYear: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# order by min() on columns of table "import_request"
input import_request_min_order_by {
  approved: order_by
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  deletedDate: order_by
  dtype: order_by
  duration: order_by
  error: order_by
  excludedIdentifiers: order_by
  fileMtid: order_by
  formatMtid: order_by
  idList: order_by
  instituteMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  languageMtid: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  publicationMtid: order_by
  recordType: order_by
  records: order_by
  resultName: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# response of any mutation on the table "import_request"
type import_request_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [import_request!]!
}

# input type for inserting object relation for remote table "import_request"
input import_request_obj_rel_insert_input {
  data: import_request_insert_input!
  on_conflict: import_request_on_conflict
}

# on conflict condition type for table "import_request"
input import_request_on_conflict {
  constraint: import_request_constraint!
  update_columns: [import_request_update_column!]!
  where: import_request_bool_exp
}

# ordering options when selecting data from "import_request"
input import_request_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  author: users_order_by
  authorMtid: order_by
  category: category_order_by
  categoryMtid: order_by
  citation: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  cronJobRunRequest: cron_job_run_request_order_by
  cronJobRunRequestMtid: order_by
  deleted: order_by
  deletedDate: order_by
  doDuplumSearch: order_by
  doFullDuplumSearch: order_by
  dtype: order_by
  duration: order_by
  error: order_by
  excludedIdentifiers: order_by
  file: uploaded_file_order_by
  fileMtid: order_by
  format: import_format_order_by
  formatMtid: order_by
  idList: order_by
  importErrors: order_by
  importFailed: order_by
  institute: organization_order_by
  instituteMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: language_order_by
  languageMtid: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  logs_aggregate: import_log_aggregate_order_by
  mode: order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  publication: publication_order_by
  publicationMtid: order_by
  published: order_by
  queued: order_by
  recordType: order_by
  records: order_by
  refreshed: order_by
  result: named_list_order_by
  resultName: order_by
  resultStatus: order_by
  seen: order_by
  selfCitationCheck: order_by
  status: order_by
  subType: sub_type_order_by
  subTypeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# primary key columns input for table: "import_request"
input import_request_pk_columns_input {
  mtid: bigint!
}

# select columns of table "import_request"
enum import_request_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  categoryMtid

  # column name
  citation

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronJobRunRequestMtid

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doDuplumSearch

  # column name
  doFullDuplumSearch

  # column name
  dtype

  # column name
  duration

  # column name
  error

  # column name
  excludedIdentifiers

  # column name
  fileMtid

  # column name
  formatMtid

  # column name
  idList

  # column name
  importErrors

  # column name
  importFailed

  # column name
  instituteMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  languageMtid

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mode

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  publicationMtid

  # column name
  published

  # column name
  queued

  # column name
  recordType

  # column name
  records

  # column name
  refreshed

  # column name
  resultName

  # column name
  resultStatus

  # column name
  seen

  # column name
  selfCitationCheck

  # column name
  status

  # column name
  subTypeMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  toYear

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  year
}

# input type for updating data in table "import_request"
input import_request_set_input {
  approved: timestamp
  approverMtid: bigint
  authorMtid: bigint
  categoryMtid: bigint
  citation: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronJobRunRequestMtid: bigint
  deleted: Boolean
  deletedDate: timestamp
  doDuplumSearch: Boolean
  doFullDuplumSearch: Boolean
  dtype: String
  duration: bigint
  error: Int
  excludedIdentifiers: String
  fileMtid: bigint
  formatMtid: bigint
  idList: String
  importErrors: Boolean
  importFailed: Boolean
  instituteMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  languageMtid: bigint
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mode: Int
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  publicationMtid: bigint
  published: Boolean
  queued: Boolean
  recordType: Int
  records: String
  refreshed: Boolean
  resultName: String
  resultStatus: Int
  seen: Boolean
  selfCitationCheck: Boolean
  status: Int
  subTypeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  toYear: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# aggregate stddev on columns
type import_request_stddev_fields {
  approverMtid: Float
  authorMtid: Float
  categoryMtid: Float
  creator: Float
  cronJobRunRequestMtid: Float
  duration: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  instituteMtid: Float
  jobId: Float
  jobStatus: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mode: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  recordType: Float
  resultStatus: Float
  status: Float
  subTypeMtid: Float
  threadId: Float
  threadPriority: Float
  toYear: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev() on columns of table "import_request"
input import_request_stddev_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate stddev_pop on columns
type import_request_stddev_pop_fields {
  approverMtid: Float
  authorMtid: Float
  categoryMtid: Float
  creator: Float
  cronJobRunRequestMtid: Float
  duration: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  instituteMtid: Float
  jobId: Float
  jobStatus: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mode: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  recordType: Float
  resultStatus: Float
  status: Float
  subTypeMtid: Float
  threadId: Float
  threadPriority: Float
  toYear: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev_pop() on columns of table "import_request"
input import_request_stddev_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate stddev_samp on columns
type import_request_stddev_samp_fields {
  approverMtid: Float
  authorMtid: Float
  categoryMtid: Float
  creator: Float
  cronJobRunRequestMtid: Float
  duration: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  instituteMtid: Float
  jobId: Float
  jobStatus: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mode: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  recordType: Float
  resultStatus: Float
  status: Float
  subTypeMtid: Float
  threadId: Float
  threadPriority: Float
  toYear: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev_samp() on columns of table "import_request"
input import_request_stddev_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate sum on columns
type import_request_sum_fields {
  approverMtid: bigint
  authorMtid: bigint
  categoryMtid: bigint
  creator: bigint
  cronJobRunRequestMtid: bigint
  duration: bigint
  error: Int
  fileMtid: bigint
  formatMtid: bigint
  instituteMtid: bigint
  jobId: bigint
  jobStatus: Int
  languageMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mode: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  recordType: Int
  resultStatus: Int
  status: Int
  subTypeMtid: bigint
  threadId: bigint
  threadPriority: Int
  toYear: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: Int
}

# order by sum() on columns of table "import_request"
input import_request_sum_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# update columns of table "import_request"
enum import_request_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  authorMtid

  # column name
  categoryMtid

  # column name
  citation

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronJobRunRequestMtid

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doDuplumSearch

  # column name
  doFullDuplumSearch

  # column name
  dtype

  # column name
  duration

  # column name
  error

  # column name
  excludedIdentifiers

  # column name
  fileMtid

  # column name
  formatMtid

  # column name
  idList

  # column name
  importErrors

  # column name
  importFailed

  # column name
  instituteMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  languageMtid

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mode

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  publicationMtid

  # column name
  published

  # column name
  queued

  # column name
  recordType

  # column name
  records

  # column name
  refreshed

  # column name
  resultName

  # column name
  resultStatus

  # column name
  seen

  # column name
  selfCitationCheck

  # column name
  status

  # column name
  subTypeMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  toYear

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  year
}

# aggregate var_pop on columns
type import_request_var_pop_fields {
  approverMtid: Float
  authorMtid: Float
  categoryMtid: Float
  creator: Float
  cronJobRunRequestMtid: Float
  duration: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  instituteMtid: Float
  jobId: Float
  jobStatus: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mode: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  recordType: Float
  resultStatus: Float
  status: Float
  subTypeMtid: Float
  threadId: Float
  threadPriority: Float
  toYear: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by var_pop() on columns of table "import_request"
input import_request_var_pop_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate var_samp on columns
type import_request_var_samp_fields {
  approverMtid: Float
  authorMtid: Float
  categoryMtid: Float
  creator: Float
  cronJobRunRequestMtid: Float
  duration: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  instituteMtid: Float
  jobId: Float
  jobStatus: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mode: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  recordType: Float
  resultStatus: Float
  status: Float
  subTypeMtid: Float
  threadId: Float
  threadPriority: Float
  toYear: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by var_samp() on columns of table "import_request"
input import_request_var_samp_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate variance on columns
type import_request_variance_fields {
  approverMtid: Float
  authorMtid: Float
  categoryMtid: Float
  creator: Float
  cronJobRunRequestMtid: Float
  duration: Float
  error: Float
  fileMtid: Float
  formatMtid: Float
  instituteMtid: Float
  jobId: Float
  jobStatus: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mode: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  recordType: Float
  resultStatus: Float
  status: Float
  subTypeMtid: Float
  threadId: Float
  threadPriority: Float
  toYear: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by variance() on columns of table "import_request"
input import_request_variance_order_by {
  approverMtid: order_by
  authorMtid: order_by
  categoryMtid: order_by
  creator: order_by
  cronJobRunRequestMtid: order_by
  duration: order_by
  error: order_by
  fileMtid: order_by
  formatMtid: order_by
  instituteMtid: order_by
  jobId: order_by
  jobStatus: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mode: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  recordType: order_by
  resultStatus: order_by
  status: order_by
  subTypeMtid: order_by
  threadId: order_by
  threadPriority: order_by
  toYear: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# columns and relationships of "import_stat"
type import_stat {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int

  # An array relationship
  importErrorDetails(
    # distinct select on columns
    distinct_on: [import_stat_import_error_details_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_import_error_details_order_by!]

    # filter the rows returned
    where: import_stat_import_error_details_bool_exp
  ): [import_stat_import_error_details!]!

  # An aggregated array relationship
  importErrorDetails_aggregate(
    # distinct select on columns
    distinct_on: [import_stat_import_error_details_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_import_error_details_order_by!]

    # filter the rows returned
    where: import_stat_import_error_details_bool_exp
  ): import_stat_import_error_details_aggregate!
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  numberOfDuplums: Int!
  numberOfExistingPubs: Int!
  numberOfNewPubs: Int!
  numberOfOverwrittenPubs: Int!
  numberOfPubsToImport: Int!
  numberOfPubsWithError: Int!
  numberOfSkippedPubs: Int!
  oldId: Int
  oldTimestamp: timestamp
  originalEncoding: String
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  result: named_list
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  unparsableRecords: Int!
  validFromYear: smallint
  validToYear: smallint

  # An array relationship
  wosIds(
    # distinct select on columns
    distinct_on: [import_stat_wos_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_wos_ids_order_by!]

    # filter the rows returned
    where: import_stat_wos_ids_bool_exp
  ): [import_stat_wos_ids!]!

  # An aggregated array relationship
  wosIds_aggregate(
    # distinct select on columns
    distinct_on: [import_stat_wos_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_wos_ids_order_by!]

    # filter the rows returned
    where: import_stat_wos_ids_bool_exp
  ): import_stat_wos_ids_aggregate!
}

# aggregated selection of "import_stat"
type import_stat_aggregate {
  aggregate: import_stat_aggregate_fields
  nodes: [import_stat!]!
}

# aggregate fields of "import_stat"
type import_stat_aggregate_fields {
  avg: import_stat_avg_fields
  count(columns: [import_stat_select_column!], distinct: Boolean): Int
  max: import_stat_max_fields
  min: import_stat_min_fields
  stddev: import_stat_stddev_fields
  stddev_pop: import_stat_stddev_pop_fields
  stddev_samp: import_stat_stddev_samp_fields
  sum: import_stat_sum_fields
  var_pop: import_stat_var_pop_fields
  var_samp: import_stat_var_samp_fields
  variance: import_stat_variance_fields
}

# order by aggregate values of table "import_stat"
input import_stat_aggregate_order_by {
  avg: import_stat_avg_order_by
  count: order_by
  max: import_stat_max_order_by
  min: import_stat_min_order_by
  stddev: import_stat_stddev_order_by
  stddev_pop: import_stat_stddev_pop_order_by
  stddev_samp: import_stat_stddev_samp_order_by
  sum: import_stat_sum_order_by
  var_pop: import_stat_var_pop_order_by
  var_samp: import_stat_var_samp_order_by
  variance: import_stat_variance_order_by
}

# input type for inserting array relation for remote table "import_stat"
input import_stat_arr_rel_insert_input {
  data: [import_stat_insert_input!]!
  on_conflict: import_stat_on_conflict
}

# aggregate avg on columns
type import_stat_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfDuplums: Float
  numberOfExistingPubs: Float
  numberOfNewPubs: Float
  numberOfOverwrittenPubs: Float
  numberOfPubsToImport: Float
  numberOfPubsWithError: Float
  numberOfSkippedPubs: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  unparsableRecords: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "import_stat"
input import_stat_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "import_stat". All fields are combined with a logical 'AND'.
input import_stat_bool_exp {
  _and: [import_stat_bool_exp]
  _not: import_stat_bool_exp
  _or: [import_stat_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  importErrorDetails: import_stat_import_error_details_bool_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  numberOfDuplums: Int_comparison_exp
  numberOfExistingPubs: Int_comparison_exp
  numberOfNewPubs: Int_comparison_exp
  numberOfOverwrittenPubs: Int_comparison_exp
  numberOfPubsToImport: Int_comparison_exp
  numberOfPubsWithError: Int_comparison_exp
  numberOfSkippedPubs: Int_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  originalEncoding: String_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  result: named_list_bool_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  unparsableRecords: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  wosIds: import_stat_wos_ids_bool_exp
}

# unique or primary key constraints on table "import_stat"
enum import_stat_constraint {
  # unique or primary key constraint
  import_stat_pkey
}

# columns and relationships of "import_stat_import_error_details"
type import_stat_import_error_details {
  importErrorDetailsMtid: bigint!
  importStatMtid: bigint!

  # An object relationship
  risImportErrorDetail: ris_import_error_detail!
}

# aggregated selection of "import_stat_import_error_details"
type import_stat_import_error_details_aggregate {
  aggregate: import_stat_import_error_details_aggregate_fields
  nodes: [import_stat_import_error_details!]!
}

# aggregate fields of "import_stat_import_error_details"
type import_stat_import_error_details_aggregate_fields {
  avg: import_stat_import_error_details_avg_fields
  count(columns: [import_stat_import_error_details_select_column!], distinct: Boolean): Int
  max: import_stat_import_error_details_max_fields
  min: import_stat_import_error_details_min_fields
  stddev: import_stat_import_error_details_stddev_fields
  stddev_pop: import_stat_import_error_details_stddev_pop_fields
  stddev_samp: import_stat_import_error_details_stddev_samp_fields
  sum: import_stat_import_error_details_sum_fields
  var_pop: import_stat_import_error_details_var_pop_fields
  var_samp: import_stat_import_error_details_var_samp_fields
  variance: import_stat_import_error_details_variance_fields
}

# order by aggregate values of table "import_stat_import_error_details"
input import_stat_import_error_details_aggregate_order_by {
  avg: import_stat_import_error_details_avg_order_by
  count: order_by
  max: import_stat_import_error_details_max_order_by
  min: import_stat_import_error_details_min_order_by
  stddev: import_stat_import_error_details_stddev_order_by
  stddev_pop: import_stat_import_error_details_stddev_pop_order_by
  stddev_samp: import_stat_import_error_details_stddev_samp_order_by
  sum: import_stat_import_error_details_sum_order_by
  var_pop: import_stat_import_error_details_var_pop_order_by
  var_samp: import_stat_import_error_details_var_samp_order_by
  variance: import_stat_import_error_details_variance_order_by
}

# input type for inserting array relation for remote table "import_stat_import_error_details"
input import_stat_import_error_details_arr_rel_insert_input {
  data: [import_stat_import_error_details_insert_input!]!
  on_conflict: import_stat_import_error_details_on_conflict
}

# aggregate avg on columns
type import_stat_import_error_details_avg_fields {
  importErrorDetailsMtid: Float
  importStatMtid: Float
}

# order by avg() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_avg_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# Boolean expression to filter rows from the table
# "import_stat_import_error_details". All fields are combined with a logical 'AND'.
input import_stat_import_error_details_bool_exp {
  _and: [import_stat_import_error_details_bool_exp]
  _not: import_stat_import_error_details_bool_exp
  _or: [import_stat_import_error_details_bool_exp]
  importErrorDetailsMtid: bigint_comparison_exp
  importStatMtid: bigint_comparison_exp
  risImportErrorDetail: ris_import_error_detail_bool_exp
}

# unique or primary key constraints on table "import_stat_import_error_details"
enum import_stat_import_error_details_constraint {
  # unique or primary key constraint
  uk_qv2ut6p9l0on7kwekhv13dlwd
}

# input type for incrementing integer column in table "import_stat_import_error_details"
input import_stat_import_error_details_inc_input {
  importErrorDetailsMtid: bigint
  importStatMtid: bigint
}

# input type for inserting data into table "import_stat_import_error_details"
input import_stat_import_error_details_insert_input {
  importErrorDetailsMtid: bigint
  importStatMtid: bigint
  risImportErrorDetail: ris_import_error_detail_obj_rel_insert_input
}

# aggregate max on columns
type import_stat_import_error_details_max_fields {
  importErrorDetailsMtid: bigint
  importStatMtid: bigint
}

# order by max() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_max_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# aggregate min on columns
type import_stat_import_error_details_min_fields {
  importErrorDetailsMtid: bigint
  importStatMtid: bigint
}

# order by min() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_min_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# response of any mutation on the table "import_stat_import_error_details"
type import_stat_import_error_details_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [import_stat_import_error_details!]!
}

# input type for inserting object relation for remote table "import_stat_import_error_details"
input import_stat_import_error_details_obj_rel_insert_input {
  data: import_stat_import_error_details_insert_input!
  on_conflict: import_stat_import_error_details_on_conflict
}

# on conflict condition type for table "import_stat_import_error_details"
input import_stat_import_error_details_on_conflict {
  constraint: import_stat_import_error_details_constraint!
  update_columns: [import_stat_import_error_details_update_column!]!
  where: import_stat_import_error_details_bool_exp
}

# ordering options when selecting data from "import_stat_import_error_details"
input import_stat_import_error_details_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
  risImportErrorDetail: ris_import_error_detail_order_by
}

# select columns of table "import_stat_import_error_details"
enum import_stat_import_error_details_select_column {
  # column name
  importErrorDetailsMtid

  # column name
  importStatMtid
}

# input type for updating data in table "import_stat_import_error_details"
input import_stat_import_error_details_set_input {
  importErrorDetailsMtid: bigint
  importStatMtid: bigint
}

# aggregate stddev on columns
type import_stat_import_error_details_stddev_fields {
  importErrorDetailsMtid: Float
  importStatMtid: Float
}

# order by stddev() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_stddev_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# aggregate stddev_pop on columns
type import_stat_import_error_details_stddev_pop_fields {
  importErrorDetailsMtid: Float
  importStatMtid: Float
}

# order by stddev_pop() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_stddev_pop_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# aggregate stddev_samp on columns
type import_stat_import_error_details_stddev_samp_fields {
  importErrorDetailsMtid: Float
  importStatMtid: Float
}

# order by stddev_samp() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_stddev_samp_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# aggregate sum on columns
type import_stat_import_error_details_sum_fields {
  importErrorDetailsMtid: bigint
  importStatMtid: bigint
}

# order by sum() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_sum_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# update columns of table "import_stat_import_error_details"
enum import_stat_import_error_details_update_column {
  # column name
  importErrorDetailsMtid

  # column name
  importStatMtid
}

# aggregate var_pop on columns
type import_stat_import_error_details_var_pop_fields {
  importErrorDetailsMtid: Float
  importStatMtid: Float
}

# order by var_pop() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_var_pop_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# aggregate var_samp on columns
type import_stat_import_error_details_var_samp_fields {
  importErrorDetailsMtid: Float
  importStatMtid: Float
}

# order by var_samp() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_var_samp_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# aggregate variance on columns
type import_stat_import_error_details_variance_fields {
  importErrorDetailsMtid: Float
  importStatMtid: Float
}

# order by variance() on columns of table "import_stat_import_error_details"
input import_stat_import_error_details_variance_order_by {
  importErrorDetailsMtid: order_by
  importStatMtid: order_by
}

# input type for incrementing integer column in table "import_stat"
input import_stat_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  numberOfDuplums: Int
  numberOfExistingPubs: Int
  numberOfNewPubs: Int
  numberOfOverwrittenPubs: Int
  numberOfPubsToImport: Int
  numberOfPubsWithError: Int
  numberOfSkippedPubs: Int
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  unparsableRecords: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "import_stat"
input import_stat_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  importErrorDetails: import_stat_import_error_details_arr_rel_insert_input
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  numberOfDuplums: Int
  numberOfExistingPubs: Int
  numberOfNewPubs: Int
  numberOfOverwrittenPubs: Int
  numberOfPubsToImport: Int
  numberOfPubsWithError: Int
  numberOfSkippedPubs: Int
  oldId: Int
  oldTimestamp: timestamp
  originalEncoding: String
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  result: named_list_obj_rel_insert_input
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unparsableRecords: Int
  validFromYear: smallint
  validToYear: smallint
  wosIds: import_stat_wos_ids_arr_rel_insert_input
}

# aggregate max on columns
type import_stat_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  numberOfDuplums: Int
  numberOfExistingPubs: Int
  numberOfNewPubs: Int
  numberOfOverwrittenPubs: Int
  numberOfPubsToImport: Int
  numberOfPubsWithError: Int
  numberOfSkippedPubs: Int
  oldId: Int
  oldTimestamp: timestamp
  originalEncoding: String
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unparsableRecords: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "import_stat"
input import_stat_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  oldTimestamp: order_by
  originalEncoding: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type import_stat_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  numberOfDuplums: Int
  numberOfExistingPubs: Int
  numberOfNewPubs: Int
  numberOfOverwrittenPubs: Int
  numberOfPubsToImport: Int
  numberOfPubsWithError: Int
  numberOfSkippedPubs: Int
  oldId: Int
  oldTimestamp: timestamp
  originalEncoding: String
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unparsableRecords: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "import_stat"
input import_stat_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  oldTimestamp: order_by
  originalEncoding: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "import_stat"
type import_stat_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [import_stat!]!
}

# input type for inserting object relation for remote table "import_stat"
input import_stat_obj_rel_insert_input {
  data: import_stat_insert_input!
  on_conflict: import_stat_on_conflict
}

# on conflict condition type for table "import_stat"
input import_stat_on_conflict {
  constraint: import_stat_constraint!
  update_columns: [import_stat_update_column!]!
  where: import_stat_bool_exp
}

# ordering options when selecting data from "import_stat"
input import_stat_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  importErrorDetails_aggregate: import_stat_import_error_details_aggregate_order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  oldTimestamp: order_by
  originalEncoding: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  result: named_list_order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
  wosIds_aggregate: import_stat_wos_ids_aggregate_order_by
}

# primary key columns input for table: "import_stat"
input import_stat_pk_columns_input {
  mtid: bigint!
}

# select columns of table "import_stat"
enum import_stat_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  numberOfDuplums

  # column name
  numberOfExistingPubs

  # column name
  numberOfNewPubs

  # column name
  numberOfOverwrittenPubs

  # column name
  numberOfPubsToImport

  # column name
  numberOfPubsWithError

  # column name
  numberOfSkippedPubs

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  originalEncoding

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  unparsableRecords

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "import_stat"
input import_stat_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  numberOfDuplums: Int
  numberOfExistingPubs: Int
  numberOfNewPubs: Int
  numberOfOverwrittenPubs: Int
  numberOfPubsToImport: Int
  numberOfPubsWithError: Int
  numberOfSkippedPubs: Int
  oldId: Int
  oldTimestamp: timestamp
  originalEncoding: String
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unparsableRecords: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type import_stat_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfDuplums: Float
  numberOfExistingPubs: Float
  numberOfNewPubs: Float
  numberOfOverwrittenPubs: Float
  numberOfPubsToImport: Float
  numberOfPubsWithError: Float
  numberOfSkippedPubs: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  unparsableRecords: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "import_stat"
input import_stat_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type import_stat_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfDuplums: Float
  numberOfExistingPubs: Float
  numberOfNewPubs: Float
  numberOfOverwrittenPubs: Float
  numberOfPubsToImport: Float
  numberOfPubsWithError: Float
  numberOfSkippedPubs: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  unparsableRecords: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "import_stat"
input import_stat_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type import_stat_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfDuplums: Float
  numberOfExistingPubs: Float
  numberOfNewPubs: Float
  numberOfOverwrittenPubs: Float
  numberOfPubsToImport: Float
  numberOfPubsWithError: Float
  numberOfSkippedPubs: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  unparsableRecords: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "import_stat"
input import_stat_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type import_stat_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  numberOfDuplums: Int
  numberOfExistingPubs: Int
  numberOfNewPubs: Int
  numberOfOverwrittenPubs: Int
  numberOfPubsToImport: Int
  numberOfPubsWithError: Int
  numberOfSkippedPubs: Int
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  unparsableRecords: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "import_stat"
input import_stat_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "import_stat"
enum import_stat_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  numberOfDuplums

  # column name
  numberOfExistingPubs

  # column name
  numberOfNewPubs

  # column name
  numberOfOverwrittenPubs

  # column name
  numberOfPubsToImport

  # column name
  numberOfPubsWithError

  # column name
  numberOfSkippedPubs

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  originalEncoding

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  unparsableRecords

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type import_stat_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfDuplums: Float
  numberOfExistingPubs: Float
  numberOfNewPubs: Float
  numberOfOverwrittenPubs: Float
  numberOfPubsToImport: Float
  numberOfPubsWithError: Float
  numberOfSkippedPubs: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  unparsableRecords: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "import_stat"
input import_stat_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type import_stat_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfDuplums: Float
  numberOfExistingPubs: Float
  numberOfNewPubs: Float
  numberOfOverwrittenPubs: Float
  numberOfPubsToImport: Float
  numberOfPubsWithError: Float
  numberOfSkippedPubs: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  unparsableRecords: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "import_stat"
input import_stat_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type import_stat_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfDuplums: Float
  numberOfExistingPubs: Float
  numberOfNewPubs: Float
  numberOfOverwrittenPubs: Float
  numberOfPubsToImport: Float
  numberOfPubsWithError: Float
  numberOfSkippedPubs: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  unparsableRecords: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "import_stat"
input import_stat_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfDuplums: order_by
  numberOfExistingPubs: order_by
  numberOfNewPubs: order_by
  numberOfOverwrittenPubs: order_by
  numberOfPubsToImport: order_by
  numberOfPubsWithError: order_by
  numberOfSkippedPubs: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  unparsableRecords: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "import_stat_wos_ids"
type import_stat_wos_ids {
  import_stat_mtid: bigint!
  wos_ids: String
}

# aggregated selection of "import_stat_wos_ids"
type import_stat_wos_ids_aggregate {
  aggregate: import_stat_wos_ids_aggregate_fields
  nodes: [import_stat_wos_ids!]!
}

# aggregate fields of "import_stat_wos_ids"
type import_stat_wos_ids_aggregate_fields {
  avg: import_stat_wos_ids_avg_fields
  count(columns: [import_stat_wos_ids_select_column!], distinct: Boolean): Int
  max: import_stat_wos_ids_max_fields
  min: import_stat_wos_ids_min_fields
  stddev: import_stat_wos_ids_stddev_fields
  stddev_pop: import_stat_wos_ids_stddev_pop_fields
  stddev_samp: import_stat_wos_ids_stddev_samp_fields
  sum: import_stat_wos_ids_sum_fields
  var_pop: import_stat_wos_ids_var_pop_fields
  var_samp: import_stat_wos_ids_var_samp_fields
  variance: import_stat_wos_ids_variance_fields
}

# order by aggregate values of table "import_stat_wos_ids"
input import_stat_wos_ids_aggregate_order_by {
  avg: import_stat_wos_ids_avg_order_by
  count: order_by
  max: import_stat_wos_ids_max_order_by
  min: import_stat_wos_ids_min_order_by
  stddev: import_stat_wos_ids_stddev_order_by
  stddev_pop: import_stat_wos_ids_stddev_pop_order_by
  stddev_samp: import_stat_wos_ids_stddev_samp_order_by
  sum: import_stat_wos_ids_sum_order_by
  var_pop: import_stat_wos_ids_var_pop_order_by
  var_samp: import_stat_wos_ids_var_samp_order_by
  variance: import_stat_wos_ids_variance_order_by
}

# input type for inserting array relation for remote table "import_stat_wos_ids"
input import_stat_wos_ids_arr_rel_insert_input {
  data: [import_stat_wos_ids_insert_input!]!
}

# aggregate avg on columns
type import_stat_wos_ids_avg_fields {
  import_stat_mtid: Float
}

# order by avg() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_avg_order_by {
  import_stat_mtid: order_by
}

# Boolean expression to filter rows from the table "import_stat_wos_ids". All fields are combined with a logical 'AND'.
input import_stat_wos_ids_bool_exp {
  _and: [import_stat_wos_ids_bool_exp]
  _not: import_stat_wos_ids_bool_exp
  _or: [import_stat_wos_ids_bool_exp]
  import_stat_mtid: bigint_comparison_exp
  wos_ids: String_comparison_exp
}

# input type for incrementing integer column in table "import_stat_wos_ids"
input import_stat_wos_ids_inc_input {
  import_stat_mtid: bigint
}

# input type for inserting data into table "import_stat_wos_ids"
input import_stat_wos_ids_insert_input {
  import_stat_mtid: bigint
  wos_ids: String
}

# aggregate max on columns
type import_stat_wos_ids_max_fields {
  import_stat_mtid: bigint
  wos_ids: String
}

# order by max() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_max_order_by {
  import_stat_mtid: order_by
  wos_ids: order_by
}

# aggregate min on columns
type import_stat_wos_ids_min_fields {
  import_stat_mtid: bigint
  wos_ids: String
}

# order by min() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_min_order_by {
  import_stat_mtid: order_by
  wos_ids: order_by
}

# response of any mutation on the table "import_stat_wos_ids"
type import_stat_wos_ids_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [import_stat_wos_ids!]!
}

# input type for inserting object relation for remote table "import_stat_wos_ids"
input import_stat_wos_ids_obj_rel_insert_input {
  data: import_stat_wos_ids_insert_input!
}

# ordering options when selecting data from "import_stat_wos_ids"
input import_stat_wos_ids_order_by {
  import_stat_mtid: order_by
  wos_ids: order_by
}

# select columns of table "import_stat_wos_ids"
enum import_stat_wos_ids_select_column {
  # column name
  import_stat_mtid

  # column name
  wos_ids
}

# input type for updating data in table "import_stat_wos_ids"
input import_stat_wos_ids_set_input {
  import_stat_mtid: bigint
  wos_ids: String
}

# aggregate stddev on columns
type import_stat_wos_ids_stddev_fields {
  import_stat_mtid: Float
}

# order by stddev() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_stddev_order_by {
  import_stat_mtid: order_by
}

# aggregate stddev_pop on columns
type import_stat_wos_ids_stddev_pop_fields {
  import_stat_mtid: Float
}

# order by stddev_pop() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_stddev_pop_order_by {
  import_stat_mtid: order_by
}

# aggregate stddev_samp on columns
type import_stat_wos_ids_stddev_samp_fields {
  import_stat_mtid: Float
}

# order by stddev_samp() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_stddev_samp_order_by {
  import_stat_mtid: order_by
}

# aggregate sum on columns
type import_stat_wos_ids_sum_fields {
  import_stat_mtid: bigint
}

# order by sum() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_sum_order_by {
  import_stat_mtid: order_by
}

# aggregate var_pop on columns
type import_stat_wos_ids_var_pop_fields {
  import_stat_mtid: Float
}

# order by var_pop() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_var_pop_order_by {
  import_stat_mtid: order_by
}

# aggregate var_samp on columns
type import_stat_wos_ids_var_samp_fields {
  import_stat_mtid: Float
}

# order by var_samp() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_var_samp_order_by {
  import_stat_mtid: order_by
}

# aggregate variance on columns
type import_stat_wos_ids_variance_fields {
  import_stat_mtid: Float
}

# order by variance() on columns of table "import_stat_wos_ids"
input import_stat_wos_ids_variance_order_by {
  import_stat_mtid: order_by
}

# columns and relationships of "institute_type"
type institute_type {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  code: Int!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicSearchable: Boolean
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "institute_type"
type institute_type_aggregate {
  aggregate: institute_type_aggregate_fields
  nodes: [institute_type!]!
}

# aggregate fields of "institute_type"
type institute_type_aggregate_fields {
  avg: institute_type_avg_fields
  count(columns: [institute_type_select_column!], distinct: Boolean): Int
  max: institute_type_max_fields
  min: institute_type_min_fields
  stddev: institute_type_stddev_fields
  stddev_pop: institute_type_stddev_pop_fields
  stddev_samp: institute_type_stddev_samp_fields
  sum: institute_type_sum_fields
  var_pop: institute_type_var_pop_fields
  var_samp: institute_type_var_samp_fields
  variance: institute_type_variance_fields
}

# order by aggregate values of table "institute_type"
input institute_type_aggregate_order_by {
  avg: institute_type_avg_order_by
  count: order_by
  max: institute_type_max_order_by
  min: institute_type_min_order_by
  stddev: institute_type_stddev_order_by
  stddev_pop: institute_type_stddev_pop_order_by
  stddev_samp: institute_type_stddev_samp_order_by
  sum: institute_type_sum_order_by
  var_pop: institute_type_var_pop_order_by
  var_samp: institute_type_var_samp_order_by
  variance: institute_type_variance_order_by
}

# input type for inserting array relation for remote table "institute_type"
input institute_type_arr_rel_insert_input {
  data: [institute_type_insert_input!]!
  on_conflict: institute_type_on_conflict
}

# aggregate avg on columns
type institute_type_avg_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "institute_type"
input institute_type_avg_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "institute_type". All fields are combined with a logical 'AND'.
input institute_type_bool_exp {
  _and: [institute_type_bool_exp]
  _not: institute_type_bool_exp
  _or: [institute_type_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  code: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  publicSearchable: Boolean_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "institute_type"
enum institute_type_constraint {
  # unique or primary key constraint
  institute_type_pkey
}

# input type for incrementing integer column in table "institute_type"
input institute_type_inc_input {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "institute_type"
input institute_type_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicSearchable: Boolean
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type institute_type_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "institute_type"
input institute_type_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type institute_type_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "institute_type"
input institute_type_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "institute_type"
type institute_type_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [institute_type!]!
}

# input type for inserting object relation for remote table "institute_type"
input institute_type_obj_rel_insert_input {
  data: institute_type_insert_input!
  on_conflict: institute_type_on_conflict
}

# on conflict condition type for table "institute_type"
input institute_type_on_conflict {
  constraint: institute_type_constraint!
  update_columns: [institute_type_update_column!]!
  where: institute_type_bool_exp
}

# ordering options when selecting data from "institute_type"
input institute_type_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publicSearchable: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "institute_type"
input institute_type_pk_columns_input {
  mtid: bigint!
}

# select columns of table "institute_type"
enum institute_type_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicSearchable

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "institute_type"
input institute_type_set_input {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicSearchable: Boolean
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type institute_type_stddev_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "institute_type"
input institute_type_stddev_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type institute_type_stddev_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "institute_type"
input institute_type_stddev_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type institute_type_stddev_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "institute_type"
input institute_type_stddev_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type institute_type_sum_fields {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "institute_type"
input institute_type_sum_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "institute_type"
enum institute_type_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicSearchable

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type institute_type_var_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "institute_type"
input institute_type_var_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type institute_type_var_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "institute_type"
input institute_type_var_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type institute_type_variance_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "institute_type"
input institute_type_variance_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# expression to compare columns of type Int. All fields are combined with logical 'AND'.
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

# columns and relationships of "journal_successors"
type journal_successors {
  # An object relationship
  ancestor: periodical!
  journalMtid: bigint!

  # An object relationship
  successor: periodical!
  successorsMtid: bigint!
}

# aggregated selection of "journal_successors"
type journal_successors_aggregate {
  aggregate: journal_successors_aggregate_fields
  nodes: [journal_successors!]!
}

# aggregate fields of "journal_successors"
type journal_successors_aggregate_fields {
  avg: journal_successors_avg_fields
  count(columns: [journal_successors_select_column!], distinct: Boolean): Int
  max: journal_successors_max_fields
  min: journal_successors_min_fields
  stddev: journal_successors_stddev_fields
  stddev_pop: journal_successors_stddev_pop_fields
  stddev_samp: journal_successors_stddev_samp_fields
  sum: journal_successors_sum_fields
  var_pop: journal_successors_var_pop_fields
  var_samp: journal_successors_var_samp_fields
  variance: journal_successors_variance_fields
}

# order by aggregate values of table "journal_successors"
input journal_successors_aggregate_order_by {
  avg: journal_successors_avg_order_by
  count: order_by
  max: journal_successors_max_order_by
  min: journal_successors_min_order_by
  stddev: journal_successors_stddev_order_by
  stddev_pop: journal_successors_stddev_pop_order_by
  stddev_samp: journal_successors_stddev_samp_order_by
  sum: journal_successors_sum_order_by
  var_pop: journal_successors_var_pop_order_by
  var_samp: journal_successors_var_samp_order_by
  variance: journal_successors_variance_order_by
}

# input type for inserting array relation for remote table "journal_successors"
input journal_successors_arr_rel_insert_input {
  data: [journal_successors_insert_input!]!
}

# aggregate avg on columns
type journal_successors_avg_fields {
  journalMtid: Float
  successorsMtid: Float
}

# order by avg() on columns of table "journal_successors"
input journal_successors_avg_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# Boolean expression to filter rows from the table "journal_successors". All fields are combined with a logical 'AND'.
input journal_successors_bool_exp {
  _and: [journal_successors_bool_exp]
  _not: journal_successors_bool_exp
  _or: [journal_successors_bool_exp]
  ancestor: periodical_bool_exp
  journalMtid: bigint_comparison_exp
  successor: periodical_bool_exp
  successorsMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "journal_successors"
input journal_successors_inc_input {
  journalMtid: bigint
  successorsMtid: bigint
}

# input type for inserting data into table "journal_successors"
input journal_successors_insert_input {
  ancestor: periodical_obj_rel_insert_input
  journalMtid: bigint
  successor: periodical_obj_rel_insert_input
  successorsMtid: bigint
}

# aggregate max on columns
type journal_successors_max_fields {
  journalMtid: bigint
  successorsMtid: bigint
}

# order by max() on columns of table "journal_successors"
input journal_successors_max_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# aggregate min on columns
type journal_successors_min_fields {
  journalMtid: bigint
  successorsMtid: bigint
}

# order by min() on columns of table "journal_successors"
input journal_successors_min_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# response of any mutation on the table "journal_successors"
type journal_successors_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [journal_successors!]!
}

# input type for inserting object relation for remote table "journal_successors"
input journal_successors_obj_rel_insert_input {
  data: journal_successors_insert_input!
}

# ordering options when selecting data from "journal_successors"
input journal_successors_order_by {
  ancestor: periodical_order_by
  journalMtid: order_by
  successor: periodical_order_by
  successorsMtid: order_by
}

# select columns of table "journal_successors"
enum journal_successors_select_column {
  # column name
  journalMtid

  # column name
  successorsMtid
}

# input type for updating data in table "journal_successors"
input journal_successors_set_input {
  journalMtid: bigint
  successorsMtid: bigint
}

# aggregate stddev on columns
type journal_successors_stddev_fields {
  journalMtid: Float
  successorsMtid: Float
}

# order by stddev() on columns of table "journal_successors"
input journal_successors_stddev_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# aggregate stddev_pop on columns
type journal_successors_stddev_pop_fields {
  journalMtid: Float
  successorsMtid: Float
}

# order by stddev_pop() on columns of table "journal_successors"
input journal_successors_stddev_pop_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# aggregate stddev_samp on columns
type journal_successors_stddev_samp_fields {
  journalMtid: Float
  successorsMtid: Float
}

# order by stddev_samp() on columns of table "journal_successors"
input journal_successors_stddev_samp_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# aggregate sum on columns
type journal_successors_sum_fields {
  journalMtid: bigint
  successorsMtid: bigint
}

# order by sum() on columns of table "journal_successors"
input journal_successors_sum_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# aggregate var_pop on columns
type journal_successors_var_pop_fields {
  journalMtid: Float
  successorsMtid: Float
}

# order by var_pop() on columns of table "journal_successors"
input journal_successors_var_pop_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# aggregate var_samp on columns
type journal_successors_var_samp_fields {
  journalMtid: Float
  successorsMtid: Float
}

# order by var_samp() on columns of table "journal_successors"
input journal_successors_var_samp_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# aggregate variance on columns
type journal_successors_variance_fields {
  journalMtid: Float
  successorsMtid: Float
}

# order by variance() on columns of table "journal_successors"
input journal_successors_variance_order_by {
  journalMtid: order_by
  successorsMtid: order_by
}

# columns and relationships of "keyword"
type keyword {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  keyword: String
  labelEng: String
  labelHun: String

  # An object relationship
  language: language
  languageMtid: bigint
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  useCount: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "keyword"
type keyword_aggregate {
  aggregate: keyword_aggregate_fields
  nodes: [keyword!]!
}

# aggregate fields of "keyword"
type keyword_aggregate_fields {
  avg: keyword_avg_fields
  count(columns: [keyword_select_column!], distinct: Boolean): Int
  max: keyword_max_fields
  min: keyword_min_fields
  stddev: keyword_stddev_fields
  stddev_pop: keyword_stddev_pop_fields
  stddev_samp: keyword_stddev_samp_fields
  sum: keyword_sum_fields
  var_pop: keyword_var_pop_fields
  var_samp: keyword_var_samp_fields
  variance: keyword_variance_fields
}

# order by aggregate values of table "keyword"
input keyword_aggregate_order_by {
  avg: keyword_avg_order_by
  count: order_by
  max: keyword_max_order_by
  min: keyword_min_order_by
  stddev: keyword_stddev_order_by
  stddev_pop: keyword_stddev_pop_order_by
  stddev_samp: keyword_stddev_samp_order_by
  sum: keyword_sum_order_by
  var_pop: keyword_var_pop_order_by
  var_samp: keyword_var_samp_order_by
  variance: keyword_variance_order_by
}

# input type for inserting array relation for remote table "keyword"
input keyword_arr_rel_insert_input {
  data: [keyword_insert_input!]!
  on_conflict: keyword_on_conflict
}

# aggregate avg on columns
type keyword_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "keyword"
input keyword_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "keyword". All fields are combined with a logical 'AND'.
input keyword_bool_exp {
  _and: [keyword_bool_exp]
  _not: keyword_bool_exp
  _or: [keyword_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  keyword: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  language: language_bool_exp
  languageMtid: bigint_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  useCount: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "keyword"
enum keyword_constraint {
  # unique or primary key constraint
  keyword_pkey
}

# input type for incrementing integer column in table "keyword"
input keyword_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  languageMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "keyword"
input keyword_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  keyword: String
  labelEng: String
  labelHun: String
  language: language_obj_rel_insert_input
  languageMtid: bigint
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type keyword_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  keyword: String
  labelEng: String
  labelHun: String
  languageMtid: bigint
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "keyword"
input keyword_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  keyword: order_by
  labelEng: order_by
  labelHun: order_by
  languageMtid: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type keyword_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  keyword: String
  labelEng: String
  labelHun: String
  languageMtid: bigint
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "keyword"
input keyword_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  keyword: order_by
  labelEng: order_by
  labelHun: order_by
  languageMtid: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "keyword"
type keyword_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [keyword!]!
}

# input type for inserting object relation for remote table "keyword"
input keyword_obj_rel_insert_input {
  data: keyword_insert_input!
  on_conflict: keyword_on_conflict
}

# on conflict condition type for table "keyword"
input keyword_on_conflict {
  constraint: keyword_constraint!
  update_columns: [keyword_update_column!]!
  where: keyword_bool_exp
}

# ordering options when selecting data from "keyword"
input keyword_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  keyword: order_by
  labelEng: order_by
  labelHun: order_by
  language: language_order_by
  languageMtid: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "keyword"
input keyword_pk_columns_input {
  mtid: bigint!
}

# select columns of table "keyword"
enum keyword_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  keyword

  # column name
  labelEng

  # column name
  labelHun

  # column name
  languageMtid

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "keyword"
input keyword_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  keyword: String
  labelEng: String
  labelHun: String
  languageMtid: bigint
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type keyword_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "keyword"
input keyword_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type keyword_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "keyword"
input keyword_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type keyword_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "keyword"
input keyword_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type keyword_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  languageMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  useCount: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "keyword"
input keyword_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "keyword"
enum keyword_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  keyword

  # column name
  labelEng

  # column name
  labelHun

  # column name
  languageMtid

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  useCount

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type keyword_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "keyword"
input keyword_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type keyword_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "keyword"
input keyword_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type keyword_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  languageMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  useCount: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "keyword"
input keyword_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  languageMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  useCount: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "language"
type language {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  code: String
  code2: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "language"
type language_aggregate {
  aggregate: language_aggregate_fields
  nodes: [language!]!
}

# aggregate fields of "language"
type language_aggregate_fields {
  avg: language_avg_fields
  count(columns: [language_select_column!], distinct: Boolean): Int
  max: language_max_fields
  min: language_min_fields
  stddev: language_stddev_fields
  stddev_pop: language_stddev_pop_fields
  stddev_samp: language_stddev_samp_fields
  sum: language_sum_fields
  var_pop: language_var_pop_fields
  var_samp: language_var_samp_fields
  variance: language_variance_fields
}

# order by aggregate values of table "language"
input language_aggregate_order_by {
  avg: language_avg_order_by
  count: order_by
  max: language_max_order_by
  min: language_min_order_by
  stddev: language_stddev_order_by
  stddev_pop: language_stddev_pop_order_by
  stddev_samp: language_stddev_samp_order_by
  sum: language_sum_order_by
  var_pop: language_var_pop_order_by
  var_samp: language_var_samp_order_by
  variance: language_variance_order_by
}

# input type for inserting array relation for remote table "language"
input language_arr_rel_insert_input {
  data: [language_insert_input!]!
  on_conflict: language_on_conflict
}

# aggregate avg on columns
type language_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "language"
input language_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "language". All fields are combined with a logical 'AND'.
input language_bool_exp {
  _and: [language_bool_exp]
  _not: language_bool_exp
  _or: [language_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  code: String_comparison_exp
  code2: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "language"
enum language_constraint {
  # unique or primary key constraint
  language_pkey
}

# input type for incrementing integer column in table "language"
input language_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "language"
input language_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  code: String
  code2: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type language_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  code2: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "language"
input language_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  code2: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type language_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  code2: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "language"
input language_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  code2: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "language"
type language_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [language!]!
}

# input type for inserting object relation for remote table "language"
input language_obj_rel_insert_input {
  data: language_insert_input!
  on_conflict: language_on_conflict
}

# on conflict condition type for table "language"
input language_on_conflict {
  constraint: language_constraint!
  update_columns: [language_update_column!]!
  where: language_bool_exp
}

# ordering options when selecting data from "language"
input language_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  code: order_by
  code2: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "language"
input language_pk_columns_input {
  mtid: bigint!
}

# select columns of table "language"
enum language_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  code2

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "language"
input language_set_input {
  approved: timestamp
  approverMtid: bigint
  code: String
  code2: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type language_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "language"
input language_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type language_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "language"
input language_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type language_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "language"
input language_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type language_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "language"
input language_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "language"
enum language_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  code2

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type language_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "language"
input language_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type language_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "language"
input language_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type language_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "language"
input language_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "localized_message"
type localized_message {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  english: String
  error: Int
  hungarian: String
  key: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  source: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "localized_message"
type localized_message_aggregate {
  aggregate: localized_message_aggregate_fields
  nodes: [localized_message!]!
}

# aggregate fields of "localized_message"
type localized_message_aggregate_fields {
  avg: localized_message_avg_fields
  count(columns: [localized_message_select_column!], distinct: Boolean): Int
  max: localized_message_max_fields
  min: localized_message_min_fields
  stddev: localized_message_stddev_fields
  stddev_pop: localized_message_stddev_pop_fields
  stddev_samp: localized_message_stddev_samp_fields
  sum: localized_message_sum_fields
  var_pop: localized_message_var_pop_fields
  var_samp: localized_message_var_samp_fields
  variance: localized_message_variance_fields
}

# order by aggregate values of table "localized_message"
input localized_message_aggregate_order_by {
  avg: localized_message_avg_order_by
  count: order_by
  max: localized_message_max_order_by
  min: localized_message_min_order_by
  stddev: localized_message_stddev_order_by
  stddev_pop: localized_message_stddev_pop_order_by
  stddev_samp: localized_message_stddev_samp_order_by
  sum: localized_message_sum_order_by
  var_pop: localized_message_var_pop_order_by
  var_samp: localized_message_var_samp_order_by
  variance: localized_message_variance_order_by
}

# input type for inserting array relation for remote table "localized_message"
input localized_message_arr_rel_insert_input {
  data: [localized_message_insert_input!]!
  on_conflict: localized_message_on_conflict
}

# aggregate avg on columns
type localized_message_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  source: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "localized_message"
input localized_message_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "localized_message". All fields are combined with a logical 'AND'.
input localized_message_bool_exp {
  _and: [localized_message_bool_exp]
  _not: localized_message_bool_exp
  _or: [localized_message_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  english: String_comparison_exp
  error: Int_comparison_exp
  hungarian: String_comparison_exp
  key: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  source: Int_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "localized_message"
enum localized_message_constraint {
  # unique or primary key constraint
  localized_message_pkey

  # unique or primary key constraint
  uk_1b0eyfs6rhlk5d6jq198cl0bi
}

# input type for incrementing integer column in table "localized_message"
input localized_message_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  source: Int
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "localized_message"
input localized_message_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  english: String
  error: Int
  hungarian: String
  key: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  source: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type localized_message_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  english: String
  error: Int
  hungarian: String
  key: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  source: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "localized_message"
input localized_message_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  english: order_by
  error: order_by
  hungarian: order_by
  key: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type localized_message_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  english: String
  error: Int
  hungarian: String
  key: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  source: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "localized_message"
input localized_message_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  english: order_by
  error: order_by
  hungarian: order_by
  key: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "localized_message"
type localized_message_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [localized_message!]!
}

# input type for inserting object relation for remote table "localized_message"
input localized_message_obj_rel_insert_input {
  data: localized_message_insert_input!
  on_conflict: localized_message_on_conflict
}

# on conflict condition type for table "localized_message"
input localized_message_on_conflict {
  constraint: localized_message_constraint!
  update_columns: [localized_message_update_column!]!
  where: localized_message_bool_exp
}

# ordering options when selecting data from "localized_message"
input localized_message_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  english: order_by
  error: order_by
  hungarian: order_by
  key: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  source: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "localized_message"
input localized_message_pk_columns_input {
  mtid: bigint!
}

# select columns of table "localized_message"
enum localized_message_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  english

  # column name
  error

  # column name
  hungarian

  # column name
  key

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  source

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "localized_message"
input localized_message_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  english: String
  error: Int
  hungarian: String
  key: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  source: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type localized_message_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  source: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "localized_message"
input localized_message_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type localized_message_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  source: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "localized_message"
input localized_message_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type localized_message_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  source: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "localized_message"
input localized_message_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type localized_message_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  source: Int
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "localized_message"
input localized_message_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "localized_message"
enum localized_message_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  english

  # column name
  error

  # column name
  hungarian

  # column name
  key

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  source

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type localized_message_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  source: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "localized_message"
input localized_message_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type localized_message_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  source: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "localized_message"
input localized_message_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type localized_message_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  source: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "localized_message"
input localized_message_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  source: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "location"
type location {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  dtype: String!
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  fromCitation: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An object relationship
  partOf: location
  partOfMtid: bigint
  prevValid: bigint

  # An object relationship
  province: location
  provinceMtid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "location"
type location_aggregate {
  aggregate: location_aggregate_fields
  nodes: [location!]!
}

# aggregate fields of "location"
type location_aggregate_fields {
  avg: location_avg_fields
  count(columns: [location_select_column!], distinct: Boolean): Int
  max: location_max_fields
  min: location_min_fields
  stddev: location_stddev_fields
  stddev_pop: location_stddev_pop_fields
  stddev_samp: location_stddev_samp_fields
  sum: location_sum_fields
  var_pop: location_var_pop_fields
  var_samp: location_var_samp_fields
  variance: location_variance_fields
}

# order by aggregate values of table "location"
input location_aggregate_order_by {
  avg: location_avg_order_by
  count: order_by
  max: location_max_order_by
  min: location_min_order_by
  stddev: location_stddev_order_by
  stddev_pop: location_stddev_pop_order_by
  stddev_samp: location_stddev_samp_order_by
  sum: location_sum_order_by
  var_pop: location_var_pop_order_by
  var_samp: location_var_samp_order_by
  variance: location_variance_order_by
}

# input type for inserting array relation for remote table "location"
input location_arr_rel_insert_input {
  data: [location_insert_input!]!
  on_conflict: location_on_conflict
}

# aggregate avg on columns
type location_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  partOfMtid: Float
  prevValid: Float
  provinceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "location"
input location_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "location". All fields are combined with a logical 'AND'.
input location_bool_exp {
  _and: [location_bool_exp]
  _not: location_bool_exp
  _or: [location_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  dtype: String_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  fromCitation: Boolean_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  partOf: location_bool_exp
  partOfMtid: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  province: location_bool_exp
  provinceMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "location"
enum location_constraint {
  # unique or primary key constraint
  location_pkey
}

# input type for incrementing integer column in table "location"
input location_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  partOfMtid: bigint
  prevValid: bigint
  provinceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "location"
input location_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  dtype: String
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  fromCitation: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  partOf: location_obj_rel_insert_input
  partOfMtid: bigint
  prevValid: bigint
  province: location_obj_rel_insert_input
  provinceMtid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type location_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  partOfMtid: bigint
  prevValid: bigint
  provinceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "location"
input location_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type location_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  partOfMtid: bigint
  prevValid: bigint
  provinceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "location"
input location_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "location"
type location_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [location!]!
}

# input type for inserting object relation for remote table "location"
input location_obj_rel_insert_input {
  data: location_insert_input!
  on_conflict: location_on_conflict
}

# on conflict condition type for table "location"
input location_on_conflict {
  constraint: location_constraint!
  update_columns: [location_update_column!]!
  where: location_bool_exp
}

# ordering options when selecting data from "location"
input location_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fromCitation: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  partOf: location_order_by
  partOfMtid: order_by
  prevValid: order_by
  province: location_order_by
  provinceMtid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "location"
input location_pk_columns_input {
  mtid: bigint!
}

# select columns of table "location"
enum location_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fromCitation

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  partOfMtid

  # column name
  prevValid

  # column name
  provinceMtid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "location"
input location_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fromCitation: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  partOfMtid: bigint
  prevValid: bigint
  provinceMtid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type location_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  partOfMtid: Float
  prevValid: Float
  provinceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "location"
input location_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type location_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  partOfMtid: Float
  prevValid: Float
  provinceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "location"
input location_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type location_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  partOfMtid: Float
  prevValid: Float
  provinceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "location"
input location_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type location_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  partOfMtid: bigint
  prevValid: bigint
  provinceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "location"
input location_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "location"
enum location_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fromCitation

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  partOfMtid

  # column name
  prevValid

  # column name
  provinceMtid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type location_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  partOfMtid: Float
  prevValid: Float
  provinceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "location"
input location_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type location_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  partOfMtid: Float
  prevValid: Float
  provinceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "location"
input location_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type location_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  partOfMtid: Float
  prevValid: Float
  provinceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "location"
input location_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  partOfMtid: order_by
  prevValid: order_by
  provinceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "lock_list"
type lock_list {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users

  # An array relationship
  delegatedAdmins(
    # distinct select on columns
    distinct_on: [lock_list_delegated_admins_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_delegated_admins_order_by!]

    # filter the rows returned
    where: lock_list_delegated_admins_bool_exp
  ): [lock_list_delegated_admins!]!

  # An aggregated array relationship
  delegatedAdmins_aggregate(
    # distinct select on columns
    distinct_on: [lock_list_delegated_admins_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_delegated_admins_order_by!]

    # filter the rows returned
    where: lock_list_delegated_admins_bool_exp
  ): lock_list_delegated_admins_aggregate!
  deleted: Boolean!
  deletedDate: timestamp
  depth: smallint

  # An object relationship
  duplumSearchRequest: duplum_search_request
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String

  # An object relationship
  importRequest: import_request
  importRequestMtid: bigint

  # An object relationship
  importStatistics: import_stat
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  listType: Int
  locked: timestamp

  # An object relationship
  lockedAuthor: users
  lockedAuthorMtid: bigint
  lockedUntil: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  published: Boolean!
  queued: Boolean!
  refreshed: Boolean!
  seen: Boolean
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "lock_list"
type lock_list_aggregate {
  aggregate: lock_list_aggregate_fields
  nodes: [lock_list!]!
}

# aggregate fields of "lock_list"
type lock_list_aggregate_fields {
  avg: lock_list_avg_fields
  count(columns: [lock_list_select_column!], distinct: Boolean): Int
  max: lock_list_max_fields
  min: lock_list_min_fields
  stddev: lock_list_stddev_fields
  stddev_pop: lock_list_stddev_pop_fields
  stddev_samp: lock_list_stddev_samp_fields
  sum: lock_list_sum_fields
  var_pop: lock_list_var_pop_fields
  var_samp: lock_list_var_samp_fields
  variance: lock_list_variance_fields
}

# order by aggregate values of table "lock_list"
input lock_list_aggregate_order_by {
  avg: lock_list_avg_order_by
  count: order_by
  max: lock_list_max_order_by
  min: lock_list_min_order_by
  stddev: lock_list_stddev_order_by
  stddev_pop: lock_list_stddev_pop_order_by
  stddev_samp: lock_list_stddev_samp_order_by
  sum: lock_list_sum_order_by
  var_pop: lock_list_var_pop_order_by
  var_samp: lock_list_var_samp_order_by
  variance: lock_list_variance_order_by
}

# input type for inserting array relation for remote table "lock_list"
input lock_list_arr_rel_insert_input {
  data: [lock_list_insert_input!]!
  on_conflict: lock_list_on_conflict
}

# aggregate avg on columns
type lock_list_avg_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listType: Float
  lockedAuthorMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "lock_list"
input lock_list_avg_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "lock_list". All fields are combined with a logical 'AND'.
input lock_list_bool_exp {
  _and: [lock_list_bool_exp]
  _not: lock_list_bool_exp
  _or: [lock_list_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  aux: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  count: Int_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  delegatedAdmins: lock_list_delegated_admins_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  depth: smallint_comparison_exp
  duplumSearchRequest: duplum_search_request_bool_exp
  elementType: String_comparison_exp
  error: Int_comparison_exp
  format: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  importRequest: import_request_bool_exp
  importRequestMtid: bigint_comparison_exp
  importStatistics: import_stat_bool_exp
  importStatisticsMtid: bigint_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  language: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  list: String_comparison_exp
  listType: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockedAuthor: users_bool_exp
  lockedAuthorMtid: bigint_comparison_exp
  lockedUntil: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  position: Int_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  seen: Boolean_comparison_exp
  status: Int_comparison_exp
  tag: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "lock_list"
enum lock_list_constraint {
  # unique or primary key constraint
  lock_list_pkey
}

# columns and relationships of "lock_list_delegated_admins"
type lock_list_delegated_admins {
  delegatedAdminsMtid: bigint!
  lockListMtid: bigint!

  # An object relationship
  users: users!
}

# aggregated selection of "lock_list_delegated_admins"
type lock_list_delegated_admins_aggregate {
  aggregate: lock_list_delegated_admins_aggregate_fields
  nodes: [lock_list_delegated_admins!]!
}

# aggregate fields of "lock_list_delegated_admins"
type lock_list_delegated_admins_aggregate_fields {
  avg: lock_list_delegated_admins_avg_fields
  count(columns: [lock_list_delegated_admins_select_column!], distinct: Boolean): Int
  max: lock_list_delegated_admins_max_fields
  min: lock_list_delegated_admins_min_fields
  stddev: lock_list_delegated_admins_stddev_fields
  stddev_pop: lock_list_delegated_admins_stddev_pop_fields
  stddev_samp: lock_list_delegated_admins_stddev_samp_fields
  sum: lock_list_delegated_admins_sum_fields
  var_pop: lock_list_delegated_admins_var_pop_fields
  var_samp: lock_list_delegated_admins_var_samp_fields
  variance: lock_list_delegated_admins_variance_fields
}

# order by aggregate values of table "lock_list_delegated_admins"
input lock_list_delegated_admins_aggregate_order_by {
  avg: lock_list_delegated_admins_avg_order_by
  count: order_by
  max: lock_list_delegated_admins_max_order_by
  min: lock_list_delegated_admins_min_order_by
  stddev: lock_list_delegated_admins_stddev_order_by
  stddev_pop: lock_list_delegated_admins_stddev_pop_order_by
  stddev_samp: lock_list_delegated_admins_stddev_samp_order_by
  sum: lock_list_delegated_admins_sum_order_by
  var_pop: lock_list_delegated_admins_var_pop_order_by
  var_samp: lock_list_delegated_admins_var_samp_order_by
  variance: lock_list_delegated_admins_variance_order_by
}

# input type for inserting array relation for remote table "lock_list_delegated_admins"
input lock_list_delegated_admins_arr_rel_insert_input {
  data: [lock_list_delegated_admins_insert_input!]!
}

# aggregate avg on columns
type lock_list_delegated_admins_avg_fields {
  delegatedAdminsMtid: Float
  lockListMtid: Float
}

# order by avg() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_avg_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# Boolean expression to filter rows from the table "lock_list_delegated_admins". All fields are combined with a logical 'AND'.
input lock_list_delegated_admins_bool_exp {
  _and: [lock_list_delegated_admins_bool_exp]
  _not: lock_list_delegated_admins_bool_exp
  _or: [lock_list_delegated_admins_bool_exp]
  delegatedAdminsMtid: bigint_comparison_exp
  lockListMtid: bigint_comparison_exp
  users: users_bool_exp
}

# input type for incrementing integer column in table "lock_list_delegated_admins"
input lock_list_delegated_admins_inc_input {
  delegatedAdminsMtid: bigint
  lockListMtid: bigint
}

# input type for inserting data into table "lock_list_delegated_admins"
input lock_list_delegated_admins_insert_input {
  delegatedAdminsMtid: bigint
  lockListMtid: bigint
  users: users_obj_rel_insert_input
}

# aggregate max on columns
type lock_list_delegated_admins_max_fields {
  delegatedAdminsMtid: bigint
  lockListMtid: bigint
}

# order by max() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_max_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# aggregate min on columns
type lock_list_delegated_admins_min_fields {
  delegatedAdminsMtid: bigint
  lockListMtid: bigint
}

# order by min() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_min_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# response of any mutation on the table "lock_list_delegated_admins"
type lock_list_delegated_admins_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [lock_list_delegated_admins!]!
}

# input type for inserting object relation for remote table "lock_list_delegated_admins"
input lock_list_delegated_admins_obj_rel_insert_input {
  data: lock_list_delegated_admins_insert_input!
}

# ordering options when selecting data from "lock_list_delegated_admins"
input lock_list_delegated_admins_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
  users: users_order_by
}

# select columns of table "lock_list_delegated_admins"
enum lock_list_delegated_admins_select_column {
  # column name
  delegatedAdminsMtid

  # column name
  lockListMtid
}

# input type for updating data in table "lock_list_delegated_admins"
input lock_list_delegated_admins_set_input {
  delegatedAdminsMtid: bigint
  lockListMtid: bigint
}

# aggregate stddev on columns
type lock_list_delegated_admins_stddev_fields {
  delegatedAdminsMtid: Float
  lockListMtid: Float
}

# order by stddev() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_stddev_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# aggregate stddev_pop on columns
type lock_list_delegated_admins_stddev_pop_fields {
  delegatedAdminsMtid: Float
  lockListMtid: Float
}

# order by stddev_pop() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_stddev_pop_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# aggregate stddev_samp on columns
type lock_list_delegated_admins_stddev_samp_fields {
  delegatedAdminsMtid: Float
  lockListMtid: Float
}

# order by stddev_samp() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_stddev_samp_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# aggregate sum on columns
type lock_list_delegated_admins_sum_fields {
  delegatedAdminsMtid: bigint
  lockListMtid: bigint
}

# order by sum() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_sum_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# aggregate var_pop on columns
type lock_list_delegated_admins_var_pop_fields {
  delegatedAdminsMtid: Float
  lockListMtid: Float
}

# order by var_pop() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_var_pop_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# aggregate var_samp on columns
type lock_list_delegated_admins_var_samp_fields {
  delegatedAdminsMtid: Float
  lockListMtid: Float
}

# order by var_samp() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_var_samp_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# aggregate variance on columns
type lock_list_delegated_admins_variance_fields {
  delegatedAdminsMtid: Float
  lockListMtid: Float
}

# order by variance() on columns of table "lock_list_delegated_admins"
input lock_list_delegated_admins_variance_order_by {
  delegatedAdminsMtid: order_by
  lockListMtid: order_by
}

# input type for incrementing integer column in table "lock_list"
input lock_list_inc_input {
  approverMtid: bigint
  count: Int
  creator: bigint
  depth: smallint
  error: Int
  format: Int
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listType: Int
  lockedAuthorMtid: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  position: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "lock_list"
input lock_list_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  delegatedAdmins: lock_list_delegated_admins_arr_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  depth: smallint
  duplumSearchRequest: duplum_search_request_obj_rel_insert_input
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequest: import_request_obj_rel_insert_input
  importRequestMtid: bigint
  importStatistics: import_stat_obj_rel_insert_input
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  listType: Int
  locked: timestamp
  lockedAuthor: users_obj_rel_insert_input
  lockedAuthorMtid: bigint
  lockedUntil: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type lock_list_max_fields {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  listType: Int
  locked: timestamp
  lockedAuthorMtid: bigint
  lockedUntil: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "lock_list"
input lock_list_max_order_by {
  approved: order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  depth: order_by
  elementType: order_by
  error: order_by
  format: order_by
  hint: order_by
  hintEng: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  listType: order_by
  locked: order_by
  lockedAuthorMtid: order_by
  lockedUntil: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  position: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type lock_list_min_fields {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  listType: Int
  locked: timestamp
  lockedAuthorMtid: bigint
  lockedUntil: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "lock_list"
input lock_list_min_order_by {
  approved: order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  depth: order_by
  elementType: order_by
  error: order_by
  format: order_by
  hint: order_by
  hintEng: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  listType: order_by
  locked: order_by
  lockedAuthorMtid: order_by
  lockedUntil: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  position: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "lock_list"
type lock_list_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [lock_list!]!
}

# input type for inserting object relation for remote table "lock_list"
input lock_list_obj_rel_insert_input {
  data: lock_list_insert_input!
  on_conflict: lock_list_on_conflict
}

# on conflict condition type for table "lock_list"
input lock_list_on_conflict {
  constraint: lock_list_constraint!
  update_columns: [lock_list_update_column!]!
  where: lock_list_bool_exp
}

# ordering options when selecting data from "lock_list"
input lock_list_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  delegatedAdmins_aggregate: lock_list_delegated_admins_aggregate_order_by
  deleted: order_by
  deletedDate: order_by
  depth: order_by
  duplumSearchRequest: duplum_search_request_order_by
  elementType: order_by
  error: order_by
  format: order_by
  hint: order_by
  hintEng: order_by
  importRequest: import_request_order_by
  importRequestMtid: order_by
  importStatistics: import_stat_order_by
  importStatisticsMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  listType: order_by
  locked: order_by
  lockedAuthor: users_order_by
  lockedAuthorMtid: order_by
  lockedUntil: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  position: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  queued: order_by
  refreshed: order_by
  seen: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "lock_list"
input lock_list_pk_columns_input {
  mtid: bigint!
}

# select columns of table "lock_list"
enum lock_list_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  aux

  # column name
  comment

  # column name
  comment2

  # column name
  count

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  depth

  # column name
  elementType

  # column name
  error

  # column name
  format

  # column name
  hint

  # column name
  hintEng

  # column name
  importRequestMtid

  # column name
  importStatisticsMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list

  # column name
  listType

  # column name
  locked

  # column name
  lockedAuthorMtid

  # column name
  lockedUntil

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  position

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "lock_list"
input lock_list_set_input {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  listType: Int
  locked: timestamp
  lockedAuthorMtid: bigint
  lockedUntil: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type lock_list_stddev_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listType: Float
  lockedAuthorMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "lock_list"
input lock_list_stddev_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type lock_list_stddev_pop_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listType: Float
  lockedAuthorMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "lock_list"
input lock_list_stddev_pop_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type lock_list_stddev_samp_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listType: Float
  lockedAuthorMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "lock_list"
input lock_list_stddev_samp_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type lock_list_sum_fields {
  approverMtid: bigint
  count: Int
  creator: bigint
  depth: smallint
  error: Int
  format: Int
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listType: Int
  lockedAuthorMtid: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  position: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "lock_list"
input lock_list_sum_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "lock_list"
enum lock_list_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  aux

  # column name
  comment

  # column name
  comment2

  # column name
  count

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  depth

  # column name
  elementType

  # column name
  error

  # column name
  format

  # column name
  hint

  # column name
  hintEng

  # column name
  importRequestMtid

  # column name
  importStatisticsMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list

  # column name
  listType

  # column name
  locked

  # column name
  lockedAuthorMtid

  # column name
  lockedUntil

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  position

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type lock_list_var_pop_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listType: Float
  lockedAuthorMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "lock_list"
input lock_list_var_pop_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type lock_list_var_samp_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listType: Float
  lockedAuthorMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "lock_list"
input lock_list_var_samp_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type lock_list_variance_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listType: Float
  lockedAuthorMtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "lock_list"
input lock_list_variance_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listType: order_by
  lockedAuthorMtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "mab_discipline"
type mab_discipline {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  groupName: String
  groupNameEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "mab_discipline"
type mab_discipline_aggregate {
  aggregate: mab_discipline_aggregate_fields
  nodes: [mab_discipline!]!
}

# aggregate fields of "mab_discipline"
type mab_discipline_aggregate_fields {
  avg: mab_discipline_avg_fields
  count(columns: [mab_discipline_select_column!], distinct: Boolean): Int
  max: mab_discipline_max_fields
  min: mab_discipline_min_fields
  stddev: mab_discipline_stddev_fields
  stddev_pop: mab_discipline_stddev_pop_fields
  stddev_samp: mab_discipline_stddev_samp_fields
  sum: mab_discipline_sum_fields
  var_pop: mab_discipline_var_pop_fields
  var_samp: mab_discipline_var_samp_fields
  variance: mab_discipline_variance_fields
}

# order by aggregate values of table "mab_discipline"
input mab_discipline_aggregate_order_by {
  avg: mab_discipline_avg_order_by
  count: order_by
  max: mab_discipline_max_order_by
  min: mab_discipline_min_order_by
  stddev: mab_discipline_stddev_order_by
  stddev_pop: mab_discipline_stddev_pop_order_by
  stddev_samp: mab_discipline_stddev_samp_order_by
  sum: mab_discipline_sum_order_by
  var_pop: mab_discipline_var_pop_order_by
  var_samp: mab_discipline_var_samp_order_by
  variance: mab_discipline_variance_order_by
}

# input type for inserting array relation for remote table "mab_discipline"
input mab_discipline_arr_rel_insert_input {
  data: [mab_discipline_insert_input!]!
  on_conflict: mab_discipline_on_conflict
}

# aggregate avg on columns
type mab_discipline_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "mab_discipline"
input mab_discipline_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "mab_discipline". All fields are combined with a logical 'AND'.
input mab_discipline_bool_exp {
  _and: [mab_discipline_bool_exp]
  _not: mab_discipline_bool_exp
  _or: [mab_discipline_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  groupName: String_comparison_exp
  groupNameEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "mab_discipline"
enum mab_discipline_constraint {
  # unique or primary key constraint
  mab_discipline_pkey
}

# input type for incrementing integer column in table "mab_discipline"
input mab_discipline_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "mab_discipline"
input mab_discipline_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  groupName: String
  groupNameEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type mab_discipline_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  groupName: String
  groupNameEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "mab_discipline"
input mab_discipline_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  groupName: order_by
  groupNameEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type mab_discipline_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  groupName: String
  groupNameEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "mab_discipline"
input mab_discipline_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  groupName: order_by
  groupNameEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "mab_discipline"
type mab_discipline_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [mab_discipline!]!
}

# input type for inserting object relation for remote table "mab_discipline"
input mab_discipline_obj_rel_insert_input {
  data: mab_discipline_insert_input!
  on_conflict: mab_discipline_on_conflict
}

# on conflict condition type for table "mab_discipline"
input mab_discipline_on_conflict {
  constraint: mab_discipline_constraint!
  update_columns: [mab_discipline_update_column!]!
  where: mab_discipline_bool_exp
}

# ordering options when selecting data from "mab_discipline"
input mab_discipline_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  groupName: order_by
  groupNameEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "mab_discipline"
input mab_discipline_pk_columns_input {
  mtid: bigint!
}

# select columns of table "mab_discipline"
enum mab_discipline_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  groupName

  # column name
  groupNameEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "mab_discipline"
input mab_discipline_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  groupName: String
  groupNameEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type mab_discipline_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "mab_discipline"
input mab_discipline_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type mab_discipline_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "mab_discipline"
input mab_discipline_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type mab_discipline_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "mab_discipline"
input mab_discipline_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type mab_discipline_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "mab_discipline"
input mab_discipline_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "mab_discipline"
enum mab_discipline_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  groupName

  # column name
  groupNameEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type mab_discipline_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "mab_discipline"
input mab_discipline_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type mab_discipline_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "mab_discipline"
input mab_discipline_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type mab_discipline_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "mab_discipline"
input mab_discipline_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "mention"
type mention {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  citation: citation
  citationMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "mention"
type mention_aggregate {
  aggregate: mention_aggregate_fields
  nodes: [mention!]!
}

# aggregate fields of "mention"
type mention_aggregate_fields {
  avg: mention_avg_fields
  count(columns: [mention_select_column!], distinct: Boolean): Int
  max: mention_max_fields
  min: mention_min_fields
  stddev: mention_stddev_fields
  stddev_pop: mention_stddev_pop_fields
  stddev_samp: mention_stddev_samp_fields
  sum: mention_sum_fields
  var_pop: mention_var_pop_fields
  var_samp: mention_var_samp_fields
  variance: mention_variance_fields
}

# order by aggregate values of table "mention"
input mention_aggregate_order_by {
  avg: mention_avg_order_by
  count: order_by
  max: mention_max_order_by
  min: mention_min_order_by
  stddev: mention_stddev_order_by
  stddev_pop: mention_stddev_pop_order_by
  stddev_samp: mention_stddev_samp_order_by
  sum: mention_sum_order_by
  var_pop: mention_var_pop_order_by
  var_samp: mention_var_samp_order_by
  variance: mention_variance_order_by
}

# input type for inserting array relation for remote table "mention"
input mention_arr_rel_insert_input {
  data: [mention_insert_input!]!
  on_conflict: mention_on_conflict
}

# aggregate avg on columns
type mention_avg_fields {
  approverMtid: Float
  citationMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "mention"
input mention_avg_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "mention". All fields are combined with a logical 'AND'.
input mention_bool_exp {
  _and: [mention_bool_exp]
  _not: mention_bool_exp
  _or: [mention_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  citation: citation_bool_exp
  citationMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  context: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  note: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  page: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "mention"
enum mention_constraint {
  # unique or primary key constraint
  mention_pkey
}

# input type for incrementing integer column in table "mention"
input mention_inc_input {
  approverMtid: bigint
  citationMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "mention"
input mention_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  citation: citation_obj_rel_insert_input
  citationMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type mention_max_fields {
  approved: timestamp
  approverMtid: bigint
  citationMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "mention"
input mention_max_order_by {
  approved: order_by
  approverMtid: order_by
  citationMtid: order_by
  comment: order_by
  comment2: order_by
  context: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  note: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  page: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type mention_min_fields {
  approved: timestamp
  approverMtid: bigint
  citationMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "mention"
input mention_min_order_by {
  approved: order_by
  approverMtid: order_by
  citationMtid: order_by
  comment: order_by
  comment2: order_by
  context: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  note: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  page: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "mention"
type mention_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [mention!]!
}

# input type for inserting object relation for remote table "mention"
input mention_obj_rel_insert_input {
  data: mention_insert_input!
  on_conflict: mention_on_conflict
}

# on conflict condition type for table "mention"
input mention_on_conflict {
  constraint: mention_constraint!
  update_columns: [mention_update_column!]!
  where: mention_bool_exp
}

# ordering options when selecting data from "mention"
input mention_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  citation: citation_order_by
  citationMtid: order_by
  comment: order_by
  comment2: order_by
  context: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  note: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  page: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "mention"
input mention_pk_columns_input {
  mtid: bigint!
}

# select columns of table "mention"
enum mention_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  citationMtid

  # column name
  comment

  # column name
  comment2

  # column name
  context

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  note

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  page

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "mention"
input mention_set_input {
  approved: timestamp
  approverMtid: bigint
  citationMtid: bigint
  comment: String
  comment2: String
  context: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  note: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  page: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type mention_stddev_fields {
  approverMtid: Float
  citationMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "mention"
input mention_stddev_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type mention_stddev_pop_fields {
  approverMtid: Float
  citationMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "mention"
input mention_stddev_pop_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type mention_stddev_samp_fields {
  approverMtid: Float
  citationMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "mention"
input mention_stddev_samp_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type mention_sum_fields {
  approverMtid: bigint
  citationMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "mention"
input mention_sum_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "mention"
enum mention_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  citationMtid

  # column name
  comment

  # column name
  comment2

  # column name
  context

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  note

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  page

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type mention_var_pop_fields {
  approverMtid: Float
  citationMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "mention"
input mention_var_pop_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type mention_var_samp_fields {
  approverMtid: Float
  citationMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "mention"
input mention_var_samp_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type mention_variance_fields {
  approverMtid: Float
  citationMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "mention"
input mention_variance_order_by {
  approverMtid: order_by
  citationMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "message"
type message {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  body: String
  bodyEng: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  deliveryStatus: Int
  dtype: String!
  error: Int

  # An array relationship
  files(
    # distinct select on columns
    distinct_on: [message_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_files_order_by!]

    # filter the rows returned
    where: message_files_bool_exp
  ): [message_files!]!

  # An aggregated array relationship
  files_aggregate(
    # distinct select on columns
    distinct_on: [message_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_files_order_by!]

    # filter the rows returned
    where: message_files_bool_exp
  ): message_files_aggregate!

  # An object relationship
  forum: forum
  forumMtid: bigint

  # An array relationship
  institutes(
    # distinct select on columns
    distinct_on: [message_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_institutes_order_by!]

    # filter the rows returned
    where: message_institutes_bool_exp
  ): [message_institutes!]!

  # An aggregated array relationship
  institutes_aggregate(
    # distinct select on columns
    distinct_on: [message_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_institutes_order_by!]

    # filter the rows returned
    where: message_institutes_bool_exp
  ): message_institutes_aggregate!
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users

  # An array relationship
  mailboxes(
    # distinct select on columns
    distinct_on: [message_mailboxes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_mailboxes_order_by!]

    # filter the rows returned
    where: message_mailboxes_bool_exp
  ): [message_mailboxes!]!

  # An aggregated array relationship
  mailboxes_aggregate(
    # distinct select on columns
    distinct_on: [message_mailboxes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_mailboxes_order_by!]

    # filter the rows returned
    where: message_mailboxes_bool_exp
  ): message_mailboxes_aggregate!
  msgStatus: Int

  # An object relationship
  msgTemplate: message_template
  msgTemplateMtid: bigint
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!

  # An array relationship
  recipients(
    # distinct select on columns
    distinct_on: [message_recipients_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_recipients_order_by!]

    # filter the rows returned
    where: message_recipients_bool_exp
  ): [message_recipients!]!

  # An aggregated array relationship
  recipients_aggregate(
    # distinct select on columns
    distinct_on: [message_recipients_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_recipients_order_by!]

    # filter the rows returned
    where: message_recipients_bool_exp
  ): message_recipients_aggregate!
  refreshed: Boolean!

  # An object relationship
  replyForum: message
  replyForumMtid: bigint

  # An object relationship
  replyTo: message
  replyToAddress: String
  replyToMtid: bigint
  scheduleDate: timestamp
  sendDate: timestamp
  sendOut: Boolean

  # An object relationship
  sender: users
  senderEmail: String
  senderMtid: bigint
  status: Int
  subject: String
  subjectEng: String
  sysMsgType: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  threadPath: String
  type: Int
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  validUntil: timestamp
}

# aggregated selection of "message"
type message_aggregate {
  aggregate: message_aggregate_fields
  nodes: [message!]!
}

# aggregate fields of "message"
type message_aggregate_fields {
  avg: message_avg_fields
  count(columns: [message_select_column!], distinct: Boolean): Int
  max: message_max_fields
  min: message_min_fields
  stddev: message_stddev_fields
  stddev_pop: message_stddev_pop_fields
  stddev_samp: message_stddev_samp_fields
  sum: message_sum_fields
  var_pop: message_var_pop_fields
  var_samp: message_var_samp_fields
  variance: message_variance_fields
}

# order by aggregate values of table "message"
input message_aggregate_order_by {
  avg: message_avg_order_by
  count: order_by
  max: message_max_order_by
  min: message_min_order_by
  stddev: message_stddev_order_by
  stddev_pop: message_stddev_pop_order_by
  stddev_samp: message_stddev_samp_order_by
  sum: message_sum_order_by
  var_pop: message_var_pop_order_by
  var_samp: message_var_samp_order_by
  variance: message_variance_order_by
}

# input type for inserting array relation for remote table "message"
input message_arr_rel_insert_input {
  data: [message_insert_input!]!
  on_conflict: message_on_conflict
}

# aggregate avg on columns
type message_avg_fields {
  approverMtid: Float
  creator: Float
  deliveryStatus: Float
  error: Float
  forumMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  msgStatus: Float
  msgTemplateMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  replyForumMtid: Float
  replyToMtid: Float
  senderMtid: Float
  status: Float
  sysMsgType: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "message"
input message_avg_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "message". All fields are combined with a logical 'AND'.
input message_bool_exp {
  _and: [message_bool_exp]
  _not: message_bool_exp
  _or: [message_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  body: String_comparison_exp
  bodyEng: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  deliveryStatus: Int_comparison_exp
  dtype: String_comparison_exp
  error: Int_comparison_exp
  files: message_files_bool_exp
  forum: forum_bool_exp
  forumMtid: bigint_comparison_exp
  institutes: message_institutes_bool_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mailboxes: message_mailboxes_bool_exp
  msgStatus: Int_comparison_exp
  msgTemplate: message_template_bool_exp
  msgTemplateMtid: bigint_comparison_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  recipients: message_recipients_bool_exp
  refreshed: Boolean_comparison_exp
  replyForum: message_bool_exp
  replyForumMtid: bigint_comparison_exp
  replyTo: message_bool_exp
  replyToAddress: String_comparison_exp
  replyToMtid: bigint_comparison_exp
  scheduleDate: timestamp_comparison_exp
  sendDate: timestamp_comparison_exp
  sendOut: Boolean_comparison_exp
  sender: users_bool_exp
  senderEmail: String_comparison_exp
  senderMtid: bigint_comparison_exp
  status: Int_comparison_exp
  subject: String_comparison_exp
  subjectEng: String_comparison_exp
  sysMsgType: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  threadPath: String_comparison_exp
  type: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  validUntil: timestamp_comparison_exp
}

# unique or primary key constraints on table "message"
enum message_constraint {
  # unique or primary key constraint
  message_pkey
}

# columns and relationships of "message_files"
type message_files {
  filesMtid: bigint!
  messageMtid: bigint!

  # An object relationship
  uploadedFile: uploaded_file!
}

# aggregated selection of "message_files"
type message_files_aggregate {
  aggregate: message_files_aggregate_fields
  nodes: [message_files!]!
}

# aggregate fields of "message_files"
type message_files_aggregate_fields {
  avg: message_files_avg_fields
  count(columns: [message_files_select_column!], distinct: Boolean): Int
  max: message_files_max_fields
  min: message_files_min_fields
  stddev: message_files_stddev_fields
  stddev_pop: message_files_stddev_pop_fields
  stddev_samp: message_files_stddev_samp_fields
  sum: message_files_sum_fields
  var_pop: message_files_var_pop_fields
  var_samp: message_files_var_samp_fields
  variance: message_files_variance_fields
}

# order by aggregate values of table "message_files"
input message_files_aggregate_order_by {
  avg: message_files_avg_order_by
  count: order_by
  max: message_files_max_order_by
  min: message_files_min_order_by
  stddev: message_files_stddev_order_by
  stddev_pop: message_files_stddev_pop_order_by
  stddev_samp: message_files_stddev_samp_order_by
  sum: message_files_sum_order_by
  var_pop: message_files_var_pop_order_by
  var_samp: message_files_var_samp_order_by
  variance: message_files_variance_order_by
}

# input type for inserting array relation for remote table "message_files"
input message_files_arr_rel_insert_input {
  data: [message_files_insert_input!]!
  on_conflict: message_files_on_conflict
}

# aggregate avg on columns
type message_files_avg_fields {
  filesMtid: Float
  messageMtid: Float
}

# order by avg() on columns of table "message_files"
input message_files_avg_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# Boolean expression to filter rows from the table "message_files". All fields are combined with a logical 'AND'.
input message_files_bool_exp {
  _and: [message_files_bool_exp]
  _not: message_files_bool_exp
  _or: [message_files_bool_exp]
  filesMtid: bigint_comparison_exp
  messageMtid: bigint_comparison_exp
  uploadedFile: uploaded_file_bool_exp
}

# unique or primary key constraints on table "message_files"
enum message_files_constraint {
  # unique or primary key constraint
  uk_oafl0air1phy3gaf6k7oy2tqr
}

# input type for incrementing integer column in table "message_files"
input message_files_inc_input {
  filesMtid: bigint
  messageMtid: bigint
}

# input type for inserting data into table "message_files"
input message_files_insert_input {
  filesMtid: bigint
  messageMtid: bigint
  uploadedFile: uploaded_file_obj_rel_insert_input
}

# aggregate max on columns
type message_files_max_fields {
  filesMtid: bigint
  messageMtid: bigint
}

# order by max() on columns of table "message_files"
input message_files_max_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# aggregate min on columns
type message_files_min_fields {
  filesMtid: bigint
  messageMtid: bigint
}

# order by min() on columns of table "message_files"
input message_files_min_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# response of any mutation on the table "message_files"
type message_files_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_files!]!
}

# input type for inserting object relation for remote table "message_files"
input message_files_obj_rel_insert_input {
  data: message_files_insert_input!
  on_conflict: message_files_on_conflict
}

# on conflict condition type for table "message_files"
input message_files_on_conflict {
  constraint: message_files_constraint!
  update_columns: [message_files_update_column!]!
  where: message_files_bool_exp
}

# ordering options when selecting data from "message_files"
input message_files_order_by {
  filesMtid: order_by
  messageMtid: order_by
  uploadedFile: uploaded_file_order_by
}

# select columns of table "message_files"
enum message_files_select_column {
  # column name
  filesMtid

  # column name
  messageMtid
}

# input type for updating data in table "message_files"
input message_files_set_input {
  filesMtid: bigint
  messageMtid: bigint
}

# aggregate stddev on columns
type message_files_stddev_fields {
  filesMtid: Float
  messageMtid: Float
}

# order by stddev() on columns of table "message_files"
input message_files_stddev_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# aggregate stddev_pop on columns
type message_files_stddev_pop_fields {
  filesMtid: Float
  messageMtid: Float
}

# order by stddev_pop() on columns of table "message_files"
input message_files_stddev_pop_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# aggregate stddev_samp on columns
type message_files_stddev_samp_fields {
  filesMtid: Float
  messageMtid: Float
}

# order by stddev_samp() on columns of table "message_files"
input message_files_stddev_samp_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# aggregate sum on columns
type message_files_sum_fields {
  filesMtid: bigint
  messageMtid: bigint
}

# order by sum() on columns of table "message_files"
input message_files_sum_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# update columns of table "message_files"
enum message_files_update_column {
  # column name
  filesMtid

  # column name
  messageMtid
}

# aggregate var_pop on columns
type message_files_var_pop_fields {
  filesMtid: Float
  messageMtid: Float
}

# order by var_pop() on columns of table "message_files"
input message_files_var_pop_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# aggregate var_samp on columns
type message_files_var_samp_fields {
  filesMtid: Float
  messageMtid: Float
}

# order by var_samp() on columns of table "message_files"
input message_files_var_samp_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# aggregate variance on columns
type message_files_variance_fields {
  filesMtid: Float
  messageMtid: Float
}

# order by variance() on columns of table "message_files"
input message_files_variance_order_by {
  filesMtid: order_by
  messageMtid: order_by
}

# input type for incrementing integer column in table "message"
input message_inc_input {
  approverMtid: bigint
  creator: bigint
  deliveryStatus: Int
  error: Int
  forumMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  msgStatus: Int
  msgTemplateMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  replyForumMtid: bigint
  replyToMtid: bigint
  senderMtid: bigint
  status: Int
  sysMsgType: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "message"
input message_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  body: String
  bodyEng: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  deliveryStatus: Int
  dtype: String
  error: Int
  files: message_files_arr_rel_insert_input
  forum: forum_obj_rel_insert_input
  forumMtid: bigint
  institutes: message_institutes_arr_rel_insert_input
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mailboxes: message_mailboxes_arr_rel_insert_input
  msgStatus: Int
  msgTemplate: message_template_obj_rel_insert_input
  msgTemplateMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  recipients: message_recipients_arr_rel_insert_input
  refreshed: Boolean
  replyForum: message_obj_rel_insert_input
  replyForumMtid: bigint
  replyTo: message_obj_rel_insert_input
  replyToAddress: String
  replyToMtid: bigint
  scheduleDate: timestamp
  sendDate: timestamp
  sendOut: Boolean
  sender: users_obj_rel_insert_input
  senderEmail: String
  senderMtid: bigint
  status: Int
  subject: String
  subjectEng: String
  sysMsgType: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  threadPath: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validUntil: timestamp
}

# columns and relationships of "message_institutes"
type message_institutes {
  forumMessageMtid: bigint!
  institutesMtid: bigint!

  # An object relationship
  organization: organization!
}

# aggregated selection of "message_institutes"
type message_institutes_aggregate {
  aggregate: message_institutes_aggregate_fields
  nodes: [message_institutes!]!
}

# aggregate fields of "message_institutes"
type message_institutes_aggregate_fields {
  avg: message_institutes_avg_fields
  count(columns: [message_institutes_select_column!], distinct: Boolean): Int
  max: message_institutes_max_fields
  min: message_institutes_min_fields
  stddev: message_institutes_stddev_fields
  stddev_pop: message_institutes_stddev_pop_fields
  stddev_samp: message_institutes_stddev_samp_fields
  sum: message_institutes_sum_fields
  var_pop: message_institutes_var_pop_fields
  var_samp: message_institutes_var_samp_fields
  variance: message_institutes_variance_fields
}

# order by aggregate values of table "message_institutes"
input message_institutes_aggregate_order_by {
  avg: message_institutes_avg_order_by
  count: order_by
  max: message_institutes_max_order_by
  min: message_institutes_min_order_by
  stddev: message_institutes_stddev_order_by
  stddev_pop: message_institutes_stddev_pop_order_by
  stddev_samp: message_institutes_stddev_samp_order_by
  sum: message_institutes_sum_order_by
  var_pop: message_institutes_var_pop_order_by
  var_samp: message_institutes_var_samp_order_by
  variance: message_institutes_variance_order_by
}

# input type for inserting array relation for remote table "message_institutes"
input message_institutes_arr_rel_insert_input {
  data: [message_institutes_insert_input!]!
  on_conflict: message_institutes_on_conflict
}

# aggregate avg on columns
type message_institutes_avg_fields {
  forumMessageMtid: Float
  institutesMtid: Float
}

# order by avg() on columns of table "message_institutes"
input message_institutes_avg_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# Boolean expression to filter rows from the table "message_institutes". All fields are combined with a logical 'AND'.
input message_institutes_bool_exp {
  _and: [message_institutes_bool_exp]
  _not: message_institutes_bool_exp
  _or: [message_institutes_bool_exp]
  forumMessageMtid: bigint_comparison_exp
  institutesMtid: bigint_comparison_exp
  organization: organization_bool_exp
}

# unique or primary key constraints on table "message_institutes"
enum message_institutes_constraint {
  # unique or primary key constraint
  message_institutes_pkey
}

# input type for incrementing integer column in table "message_institutes"
input message_institutes_inc_input {
  forumMessageMtid: bigint
  institutesMtid: bigint
}

# input type for inserting data into table "message_institutes"
input message_institutes_insert_input {
  forumMessageMtid: bigint
  institutesMtid: bigint
  organization: organization_obj_rel_insert_input
}

# aggregate max on columns
type message_institutes_max_fields {
  forumMessageMtid: bigint
  institutesMtid: bigint
}

# order by max() on columns of table "message_institutes"
input message_institutes_max_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# aggregate min on columns
type message_institutes_min_fields {
  forumMessageMtid: bigint
  institutesMtid: bigint
}

# order by min() on columns of table "message_institutes"
input message_institutes_min_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# response of any mutation on the table "message_institutes"
type message_institutes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_institutes!]!
}

# input type for inserting object relation for remote table "message_institutes"
input message_institutes_obj_rel_insert_input {
  data: message_institutes_insert_input!
  on_conflict: message_institutes_on_conflict
}

# on conflict condition type for table "message_institutes"
input message_institutes_on_conflict {
  constraint: message_institutes_constraint!
  update_columns: [message_institutes_update_column!]!
  where: message_institutes_bool_exp
}

# ordering options when selecting data from "message_institutes"
input message_institutes_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
  organization: organization_order_by
}

# primary key columns input for table: "message_institutes"
input message_institutes_pk_columns_input {
  forumMessageMtid: bigint!
  institutesMtid: bigint!
}

# select columns of table "message_institutes"
enum message_institutes_select_column {
  # column name
  forumMessageMtid

  # column name
  institutesMtid
}

# input type for updating data in table "message_institutes"
input message_institutes_set_input {
  forumMessageMtid: bigint
  institutesMtid: bigint
}

# aggregate stddev on columns
type message_institutes_stddev_fields {
  forumMessageMtid: Float
  institutesMtid: Float
}

# order by stddev() on columns of table "message_institutes"
input message_institutes_stddev_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# aggregate stddev_pop on columns
type message_institutes_stddev_pop_fields {
  forumMessageMtid: Float
  institutesMtid: Float
}

# order by stddev_pop() on columns of table "message_institutes"
input message_institutes_stddev_pop_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# aggregate stddev_samp on columns
type message_institutes_stddev_samp_fields {
  forumMessageMtid: Float
  institutesMtid: Float
}

# order by stddev_samp() on columns of table "message_institutes"
input message_institutes_stddev_samp_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# aggregate sum on columns
type message_institutes_sum_fields {
  forumMessageMtid: bigint
  institutesMtid: bigint
}

# order by sum() on columns of table "message_institutes"
input message_institutes_sum_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# update columns of table "message_institutes"
enum message_institutes_update_column {
  # column name
  forumMessageMtid

  # column name
  institutesMtid
}

# aggregate var_pop on columns
type message_institutes_var_pop_fields {
  forumMessageMtid: Float
  institutesMtid: Float
}

# order by var_pop() on columns of table "message_institutes"
input message_institutes_var_pop_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# aggregate var_samp on columns
type message_institutes_var_samp_fields {
  forumMessageMtid: Float
  institutesMtid: Float
}

# order by var_samp() on columns of table "message_institutes"
input message_institutes_var_samp_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# aggregate variance on columns
type message_institutes_variance_fields {
  forumMessageMtid: Float
  institutesMtid: Float
}

# order by variance() on columns of table "message_institutes"
input message_institutes_variance_order_by {
  forumMessageMtid: order_by
  institutesMtid: order_by
}

# columns and relationships of "message_mailboxes"
type message_mailboxes {
  mailboxesMtid: bigint!
  messageMtid: bigint!

  # An object relationship
  users: users!
}

# aggregated selection of "message_mailboxes"
type message_mailboxes_aggregate {
  aggregate: message_mailboxes_aggregate_fields
  nodes: [message_mailboxes!]!
}

# aggregate fields of "message_mailboxes"
type message_mailboxes_aggregate_fields {
  avg: message_mailboxes_avg_fields
  count(columns: [message_mailboxes_select_column!], distinct: Boolean): Int
  max: message_mailboxes_max_fields
  min: message_mailboxes_min_fields
  stddev: message_mailboxes_stddev_fields
  stddev_pop: message_mailboxes_stddev_pop_fields
  stddev_samp: message_mailboxes_stddev_samp_fields
  sum: message_mailboxes_sum_fields
  var_pop: message_mailboxes_var_pop_fields
  var_samp: message_mailboxes_var_samp_fields
  variance: message_mailboxes_variance_fields
}

# order by aggregate values of table "message_mailboxes"
input message_mailboxes_aggregate_order_by {
  avg: message_mailboxes_avg_order_by
  count: order_by
  max: message_mailboxes_max_order_by
  min: message_mailboxes_min_order_by
  stddev: message_mailboxes_stddev_order_by
  stddev_pop: message_mailboxes_stddev_pop_order_by
  stddev_samp: message_mailboxes_stddev_samp_order_by
  sum: message_mailboxes_sum_order_by
  var_pop: message_mailboxes_var_pop_order_by
  var_samp: message_mailboxes_var_samp_order_by
  variance: message_mailboxes_variance_order_by
}

# input type for inserting array relation for remote table "message_mailboxes"
input message_mailboxes_arr_rel_insert_input {
  data: [message_mailboxes_insert_input!]!
}

# aggregate avg on columns
type message_mailboxes_avg_fields {
  mailboxesMtid: Float
  messageMtid: Float
}

# order by avg() on columns of table "message_mailboxes"
input message_mailboxes_avg_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# Boolean expression to filter rows from the table "message_mailboxes". All fields are combined with a logical 'AND'.
input message_mailboxes_bool_exp {
  _and: [message_mailboxes_bool_exp]
  _not: message_mailboxes_bool_exp
  _or: [message_mailboxes_bool_exp]
  mailboxesMtid: bigint_comparison_exp
  messageMtid: bigint_comparison_exp
  users: users_bool_exp
}

# input type for incrementing integer column in table "message_mailboxes"
input message_mailboxes_inc_input {
  mailboxesMtid: bigint
  messageMtid: bigint
}

# input type for inserting data into table "message_mailboxes"
input message_mailboxes_insert_input {
  mailboxesMtid: bigint
  messageMtid: bigint
  users: users_obj_rel_insert_input
}

# aggregate max on columns
type message_mailboxes_max_fields {
  mailboxesMtid: bigint
  messageMtid: bigint
}

# order by max() on columns of table "message_mailboxes"
input message_mailboxes_max_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate min on columns
type message_mailboxes_min_fields {
  mailboxesMtid: bigint
  messageMtid: bigint
}

# order by min() on columns of table "message_mailboxes"
input message_mailboxes_min_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# response of any mutation on the table "message_mailboxes"
type message_mailboxes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_mailboxes!]!
}

# input type for inserting object relation for remote table "message_mailboxes"
input message_mailboxes_obj_rel_insert_input {
  data: message_mailboxes_insert_input!
}

# ordering options when selecting data from "message_mailboxes"
input message_mailboxes_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
  users: users_order_by
}

# select columns of table "message_mailboxes"
enum message_mailboxes_select_column {
  # column name
  mailboxesMtid

  # column name
  messageMtid
}

# input type for updating data in table "message_mailboxes"
input message_mailboxes_set_input {
  mailboxesMtid: bigint
  messageMtid: bigint
}

# aggregate stddev on columns
type message_mailboxes_stddev_fields {
  mailboxesMtid: Float
  messageMtid: Float
}

# order by stddev() on columns of table "message_mailboxes"
input message_mailboxes_stddev_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate stddev_pop on columns
type message_mailboxes_stddev_pop_fields {
  mailboxesMtid: Float
  messageMtid: Float
}

# order by stddev_pop() on columns of table "message_mailboxes"
input message_mailboxes_stddev_pop_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate stddev_samp on columns
type message_mailboxes_stddev_samp_fields {
  mailboxesMtid: Float
  messageMtid: Float
}

# order by stddev_samp() on columns of table "message_mailboxes"
input message_mailboxes_stddev_samp_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate sum on columns
type message_mailboxes_sum_fields {
  mailboxesMtid: bigint
  messageMtid: bigint
}

# order by sum() on columns of table "message_mailboxes"
input message_mailboxes_sum_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate var_pop on columns
type message_mailboxes_var_pop_fields {
  mailboxesMtid: Float
  messageMtid: Float
}

# order by var_pop() on columns of table "message_mailboxes"
input message_mailboxes_var_pop_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate var_samp on columns
type message_mailboxes_var_samp_fields {
  mailboxesMtid: Float
  messageMtid: Float
}

# order by var_samp() on columns of table "message_mailboxes"
input message_mailboxes_var_samp_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate variance on columns
type message_mailboxes_variance_fields {
  mailboxesMtid: Float
  messageMtid: Float
}

# order by variance() on columns of table "message_mailboxes"
input message_mailboxes_variance_order_by {
  mailboxesMtid: order_by
  messageMtid: order_by
}

# aggregate max on columns
type message_max_fields {
  approved: timestamp
  approverMtid: bigint
  body: String
  bodyEng: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  deliveryStatus: Int
  dtype: String
  error: Int
  forumMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  msgStatus: Int
  msgTemplateMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  replyForumMtid: bigint
  replyToAddress: String
  replyToMtid: bigint
  scheduleDate: timestamp
  sendDate: timestamp
  senderEmail: String
  senderMtid: bigint
  status: Int
  subject: String
  subjectEng: String
  sysMsgType: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  threadPath: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validUntil: timestamp
}

# order by max() on columns of table "message"
input message_max_order_by {
  approved: order_by
  approverMtid: order_by
  body: order_by
  bodyEng: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  deliveryStatus: order_by
  dtype: order_by
  error: order_by
  forumMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToAddress: order_by
  replyToMtid: order_by
  scheduleDate: order_by
  sendDate: order_by
  senderEmail: order_by
  senderMtid: order_by
  status: order_by
  subject: order_by
  subjectEng: order_by
  sysMsgType: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  threadPath: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validUntil: order_by
}

# aggregate min on columns
type message_min_fields {
  approved: timestamp
  approverMtid: bigint
  body: String
  bodyEng: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  deliveryStatus: Int
  dtype: String
  error: Int
  forumMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  msgStatus: Int
  msgTemplateMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  replyForumMtid: bigint
  replyToAddress: String
  replyToMtid: bigint
  scheduleDate: timestamp
  sendDate: timestamp
  senderEmail: String
  senderMtid: bigint
  status: Int
  subject: String
  subjectEng: String
  sysMsgType: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  threadPath: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validUntil: timestamp
}

# order by min() on columns of table "message"
input message_min_order_by {
  approved: order_by
  approverMtid: order_by
  body: order_by
  bodyEng: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  deliveryStatus: order_by
  dtype: order_by
  error: order_by
  forumMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToAddress: order_by
  replyToMtid: order_by
  scheduleDate: order_by
  sendDate: order_by
  senderEmail: order_by
  senderMtid: order_by
  status: order_by
  subject: order_by
  subjectEng: order_by
  sysMsgType: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  threadPath: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validUntil: order_by
}

# response of any mutation on the table "message"
type message_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message!]!
}

# input type for inserting object relation for remote table "message"
input message_obj_rel_insert_input {
  data: message_insert_input!
  on_conflict: message_on_conflict
}

# on conflict condition type for table "message"
input message_on_conflict {
  constraint: message_constraint!
  update_columns: [message_update_column!]!
  where: message_bool_exp
}

# ordering options when selecting data from "message"
input message_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  body: order_by
  bodyEng: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  deliveryStatus: order_by
  dtype: order_by
  error: order_by
  files_aggregate: message_files_aggregate_order_by
  forum: forum_order_by
  forumMtid: order_by
  institutes_aggregate: message_institutes_aggregate_order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mailboxes_aggregate: message_mailboxes_aggregate_order_by
  msgStatus: order_by
  msgTemplate: message_template_order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  recipients_aggregate: message_recipients_aggregate_order_by
  refreshed: order_by
  replyForum: message_order_by
  replyForumMtid: order_by
  replyTo: message_order_by
  replyToAddress: order_by
  replyToMtid: order_by
  scheduleDate: order_by
  sendDate: order_by
  sendOut: order_by
  sender: users_order_by
  senderEmail: order_by
  senderMtid: order_by
  status: order_by
  subject: order_by
  subjectEng: order_by
  sysMsgType: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  threadPath: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validUntil: order_by
}

# columns and relationships of "message_parameter"
type message_parameter {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  token: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "message_parameter"
type message_parameter_aggregate {
  aggregate: message_parameter_aggregate_fields
  nodes: [message_parameter!]!
}

# aggregate fields of "message_parameter"
type message_parameter_aggregate_fields {
  avg: message_parameter_avg_fields
  count(columns: [message_parameter_select_column!], distinct: Boolean): Int
  max: message_parameter_max_fields
  min: message_parameter_min_fields
  stddev: message_parameter_stddev_fields
  stddev_pop: message_parameter_stddev_pop_fields
  stddev_samp: message_parameter_stddev_samp_fields
  sum: message_parameter_sum_fields
  var_pop: message_parameter_var_pop_fields
  var_samp: message_parameter_var_samp_fields
  variance: message_parameter_variance_fields
}

# order by aggregate values of table "message_parameter"
input message_parameter_aggregate_order_by {
  avg: message_parameter_avg_order_by
  count: order_by
  max: message_parameter_max_order_by
  min: message_parameter_min_order_by
  stddev: message_parameter_stddev_order_by
  stddev_pop: message_parameter_stddev_pop_order_by
  stddev_samp: message_parameter_stddev_samp_order_by
  sum: message_parameter_sum_order_by
  var_pop: message_parameter_var_pop_order_by
  var_samp: message_parameter_var_samp_order_by
  variance: message_parameter_variance_order_by
}

# input type for inserting array relation for remote table "message_parameter"
input message_parameter_arr_rel_insert_input {
  data: [message_parameter_insert_input!]!
  on_conflict: message_parameter_on_conflict
}

# aggregate avg on columns
type message_parameter_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "message_parameter"
input message_parameter_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "message_parameter". All fields are combined with a logical 'AND'.
input message_parameter_bool_exp {
  _and: [message_parameter_bool_exp]
  _not: message_parameter_bool_exp
  _or: [message_parameter_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  token: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "message_parameter"
enum message_parameter_constraint {
  # unique or primary key constraint
  message_parameter_pkey
}

# input type for incrementing integer column in table "message_parameter"
input message_parameter_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "message_parameter"
input message_parameter_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  token: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type message_parameter_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  token: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "message_parameter"
input message_parameter_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  token: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type message_parameter_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  token: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "message_parameter"
input message_parameter_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  token: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "message_parameter"
type message_parameter_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_parameter!]!
}

# input type for inserting object relation for remote table "message_parameter"
input message_parameter_obj_rel_insert_input {
  data: message_parameter_insert_input!
  on_conflict: message_parameter_on_conflict
}

# on conflict condition type for table "message_parameter"
input message_parameter_on_conflict {
  constraint: message_parameter_constraint!
  update_columns: [message_parameter_update_column!]!
  where: message_parameter_bool_exp
}

# ordering options when selecting data from "message_parameter"
input message_parameter_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  token: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "message_parameter"
input message_parameter_pk_columns_input {
  mtid: bigint!
}

# select columns of table "message_parameter"
enum message_parameter_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  token

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "message_parameter"
input message_parameter_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  token: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type message_parameter_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "message_parameter"
input message_parameter_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type message_parameter_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "message_parameter"
input message_parameter_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type message_parameter_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "message_parameter"
input message_parameter_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type message_parameter_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "message_parameter"
input message_parameter_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "message_parameter"
enum message_parameter_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  token

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type message_parameter_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "message_parameter"
input message_parameter_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type message_parameter_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "message_parameter"
input message_parameter_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type message_parameter_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "message_parameter"
input message_parameter_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "message"
input message_pk_columns_input {
  mtid: bigint!
}

# columns and relationships of "message_recipients"
type message_recipients {
  messageMtid: bigint!
  recipientsMtid: bigint!

  # An object relationship
  users: users!
}

# aggregated selection of "message_recipients"
type message_recipients_aggregate {
  aggregate: message_recipients_aggregate_fields
  nodes: [message_recipients!]!
}

# aggregate fields of "message_recipients"
type message_recipients_aggregate_fields {
  avg: message_recipients_avg_fields
  count(columns: [message_recipients_select_column!], distinct: Boolean): Int
  max: message_recipients_max_fields
  min: message_recipients_min_fields
  stddev: message_recipients_stddev_fields
  stddev_pop: message_recipients_stddev_pop_fields
  stddev_samp: message_recipients_stddev_samp_fields
  sum: message_recipients_sum_fields
  var_pop: message_recipients_var_pop_fields
  var_samp: message_recipients_var_samp_fields
  variance: message_recipients_variance_fields
}

# order by aggregate values of table "message_recipients"
input message_recipients_aggregate_order_by {
  avg: message_recipients_avg_order_by
  count: order_by
  max: message_recipients_max_order_by
  min: message_recipients_min_order_by
  stddev: message_recipients_stddev_order_by
  stddev_pop: message_recipients_stddev_pop_order_by
  stddev_samp: message_recipients_stddev_samp_order_by
  sum: message_recipients_sum_order_by
  var_pop: message_recipients_var_pop_order_by
  var_samp: message_recipients_var_samp_order_by
  variance: message_recipients_variance_order_by
}

# input type for inserting array relation for remote table "message_recipients"
input message_recipients_arr_rel_insert_input {
  data: [message_recipients_insert_input!]!
}

# aggregate avg on columns
type message_recipients_avg_fields {
  messageMtid: Float
  recipientsMtid: Float
}

# order by avg() on columns of table "message_recipients"
input message_recipients_avg_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# Boolean expression to filter rows from the table "message_recipients". All fields are combined with a logical 'AND'.
input message_recipients_bool_exp {
  _and: [message_recipients_bool_exp]
  _not: message_recipients_bool_exp
  _or: [message_recipients_bool_exp]
  messageMtid: bigint_comparison_exp
  recipientsMtid: bigint_comparison_exp
  users: users_bool_exp
}

# input type for incrementing integer column in table "message_recipients"
input message_recipients_inc_input {
  messageMtid: bigint
  recipientsMtid: bigint
}

# input type for inserting data into table "message_recipients"
input message_recipients_insert_input {
  messageMtid: bigint
  recipientsMtid: bigint
  users: users_obj_rel_insert_input
}

# aggregate max on columns
type message_recipients_max_fields {
  messageMtid: bigint
  recipientsMtid: bigint
}

# order by max() on columns of table "message_recipients"
input message_recipients_max_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# aggregate min on columns
type message_recipients_min_fields {
  messageMtid: bigint
  recipientsMtid: bigint
}

# order by min() on columns of table "message_recipients"
input message_recipients_min_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# response of any mutation on the table "message_recipients"
type message_recipients_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_recipients!]!
}

# input type for inserting object relation for remote table "message_recipients"
input message_recipients_obj_rel_insert_input {
  data: message_recipients_insert_input!
}

# ordering options when selecting data from "message_recipients"
input message_recipients_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
  users: users_order_by
}

# select columns of table "message_recipients"
enum message_recipients_select_column {
  # column name
  messageMtid

  # column name
  recipientsMtid
}

# input type for updating data in table "message_recipients"
input message_recipients_set_input {
  messageMtid: bigint
  recipientsMtid: bigint
}

# aggregate stddev on columns
type message_recipients_stddev_fields {
  messageMtid: Float
  recipientsMtid: Float
}

# order by stddev() on columns of table "message_recipients"
input message_recipients_stddev_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# aggregate stddev_pop on columns
type message_recipients_stddev_pop_fields {
  messageMtid: Float
  recipientsMtid: Float
}

# order by stddev_pop() on columns of table "message_recipients"
input message_recipients_stddev_pop_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# aggregate stddev_samp on columns
type message_recipients_stddev_samp_fields {
  messageMtid: Float
  recipientsMtid: Float
}

# order by stddev_samp() on columns of table "message_recipients"
input message_recipients_stddev_samp_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# aggregate sum on columns
type message_recipients_sum_fields {
  messageMtid: bigint
  recipientsMtid: bigint
}

# order by sum() on columns of table "message_recipients"
input message_recipients_sum_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# aggregate var_pop on columns
type message_recipients_var_pop_fields {
  messageMtid: Float
  recipientsMtid: Float
}

# order by var_pop() on columns of table "message_recipients"
input message_recipients_var_pop_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# aggregate var_samp on columns
type message_recipients_var_samp_fields {
  messageMtid: Float
  recipientsMtid: Float
}

# order by var_samp() on columns of table "message_recipients"
input message_recipients_var_samp_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# aggregate variance on columns
type message_recipients_variance_fields {
  messageMtid: Float
  recipientsMtid: Float
}

# order by variance() on columns of table "message_recipients"
input message_recipients_variance_order_by {
  messageMtid: order_by
  recipientsMtid: order_by
}

# select columns of table "message"
enum message_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  body

  # column name
  bodyEng

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  deliveryStatus

  # column name
  dtype

  # column name
  error

  # column name
  forumMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  msgStatus

  # column name
  msgTemplateMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  replyForumMtid

  # column name
  replyToAddress

  # column name
  replyToMtid

  # column name
  scheduleDate

  # column name
  sendDate

  # column name
  sendOut

  # column name
  senderEmail

  # column name
  senderMtid

  # column name
  status

  # column name
  subject

  # column name
  subjectEng

  # column name
  sysMsgType

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  threadPath

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  validUntil
}

# columns and relationships of "message_sent"
type message_sent {
  body: String
  error: String
  fromAddress: String
  id: bigint!
  subject: String
  timestamp: timestamp
  toAddress: String
}

# aggregated selection of "message_sent"
type message_sent_aggregate {
  aggregate: message_sent_aggregate_fields
  nodes: [message_sent!]!
}

# aggregate fields of "message_sent"
type message_sent_aggregate_fields {
  avg: message_sent_avg_fields
  count(columns: [message_sent_select_column!], distinct: Boolean): Int
  max: message_sent_max_fields
  min: message_sent_min_fields
  stddev: message_sent_stddev_fields
  stddev_pop: message_sent_stddev_pop_fields
  stddev_samp: message_sent_stddev_samp_fields
  sum: message_sent_sum_fields
  var_pop: message_sent_var_pop_fields
  var_samp: message_sent_var_samp_fields
  variance: message_sent_variance_fields
}

# order by aggregate values of table "message_sent"
input message_sent_aggregate_order_by {
  avg: message_sent_avg_order_by
  count: order_by
  max: message_sent_max_order_by
  min: message_sent_min_order_by
  stddev: message_sent_stddev_order_by
  stddev_pop: message_sent_stddev_pop_order_by
  stddev_samp: message_sent_stddev_samp_order_by
  sum: message_sent_sum_order_by
  var_pop: message_sent_var_pop_order_by
  var_samp: message_sent_var_samp_order_by
  variance: message_sent_variance_order_by
}

# input type for inserting array relation for remote table "message_sent"
input message_sent_arr_rel_insert_input {
  data: [message_sent_insert_input!]!
  on_conflict: message_sent_on_conflict
}

# aggregate avg on columns
type message_sent_avg_fields {
  id: Float
}

# order by avg() on columns of table "message_sent"
input message_sent_avg_order_by {
  id: order_by
}

# Boolean expression to filter rows from the table "message_sent". All fields are combined with a logical 'AND'.
input message_sent_bool_exp {
  _and: [message_sent_bool_exp]
  _not: message_sent_bool_exp
  _or: [message_sent_bool_exp]
  body: String_comparison_exp
  error: String_comparison_exp
  fromAddress: String_comparison_exp
  id: bigint_comparison_exp
  subject: String_comparison_exp
  timestamp: timestamp_comparison_exp
  toAddress: String_comparison_exp
}

# unique or primary key constraints on table "message_sent"
enum message_sent_constraint {
  # unique or primary key constraint
  message_sent_pkey
}

# input type for incrementing integer column in table "message_sent"
input message_sent_inc_input {
  id: bigint
}

# input type for inserting data into table "message_sent"
input message_sent_insert_input {
  body: String
  error: String
  fromAddress: String
  id: bigint
  subject: String
  timestamp: timestamp
  toAddress: String
}

# aggregate max on columns
type message_sent_max_fields {
  body: String
  error: String
  fromAddress: String
  id: bigint
  subject: String
  timestamp: timestamp
  toAddress: String
}

# order by max() on columns of table "message_sent"
input message_sent_max_order_by {
  body: order_by
  error: order_by
  fromAddress: order_by
  id: order_by
  subject: order_by
  timestamp: order_by
  toAddress: order_by
}

# aggregate min on columns
type message_sent_min_fields {
  body: String
  error: String
  fromAddress: String
  id: bigint
  subject: String
  timestamp: timestamp
  toAddress: String
}

# order by min() on columns of table "message_sent"
input message_sent_min_order_by {
  body: order_by
  error: order_by
  fromAddress: order_by
  id: order_by
  subject: order_by
  timestamp: order_by
  toAddress: order_by
}

# response of any mutation on the table "message_sent"
type message_sent_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_sent!]!
}

# input type for inserting object relation for remote table "message_sent"
input message_sent_obj_rel_insert_input {
  data: message_sent_insert_input!
  on_conflict: message_sent_on_conflict
}

# on conflict condition type for table "message_sent"
input message_sent_on_conflict {
  constraint: message_sent_constraint!
  update_columns: [message_sent_update_column!]!
  where: message_sent_bool_exp
}

# ordering options when selecting data from "message_sent"
input message_sent_order_by {
  body: order_by
  error: order_by
  fromAddress: order_by
  id: order_by
  subject: order_by
  timestamp: order_by
  toAddress: order_by
}

# primary key columns input for table: "message_sent"
input message_sent_pk_columns_input {
  id: bigint!
}

# select columns of table "message_sent"
enum message_sent_select_column {
  # column name
  body

  # column name
  error

  # column name
  fromAddress

  # column name
  id

  # column name
  subject

  # column name
  timestamp

  # column name
  toAddress
}

# input type for updating data in table "message_sent"
input message_sent_set_input {
  body: String
  error: String
  fromAddress: String
  id: bigint
  subject: String
  timestamp: timestamp
  toAddress: String
}

# aggregate stddev on columns
type message_sent_stddev_fields {
  id: Float
}

# order by stddev() on columns of table "message_sent"
input message_sent_stddev_order_by {
  id: order_by
}

# aggregate stddev_pop on columns
type message_sent_stddev_pop_fields {
  id: Float
}

# order by stddev_pop() on columns of table "message_sent"
input message_sent_stddev_pop_order_by {
  id: order_by
}

# aggregate stddev_samp on columns
type message_sent_stddev_samp_fields {
  id: Float
}

# order by stddev_samp() on columns of table "message_sent"
input message_sent_stddev_samp_order_by {
  id: order_by
}

# aggregate sum on columns
type message_sent_sum_fields {
  id: bigint
}

# order by sum() on columns of table "message_sent"
input message_sent_sum_order_by {
  id: order_by
}

# update columns of table "message_sent"
enum message_sent_update_column {
  # column name
  body

  # column name
  error

  # column name
  fromAddress

  # column name
  id

  # column name
  subject

  # column name
  timestamp

  # column name
  toAddress
}

# aggregate var_pop on columns
type message_sent_var_pop_fields {
  id: Float
}

# order by var_pop() on columns of table "message_sent"
input message_sent_var_pop_order_by {
  id: order_by
}

# aggregate var_samp on columns
type message_sent_var_samp_fields {
  id: Float
}

# order by var_samp() on columns of table "message_sent"
input message_sent_var_samp_order_by {
  id: order_by
}

# aggregate variance on columns
type message_sent_variance_fields {
  id: Float
}

# order by variance() on columns of table "message_sent"
input message_sent_variance_order_by {
  id: order_by
}

# input type for updating data in table "message"
input message_set_input {
  approved: timestamp
  approverMtid: bigint
  body: String
  bodyEng: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  deliveryStatus: Int
  dtype: String
  error: Int
  forumMtid: bigint
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  msgStatus: Int
  msgTemplateMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  replyForumMtid: bigint
  replyToAddress: String
  replyToMtid: bigint
  scheduleDate: timestamp
  sendDate: timestamp
  sendOut: Boolean
  senderEmail: String
  senderMtid: bigint
  status: Int
  subject: String
  subjectEng: String
  sysMsgType: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  threadPath: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validUntil: timestamp
}

# aggregate stddev on columns
type message_stddev_fields {
  approverMtid: Float
  creator: Float
  deliveryStatus: Float
  error: Float
  forumMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  msgStatus: Float
  msgTemplateMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  replyForumMtid: Float
  replyToMtid: Float
  senderMtid: Float
  status: Float
  sysMsgType: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "message"
input message_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type message_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  deliveryStatus: Float
  error: Float
  forumMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  msgStatus: Float
  msgTemplateMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  replyForumMtid: Float
  replyToMtid: Float
  senderMtid: Float
  status: Float
  sysMsgType: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "message"
input message_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type message_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  deliveryStatus: Float
  error: Float
  forumMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  msgStatus: Float
  msgTemplateMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  replyForumMtid: Float
  replyToMtid: Float
  senderMtid: Float
  status: Float
  sysMsgType: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "message"
input message_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type message_sum_fields {
  approverMtid: bigint
  creator: bigint
  deliveryStatus: Int
  error: Int
  forumMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  msgStatus: Int
  msgTemplateMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  replyForumMtid: bigint
  replyToMtid: bigint
  senderMtid: bigint
  status: Int
  sysMsgType: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "message"
input message_sum_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "message_template"
type message_template {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  body: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  icon: String
  labelEng: String
  labelHun: String
  lang: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp

  # An object relationship
  organization: organization
  organizationMtid: bigint
  otype: String

  # An array relationship
  parameters(
    # distinct select on columns
    distinct_on: [message_template_parameters_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_parameters_order_by!]

    # filter the rows returned
    where: message_template_parameters_bool_exp
  ): [message_template_parameters!]!

  # An aggregated array relationship
  parameters_aggregate(
    # distinct select on columns
    distinct_on: [message_template_parameters_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_parameters_order_by!]

    # filter the rows returned
    where: message_template_parameters_bool_exp
  ): message_template_parameters_aggregate!
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  replyToSenderAllowed: Boolean!
  sender: String
  shortName: String
  status: Int
  subject: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "message_template"
type message_template_aggregate {
  aggregate: message_template_aggregate_fields
  nodes: [message_template!]!
}

# aggregate fields of "message_template"
type message_template_aggregate_fields {
  avg: message_template_avg_fields
  count(columns: [message_template_select_column!], distinct: Boolean): Int
  max: message_template_max_fields
  min: message_template_min_fields
  stddev: message_template_stddev_fields
  stddev_pop: message_template_stddev_pop_fields
  stddev_samp: message_template_stddev_samp_fields
  sum: message_template_sum_fields
  var_pop: message_template_var_pop_fields
  var_samp: message_template_var_samp_fields
  variance: message_template_variance_fields
}

# order by aggregate values of table "message_template"
input message_template_aggregate_order_by {
  avg: message_template_avg_order_by
  count: order_by
  max: message_template_max_order_by
  min: message_template_min_order_by
  stddev: message_template_stddev_order_by
  stddev_pop: message_template_stddev_pop_order_by
  stddev_samp: message_template_stddev_samp_order_by
  sum: message_template_sum_order_by
  var_pop: message_template_var_pop_order_by
  var_samp: message_template_var_samp_order_by
  variance: message_template_variance_order_by
}

# input type for inserting array relation for remote table "message_template"
input message_template_arr_rel_insert_input {
  data: [message_template_insert_input!]!
  on_conflict: message_template_on_conflict
}

# aggregate avg on columns
type message_template_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "message_template"
input message_template_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "message_template". All fields are combined with a logical 'AND'.
input message_template_bool_exp {
  _and: [message_template_bool_exp]
  _not: message_template_bool_exp
  _or: [message_template_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  body: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  icon: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lang: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  organization: organization_bool_exp
  organizationMtid: bigint_comparison_exp
  otype: String_comparison_exp
  parameters: message_template_parameters_bool_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  replyToSenderAllowed: Boolean_comparison_exp
  sender: String_comparison_exp
  shortName: String_comparison_exp
  status: Int_comparison_exp
  subject: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "message_template"
enum message_template_constraint {
  # unique or primary key constraint
  message_template_pkey
}

# input type for incrementing integer column in table "message_template"
input message_template_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  organizationMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "message_template"
input message_template_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  body: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  icon: String
  labelEng: String
  labelHun: String
  lang: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  organization: organization_obj_rel_insert_input
  organizationMtid: bigint
  otype: String
  parameters: message_template_parameters_arr_rel_insert_input
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  replyToSenderAllowed: Boolean
  sender: String
  shortName: String
  status: Int
  subject: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type message_template_max_fields {
  approved: timestamp
  approverMtid: bigint
  body: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  icon: String
  labelEng: String
  labelHun: String
  lang: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  sender: String
  shortName: String
  status: Int
  subject: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "message_template"
input message_template_max_order_by {
  approved: order_by
  approverMtid: order_by
  body: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  icon: order_by
  labelEng: order_by
  labelHun: order_by
  lang: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  sender: order_by
  shortName: order_by
  status: order_by
  subject: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type message_template_min_fields {
  approved: timestamp
  approverMtid: bigint
  body: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  icon: String
  labelEng: String
  labelHun: String
  lang: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  sender: String
  shortName: String
  status: Int
  subject: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "message_template"
input message_template_min_order_by {
  approved: order_by
  approverMtid: order_by
  body: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  icon: order_by
  labelEng: order_by
  labelHun: order_by
  lang: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  sender: order_by
  shortName: order_by
  status: order_by
  subject: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "message_template"
type message_template_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_template!]!
}

# input type for inserting object relation for remote table "message_template"
input message_template_obj_rel_insert_input {
  data: message_template_insert_input!
  on_conflict: message_template_on_conflict
}

# on conflict condition type for table "message_template"
input message_template_on_conflict {
  constraint: message_template_constraint!
  update_columns: [message_template_update_column!]!
  where: message_template_bool_exp
}

# ordering options when selecting data from "message_template"
input message_template_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  body: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  icon: order_by
  labelEng: order_by
  labelHun: order_by
  lang: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  organization: organization_order_by
  organizationMtid: order_by
  otype: order_by
  parameters_aggregate: message_template_parameters_aggregate_order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  replyToSenderAllowed: order_by
  sender: order_by
  shortName: order_by
  status: order_by
  subject: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "message_template_parameters"
type message_template_parameters {
  # An object relationship
  messageParameter: message_parameter!
  messageTemplateMtid: bigint!
  parametersMtid: bigint!
}

# aggregated selection of "message_template_parameters"
type message_template_parameters_aggregate {
  aggregate: message_template_parameters_aggregate_fields
  nodes: [message_template_parameters!]!
}

# aggregate fields of "message_template_parameters"
type message_template_parameters_aggregate_fields {
  avg: message_template_parameters_avg_fields
  count(columns: [message_template_parameters_select_column!], distinct: Boolean): Int
  max: message_template_parameters_max_fields
  min: message_template_parameters_min_fields
  stddev: message_template_parameters_stddev_fields
  stddev_pop: message_template_parameters_stddev_pop_fields
  stddev_samp: message_template_parameters_stddev_samp_fields
  sum: message_template_parameters_sum_fields
  var_pop: message_template_parameters_var_pop_fields
  var_samp: message_template_parameters_var_samp_fields
  variance: message_template_parameters_variance_fields
}

# order by aggregate values of table "message_template_parameters"
input message_template_parameters_aggregate_order_by {
  avg: message_template_parameters_avg_order_by
  count: order_by
  max: message_template_parameters_max_order_by
  min: message_template_parameters_min_order_by
  stddev: message_template_parameters_stddev_order_by
  stddev_pop: message_template_parameters_stddev_pop_order_by
  stddev_samp: message_template_parameters_stddev_samp_order_by
  sum: message_template_parameters_sum_order_by
  var_pop: message_template_parameters_var_pop_order_by
  var_samp: message_template_parameters_var_samp_order_by
  variance: message_template_parameters_variance_order_by
}

# input type for inserting array relation for remote table "message_template_parameters"
input message_template_parameters_arr_rel_insert_input {
  data: [message_template_parameters_insert_input!]!
}

# aggregate avg on columns
type message_template_parameters_avg_fields {
  messageTemplateMtid: Float
  parametersMtid: Float
}

# order by avg() on columns of table "message_template_parameters"
input message_template_parameters_avg_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# Boolean expression to filter rows from the table "message_template_parameters".
# All fields are combined with a logical 'AND'.
input message_template_parameters_bool_exp {
  _and: [message_template_parameters_bool_exp]
  _not: message_template_parameters_bool_exp
  _or: [message_template_parameters_bool_exp]
  messageParameter: message_parameter_bool_exp
  messageTemplateMtid: bigint_comparison_exp
  parametersMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "message_template_parameters"
input message_template_parameters_inc_input {
  messageTemplateMtid: bigint
  parametersMtid: bigint
}

# input type for inserting data into table "message_template_parameters"
input message_template_parameters_insert_input {
  messageParameter: message_parameter_obj_rel_insert_input
  messageTemplateMtid: bigint
  parametersMtid: bigint
}

# aggregate max on columns
type message_template_parameters_max_fields {
  messageTemplateMtid: bigint
  parametersMtid: bigint
}

# order by max() on columns of table "message_template_parameters"
input message_template_parameters_max_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# aggregate min on columns
type message_template_parameters_min_fields {
  messageTemplateMtid: bigint
  parametersMtid: bigint
}

# order by min() on columns of table "message_template_parameters"
input message_template_parameters_min_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# response of any mutation on the table "message_template_parameters"
type message_template_parameters_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [message_template_parameters!]!
}

# input type for inserting object relation for remote table "message_template_parameters"
input message_template_parameters_obj_rel_insert_input {
  data: message_template_parameters_insert_input!
}

# ordering options when selecting data from "message_template_parameters"
input message_template_parameters_order_by {
  messageParameter: message_parameter_order_by
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# select columns of table "message_template_parameters"
enum message_template_parameters_select_column {
  # column name
  messageTemplateMtid

  # column name
  parametersMtid
}

# input type for updating data in table "message_template_parameters"
input message_template_parameters_set_input {
  messageTemplateMtid: bigint
  parametersMtid: bigint
}

# aggregate stddev on columns
type message_template_parameters_stddev_fields {
  messageTemplateMtid: Float
  parametersMtid: Float
}

# order by stddev() on columns of table "message_template_parameters"
input message_template_parameters_stddev_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# aggregate stddev_pop on columns
type message_template_parameters_stddev_pop_fields {
  messageTemplateMtid: Float
  parametersMtid: Float
}

# order by stddev_pop() on columns of table "message_template_parameters"
input message_template_parameters_stddev_pop_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# aggregate stddev_samp on columns
type message_template_parameters_stddev_samp_fields {
  messageTemplateMtid: Float
  parametersMtid: Float
}

# order by stddev_samp() on columns of table "message_template_parameters"
input message_template_parameters_stddev_samp_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# aggregate sum on columns
type message_template_parameters_sum_fields {
  messageTemplateMtid: bigint
  parametersMtid: bigint
}

# order by sum() on columns of table "message_template_parameters"
input message_template_parameters_sum_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# aggregate var_pop on columns
type message_template_parameters_var_pop_fields {
  messageTemplateMtid: Float
  parametersMtid: Float
}

# order by var_pop() on columns of table "message_template_parameters"
input message_template_parameters_var_pop_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# aggregate var_samp on columns
type message_template_parameters_var_samp_fields {
  messageTemplateMtid: Float
  parametersMtid: Float
}

# order by var_samp() on columns of table "message_template_parameters"
input message_template_parameters_var_samp_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# aggregate variance on columns
type message_template_parameters_variance_fields {
  messageTemplateMtid: Float
  parametersMtid: Float
}

# order by variance() on columns of table "message_template_parameters"
input message_template_parameters_variance_order_by {
  messageTemplateMtid: order_by
  parametersMtid: order_by
}

# primary key columns input for table: "message_template"
input message_template_pk_columns_input {
  mtid: bigint!
}

# select columns of table "message_template"
enum message_template_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  body

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  icon

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lang

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  organizationMtid

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  replyToSenderAllowed

  # column name
  sender

  # column name
  shortName

  # column name
  status

  # column name
  subject

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "message_template"
input message_template_set_input {
  approved: timestamp
  approverMtid: bigint
  body: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  icon: String
  labelEng: String
  labelHun: String
  lang: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  replyToSenderAllowed: Boolean
  sender: String
  shortName: String
  status: Int
  subject: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type message_template_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "message_template"
input message_template_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type message_template_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "message_template"
input message_template_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type message_template_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "message_template"
input message_template_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type message_template_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  organizationMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "message_template"
input message_template_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "message_template"
enum message_template_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  body

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  icon

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lang

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  organizationMtid

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  replyToSenderAllowed

  # column name
  sender

  # column name
  shortName

  # column name
  status

  # column name
  subject

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type message_template_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "message_template"
input message_template_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type message_template_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "message_template"
input message_template_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type message_template_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "message_template"
input message_template_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "message"
enum message_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  body

  # column name
  bodyEng

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  deliveryStatus

  # column name
  dtype

  # column name
  error

  # column name
  forumMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  msgStatus

  # column name
  msgTemplateMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  replyForumMtid

  # column name
  replyToAddress

  # column name
  replyToMtid

  # column name
  scheduleDate

  # column name
  sendDate

  # column name
  sendOut

  # column name
  senderEmail

  # column name
  senderMtid

  # column name
  status

  # column name
  subject

  # column name
  subjectEng

  # column name
  sysMsgType

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  threadPath

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  validUntil
}

# aggregate var_pop on columns
type message_var_pop_fields {
  approverMtid: Float
  creator: Float
  deliveryStatus: Float
  error: Float
  forumMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  msgStatus: Float
  msgTemplateMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  replyForumMtid: Float
  replyToMtid: Float
  senderMtid: Float
  status: Float
  sysMsgType: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "message"
input message_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type message_var_samp_fields {
  approverMtid: Float
  creator: Float
  deliveryStatus: Float
  error: Float
  forumMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  msgStatus: Float
  msgTemplateMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  replyForumMtid: Float
  replyToMtid: Float
  senderMtid: Float
  status: Float
  sysMsgType: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "message"
input message_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type message_variance_fields {
  approverMtid: Float
  creator: Float
  deliveryStatus: Float
  error: Float
  forumMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  msgStatus: Float
  msgTemplateMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  replyForumMtid: Float
  replyToMtid: Float
  senderMtid: Float
  status: Float
  sysMsgType: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "message"
input message_variance_order_by {
  approverMtid: order_by
  creator: order_by
  deliveryStatus: order_by
  error: order_by
  forumMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  msgStatus: order_by
  msgTemplateMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  replyForumMtid: order_by
  replyToMtid: order_by
  senderMtid: order_by
  status: order_by
  sysMsgType: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# mutation root
type mutation_root {
  # delete data from the table: "achievement_property"
  delete_achievement_property(
    # filter the rows which have to be deleted
    where: achievement_property_bool_exp!
  ): achievement_property_mutation_response

  # delete single row from the table: "achievement_property"
  delete_achievement_property_by_pk(mtid: bigint!): achievement_property

  # delete data from the table: "achievement_property_listing"
  delete_achievement_property_listing(
    # filter the rows which have to be deleted
    where: achievement_property_listing_bool_exp!
  ): achievement_property_listing_mutation_response

  # delete single row from the table: "achievement_property_listing"
  delete_achievement_property_listing_by_pk(mtid: bigint!): achievement_property_listing

  # delete data from the table: "achievement_property_value"
  delete_achievement_property_value(
    # filter the rows which have to be deleted
    where: achievement_property_value_bool_exp!
  ): achievement_property_value_mutation_response

  # delete single row from the table: "achievement_property_value"
  delete_achievement_property_value_by_pk(mtid: bigint!): achievement_property_value

  # delete data from the table: "activity_log"
  delete_activity_log(
    # filter the rows which have to be deleted
    where: activity_log_bool_exp!
  ): activity_log_mutation_response

  # delete single row from the table: "activity_log"
  delete_activity_log_by_pk(id: bigint!): activity_log

  # delete data from the table: "address"
  delete_address(
    # filter the rows which have to be deleted
    where: address_bool_exp!
  ): address_mutation_response

  # delete single row from the table: "address"
  delete_address_by_pk(mtid: bigint!): address

  # delete data from the table: "admin_role"
  delete_admin_role(
    # filter the rows which have to be deleted
    where: admin_role_bool_exp!
  ): admin_role_mutation_response

  # delete single row from the table: "admin_role"
  delete_admin_role_by_pk(mtid: bigint!): admin_role

  # delete data from the table: "affiliation"
  delete_affiliation(
    # filter the rows which have to be deleted
    where: affiliation_bool_exp!
  ): affiliation_mutation_response

  # delete single row from the table: "affiliation"
  delete_affiliation_by_pk(mtid: bigint!): affiliation

  # delete data from the table: "appearance"
  delete_appearance(
    # filter the rows which have to be deleted
    where: appearance_bool_exp!
  ): appearance_mutation_response

  # delete single row from the table: "appearance"
  delete_appearance_by_pk(mtid: bigint!): appearance

  # delete data from the table: "authentication_failure"
  delete_authentication_failure(
    # filter the rows which have to be deleted
    where: authentication_failure_bool_exp!
  ): authentication_failure_mutation_response

  # delete single row from the table: "authentication_failure"
  delete_authentication_failure_by_pk(id: bigint!): authentication_failure

  # delete data from the table: "author_identifier"
  delete_author_identifier(
    # filter the rows which have to be deleted
    where: author_identifier_bool_exp!
  ): author_identifier_mutation_response

  # delete single row from the table: "author_identifier"
  delete_author_identifier_by_pk(mtid: bigint!): author_identifier

  # delete data from the table: "author_name"
  delete_author_name(
    # filter the rows which have to be deleted
    where: author_name_bool_exp!
  ): author_name_mutation_response

  # delete single row from the table: "author_name"
  delete_author_name_by_pk(mtid: bigint!): author_name

  # delete data from the table: "authorship"
  delete_authorship(
    # filter the rows which have to be deleted
    where: authorship_bool_exp!
  ): authorship_mutation_response

  # delete single row from the table: "authorship"
  delete_authorship_by_pk(mtid: bigint!): authorship

  # delete data from the table: "authorship_organizations"
  delete_authorship_organizations(
    # filter the rows which have to be deleted
    where: authorship_organizations_bool_exp!
  ): authorship_organizations_mutation_response

  # delete data from the table: "authorship_type"
  delete_authorship_type(
    # filter the rows which have to be deleted
    where: authorship_type_bool_exp!
  ): authorship_type_mutation_response

  # delete single row from the table: "authorship_type"
  delete_authorship_type_by_pk(mtid: bigint!): authorship_type

  # delete data from the table: "authorship_type_sub_types_allowed"
  delete_authorship_type_sub_types_allowed(
    # filter the rows which have to be deleted
    where: authorship_type_sub_types_allowed_bool_exp!
  ): authorship_type_sub_types_allowed_mutation_response

  # delete data from the table: "authorship_type_types_allowed"
  delete_authorship_type_types_allowed(
    # filter the rows which have to be deleted
    where: authorship_type_types_allowed_bool_exp!
  ): authorship_type_types_allowed_mutation_response

  # delete data from the table: "binary_content"
  delete_binary_content(
    # filter the rows which have to be deleted
    where: binary_content_bool_exp!
  ): binary_content_mutation_response

  # delete single row from the table: "binary_content"
  delete_binary_content_by_pk(id: bigint!): binary_content

  # delete data from the table: "bulk_duplum_merge_request"
  delete_bulk_duplum_merge_request(
    # filter the rows which have to be deleted
    where: bulk_duplum_merge_request_bool_exp!
  ): bulk_duplum_merge_request_mutation_response

  # delete single row from the table: "bulk_duplum_merge_request"
  delete_bulk_duplum_merge_request_by_pk(mtid: bigint!): bulk_duplum_merge_request

  # delete data from the table: "category"
  delete_category(
    # filter the rows which have to be deleted
    where: category_bool_exp!
  ): category_mutation_response

  # delete single row from the table: "category"
  delete_category_by_pk(mtid: bigint!): category

  # delete data from the table: "category_sub_types_allowed"
  delete_category_sub_types_allowed(
    # filter the rows which have to be deleted
    where: category_sub_types_allowed_bool_exp!
  ): category_sub_types_allowed_mutation_response

  # delete data from the table: "category_types_allowed"
  delete_category_types_allowed(
    # filter the rows which have to be deleted
    where: category_types_allowed_bool_exp!
  ): category_types_allowed_mutation_response

  # delete data from the table: "citation"
  delete_citation(
    # filter the rows which have to be deleted
    where: citation_bool_exp!
  ): citation_mutation_response

  # delete single row from the table: "citation"
  delete_citation_by_pk(mtid: bigint!): citation

  # delete data from the table: "classification"
  delete_classification(
    # filter the rows which have to be deleted
    where: classification_bool_exp!
  ): classification_mutation_response

  # delete single row from the table: "classification"
  delete_classification_by_pk(mtid: bigint!): classification

  # delete data from the table: "classification_external"
  delete_classification_external(
    # filter the rows which have to be deleted
    where: classification_external_bool_exp!
  ): classification_external_mutation_response

  # delete single row from the table: "classification_external"
  delete_classification_external_by_pk(mtid: bigint!): classification_external

  # delete data from the table: "classification_external_mapped_to"
  delete_classification_external_mapped_to(
    # filter the rows which have to be deleted
    where: classification_external_mapped_to_bool_exp!
  ): classification_external_mapped_to_mutation_response

  # delete data from the table: "classification_parents"
  delete_classification_parents(
    # filter the rows which have to be deleted
    where: classification_parents_bool_exp!
  ): classification_parents_mutation_response

  # delete data from the table: "classification_tree"
  delete_classification_tree(
    # filter the rows which have to be deleted
    where: classification_tree_bool_exp!
  ): classification_tree_mutation_response

  # delete single row from the table: "classification_tree"
  delete_classification_tree_by_pk(mtid: bigint!): classification_tree

  # delete data from the table: "conference"
  delete_conference(
    # filter the rows which have to be deleted
    where: conference_bool_exp!
  ): conference_mutation_response

  # delete single row from the table: "conference"
  delete_conference_by_pk(mtid: bigint!): conference

  # delete data from the table: "conference_location"
  delete_conference_location(
    # filter the rows which have to be deleted
    where: conference_location_bool_exp!
  ): conference_location_mutation_response

  # delete data from the table: "conference_organizers"
  delete_conference_organizers(
    # filter the rows which have to be deleted
    where: conference_organizers_bool_exp!
  ): conference_organizers_mutation_response

  # delete data from the table: "cron_job"
  delete_cron_job(
    # filter the rows which have to be deleted
    where: cron_job_bool_exp!
  ): cron_job_mutation_response

  # delete single row from the table: "cron_job"
  delete_cron_job_by_pk(mtid: bigint!): cron_job

  # delete data from the table: "cron_job_run_request"
  delete_cron_job_run_request(
    # filter the rows which have to be deleted
    where: cron_job_run_request_bool_exp!
  ): cron_job_run_request_mutation_response

  # delete single row from the table: "cron_job_run_request"
  delete_cron_job_run_request_by_pk(mtid: bigint!): cron_job_run_request

  # delete data from the table: "degree"
  delete_degree(
    # filter the rows which have to be deleted
    where: degree_bool_exp!
  ): degree_mutation_response

  # delete single row from the table: "degree"
  delete_degree_by_pk(mtid: bigint!): degree

  # delete data from the table: "degree_holder"
  delete_degree_holder(
    # filter the rows which have to be deleted
    where: degree_holder_bool_exp!
  ): degree_holder_mutation_response

  # delete single row from the table: "degree_holder"
  delete_degree_holder_by_pk(mtid: bigint!): degree_holder

  # delete data from the table: "discipline"
  delete_discipline(
    # filter the rows which have to be deleted
    where: discipline_bool_exp!
  ): discipline_mutation_response

  # delete single row from the table: "discipline"
  delete_discipline_by_pk(mtid: bigint!): discipline

  # delete data from the table: "division_containment"
  delete_division_containment(
    # filter the rows which have to be deleted
    where: division_containment_bool_exp!
  ): division_containment_mutation_response

  # delete single row from the table: "division_containment"
  delete_division_containment_by_pk(mtid: bigint!): division_containment

  # delete data from the table: "duplum_desc"
  delete_duplum_desc(
    # filter the rows which have to be deleted
    where: duplum_desc_bool_exp!
  ): duplum_desc_mutation_response

  # delete data from the table: "duplum_desc_book_chapters_merged"
  delete_duplum_desc_book_chapters_merged(
    # filter the rows which have to be deleted
    where: duplum_desc_book_chapters_merged_bool_exp!
  ): duplum_desc_book_chapters_merged_mutation_response

  # delete single row from the table: "duplum_desc"
  delete_duplum_desc_by_pk(id: bigint!): duplum_desc

  # delete data from the table: "duplum_desc_citations_merged"
  delete_duplum_desc_citations_merged(
    # filter the rows which have to be deleted
    where: duplum_desc_citations_merged_bool_exp!
  ): duplum_desc_citations_merged_mutation_response

  # delete data from the table: "duplum_search_request"
  delete_duplum_search_request(
    # filter the rows which have to be deleted
    where: duplum_search_request_bool_exp!
  ): duplum_search_request_mutation_response

  # delete single row from the table: "duplum_search_request"
  delete_duplum_search_request_by_pk(mtid: bigint!): duplum_search_request

  # delete data from the table: "duplum_search_result"
  delete_duplum_search_result(
    # filter the rows which have to be deleted
    where: duplum_search_result_bool_exp!
  ): duplum_search_result_mutation_response

  # delete single row from the table: "duplum_search_result"
  delete_duplum_search_result_by_pk(id: bigint!): duplum_search_result

  # delete data from the table: "error_log"
  delete_error_log(
    # filter the rows which have to be deleted
    where: error_log_bool_exp!
  ): error_log_mutation_response

  # delete single row from the table: "error_log"
  delete_error_log_by_pk(id: bigint!): error_log

  # delete data from the table: "export_format"
  delete_export_format(
    # filter the rows which have to be deleted
    where: export_format_bool_exp!
  ): export_format_mutation_response

  # delete single row from the table: "export_format"
  delete_export_format_by_pk(mtid: bigint!): export_format

  # delete data from the table: "export_request"
  delete_export_request(
    # filter the rows which have to be deleted
    where: export_request_bool_exp!
  ): export_request_mutation_response

  # delete single row from the table: "export_request"
  delete_export_request_by_pk(mtid: bigint!): export_request

  # delete data from the table: "forum"
  delete_forum(
    # filter the rows which have to be deleted
    where: forum_bool_exp!
  ): forum_mutation_response

  # delete single row from the table: "forum"
  delete_forum_by_pk(mtid: bigint!): forum

  # delete data from the table: "funding"
  delete_funding(
    # filter the rows which have to be deleted
    where: funding_bool_exp!
  ): funding_mutation_response

  # delete single row from the table: "funding"
  delete_funding_by_pk(mtid: bigint!): funding

  # delete data from the table: "import_alias"
  delete_import_alias(
    # filter the rows which have to be deleted
    where: import_alias_bool_exp!
  ): import_alias_mutation_response

  # delete single row from the table: "import_alias"
  delete_import_alias_by_pk(mtid: bigint!): import_alias

  # delete data from the table: "import_format"
  delete_import_format(
    # filter the rows which have to be deleted
    where: import_format_bool_exp!
  ): import_format_mutation_response

  # delete single row from the table: "import_format"
  delete_import_format_by_pk(mtid: bigint!): import_format

  # delete data from the table: "import_log"
  delete_import_log(
    # filter the rows which have to be deleted
    where: import_log_bool_exp!
  ): import_log_mutation_response

  # delete single row from the table: "import_log"
  delete_import_log_by_pk(id: bigint!): import_log

  # delete data from the table: "import_request"
  delete_import_request(
    # filter the rows which have to be deleted
    where: import_request_bool_exp!
  ): import_request_mutation_response

  # delete single row from the table: "import_request"
  delete_import_request_by_pk(mtid: bigint!): import_request

  # delete data from the table: "import_stat"
  delete_import_stat(
    # filter the rows which have to be deleted
    where: import_stat_bool_exp!
  ): import_stat_mutation_response

  # delete single row from the table: "import_stat"
  delete_import_stat_by_pk(mtid: bigint!): import_stat

  # delete data from the table: "import_stat_import_error_details"
  delete_import_stat_import_error_details(
    # filter the rows which have to be deleted
    where: import_stat_import_error_details_bool_exp!
  ): import_stat_import_error_details_mutation_response

  # delete data from the table: "import_stat_wos_ids"
  delete_import_stat_wos_ids(
    # filter the rows which have to be deleted
    where: import_stat_wos_ids_bool_exp!
  ): import_stat_wos_ids_mutation_response

  # delete data from the table: "institute_type"
  delete_institute_type(
    # filter the rows which have to be deleted
    where: institute_type_bool_exp!
  ): institute_type_mutation_response

  # delete single row from the table: "institute_type"
  delete_institute_type_by_pk(mtid: bigint!): institute_type

  # delete data from the table: "journal_successors"
  delete_journal_successors(
    # filter the rows which have to be deleted
    where: journal_successors_bool_exp!
  ): journal_successors_mutation_response

  # delete data from the table: "keyword"
  delete_keyword(
    # filter the rows which have to be deleted
    where: keyword_bool_exp!
  ): keyword_mutation_response

  # delete single row from the table: "keyword"
  delete_keyword_by_pk(mtid: bigint!): keyword

  # delete data from the table: "language"
  delete_language(
    # filter the rows which have to be deleted
    where: language_bool_exp!
  ): language_mutation_response

  # delete single row from the table: "language"
  delete_language_by_pk(mtid: bigint!): language

  # delete data from the table: "localized_message"
  delete_localized_message(
    # filter the rows which have to be deleted
    where: localized_message_bool_exp!
  ): localized_message_mutation_response

  # delete single row from the table: "localized_message"
  delete_localized_message_by_pk(mtid: bigint!): localized_message

  # delete data from the table: "location"
  delete_location(
    # filter the rows which have to be deleted
    where: location_bool_exp!
  ): location_mutation_response

  # delete single row from the table: "location"
  delete_location_by_pk(mtid: bigint!): location

  # delete data from the table: "lock_list"
  delete_lock_list(
    # filter the rows which have to be deleted
    where: lock_list_bool_exp!
  ): lock_list_mutation_response

  # delete single row from the table: "lock_list"
  delete_lock_list_by_pk(mtid: bigint!): lock_list

  # delete data from the table: "lock_list_delegated_admins"
  delete_lock_list_delegated_admins(
    # filter the rows which have to be deleted
    where: lock_list_delegated_admins_bool_exp!
  ): lock_list_delegated_admins_mutation_response

  # delete data from the table: "mab_discipline"
  delete_mab_discipline(
    # filter the rows which have to be deleted
    where: mab_discipline_bool_exp!
  ): mab_discipline_mutation_response

  # delete single row from the table: "mab_discipline"
  delete_mab_discipline_by_pk(mtid: bigint!): mab_discipline

  # delete data from the table: "mention"
  delete_mention(
    # filter the rows which have to be deleted
    where: mention_bool_exp!
  ): mention_mutation_response

  # delete single row from the table: "mention"
  delete_mention_by_pk(mtid: bigint!): mention

  # delete data from the table: "message"
  delete_message(
    # filter the rows which have to be deleted
    where: message_bool_exp!
  ): message_mutation_response

  # delete single row from the table: "message"
  delete_message_by_pk(mtid: bigint!): message

  # delete data from the table: "message_files"
  delete_message_files(
    # filter the rows which have to be deleted
    where: message_files_bool_exp!
  ): message_files_mutation_response

  # delete data from the table: "message_institutes"
  delete_message_institutes(
    # filter the rows which have to be deleted
    where: message_institutes_bool_exp!
  ): message_institutes_mutation_response

  # delete single row from the table: "message_institutes"
  delete_message_institutes_by_pk(forumMessageMtid: bigint!, institutesMtid: bigint!): message_institutes

  # delete data from the table: "message_mailboxes"
  delete_message_mailboxes(
    # filter the rows which have to be deleted
    where: message_mailboxes_bool_exp!
  ): message_mailboxes_mutation_response

  # delete data from the table: "message_parameter"
  delete_message_parameter(
    # filter the rows which have to be deleted
    where: message_parameter_bool_exp!
  ): message_parameter_mutation_response

  # delete single row from the table: "message_parameter"
  delete_message_parameter_by_pk(mtid: bigint!): message_parameter

  # delete data from the table: "message_recipients"
  delete_message_recipients(
    # filter the rows which have to be deleted
    where: message_recipients_bool_exp!
  ): message_recipients_mutation_response

  # delete data from the table: "message_sent"
  delete_message_sent(
    # filter the rows which have to be deleted
    where: message_sent_bool_exp!
  ): message_sent_mutation_response

  # delete single row from the table: "message_sent"
  delete_message_sent_by_pk(id: bigint!): message_sent

  # delete data from the table: "message_template"
  delete_message_template(
    # filter the rows which have to be deleted
    where: message_template_bool_exp!
  ): message_template_mutation_response

  # delete single row from the table: "message_template"
  delete_message_template_by_pk(mtid: bigint!): message_template

  # delete data from the table: "message_template_parameters"
  delete_message_template_parameters(
    # filter the rows which have to be deleted
    where: message_template_parameters_bool_exp!
  ): message_template_parameters_mutation_response

  # delete data from the table: "mycite_revision_entity"
  delete_mycite_revision_entity(
    # filter the rows which have to be deleted
    where: mycite_revision_entity_bool_exp!
  ): mycite_revision_entity_mutation_response

  # delete single row from the table: "mycite_revision_entity"
  delete_mycite_revision_entity_by_pk(id: Int!): mycite_revision_entity

  # delete data from the table: "named_list"
  delete_named_list(
    # filter the rows which have to be deleted
    where: named_list_bool_exp!
  ): named_list_mutation_response

  # delete single row from the table: "named_list"
  delete_named_list_by_pk(mtid: bigint!): named_list

  # delete data from the table: "not_duplums"
  delete_not_duplums(
    # filter the rows which have to be deleted
    where: not_duplums_bool_exp!
  ): not_duplums_mutation_response

  # delete single row from the table: "not_duplums"
  delete_not_duplums_by_pk(id: bigint!): not_duplums

  # delete data from the table: "not_duplums_not_duplum_ids"
  delete_not_duplums_not_duplum_ids(
    # filter the rows which have to be deleted
    where: not_duplums_not_duplum_ids_bool_exp!
  ): not_duplums_not_duplum_ids_mutation_response

  # delete data from the table: "organization"
  delete_organization(
    # filter the rows which have to be deleted
    where: organization_bool_exp!
  ): organization_mutation_response

  # delete single row from the table: "organization"
  delete_organization_by_pk(mtid: bigint!): organization

  # delete data from the table: "organization_identifier"
  delete_organization_identifier(
    # filter the rows which have to be deleted
    where: organization_identifier_bool_exp!
  ): organization_identifier_mutation_response

  # delete single row from the table: "organization_identifier"
  delete_organization_identifier_by_pk(mtid: bigint!): organization_identifier

  # delete data from the table: "organization_mab_disciplines"
  delete_organization_mab_disciplines(
    # filter the rows which have to be deleted
    where: organization_mab_disciplines_bool_exp!
  ): organization_mab_disciplines_mutation_response

  # delete data from the table: "periodical"
  delete_periodical(
    # filter the rows which have to be deleted
    where: periodical_bool_exp!
  ): periodical_mutation_response

  # delete single row from the table: "periodical"
  delete_periodical_by_pk(mtid: bigint!): periodical

  # delete data from the table: "periodical_issn"
  delete_periodical_issn(
    # filter the rows which have to be deleted
    where: periodical_issn_bool_exp!
  ): periodical_issn_mutation_response

  # delete single row from the table: "periodical_issn"
  delete_periodical_issn_by_pk(mtid: bigint!): periodical_issn

  # delete data from the table: "periodical_publishers"
  delete_periodical_publishers(
    # filter the rows which have to be deleted
    where: periodical_publishers_bool_exp!
  ): periodical_publishers_mutation_response

  # delete data from the table: "periodical_subjects_external"
  delete_periodical_subjects_external(
    # filter the rows which have to be deleted
    where: periodical_subjects_external_bool_exp!
  ): periodical_subjects_external_mutation_response

  # delete data from the table: "project"
  delete_project(
    # filter the rows which have to be deleted
    where: project_bool_exp!
  ): project_mutation_response

  # delete single row from the table: "project"
  delete_project_by_pk(mtid: bigint!): project

  # delete data from the table: "pub_fixer_log"
  delete_pub_fixer_log(
    # filter the rows which have to be deleted
    where: pub_fixer_log_bool_exp!
  ): pub_fixer_log_mutation_response

  # delete single row from the table: "pub_fixer_log"
  delete_pub_fixer_log_by_pk(id: bigint!): pub_fixer_log

  # delete data from the table: "publication"
  delete_publication(
    # filter the rows which have to be deleted
    where: publication_bool_exp!
  ): publication_mutation_response

  # delete data from the table: "publication_authors"
  delete_publication_authors(
    # filter the rows which have to be deleted
    where: publication_authors_bool_exp!
  ): publication_authors_mutation_response

  # delete single row from the table: "publication_authors"
  delete_publication_authors_by_pk(authorsMtid: bigint!, publicationMtid: bigint!): publication_authors

  # delete single row from the table: "publication"
  delete_publication_by_pk(mtid: bigint!): publication

  # delete data from the table: "publication_direct_institutes"
  delete_publication_direct_institutes(
    # filter the rows which have to be deleted
    where: publication_direct_institutes_bool_exp!
  ): publication_direct_institutes_mutation_response

  # delete single row from the table: "publication_direct_institutes"
  delete_publication_direct_institutes_by_pk(directInstitutesMtid: bigint!, publicationMtid: bigint!): publication_direct_institutes

  # delete data from the table: "publication_files"
  delete_publication_files(
    # filter the rows which have to be deleted
    where: publication_files_bool_exp!
  ): publication_files_mutation_response

  # delete data from the table: "publication_identifier"
  delete_publication_identifier(
    # filter the rows which have to be deleted
    where: publication_identifier_bool_exp!
  ): publication_identifier_mutation_response

  # delete single row from the table: "publication_identifier"
  delete_publication_identifier_by_pk(mtid: bigint!): publication_identifier

  # delete data from the table: "publication_institutes"
  delete_publication_institutes(
    # filter the rows which have to be deleted
    where: publication_institutes_bool_exp!
  ): publication_institutes_mutation_response

  # delete single row from the table: "publication_institutes"
  delete_publication_institutes_by_pk(institutesMtid: bigint!, publicationMtid: bigint!): publication_institutes

  # delete data from the table: "publication_keywords"
  delete_publication_keywords(
    # filter the rows which have to be deleted
    where: publication_keywords_bool_exp!
  ): publication_keywords_mutation_response

  # delete data from the table: "publication_languages"
  delete_publication_languages(
    # filter the rows which have to be deleted
    where: publication_languages_bool_exp!
  ): publication_languages_mutation_response

  # delete data from the table: "publication_old_org_authors"
  delete_publication_old_org_authors(
    # filter the rows which have to be deleted
    where: publication_old_org_authors_bool_exp!
  ): publication_old_org_authors_mutation_response

  # delete data from the table: "publication_owner_authors"
  delete_publication_owner_authors(
    # filter the rows which have to be deleted
    where: publication_owner_authors_bool_exp!
  ): publication_owner_authors_mutation_response

  # delete single row from the table: "publication_owner_authors"
  delete_publication_owner_authors_by_pk(ownerAuthorsMtid: bigint!, publicationMtid: bigint!): publication_owner_authors

  # delete data from the table: "publication_owner_institutes"
  delete_publication_owner_institutes(
    # filter the rows which have to be deleted
    where: publication_owner_institutes_bool_exp!
  ): publication_owner_institutes_mutation_response

  # delete single row from the table: "publication_owner_institutes"
  delete_publication_owner_institutes_by_pk(ownerInstitutesMtid: bigint!, publicationMtid: bigint!): publication_owner_institutes

  # delete data from the table: "publication_owners"
  delete_publication_owners(
    # filter the rows which have to be deleted
    where: publication_owners_bool_exp!
  ): publication_owners_mutation_response

  # delete data from the table: "publication_published_at"
  delete_publication_published_at(
    # filter the rows which have to be deleted
    where: publication_published_at_bool_exp!
  ): publication_published_at_mutation_response

  # delete data from the table: "publication_publishers"
  delete_publication_publishers(
    # filter the rows which have to be deleted
    where: publication_publishers_bool_exp!
  ): publication_publishers_mutation_response

  # delete data from the table: "publication_ratings"
  delete_publication_ratings(
    # filter the rows which have to be deleted
    where: publication_ratings_bool_exp!
  ): publication_ratings_mutation_response

  # delete data from the table: "publication_source_type"
  delete_publication_source_type(
    # filter the rows which have to be deleted
    where: publication_source_type_bool_exp!
  ): publication_source_type_mutation_response

  # delete single row from the table: "publication_source_type"
  delete_publication_source_type_by_pk(mtid: bigint!): publication_source_type

  # delete data from the table: "publication_subjects"
  delete_publication_subjects(
    # filter the rows which have to be deleted
    where: publication_subjects_bool_exp!
  ): publication_subjects_mutation_response

  # delete data from the table: "publication_type"
  delete_publication_type(
    # filter the rows which have to be deleted
    where: publication_type_bool_exp!
  ): publication_type_mutation_response

  # delete single row from the table: "publication_type"
  delete_publication_type_by_pk(mtid: bigint!): publication_type

  # delete data from the table: "publisher"
  delete_publisher(
    # filter the rows which have to be deleted
    where: publisher_bool_exp!
  ): publisher_mutation_response

  # delete single row from the table: "publisher"
  delete_publisher_by_pk(mtid: bigint!): publisher

  # delete data from the table: "publisher_cities"
  delete_publisher_cities(
    # filter the rows which have to be deleted
    where: publisher_cities_bool_exp!
  ): publisher_cities_mutation_response

  # delete data from the table: "query_info"
  delete_query_info(
    # filter the rows which have to be deleted
    where: query_info_bool_exp!
  ): query_info_mutation_response

  # delete single row from the table: "query_info"
  delete_query_info_by_pk(mtid: bigint!): query_info

  # delete data from the table: "queued_background_job"
  delete_queued_background_job(
    # filter the rows which have to be deleted
    where: queued_background_job_bool_exp!
  ): queued_background_job_mutation_response

  # delete single row from the table: "queued_background_job"
  delete_queued_background_job_by_pk(id: bigint!): queued_background_job

  # delete data from the table: "rating"
  delete_rating(
    # filter the rows which have to be deleted
    where: rating_bool_exp!
  ): rating_mutation_response

  # delete single row from the table: "rating"
  delete_rating_by_pk(mtid: bigint!): rating

  # delete data from the table: "rating_type"
  delete_rating_type(
    # filter the rows which have to be deleted
    where: rating_type_bool_exp!
  ): rating_type_mutation_response

  # delete single row from the table: "rating_type"
  delete_rating_type_by_pk(mtid: bigint!): rating_type

  # delete data from the table: "recalculate_institute_ownerships_request"
  delete_recalculate_institute_ownerships_request(
    # filter the rows which have to be deleted
    where: recalculate_institute_ownerships_request_bool_exp!
  ): recalculate_institute_ownerships_request_mutation_response

  # delete data from the table: "recalculate_institute_ownerships_request_affected_institutes"
  delete_recalculate_institute_ownerships_request_affected_institutes(
    # filter the rows which have to be deleted
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp!
  ): recalculate_institute_ownerships_request_affected_institutes_mutation_response

  # delete single row from the table: "recalculate_institute_ownerships_request_affected_institutes"
  delete_recalculate_institute_ownerships_request_affected_institutes_by_pk(affectedInstitutesMtid: bigint!, recalculateInstituteOwnershipsRequestMtid: bigint!): recalculate_institute_ownerships_request_affected_institutes

  # delete single row from the table: "recalculate_institute_ownerships_request"
  delete_recalculate_institute_ownerships_request_by_pk(mtid: bigint!): recalculate_institute_ownerships_request

  # delete data from the table: "reference"
  delete_reference(
    # filter the rows which have to be deleted
    where: reference_bool_exp!
  ): reference_mutation_response

  # delete single row from the table: "reference"
  delete_reference_by_pk(mtid: bigint!): reference

  # delete data from the table: "refresh_item"
  delete_refresh_item(
    # filter the rows which have to be deleted
    where: refresh_item_bool_exp!
  ): refresh_item_mutation_response

  # delete single row from the table: "refresh_item"
  delete_refresh_item_by_pk(id: String!): refresh_item

  # delete data from the table: "refresh_log"
  delete_refresh_log(
    # filter the rows which have to be deleted
    where: refresh_log_bool_exp!
  ): refresh_log_mutation_response

  # delete single row from the table: "refresh_log"
  delete_refresh_log_by_pk(id: bigint!): refresh_log

  # delete data from the table: "reorg"
  delete_reorg(
    # filter the rows which have to be deleted
    where: reorg_bool_exp!
  ): reorg_mutation_response

  # delete single row from the table: "reorg"
  delete_reorg_by_pk(mtid: bigint!): reorg

  # delete data from the table: "reorg_type"
  delete_reorg_type(
    # filter the rows which have to be deleted
    where: reorg_type_bool_exp!
  ): reorg_type_mutation_response

  # delete single row from the table: "reorg_type"
  delete_reorg_type_by_pk(mtid: bigint!): reorg_type

  # delete data from the table: "report"
  delete_report(
    # filter the rows which have to be deleted
    where: report_bool_exp!
  ): report_mutation_response

  # delete single row from the table: "report"
  delete_report_by_pk(mtid: bigint!): report

  # delete data from the table: "report_content"
  delete_report_content(
    # filter the rows which have to be deleted
    where: report_content_bool_exp!
  ): report_content_mutation_response

  # delete single row from the table: "report_content"
  delete_report_content_by_pk(mtid: bigint!): report_content

  # delete data from the table: "report_content_file_content"
  delete_report_content_file_content(
    # filter the rows which have to be deleted
    where: report_content_file_content_bool_exp!
  ): report_content_file_content_mutation_response

  # delete data from the table: "report_contents"
  delete_report_contents(
    # filter the rows which have to be deleted
    where: report_contents_bool_exp!
  ): report_contents_mutation_response

  # delete data from the table: "report_parameter"
  delete_report_parameter(
    # filter the rows which have to be deleted
    where: report_parameter_bool_exp!
  ): report_parameter_mutation_response

  # delete single row from the table: "report_parameter"
  delete_report_parameter_by_pk(mtid: bigint!): report_parameter

  # delete data from the table: "report_request"
  delete_report_request(
    # filter the rows which have to be deleted
    where: report_request_bool_exp!
  ): report_request_mutation_response

  # delete single row from the table: "report_request"
  delete_report_request_by_pk(mtid: bigint!): report_request

  # delete data from the table: "report_request_queries"
  delete_report_request_queries(
    # filter the rows which have to be deleted
    where: report_request_queries_bool_exp!
  ): report_request_queries_mutation_response

  # delete data from the table: "report_template"
  delete_report_template(
    # filter the rows which have to be deleted
    where: report_template_bool_exp!
  ): report_template_mutation_response

  # delete single row from the table: "report_template"
  delete_report_template_by_pk(mtid: bigint!): report_template

  # delete data from the table: "report_template_default_queries"
  delete_report_template_default_queries(
    # filter the rows which have to be deleted
    where: report_template_default_queries_bool_exp!
  ): report_template_default_queries_mutation_response

  # delete data from the table: "report_template_language_files"
  delete_report_template_language_files(
    # filter the rows which have to be deleted
    where: report_template_language_files_bool_exp!
  ): report_template_language_files_mutation_response

  # delete data from the table: "report_template_parameter_select"
  delete_report_template_parameter_select(
    # filter the rows which have to be deleted
    where: report_template_parameter_select_bool_exp!
  ): report_template_parameter_select_mutation_response

  # delete single row from the table: "report_template_parameter_select"
  delete_report_template_parameter_select_by_pk(mtid: bigint!): report_template_parameter_select

  # delete data from the table: "report_xml"
  delete_report_xml(
    # filter the rows which have to be deleted
    where: report_xml_bool_exp!
  ): report_xml_mutation_response

  # delete single row from the table: "report_xml"
  delete_report_xml_by_pk(mtid: bigint!): report_xml

  # delete data from the table: "ris_import_error_detail"
  delete_ris_import_error_detail(
    # filter the rows which have to be deleted
    where: ris_import_error_detail_bool_exp!
  ): ris_import_error_detail_mutation_response

  # delete single row from the table: "ris_import_error_detail"
  delete_ris_import_error_detail_by_pk(mtid: bigint!): ris_import_error_detail

  # delete data from the table: "series_volume"
  delete_series_volume(
    # filter the rows which have to be deleted
    where: series_volume_bool_exp!
  ): series_volume_mutation_response

  # delete single row from the table: "series_volume"
  delete_series_volume_by_pk(mtid: bigint!): series_volume

  # delete data from the table: "shib_id_provider"
  delete_shib_id_provider(
    # filter the rows which have to be deleted
    where: shib_id_provider_bool_exp!
  ): shib_id_provider_mutation_response

  # delete single row from the table: "shib_id_provider"
  delete_shib_id_provider_by_pk(mtid: bigint!): shib_id_provider

  # delete data from the table: "smart_query"
  delete_smart_query(
    # filter the rows which have to be deleted
    where: smart_query_bool_exp!
  ): smart_query_mutation_response

  # delete single row from the table: "smart_query"
  delete_smart_query_by_pk(mtid: bigint!): smart_query

  # delete data from the table: "smart_query_cond"
  delete_smart_query_cond(
    # filter the rows which have to be deleted
    where: smart_query_cond_bool_exp!
  ): smart_query_cond_mutation_response

  # delete single row from the table: "smart_query_cond"
  delete_smart_query_cond_by_pk(mtid: bigint!): smart_query_cond

  # delete data from the table: "smart_query_group"
  delete_smart_query_group(
    # filter the rows which have to be deleted
    where: smart_query_group_bool_exp!
  ): smart_query_group_mutation_response

  # delete single row from the table: "smart_query_group"
  delete_smart_query_group_by_pk(id: bigint!): smart_query_group

  # delete data from the table: "smart_query_sort"
  delete_smart_query_sort(
    # filter the rows which have to be deleted
    where: smart_query_sort_bool_exp!
  ): smart_query_sort_mutation_response

  # delete single row from the table: "smart_query_sort"
  delete_smart_query_sort_by_pk(mtid: bigint!): smart_query_sort

  # delete data from the table: "snippet_cache"
  delete_snippet_cache(
    # filter the rows which have to be deleted
    where: snippet_cache_bool_exp!
  ): snippet_cache_mutation_response

  # delete single row from the table: "snippet_cache"
  delete_snippet_cache_by_pk(mtid: bigint!, otype: String!): snippet_cache

  # delete data from the table: "snippet_cache_status"
  delete_snippet_cache_status(
    # filter the rows which have to be deleted
    where: snippet_cache_status_bool_exp!
  ): snippet_cache_status_mutation_response

  # delete single row from the table: "snippet_cache_status"
  delete_snippet_cache_status_by_pk(mtid: bigint!, otype: String!): snippet_cache_status

  # delete data from the table: "source"
  delete_source(
    # filter the rows which have to be deleted
    where: source_bool_exp!
  ): source_mutation_response

  # delete data from the table: "source_allowed_institutes"
  delete_source_allowed_institutes(
    # filter the rows which have to be deleted
    where: source_allowed_institutes_bool_exp!
  ): source_allowed_institutes_mutation_response

  # delete single row from the table: "source"
  delete_source_by_pk(mtid: bigint!): source

  # delete data from the table: "sub_type"
  delete_sub_type(
    # filter the rows which have to be deleted
    where: sub_type_bool_exp!
  ): sub_type_mutation_response

  # delete single row from the table: "sub_type"
  delete_sub_type_by_pk(mtid: bigint!): sub_type

  # delete data from the table: "ticket"
  delete_ticket(
    # filter the rows which have to be deleted
    where: ticket_bool_exp!
  ): ticket_mutation_response

  # delete data from the table: "ticket_authors"
  delete_ticket_authors(
    # filter the rows which have to be deleted
    where: ticket_authors_bool_exp!
  ): ticket_authors_mutation_response

  # delete single row from the table: "ticket_authors"
  delete_ticket_authors_by_pk(authorsMtid: bigint!, ticketMtid: bigint!): ticket_authors

  # delete single row from the table: "ticket"
  delete_ticket_by_pk(mtid: bigint!): ticket

  # delete data from the table: "ticket_institutes"
  delete_ticket_institutes(
    # filter the rows which have to be deleted
    where: ticket_institutes_bool_exp!
  ): ticket_institutes_mutation_response

  # delete single row from the table: "ticket_institutes"
  delete_ticket_institutes_by_pk(institutesMtid: bigint!, ticketMtid: bigint!): ticket_institutes

  # delete data from the table: "uploaded_file"
  delete_uploaded_file(
    # filter the rows which have to be deleted
    where: uploaded_file_bool_exp!
  ): uploaded_file_mutation_response

  # delete single row from the table: "uploaded_file"
  delete_uploaded_file_by_pk(mtid: bigint!): uploaded_file

  # delete data from the table: "uploaded_file_file_content"
  delete_uploaded_file_file_content(
    # filter the rows which have to be deleted
    where: uploaded_file_file_content_bool_exp!
  ): uploaded_file_file_content_mutation_response

  # delete data from the table: "usage_log"
  delete_usage_log(
    # filter the rows which have to be deleted
    where: usage_log_bool_exp!
  ): usage_log_mutation_response

  # delete single row from the table: "usage_log"
  delete_usage_log_by_pk(id: bigint!): usage_log

  # delete data from the table: "user_notification_time"
  delete_user_notification_time(
    # filter the rows which have to be deleted
    where: user_notification_time_bool_exp!
  ): user_notification_time_mutation_response

  # delete single row from the table: "user_notification_time"
  delete_user_notification_time_by_pk(mtid: bigint!): user_notification_time

  # delete data from the table: "user_preferences"
  delete_user_preferences(
    # filter the rows which have to be deleted
    where: user_preferences_bool_exp!
  ): user_preferences_mutation_response

  # delete single row from the table: "user_preferences"
  delete_user_preferences_by_pk(mtid: bigint!): user_preferences

  # delete data from the table: "users"
  delete_users(
    # filter the rows which have to be deleted
    where: users_bool_exp!
  ): users_mutation_response

  # delete data from the table: "users_assistants"
  delete_users_assistants(
    # filter the rows which have to be deleted
    where: users_assistants_bool_exp!
  ): users_assistants_mutation_response

  # delete single row from the table: "users"
  delete_users_by_pk(mtid: bigint!): users

  # delete data from the table: "users_disciplines"
  delete_users_disciplines(
    # filter the rows which have to be deleted
    where: users_disciplines_bool_exp!
  ): users_disciplines_mutation_response

  # delete data from the table: "variable"
  delete_variable(
    # filter the rows which have to be deleted
    where: variable_bool_exp!
  ): variable_mutation_response

  # delete single row from the table: "variable"
  delete_variable_by_pk(mtid: bigint!): variable

  # delete data from the table: "workflow"
  delete_workflow(
    # filter the rows which have to be deleted
    where: workflow_bool_exp!
  ): workflow_mutation_response

  # delete single row from the table: "workflow"
  delete_workflow_by_pk(mtid: bigint!): workflow

  # delete data from the table: "workflow_status"
  delete_workflow_status(
    # filter the rows which have to be deleted
    where: workflow_status_bool_exp!
  ): workflow_status_mutation_response

  # delete single row from the table: "workflow_status"
  delete_workflow_status_by_pk(mtid: bigint!): workflow_status

  # delete data from the table: "workflow_step"
  delete_workflow_step(
    # filter the rows which have to be deleted
    where: workflow_step_bool_exp!
  ): workflow_step_mutation_response

  # delete single row from the table: "workflow_step"
  delete_workflow_step_by_pk(mtid: bigint!): workflow_step

  # delete data from the table: "workflow_step_status"
  delete_workflow_step_status(
    # filter the rows which have to be deleted
    where: workflow_step_status_bool_exp!
  ): workflow_step_status_mutation_response

  # delete single row from the table: "workflow_step_status"
  delete_workflow_step_status_by_pk(mtid: bigint!): workflow_step_status

  # insert data into the table: "achievement_property"
  insert_achievement_property(
    # the rows to be inserted
    objects: [achievement_property_insert_input!]!

    # on conflict condition
    on_conflict: achievement_property_on_conflict
  ): achievement_property_mutation_response

  # insert data into the table: "achievement_property_listing"
  insert_achievement_property_listing(
    # the rows to be inserted
    objects: [achievement_property_listing_insert_input!]!

    # on conflict condition
    on_conflict: achievement_property_listing_on_conflict
  ): achievement_property_listing_mutation_response

  # insert a single row into the table: "achievement_property_listing"
  insert_achievement_property_listing_one(
    # the row to be inserted
    object: achievement_property_listing_insert_input!

    # on conflict condition
    on_conflict: achievement_property_listing_on_conflict
  ): achievement_property_listing

  # insert a single row into the table: "achievement_property"
  insert_achievement_property_one(
    # the row to be inserted
    object: achievement_property_insert_input!

    # on conflict condition
    on_conflict: achievement_property_on_conflict
  ): achievement_property

  # insert data into the table: "achievement_property_value"
  insert_achievement_property_value(
    # the rows to be inserted
    objects: [achievement_property_value_insert_input!]!

    # on conflict condition
    on_conflict: achievement_property_value_on_conflict
  ): achievement_property_value_mutation_response

  # insert a single row into the table: "achievement_property_value"
  insert_achievement_property_value_one(
    # the row to be inserted
    object: achievement_property_value_insert_input!

    # on conflict condition
    on_conflict: achievement_property_value_on_conflict
  ): achievement_property_value

  # insert data into the table: "activity_log"
  insert_activity_log(
    # the rows to be inserted
    objects: [activity_log_insert_input!]!

    # on conflict condition
    on_conflict: activity_log_on_conflict
  ): activity_log_mutation_response

  # insert a single row into the table: "activity_log"
  insert_activity_log_one(
    # the row to be inserted
    object: activity_log_insert_input!

    # on conflict condition
    on_conflict: activity_log_on_conflict
  ): activity_log

  # insert data into the table: "address"
  insert_address(
    # the rows to be inserted
    objects: [address_insert_input!]!

    # on conflict condition
    on_conflict: address_on_conflict
  ): address_mutation_response

  # insert a single row into the table: "address"
  insert_address_one(
    # the row to be inserted
    object: address_insert_input!

    # on conflict condition
    on_conflict: address_on_conflict
  ): address

  # insert data into the table: "admin_role"
  insert_admin_role(
    # the rows to be inserted
    objects: [admin_role_insert_input!]!

    # on conflict condition
    on_conflict: admin_role_on_conflict
  ): admin_role_mutation_response

  # insert a single row into the table: "admin_role"
  insert_admin_role_one(
    # the row to be inserted
    object: admin_role_insert_input!

    # on conflict condition
    on_conflict: admin_role_on_conflict
  ): admin_role

  # insert data into the table: "affiliation"
  insert_affiliation(
    # the rows to be inserted
    objects: [affiliation_insert_input!]!

    # on conflict condition
    on_conflict: affiliation_on_conflict
  ): affiliation_mutation_response

  # insert a single row into the table: "affiliation"
  insert_affiliation_one(
    # the row to be inserted
    object: affiliation_insert_input!

    # on conflict condition
    on_conflict: affiliation_on_conflict
  ): affiliation

  # insert data into the table: "appearance"
  insert_appearance(
    # the rows to be inserted
    objects: [appearance_insert_input!]!

    # on conflict condition
    on_conflict: appearance_on_conflict
  ): appearance_mutation_response

  # insert a single row into the table: "appearance"
  insert_appearance_one(
    # the row to be inserted
    object: appearance_insert_input!

    # on conflict condition
    on_conflict: appearance_on_conflict
  ): appearance

  # insert data into the table: "authentication_failure"
  insert_authentication_failure(
    # the rows to be inserted
    objects: [authentication_failure_insert_input!]!

    # on conflict condition
    on_conflict: authentication_failure_on_conflict
  ): authentication_failure_mutation_response

  # insert a single row into the table: "authentication_failure"
  insert_authentication_failure_one(
    # the row to be inserted
    object: authentication_failure_insert_input!

    # on conflict condition
    on_conflict: authentication_failure_on_conflict
  ): authentication_failure

  # insert data into the table: "author_identifier"
  insert_author_identifier(
    # the rows to be inserted
    objects: [author_identifier_insert_input!]!

    # on conflict condition
    on_conflict: author_identifier_on_conflict
  ): author_identifier_mutation_response

  # insert a single row into the table: "author_identifier"
  insert_author_identifier_one(
    # the row to be inserted
    object: author_identifier_insert_input!

    # on conflict condition
    on_conflict: author_identifier_on_conflict
  ): author_identifier

  # insert data into the table: "author_name"
  insert_author_name(
    # the rows to be inserted
    objects: [author_name_insert_input!]!

    # on conflict condition
    on_conflict: author_name_on_conflict
  ): author_name_mutation_response

  # insert a single row into the table: "author_name"
  insert_author_name_one(
    # the row to be inserted
    object: author_name_insert_input!

    # on conflict condition
    on_conflict: author_name_on_conflict
  ): author_name

  # insert data into the table: "authorship"
  insert_authorship(
    # the rows to be inserted
    objects: [authorship_insert_input!]!

    # on conflict condition
    on_conflict: authorship_on_conflict
  ): authorship_mutation_response

  # insert a single row into the table: "authorship"
  insert_authorship_one(
    # the row to be inserted
    object: authorship_insert_input!

    # on conflict condition
    on_conflict: authorship_on_conflict
  ): authorship

  # insert data into the table: "authorship_organizations"
  insert_authorship_organizations(
    # the rows to be inserted
    objects: [authorship_organizations_insert_input!]!
  ): authorship_organizations_mutation_response

  # insert a single row into the table: "authorship_organizations"
  insert_authorship_organizations_one(
    # the row to be inserted
    object: authorship_organizations_insert_input!
  ): authorship_organizations

  # insert data into the table: "authorship_type"
  insert_authorship_type(
    # the rows to be inserted
    objects: [authorship_type_insert_input!]!

    # on conflict condition
    on_conflict: authorship_type_on_conflict
  ): authorship_type_mutation_response

  # insert a single row into the table: "authorship_type"
  insert_authorship_type_one(
    # the row to be inserted
    object: authorship_type_insert_input!

    # on conflict condition
    on_conflict: authorship_type_on_conflict
  ): authorship_type

  # insert data into the table: "authorship_type_sub_types_allowed"
  insert_authorship_type_sub_types_allowed(
    # the rows to be inserted
    objects: [authorship_type_sub_types_allowed_insert_input!]!
  ): authorship_type_sub_types_allowed_mutation_response

  # insert a single row into the table: "authorship_type_sub_types_allowed"
  insert_authorship_type_sub_types_allowed_one(
    # the row to be inserted
    object: authorship_type_sub_types_allowed_insert_input!
  ): authorship_type_sub_types_allowed

  # insert data into the table: "authorship_type_types_allowed"
  insert_authorship_type_types_allowed(
    # the rows to be inserted
    objects: [authorship_type_types_allowed_insert_input!]!
  ): authorship_type_types_allowed_mutation_response

  # insert a single row into the table: "authorship_type_types_allowed"
  insert_authorship_type_types_allowed_one(
    # the row to be inserted
    object: authorship_type_types_allowed_insert_input!
  ): authorship_type_types_allowed

  # insert data into the table: "binary_content"
  insert_binary_content(
    # the rows to be inserted
    objects: [binary_content_insert_input!]!

    # on conflict condition
    on_conflict: binary_content_on_conflict
  ): binary_content_mutation_response

  # insert a single row into the table: "binary_content"
  insert_binary_content_one(
    # the row to be inserted
    object: binary_content_insert_input!

    # on conflict condition
    on_conflict: binary_content_on_conflict
  ): binary_content

  # insert data into the table: "bulk_duplum_merge_request"
  insert_bulk_duplum_merge_request(
    # the rows to be inserted
    objects: [bulk_duplum_merge_request_insert_input!]!

    # on conflict condition
    on_conflict: bulk_duplum_merge_request_on_conflict
  ): bulk_duplum_merge_request_mutation_response

  # insert a single row into the table: "bulk_duplum_merge_request"
  insert_bulk_duplum_merge_request_one(
    # the row to be inserted
    object: bulk_duplum_merge_request_insert_input!

    # on conflict condition
    on_conflict: bulk_duplum_merge_request_on_conflict
  ): bulk_duplum_merge_request

  # insert data into the table: "category"
  insert_category(
    # the rows to be inserted
    objects: [category_insert_input!]!

    # on conflict condition
    on_conflict: category_on_conflict
  ): category_mutation_response

  # insert a single row into the table: "category"
  insert_category_one(
    # the row to be inserted
    object: category_insert_input!

    # on conflict condition
    on_conflict: category_on_conflict
  ): category

  # insert data into the table: "category_sub_types_allowed"
  insert_category_sub_types_allowed(
    # the rows to be inserted
    objects: [category_sub_types_allowed_insert_input!]!
  ): category_sub_types_allowed_mutation_response

  # insert a single row into the table: "category_sub_types_allowed"
  insert_category_sub_types_allowed_one(
    # the row to be inserted
    object: category_sub_types_allowed_insert_input!
  ): category_sub_types_allowed

  # insert data into the table: "category_types_allowed"
  insert_category_types_allowed(
    # the rows to be inserted
    objects: [category_types_allowed_insert_input!]!
  ): category_types_allowed_mutation_response

  # insert a single row into the table: "category_types_allowed"
  insert_category_types_allowed_one(
    # the row to be inserted
    object: category_types_allowed_insert_input!
  ): category_types_allowed

  # insert data into the table: "citation"
  insert_citation(
    # the rows to be inserted
    objects: [citation_insert_input!]!

    # on conflict condition
    on_conflict: citation_on_conflict
  ): citation_mutation_response

  # insert a single row into the table: "citation"
  insert_citation_one(
    # the row to be inserted
    object: citation_insert_input!

    # on conflict condition
    on_conflict: citation_on_conflict
  ): citation

  # insert data into the table: "classification"
  insert_classification(
    # the rows to be inserted
    objects: [classification_insert_input!]!

    # on conflict condition
    on_conflict: classification_on_conflict
  ): classification_mutation_response

  # insert data into the table: "classification_external"
  insert_classification_external(
    # the rows to be inserted
    objects: [classification_external_insert_input!]!

    # on conflict condition
    on_conflict: classification_external_on_conflict
  ): classification_external_mutation_response

  # insert data into the table: "classification_external_mapped_to"
  insert_classification_external_mapped_to(
    # the rows to be inserted
    objects: [classification_external_mapped_to_insert_input!]!
  ): classification_external_mapped_to_mutation_response

  # insert a single row into the table: "classification_external_mapped_to"
  insert_classification_external_mapped_to_one(
    # the row to be inserted
    object: classification_external_mapped_to_insert_input!
  ): classification_external_mapped_to

  # insert a single row into the table: "classification_external"
  insert_classification_external_one(
    # the row to be inserted
    object: classification_external_insert_input!

    # on conflict condition
    on_conflict: classification_external_on_conflict
  ): classification_external

  # insert a single row into the table: "classification"
  insert_classification_one(
    # the row to be inserted
    object: classification_insert_input!

    # on conflict condition
    on_conflict: classification_on_conflict
  ): classification

  # insert data into the table: "classification_parents"
  insert_classification_parents(
    # the rows to be inserted
    objects: [classification_parents_insert_input!]!
  ): classification_parents_mutation_response

  # insert a single row into the table: "classification_parents"
  insert_classification_parents_one(
    # the row to be inserted
    object: classification_parents_insert_input!
  ): classification_parents

  # insert data into the table: "classification_tree"
  insert_classification_tree(
    # the rows to be inserted
    objects: [classification_tree_insert_input!]!

    # on conflict condition
    on_conflict: classification_tree_on_conflict
  ): classification_tree_mutation_response

  # insert a single row into the table: "classification_tree"
  insert_classification_tree_one(
    # the row to be inserted
    object: classification_tree_insert_input!

    # on conflict condition
    on_conflict: classification_tree_on_conflict
  ): classification_tree

  # insert data into the table: "conference"
  insert_conference(
    # the rows to be inserted
    objects: [conference_insert_input!]!

    # on conflict condition
    on_conflict: conference_on_conflict
  ): conference_mutation_response

  # insert data into the table: "conference_location"
  insert_conference_location(
    # the rows to be inserted
    objects: [conference_location_insert_input!]!
  ): conference_location_mutation_response

  # insert a single row into the table: "conference_location"
  insert_conference_location_one(
    # the row to be inserted
    object: conference_location_insert_input!
  ): conference_location

  # insert a single row into the table: "conference"
  insert_conference_one(
    # the row to be inserted
    object: conference_insert_input!

    # on conflict condition
    on_conflict: conference_on_conflict
  ): conference

  # insert data into the table: "conference_organizers"
  insert_conference_organizers(
    # the rows to be inserted
    objects: [conference_organizers_insert_input!]!
  ): conference_organizers_mutation_response

  # insert a single row into the table: "conference_organizers"
  insert_conference_organizers_one(
    # the row to be inserted
    object: conference_organizers_insert_input!
  ): conference_organizers

  # insert data into the table: "cron_job"
  insert_cron_job(
    # the rows to be inserted
    objects: [cron_job_insert_input!]!

    # on conflict condition
    on_conflict: cron_job_on_conflict
  ): cron_job_mutation_response

  # insert a single row into the table: "cron_job"
  insert_cron_job_one(
    # the row to be inserted
    object: cron_job_insert_input!

    # on conflict condition
    on_conflict: cron_job_on_conflict
  ): cron_job

  # insert data into the table: "cron_job_run_request"
  insert_cron_job_run_request(
    # the rows to be inserted
    objects: [cron_job_run_request_insert_input!]!

    # on conflict condition
    on_conflict: cron_job_run_request_on_conflict
  ): cron_job_run_request_mutation_response

  # insert a single row into the table: "cron_job_run_request"
  insert_cron_job_run_request_one(
    # the row to be inserted
    object: cron_job_run_request_insert_input!

    # on conflict condition
    on_conflict: cron_job_run_request_on_conflict
  ): cron_job_run_request

  # insert data into the table: "degree"
  insert_degree(
    # the rows to be inserted
    objects: [degree_insert_input!]!

    # on conflict condition
    on_conflict: degree_on_conflict
  ): degree_mutation_response

  # insert data into the table: "degree_holder"
  insert_degree_holder(
    # the rows to be inserted
    objects: [degree_holder_insert_input!]!

    # on conflict condition
    on_conflict: degree_holder_on_conflict
  ): degree_holder_mutation_response

  # insert a single row into the table: "degree_holder"
  insert_degree_holder_one(
    # the row to be inserted
    object: degree_holder_insert_input!

    # on conflict condition
    on_conflict: degree_holder_on_conflict
  ): degree_holder

  # insert a single row into the table: "degree"
  insert_degree_one(
    # the row to be inserted
    object: degree_insert_input!

    # on conflict condition
    on_conflict: degree_on_conflict
  ): degree

  # insert data into the table: "discipline"
  insert_discipline(
    # the rows to be inserted
    objects: [discipline_insert_input!]!

    # on conflict condition
    on_conflict: discipline_on_conflict
  ): discipline_mutation_response

  # insert a single row into the table: "discipline"
  insert_discipline_one(
    # the row to be inserted
    object: discipline_insert_input!

    # on conflict condition
    on_conflict: discipline_on_conflict
  ): discipline

  # insert data into the table: "division_containment"
  insert_division_containment(
    # the rows to be inserted
    objects: [division_containment_insert_input!]!

    # on conflict condition
    on_conflict: division_containment_on_conflict
  ): division_containment_mutation_response

  # insert a single row into the table: "division_containment"
  insert_division_containment_one(
    # the row to be inserted
    object: division_containment_insert_input!

    # on conflict condition
    on_conflict: division_containment_on_conflict
  ): division_containment

  # insert data into the table: "duplum_desc"
  insert_duplum_desc(
    # the rows to be inserted
    objects: [duplum_desc_insert_input!]!

    # on conflict condition
    on_conflict: duplum_desc_on_conflict
  ): duplum_desc_mutation_response

  # insert data into the table: "duplum_desc_book_chapters_merged"
  insert_duplum_desc_book_chapters_merged(
    # the rows to be inserted
    objects: [duplum_desc_book_chapters_merged_insert_input!]!
  ): duplum_desc_book_chapters_merged_mutation_response

  # insert a single row into the table: "duplum_desc_book_chapters_merged"
  insert_duplum_desc_book_chapters_merged_one(
    # the row to be inserted
    object: duplum_desc_book_chapters_merged_insert_input!
  ): duplum_desc_book_chapters_merged

  # insert data into the table: "duplum_desc_citations_merged"
  insert_duplum_desc_citations_merged(
    # the rows to be inserted
    objects: [duplum_desc_citations_merged_insert_input!]!
  ): duplum_desc_citations_merged_mutation_response

  # insert a single row into the table: "duplum_desc_citations_merged"
  insert_duplum_desc_citations_merged_one(
    # the row to be inserted
    object: duplum_desc_citations_merged_insert_input!
  ): duplum_desc_citations_merged

  # insert a single row into the table: "duplum_desc"
  insert_duplum_desc_one(
    # the row to be inserted
    object: duplum_desc_insert_input!

    # on conflict condition
    on_conflict: duplum_desc_on_conflict
  ): duplum_desc

  # insert data into the table: "duplum_search_request"
  insert_duplum_search_request(
    # the rows to be inserted
    objects: [duplum_search_request_insert_input!]!

    # on conflict condition
    on_conflict: duplum_search_request_on_conflict
  ): duplum_search_request_mutation_response

  # insert a single row into the table: "duplum_search_request"
  insert_duplum_search_request_one(
    # the row to be inserted
    object: duplum_search_request_insert_input!

    # on conflict condition
    on_conflict: duplum_search_request_on_conflict
  ): duplum_search_request

  # insert data into the table: "duplum_search_result"
  insert_duplum_search_result(
    # the rows to be inserted
    objects: [duplum_search_result_insert_input!]!

    # on conflict condition
    on_conflict: duplum_search_result_on_conflict
  ): duplum_search_result_mutation_response

  # insert a single row into the table: "duplum_search_result"
  insert_duplum_search_result_one(
    # the row to be inserted
    object: duplum_search_result_insert_input!

    # on conflict condition
    on_conflict: duplum_search_result_on_conflict
  ): duplum_search_result

  # insert data into the table: "error_log"
  insert_error_log(
    # the rows to be inserted
    objects: [error_log_insert_input!]!

    # on conflict condition
    on_conflict: error_log_on_conflict
  ): error_log_mutation_response

  # insert a single row into the table: "error_log"
  insert_error_log_one(
    # the row to be inserted
    object: error_log_insert_input!

    # on conflict condition
    on_conflict: error_log_on_conflict
  ): error_log

  # insert data into the table: "export_format"
  insert_export_format(
    # the rows to be inserted
    objects: [export_format_insert_input!]!

    # on conflict condition
    on_conflict: export_format_on_conflict
  ): export_format_mutation_response

  # insert a single row into the table: "export_format"
  insert_export_format_one(
    # the row to be inserted
    object: export_format_insert_input!

    # on conflict condition
    on_conflict: export_format_on_conflict
  ): export_format

  # insert data into the table: "export_request"
  insert_export_request(
    # the rows to be inserted
    objects: [export_request_insert_input!]!

    # on conflict condition
    on_conflict: export_request_on_conflict
  ): export_request_mutation_response

  # insert a single row into the table: "export_request"
  insert_export_request_one(
    # the row to be inserted
    object: export_request_insert_input!

    # on conflict condition
    on_conflict: export_request_on_conflict
  ): export_request

  # insert data into the table: "forum"
  insert_forum(
    # the rows to be inserted
    objects: [forum_insert_input!]!

    # on conflict condition
    on_conflict: forum_on_conflict
  ): forum_mutation_response

  # insert a single row into the table: "forum"
  insert_forum_one(
    # the row to be inserted
    object: forum_insert_input!

    # on conflict condition
    on_conflict: forum_on_conflict
  ): forum

  # insert data into the table: "funding"
  insert_funding(
    # the rows to be inserted
    objects: [funding_insert_input!]!

    # on conflict condition
    on_conflict: funding_on_conflict
  ): funding_mutation_response

  # insert a single row into the table: "funding"
  insert_funding_one(
    # the row to be inserted
    object: funding_insert_input!

    # on conflict condition
    on_conflict: funding_on_conflict
  ): funding

  # insert data into the table: "import_alias"
  insert_import_alias(
    # the rows to be inserted
    objects: [import_alias_insert_input!]!

    # on conflict condition
    on_conflict: import_alias_on_conflict
  ): import_alias_mutation_response

  # insert a single row into the table: "import_alias"
  insert_import_alias_one(
    # the row to be inserted
    object: import_alias_insert_input!

    # on conflict condition
    on_conflict: import_alias_on_conflict
  ): import_alias

  # insert data into the table: "import_format"
  insert_import_format(
    # the rows to be inserted
    objects: [import_format_insert_input!]!

    # on conflict condition
    on_conflict: import_format_on_conflict
  ): import_format_mutation_response

  # insert a single row into the table: "import_format"
  insert_import_format_one(
    # the row to be inserted
    object: import_format_insert_input!

    # on conflict condition
    on_conflict: import_format_on_conflict
  ): import_format

  # insert data into the table: "import_log"
  insert_import_log(
    # the rows to be inserted
    objects: [import_log_insert_input!]!

    # on conflict condition
    on_conflict: import_log_on_conflict
  ): import_log_mutation_response

  # insert a single row into the table: "import_log"
  insert_import_log_one(
    # the row to be inserted
    object: import_log_insert_input!

    # on conflict condition
    on_conflict: import_log_on_conflict
  ): import_log

  # insert data into the table: "import_request"
  insert_import_request(
    # the rows to be inserted
    objects: [import_request_insert_input!]!

    # on conflict condition
    on_conflict: import_request_on_conflict
  ): import_request_mutation_response

  # insert a single row into the table: "import_request"
  insert_import_request_one(
    # the row to be inserted
    object: import_request_insert_input!

    # on conflict condition
    on_conflict: import_request_on_conflict
  ): import_request

  # insert data into the table: "import_stat"
  insert_import_stat(
    # the rows to be inserted
    objects: [import_stat_insert_input!]!

    # on conflict condition
    on_conflict: import_stat_on_conflict
  ): import_stat_mutation_response

  # insert data into the table: "import_stat_import_error_details"
  insert_import_stat_import_error_details(
    # the rows to be inserted
    objects: [import_stat_import_error_details_insert_input!]!

    # on conflict condition
    on_conflict: import_stat_import_error_details_on_conflict
  ): import_stat_import_error_details_mutation_response

  # insert a single row into the table: "import_stat_import_error_details"
  insert_import_stat_import_error_details_one(
    # the row to be inserted
    object: import_stat_import_error_details_insert_input!

    # on conflict condition
    on_conflict: import_stat_import_error_details_on_conflict
  ): import_stat_import_error_details

  # insert a single row into the table: "import_stat"
  insert_import_stat_one(
    # the row to be inserted
    object: import_stat_insert_input!

    # on conflict condition
    on_conflict: import_stat_on_conflict
  ): import_stat

  # insert data into the table: "import_stat_wos_ids"
  insert_import_stat_wos_ids(
    # the rows to be inserted
    objects: [import_stat_wos_ids_insert_input!]!
  ): import_stat_wos_ids_mutation_response

  # insert a single row into the table: "import_stat_wos_ids"
  insert_import_stat_wos_ids_one(
    # the row to be inserted
    object: import_stat_wos_ids_insert_input!
  ): import_stat_wos_ids

  # insert data into the table: "institute_type"
  insert_institute_type(
    # the rows to be inserted
    objects: [institute_type_insert_input!]!

    # on conflict condition
    on_conflict: institute_type_on_conflict
  ): institute_type_mutation_response

  # insert a single row into the table: "institute_type"
  insert_institute_type_one(
    # the row to be inserted
    object: institute_type_insert_input!

    # on conflict condition
    on_conflict: institute_type_on_conflict
  ): institute_type

  # insert data into the table: "journal_successors"
  insert_journal_successors(
    # the rows to be inserted
    objects: [journal_successors_insert_input!]!
  ): journal_successors_mutation_response

  # insert a single row into the table: "journal_successors"
  insert_journal_successors_one(
    # the row to be inserted
    object: journal_successors_insert_input!
  ): journal_successors

  # insert data into the table: "keyword"
  insert_keyword(
    # the rows to be inserted
    objects: [keyword_insert_input!]!

    # on conflict condition
    on_conflict: keyword_on_conflict
  ): keyword_mutation_response

  # insert a single row into the table: "keyword"
  insert_keyword_one(
    # the row to be inserted
    object: keyword_insert_input!

    # on conflict condition
    on_conflict: keyword_on_conflict
  ): keyword

  # insert data into the table: "language"
  insert_language(
    # the rows to be inserted
    objects: [language_insert_input!]!

    # on conflict condition
    on_conflict: language_on_conflict
  ): language_mutation_response

  # insert a single row into the table: "language"
  insert_language_one(
    # the row to be inserted
    object: language_insert_input!

    # on conflict condition
    on_conflict: language_on_conflict
  ): language

  # insert data into the table: "localized_message"
  insert_localized_message(
    # the rows to be inserted
    objects: [localized_message_insert_input!]!

    # on conflict condition
    on_conflict: localized_message_on_conflict
  ): localized_message_mutation_response

  # insert a single row into the table: "localized_message"
  insert_localized_message_one(
    # the row to be inserted
    object: localized_message_insert_input!

    # on conflict condition
    on_conflict: localized_message_on_conflict
  ): localized_message

  # insert data into the table: "location"
  insert_location(
    # the rows to be inserted
    objects: [location_insert_input!]!

    # on conflict condition
    on_conflict: location_on_conflict
  ): location_mutation_response

  # insert a single row into the table: "location"
  insert_location_one(
    # the row to be inserted
    object: location_insert_input!

    # on conflict condition
    on_conflict: location_on_conflict
  ): location

  # insert data into the table: "lock_list"
  insert_lock_list(
    # the rows to be inserted
    objects: [lock_list_insert_input!]!

    # on conflict condition
    on_conflict: lock_list_on_conflict
  ): lock_list_mutation_response

  # insert data into the table: "lock_list_delegated_admins"
  insert_lock_list_delegated_admins(
    # the rows to be inserted
    objects: [lock_list_delegated_admins_insert_input!]!
  ): lock_list_delegated_admins_mutation_response

  # insert a single row into the table: "lock_list_delegated_admins"
  insert_lock_list_delegated_admins_one(
    # the row to be inserted
    object: lock_list_delegated_admins_insert_input!
  ): lock_list_delegated_admins

  # insert a single row into the table: "lock_list"
  insert_lock_list_one(
    # the row to be inserted
    object: lock_list_insert_input!

    # on conflict condition
    on_conflict: lock_list_on_conflict
  ): lock_list

  # insert data into the table: "mab_discipline"
  insert_mab_discipline(
    # the rows to be inserted
    objects: [mab_discipline_insert_input!]!

    # on conflict condition
    on_conflict: mab_discipline_on_conflict
  ): mab_discipline_mutation_response

  # insert a single row into the table: "mab_discipline"
  insert_mab_discipline_one(
    # the row to be inserted
    object: mab_discipline_insert_input!

    # on conflict condition
    on_conflict: mab_discipline_on_conflict
  ): mab_discipline

  # insert data into the table: "mention"
  insert_mention(
    # the rows to be inserted
    objects: [mention_insert_input!]!

    # on conflict condition
    on_conflict: mention_on_conflict
  ): mention_mutation_response

  # insert a single row into the table: "mention"
  insert_mention_one(
    # the row to be inserted
    object: mention_insert_input!

    # on conflict condition
    on_conflict: mention_on_conflict
  ): mention

  # insert data into the table: "message"
  insert_message(
    # the rows to be inserted
    objects: [message_insert_input!]!

    # on conflict condition
    on_conflict: message_on_conflict
  ): message_mutation_response

  # insert data into the table: "message_files"
  insert_message_files(
    # the rows to be inserted
    objects: [message_files_insert_input!]!

    # on conflict condition
    on_conflict: message_files_on_conflict
  ): message_files_mutation_response

  # insert a single row into the table: "message_files"
  insert_message_files_one(
    # the row to be inserted
    object: message_files_insert_input!

    # on conflict condition
    on_conflict: message_files_on_conflict
  ): message_files

  # insert data into the table: "message_institutes"
  insert_message_institutes(
    # the rows to be inserted
    objects: [message_institutes_insert_input!]!

    # on conflict condition
    on_conflict: message_institutes_on_conflict
  ): message_institutes_mutation_response

  # insert a single row into the table: "message_institutes"
  insert_message_institutes_one(
    # the row to be inserted
    object: message_institutes_insert_input!

    # on conflict condition
    on_conflict: message_institutes_on_conflict
  ): message_institutes

  # insert data into the table: "message_mailboxes"
  insert_message_mailboxes(
    # the rows to be inserted
    objects: [message_mailboxes_insert_input!]!
  ): message_mailboxes_mutation_response

  # insert a single row into the table: "message_mailboxes"
  insert_message_mailboxes_one(
    # the row to be inserted
    object: message_mailboxes_insert_input!
  ): message_mailboxes

  # insert a single row into the table: "message"
  insert_message_one(
    # the row to be inserted
    object: message_insert_input!

    # on conflict condition
    on_conflict: message_on_conflict
  ): message

  # insert data into the table: "message_parameter"
  insert_message_parameter(
    # the rows to be inserted
    objects: [message_parameter_insert_input!]!

    # on conflict condition
    on_conflict: message_parameter_on_conflict
  ): message_parameter_mutation_response

  # insert a single row into the table: "message_parameter"
  insert_message_parameter_one(
    # the row to be inserted
    object: message_parameter_insert_input!

    # on conflict condition
    on_conflict: message_parameter_on_conflict
  ): message_parameter

  # insert data into the table: "message_recipients"
  insert_message_recipients(
    # the rows to be inserted
    objects: [message_recipients_insert_input!]!
  ): message_recipients_mutation_response

  # insert a single row into the table: "message_recipients"
  insert_message_recipients_one(
    # the row to be inserted
    object: message_recipients_insert_input!
  ): message_recipients

  # insert data into the table: "message_sent"
  insert_message_sent(
    # the rows to be inserted
    objects: [message_sent_insert_input!]!

    # on conflict condition
    on_conflict: message_sent_on_conflict
  ): message_sent_mutation_response

  # insert a single row into the table: "message_sent"
  insert_message_sent_one(
    # the row to be inserted
    object: message_sent_insert_input!

    # on conflict condition
    on_conflict: message_sent_on_conflict
  ): message_sent

  # insert data into the table: "message_template"
  insert_message_template(
    # the rows to be inserted
    objects: [message_template_insert_input!]!

    # on conflict condition
    on_conflict: message_template_on_conflict
  ): message_template_mutation_response

  # insert a single row into the table: "message_template"
  insert_message_template_one(
    # the row to be inserted
    object: message_template_insert_input!

    # on conflict condition
    on_conflict: message_template_on_conflict
  ): message_template

  # insert data into the table: "message_template_parameters"
  insert_message_template_parameters(
    # the rows to be inserted
    objects: [message_template_parameters_insert_input!]!
  ): message_template_parameters_mutation_response

  # insert a single row into the table: "message_template_parameters"
  insert_message_template_parameters_one(
    # the row to be inserted
    object: message_template_parameters_insert_input!
  ): message_template_parameters

  # insert data into the table: "mycite_revision_entity"
  insert_mycite_revision_entity(
    # the rows to be inserted
    objects: [mycite_revision_entity_insert_input!]!

    # on conflict condition
    on_conflict: mycite_revision_entity_on_conflict
  ): mycite_revision_entity_mutation_response

  # insert a single row into the table: "mycite_revision_entity"
  insert_mycite_revision_entity_one(
    # the row to be inserted
    object: mycite_revision_entity_insert_input!

    # on conflict condition
    on_conflict: mycite_revision_entity_on_conflict
  ): mycite_revision_entity

  # insert data into the table: "named_list"
  insert_named_list(
    # the rows to be inserted
    objects: [named_list_insert_input!]!

    # on conflict condition
    on_conflict: named_list_on_conflict
  ): named_list_mutation_response

  # insert a single row into the table: "named_list"
  insert_named_list_one(
    # the row to be inserted
    object: named_list_insert_input!

    # on conflict condition
    on_conflict: named_list_on_conflict
  ): named_list

  # insert data into the table: "not_duplums"
  insert_not_duplums(
    # the rows to be inserted
    objects: [not_duplums_insert_input!]!

    # on conflict condition
    on_conflict: not_duplums_on_conflict
  ): not_duplums_mutation_response

  # insert data into the table: "not_duplums_not_duplum_ids"
  insert_not_duplums_not_duplum_ids(
    # the rows to be inserted
    objects: [not_duplums_not_duplum_ids_insert_input!]!
  ): not_duplums_not_duplum_ids_mutation_response

  # insert a single row into the table: "not_duplums_not_duplum_ids"
  insert_not_duplums_not_duplum_ids_one(
    # the row to be inserted
    object: not_duplums_not_duplum_ids_insert_input!
  ): not_duplums_not_duplum_ids

  # insert a single row into the table: "not_duplums"
  insert_not_duplums_one(
    # the row to be inserted
    object: not_duplums_insert_input!

    # on conflict condition
    on_conflict: not_duplums_on_conflict
  ): not_duplums

  # insert data into the table: "organization"
  insert_organization(
    # the rows to be inserted
    objects: [organization_insert_input!]!

    # on conflict condition
    on_conflict: organization_on_conflict
  ): organization_mutation_response

  # insert data into the table: "organization_identifier"
  insert_organization_identifier(
    # the rows to be inserted
    objects: [organization_identifier_insert_input!]!

    # on conflict condition
    on_conflict: organization_identifier_on_conflict
  ): organization_identifier_mutation_response

  # insert a single row into the table: "organization_identifier"
  insert_organization_identifier_one(
    # the row to be inserted
    object: organization_identifier_insert_input!

    # on conflict condition
    on_conflict: organization_identifier_on_conflict
  ): organization_identifier

  # insert data into the table: "organization_mab_disciplines"
  insert_organization_mab_disciplines(
    # the rows to be inserted
    objects: [organization_mab_disciplines_insert_input!]!
  ): organization_mab_disciplines_mutation_response

  # insert a single row into the table: "organization_mab_disciplines"
  insert_organization_mab_disciplines_one(
    # the row to be inserted
    object: organization_mab_disciplines_insert_input!
  ): organization_mab_disciplines

  # insert a single row into the table: "organization"
  insert_organization_one(
    # the row to be inserted
    object: organization_insert_input!

    # on conflict condition
    on_conflict: organization_on_conflict
  ): organization

  # insert data into the table: "periodical"
  insert_periodical(
    # the rows to be inserted
    objects: [periodical_insert_input!]!

    # on conflict condition
    on_conflict: periodical_on_conflict
  ): periodical_mutation_response

  # insert data into the table: "periodical_issn"
  insert_periodical_issn(
    # the rows to be inserted
    objects: [periodical_issn_insert_input!]!

    # on conflict condition
    on_conflict: periodical_issn_on_conflict
  ): periodical_issn_mutation_response

  # insert a single row into the table: "periodical_issn"
  insert_periodical_issn_one(
    # the row to be inserted
    object: periodical_issn_insert_input!

    # on conflict condition
    on_conflict: periodical_issn_on_conflict
  ): periodical_issn

  # insert a single row into the table: "periodical"
  insert_periodical_one(
    # the row to be inserted
    object: periodical_insert_input!

    # on conflict condition
    on_conflict: periodical_on_conflict
  ): periodical

  # insert data into the table: "periodical_publishers"
  insert_periodical_publishers(
    # the rows to be inserted
    objects: [periodical_publishers_insert_input!]!
  ): periodical_publishers_mutation_response

  # insert a single row into the table: "periodical_publishers"
  insert_periodical_publishers_one(
    # the row to be inserted
    object: periodical_publishers_insert_input!
  ): periodical_publishers

  # insert data into the table: "periodical_subjects_external"
  insert_periodical_subjects_external(
    # the rows to be inserted
    objects: [periodical_subjects_external_insert_input!]!
  ): periodical_subjects_external_mutation_response

  # insert a single row into the table: "periodical_subjects_external"
  insert_periodical_subjects_external_one(
    # the row to be inserted
    object: periodical_subjects_external_insert_input!
  ): periodical_subjects_external

  # insert data into the table: "project"
  insert_project(
    # the rows to be inserted
    objects: [project_insert_input!]!

    # on conflict condition
    on_conflict: project_on_conflict
  ): project_mutation_response

  # insert a single row into the table: "project"
  insert_project_one(
    # the row to be inserted
    object: project_insert_input!

    # on conflict condition
    on_conflict: project_on_conflict
  ): project

  # insert data into the table: "pub_fixer_log"
  insert_pub_fixer_log(
    # the rows to be inserted
    objects: [pub_fixer_log_insert_input!]!

    # on conflict condition
    on_conflict: pub_fixer_log_on_conflict
  ): pub_fixer_log_mutation_response

  # insert a single row into the table: "pub_fixer_log"
  insert_pub_fixer_log_one(
    # the row to be inserted
    object: pub_fixer_log_insert_input!

    # on conflict condition
    on_conflict: pub_fixer_log_on_conflict
  ): pub_fixer_log

  # insert data into the table: "publication"
  insert_publication(
    # the rows to be inserted
    objects: [publication_insert_input!]!

    # on conflict condition
    on_conflict: publication_on_conflict
  ): publication_mutation_response

  # insert data into the table: "publication_authors"
  insert_publication_authors(
    # the rows to be inserted
    objects: [publication_authors_insert_input!]!

    # on conflict condition
    on_conflict: publication_authors_on_conflict
  ): publication_authors_mutation_response

  # insert a single row into the table: "publication_authors"
  insert_publication_authors_one(
    # the row to be inserted
    object: publication_authors_insert_input!

    # on conflict condition
    on_conflict: publication_authors_on_conflict
  ): publication_authors

  # insert data into the table: "publication_direct_institutes"
  insert_publication_direct_institutes(
    # the rows to be inserted
    objects: [publication_direct_institutes_insert_input!]!

    # on conflict condition
    on_conflict: publication_direct_institutes_on_conflict
  ): publication_direct_institutes_mutation_response

  # insert a single row into the table: "publication_direct_institutes"
  insert_publication_direct_institutes_one(
    # the row to be inserted
    object: publication_direct_institutes_insert_input!

    # on conflict condition
    on_conflict: publication_direct_institutes_on_conflict
  ): publication_direct_institutes

  # insert data into the table: "publication_files"
  insert_publication_files(
    # the rows to be inserted
    objects: [publication_files_insert_input!]!

    # on conflict condition
    on_conflict: publication_files_on_conflict
  ): publication_files_mutation_response

  # insert a single row into the table: "publication_files"
  insert_publication_files_one(
    # the row to be inserted
    object: publication_files_insert_input!

    # on conflict condition
    on_conflict: publication_files_on_conflict
  ): publication_files

  # insert data into the table: "publication_identifier"
  insert_publication_identifier(
    # the rows to be inserted
    objects: [publication_identifier_insert_input!]!

    # on conflict condition
    on_conflict: publication_identifier_on_conflict
  ): publication_identifier_mutation_response

  # insert a single row into the table: "publication_identifier"
  insert_publication_identifier_one(
    # the row to be inserted
    object: publication_identifier_insert_input!

    # on conflict condition
    on_conflict: publication_identifier_on_conflict
  ): publication_identifier

  # insert data into the table: "publication_institutes"
  insert_publication_institutes(
    # the rows to be inserted
    objects: [publication_institutes_insert_input!]!

    # on conflict condition
    on_conflict: publication_institutes_on_conflict
  ): publication_institutes_mutation_response

  # insert a single row into the table: "publication_institutes"
  insert_publication_institutes_one(
    # the row to be inserted
    object: publication_institutes_insert_input!

    # on conflict condition
    on_conflict: publication_institutes_on_conflict
  ): publication_institutes

  # insert data into the table: "publication_keywords"
  insert_publication_keywords(
    # the rows to be inserted
    objects: [publication_keywords_insert_input!]!
  ): publication_keywords_mutation_response

  # insert a single row into the table: "publication_keywords"
  insert_publication_keywords_one(
    # the row to be inserted
    object: publication_keywords_insert_input!
  ): publication_keywords

  # insert data into the table: "publication_languages"
  insert_publication_languages(
    # the rows to be inserted
    objects: [publication_languages_insert_input!]!
  ): publication_languages_mutation_response

  # insert a single row into the table: "publication_languages"
  insert_publication_languages_one(
    # the row to be inserted
    object: publication_languages_insert_input!
  ): publication_languages

  # insert data into the table: "publication_old_org_authors"
  insert_publication_old_org_authors(
    # the rows to be inserted
    objects: [publication_old_org_authors_insert_input!]!
  ): publication_old_org_authors_mutation_response

  # insert a single row into the table: "publication_old_org_authors"
  insert_publication_old_org_authors_one(
    # the row to be inserted
    object: publication_old_org_authors_insert_input!
  ): publication_old_org_authors

  # insert a single row into the table: "publication"
  insert_publication_one(
    # the row to be inserted
    object: publication_insert_input!

    # on conflict condition
    on_conflict: publication_on_conflict
  ): publication

  # insert data into the table: "publication_owner_authors"
  insert_publication_owner_authors(
    # the rows to be inserted
    objects: [publication_owner_authors_insert_input!]!

    # on conflict condition
    on_conflict: publication_owner_authors_on_conflict
  ): publication_owner_authors_mutation_response

  # insert a single row into the table: "publication_owner_authors"
  insert_publication_owner_authors_one(
    # the row to be inserted
    object: publication_owner_authors_insert_input!

    # on conflict condition
    on_conflict: publication_owner_authors_on_conflict
  ): publication_owner_authors

  # insert data into the table: "publication_owner_institutes"
  insert_publication_owner_institutes(
    # the rows to be inserted
    objects: [publication_owner_institutes_insert_input!]!

    # on conflict condition
    on_conflict: publication_owner_institutes_on_conflict
  ): publication_owner_institutes_mutation_response

  # insert a single row into the table: "publication_owner_institutes"
  insert_publication_owner_institutes_one(
    # the row to be inserted
    object: publication_owner_institutes_insert_input!

    # on conflict condition
    on_conflict: publication_owner_institutes_on_conflict
  ): publication_owner_institutes

  # insert data into the table: "publication_owners"
  insert_publication_owners(
    # the rows to be inserted
    objects: [publication_owners_insert_input!]!
  ): publication_owners_mutation_response

  # insert a single row into the table: "publication_owners"
  insert_publication_owners_one(
    # the row to be inserted
    object: publication_owners_insert_input!
  ): publication_owners

  # insert data into the table: "publication_published_at"
  insert_publication_published_at(
    # the rows to be inserted
    objects: [publication_published_at_insert_input!]!
  ): publication_published_at_mutation_response

  # insert a single row into the table: "publication_published_at"
  insert_publication_published_at_one(
    # the row to be inserted
    object: publication_published_at_insert_input!
  ): publication_published_at

  # insert data into the table: "publication_publishers"
  insert_publication_publishers(
    # the rows to be inserted
    objects: [publication_publishers_insert_input!]!
  ): publication_publishers_mutation_response

  # insert a single row into the table: "publication_publishers"
  insert_publication_publishers_one(
    # the row to be inserted
    object: publication_publishers_insert_input!
  ): publication_publishers

  # insert data into the table: "publication_ratings"
  insert_publication_ratings(
    # the rows to be inserted
    objects: [publication_ratings_insert_input!]!
  ): publication_ratings_mutation_response

  # insert a single row into the table: "publication_ratings"
  insert_publication_ratings_one(
    # the row to be inserted
    object: publication_ratings_insert_input!
  ): publication_ratings

  # insert data into the table: "publication_source_type"
  insert_publication_source_type(
    # the rows to be inserted
    objects: [publication_source_type_insert_input!]!

    # on conflict condition
    on_conflict: publication_source_type_on_conflict
  ): publication_source_type_mutation_response

  # insert a single row into the table: "publication_source_type"
  insert_publication_source_type_one(
    # the row to be inserted
    object: publication_source_type_insert_input!

    # on conflict condition
    on_conflict: publication_source_type_on_conflict
  ): publication_source_type

  # insert data into the table: "publication_subjects"
  insert_publication_subjects(
    # the rows to be inserted
    objects: [publication_subjects_insert_input!]!
  ): publication_subjects_mutation_response

  # insert a single row into the table: "publication_subjects"
  insert_publication_subjects_one(
    # the row to be inserted
    object: publication_subjects_insert_input!
  ): publication_subjects

  # insert data into the table: "publication_type"
  insert_publication_type(
    # the rows to be inserted
    objects: [publication_type_insert_input!]!

    # on conflict condition
    on_conflict: publication_type_on_conflict
  ): publication_type_mutation_response

  # insert a single row into the table: "publication_type"
  insert_publication_type_one(
    # the row to be inserted
    object: publication_type_insert_input!

    # on conflict condition
    on_conflict: publication_type_on_conflict
  ): publication_type

  # insert data into the table: "publisher"
  insert_publisher(
    # the rows to be inserted
    objects: [publisher_insert_input!]!

    # on conflict condition
    on_conflict: publisher_on_conflict
  ): publisher_mutation_response

  # insert data into the table: "publisher_cities"
  insert_publisher_cities(
    # the rows to be inserted
    objects: [publisher_cities_insert_input!]!
  ): publisher_cities_mutation_response

  # insert a single row into the table: "publisher_cities"
  insert_publisher_cities_one(
    # the row to be inserted
    object: publisher_cities_insert_input!
  ): publisher_cities

  # insert a single row into the table: "publisher"
  insert_publisher_one(
    # the row to be inserted
    object: publisher_insert_input!

    # on conflict condition
    on_conflict: publisher_on_conflict
  ): publisher

  # insert data into the table: "query_info"
  insert_query_info(
    # the rows to be inserted
    objects: [query_info_insert_input!]!

    # on conflict condition
    on_conflict: query_info_on_conflict
  ): query_info_mutation_response

  # insert a single row into the table: "query_info"
  insert_query_info_one(
    # the row to be inserted
    object: query_info_insert_input!

    # on conflict condition
    on_conflict: query_info_on_conflict
  ): query_info

  # insert data into the table: "queued_background_job"
  insert_queued_background_job(
    # the rows to be inserted
    objects: [queued_background_job_insert_input!]!

    # on conflict condition
    on_conflict: queued_background_job_on_conflict
  ): queued_background_job_mutation_response

  # insert a single row into the table: "queued_background_job"
  insert_queued_background_job_one(
    # the row to be inserted
    object: queued_background_job_insert_input!

    # on conflict condition
    on_conflict: queued_background_job_on_conflict
  ): queued_background_job

  # insert data into the table: "rating"
  insert_rating(
    # the rows to be inserted
    objects: [rating_insert_input!]!

    # on conflict condition
    on_conflict: rating_on_conflict
  ): rating_mutation_response

  # insert a single row into the table: "rating"
  insert_rating_one(
    # the row to be inserted
    object: rating_insert_input!

    # on conflict condition
    on_conflict: rating_on_conflict
  ): rating

  # insert data into the table: "rating_type"
  insert_rating_type(
    # the rows to be inserted
    objects: [rating_type_insert_input!]!

    # on conflict condition
    on_conflict: rating_type_on_conflict
  ): rating_type_mutation_response

  # insert a single row into the table: "rating_type"
  insert_rating_type_one(
    # the row to be inserted
    object: rating_type_insert_input!

    # on conflict condition
    on_conflict: rating_type_on_conflict
  ): rating_type

  # insert data into the table: "recalculate_institute_ownerships_request"
  insert_recalculate_institute_ownerships_request(
    # the rows to be inserted
    objects: [recalculate_institute_ownerships_request_insert_input!]!

    # on conflict condition
    on_conflict: recalculate_institute_ownerships_request_on_conflict
  ): recalculate_institute_ownerships_request_mutation_response

  # insert data into the table: "recalculate_institute_ownerships_request_affected_institutes"
  insert_recalculate_institute_ownerships_request_affected_institutes(
    # the rows to be inserted
    objects: [recalculate_institute_ownerships_request_affected_institutes_insert_input!]!

    # on conflict condition
    on_conflict: recalculate_institute_ownerships_request_affected_institutes_on_conflict
  ): recalculate_institute_ownerships_request_affected_institutes_mutation_response

  # insert a single row into the table: "recalculate_institute_ownerships_request_affected_institutes"
  insert_recalculate_institute_ownerships_request_affected_institutes_one(
    # the row to be inserted
    object: recalculate_institute_ownerships_request_affected_institutes_insert_input!

    # on conflict condition
    on_conflict: recalculate_institute_ownerships_request_affected_institutes_on_conflict
  ): recalculate_institute_ownerships_request_affected_institutes

  # insert a single row into the table: "recalculate_institute_ownerships_request"
  insert_recalculate_institute_ownerships_request_one(
    # the row to be inserted
    object: recalculate_institute_ownerships_request_insert_input!

    # on conflict condition
    on_conflict: recalculate_institute_ownerships_request_on_conflict
  ): recalculate_institute_ownerships_request

  # insert data into the table: "reference"
  insert_reference(
    # the rows to be inserted
    objects: [reference_insert_input!]!

    # on conflict condition
    on_conflict: reference_on_conflict
  ): reference_mutation_response

  # insert a single row into the table: "reference"
  insert_reference_one(
    # the row to be inserted
    object: reference_insert_input!

    # on conflict condition
    on_conflict: reference_on_conflict
  ): reference

  # insert data into the table: "refresh_item"
  insert_refresh_item(
    # the rows to be inserted
    objects: [refresh_item_insert_input!]!

    # on conflict condition
    on_conflict: refresh_item_on_conflict
  ): refresh_item_mutation_response

  # insert a single row into the table: "refresh_item"
  insert_refresh_item_one(
    # the row to be inserted
    object: refresh_item_insert_input!

    # on conflict condition
    on_conflict: refresh_item_on_conflict
  ): refresh_item

  # insert data into the table: "refresh_log"
  insert_refresh_log(
    # the rows to be inserted
    objects: [refresh_log_insert_input!]!

    # on conflict condition
    on_conflict: refresh_log_on_conflict
  ): refresh_log_mutation_response

  # insert a single row into the table: "refresh_log"
  insert_refresh_log_one(
    # the row to be inserted
    object: refresh_log_insert_input!

    # on conflict condition
    on_conflict: refresh_log_on_conflict
  ): refresh_log

  # insert data into the table: "reorg"
  insert_reorg(
    # the rows to be inserted
    objects: [reorg_insert_input!]!

    # on conflict condition
    on_conflict: reorg_on_conflict
  ): reorg_mutation_response

  # insert a single row into the table: "reorg"
  insert_reorg_one(
    # the row to be inserted
    object: reorg_insert_input!

    # on conflict condition
    on_conflict: reorg_on_conflict
  ): reorg

  # insert data into the table: "reorg_type"
  insert_reorg_type(
    # the rows to be inserted
    objects: [reorg_type_insert_input!]!

    # on conflict condition
    on_conflict: reorg_type_on_conflict
  ): reorg_type_mutation_response

  # insert a single row into the table: "reorg_type"
  insert_reorg_type_one(
    # the row to be inserted
    object: reorg_type_insert_input!

    # on conflict condition
    on_conflict: reorg_type_on_conflict
  ): reorg_type

  # insert data into the table: "report"
  insert_report(
    # the rows to be inserted
    objects: [report_insert_input!]!

    # on conflict condition
    on_conflict: report_on_conflict
  ): report_mutation_response

  # insert data into the table: "report_content"
  insert_report_content(
    # the rows to be inserted
    objects: [report_content_insert_input!]!

    # on conflict condition
    on_conflict: report_content_on_conflict
  ): report_content_mutation_response

  # insert data into the table: "report_content_file_content"
  insert_report_content_file_content(
    # the rows to be inserted
    objects: [report_content_file_content_insert_input!]!
  ): report_content_file_content_mutation_response

  # insert a single row into the table: "report_content_file_content"
  insert_report_content_file_content_one(
    # the row to be inserted
    object: report_content_file_content_insert_input!
  ): report_content_file_content

  # insert a single row into the table: "report_content"
  insert_report_content_one(
    # the row to be inserted
    object: report_content_insert_input!

    # on conflict condition
    on_conflict: report_content_on_conflict
  ): report_content

  # insert data into the table: "report_contents"
  insert_report_contents(
    # the rows to be inserted
    objects: [report_contents_insert_input!]!

    # on conflict condition
    on_conflict: report_contents_on_conflict
  ): report_contents_mutation_response

  # insert a single row into the table: "report_contents"
  insert_report_contents_one(
    # the row to be inserted
    object: report_contents_insert_input!

    # on conflict condition
    on_conflict: report_contents_on_conflict
  ): report_contents

  # insert a single row into the table: "report"
  insert_report_one(
    # the row to be inserted
    object: report_insert_input!

    # on conflict condition
    on_conflict: report_on_conflict
  ): report

  # insert data into the table: "report_parameter"
  insert_report_parameter(
    # the rows to be inserted
    objects: [report_parameter_insert_input!]!

    # on conflict condition
    on_conflict: report_parameter_on_conflict
  ): report_parameter_mutation_response

  # insert a single row into the table: "report_parameter"
  insert_report_parameter_one(
    # the row to be inserted
    object: report_parameter_insert_input!

    # on conflict condition
    on_conflict: report_parameter_on_conflict
  ): report_parameter

  # insert data into the table: "report_request"
  insert_report_request(
    # the rows to be inserted
    objects: [report_request_insert_input!]!

    # on conflict condition
    on_conflict: report_request_on_conflict
  ): report_request_mutation_response

  # insert a single row into the table: "report_request"
  insert_report_request_one(
    # the row to be inserted
    object: report_request_insert_input!

    # on conflict condition
    on_conflict: report_request_on_conflict
  ): report_request

  # insert data into the table: "report_request_queries"
  insert_report_request_queries(
    # the rows to be inserted
    objects: [report_request_queries_insert_input!]!
  ): report_request_queries_mutation_response

  # insert a single row into the table: "report_request_queries"
  insert_report_request_queries_one(
    # the row to be inserted
    object: report_request_queries_insert_input!
  ): report_request_queries

  # insert data into the table: "report_template"
  insert_report_template(
    # the rows to be inserted
    objects: [report_template_insert_input!]!

    # on conflict condition
    on_conflict: report_template_on_conflict
  ): report_template_mutation_response

  # insert data into the table: "report_template_default_queries"
  insert_report_template_default_queries(
    # the rows to be inserted
    objects: [report_template_default_queries_insert_input!]!
  ): report_template_default_queries_mutation_response

  # insert a single row into the table: "report_template_default_queries"
  insert_report_template_default_queries_one(
    # the row to be inserted
    object: report_template_default_queries_insert_input!
  ): report_template_default_queries

  # insert data into the table: "report_template_language_files"
  insert_report_template_language_files(
    # the rows to be inserted
    objects: [report_template_language_files_insert_input!]!

    # on conflict condition
    on_conflict: report_template_language_files_on_conflict
  ): report_template_language_files_mutation_response

  # insert a single row into the table: "report_template_language_files"
  insert_report_template_language_files_one(
    # the row to be inserted
    object: report_template_language_files_insert_input!

    # on conflict condition
    on_conflict: report_template_language_files_on_conflict
  ): report_template_language_files

  # insert a single row into the table: "report_template"
  insert_report_template_one(
    # the row to be inserted
    object: report_template_insert_input!

    # on conflict condition
    on_conflict: report_template_on_conflict
  ): report_template

  # insert data into the table: "report_template_parameter_select"
  insert_report_template_parameter_select(
    # the rows to be inserted
    objects: [report_template_parameter_select_insert_input!]!

    # on conflict condition
    on_conflict: report_template_parameter_select_on_conflict
  ): report_template_parameter_select_mutation_response

  # insert a single row into the table: "report_template_parameter_select"
  insert_report_template_parameter_select_one(
    # the row to be inserted
    object: report_template_parameter_select_insert_input!

    # on conflict condition
    on_conflict: report_template_parameter_select_on_conflict
  ): report_template_parameter_select

  # insert data into the table: "report_xml"
  insert_report_xml(
    # the rows to be inserted
    objects: [report_xml_insert_input!]!

    # on conflict condition
    on_conflict: report_xml_on_conflict
  ): report_xml_mutation_response

  # insert a single row into the table: "report_xml"
  insert_report_xml_one(
    # the row to be inserted
    object: report_xml_insert_input!

    # on conflict condition
    on_conflict: report_xml_on_conflict
  ): report_xml

  # insert data into the table: "ris_import_error_detail"
  insert_ris_import_error_detail(
    # the rows to be inserted
    objects: [ris_import_error_detail_insert_input!]!

    # on conflict condition
    on_conflict: ris_import_error_detail_on_conflict
  ): ris_import_error_detail_mutation_response

  # insert a single row into the table: "ris_import_error_detail"
  insert_ris_import_error_detail_one(
    # the row to be inserted
    object: ris_import_error_detail_insert_input!

    # on conflict condition
    on_conflict: ris_import_error_detail_on_conflict
  ): ris_import_error_detail

  # insert data into the table: "series_volume"
  insert_series_volume(
    # the rows to be inserted
    objects: [series_volume_insert_input!]!

    # on conflict condition
    on_conflict: series_volume_on_conflict
  ): series_volume_mutation_response

  # insert a single row into the table: "series_volume"
  insert_series_volume_one(
    # the row to be inserted
    object: series_volume_insert_input!

    # on conflict condition
    on_conflict: series_volume_on_conflict
  ): series_volume

  # insert data into the table: "shib_id_provider"
  insert_shib_id_provider(
    # the rows to be inserted
    objects: [shib_id_provider_insert_input!]!

    # on conflict condition
    on_conflict: shib_id_provider_on_conflict
  ): shib_id_provider_mutation_response

  # insert a single row into the table: "shib_id_provider"
  insert_shib_id_provider_one(
    # the row to be inserted
    object: shib_id_provider_insert_input!

    # on conflict condition
    on_conflict: shib_id_provider_on_conflict
  ): shib_id_provider

  # insert data into the table: "smart_query"
  insert_smart_query(
    # the rows to be inserted
    objects: [smart_query_insert_input!]!

    # on conflict condition
    on_conflict: smart_query_on_conflict
  ): smart_query_mutation_response

  # insert data into the table: "smart_query_cond"
  insert_smart_query_cond(
    # the rows to be inserted
    objects: [smart_query_cond_insert_input!]!

    # on conflict condition
    on_conflict: smart_query_cond_on_conflict
  ): smart_query_cond_mutation_response

  # insert a single row into the table: "smart_query_cond"
  insert_smart_query_cond_one(
    # the row to be inserted
    object: smart_query_cond_insert_input!

    # on conflict condition
    on_conflict: smart_query_cond_on_conflict
  ): smart_query_cond

  # insert data into the table: "smart_query_group"
  insert_smart_query_group(
    # the rows to be inserted
    objects: [smart_query_group_insert_input!]!

    # on conflict condition
    on_conflict: smart_query_group_on_conflict
  ): smart_query_group_mutation_response

  # insert a single row into the table: "smart_query_group"
  insert_smart_query_group_one(
    # the row to be inserted
    object: smart_query_group_insert_input!

    # on conflict condition
    on_conflict: smart_query_group_on_conflict
  ): smart_query_group

  # insert a single row into the table: "smart_query"
  insert_smart_query_one(
    # the row to be inserted
    object: smart_query_insert_input!

    # on conflict condition
    on_conflict: smart_query_on_conflict
  ): smart_query

  # insert data into the table: "smart_query_sort"
  insert_smart_query_sort(
    # the rows to be inserted
    objects: [smart_query_sort_insert_input!]!

    # on conflict condition
    on_conflict: smart_query_sort_on_conflict
  ): smart_query_sort_mutation_response

  # insert a single row into the table: "smart_query_sort"
  insert_smart_query_sort_one(
    # the row to be inserted
    object: smart_query_sort_insert_input!

    # on conflict condition
    on_conflict: smart_query_sort_on_conflict
  ): smart_query_sort

  # insert data into the table: "snippet_cache"
  insert_snippet_cache(
    # the rows to be inserted
    objects: [snippet_cache_insert_input!]!

    # on conflict condition
    on_conflict: snippet_cache_on_conflict
  ): snippet_cache_mutation_response

  # insert a single row into the table: "snippet_cache"
  insert_snippet_cache_one(
    # the row to be inserted
    object: snippet_cache_insert_input!

    # on conflict condition
    on_conflict: snippet_cache_on_conflict
  ): snippet_cache

  # insert data into the table: "snippet_cache_status"
  insert_snippet_cache_status(
    # the rows to be inserted
    objects: [snippet_cache_status_insert_input!]!

    # on conflict condition
    on_conflict: snippet_cache_status_on_conflict
  ): snippet_cache_status_mutation_response

  # insert a single row into the table: "snippet_cache_status"
  insert_snippet_cache_status_one(
    # the row to be inserted
    object: snippet_cache_status_insert_input!

    # on conflict condition
    on_conflict: snippet_cache_status_on_conflict
  ): snippet_cache_status

  # insert data into the table: "source"
  insert_source(
    # the rows to be inserted
    objects: [source_insert_input!]!

    # on conflict condition
    on_conflict: source_on_conflict
  ): source_mutation_response

  # insert data into the table: "source_allowed_institutes"
  insert_source_allowed_institutes(
    # the rows to be inserted
    objects: [source_allowed_institutes_insert_input!]!
  ): source_allowed_institutes_mutation_response

  # insert a single row into the table: "source_allowed_institutes"
  insert_source_allowed_institutes_one(
    # the row to be inserted
    object: source_allowed_institutes_insert_input!
  ): source_allowed_institutes

  # insert a single row into the table: "source"
  insert_source_one(
    # the row to be inserted
    object: source_insert_input!

    # on conflict condition
    on_conflict: source_on_conflict
  ): source

  # insert data into the table: "sub_type"
  insert_sub_type(
    # the rows to be inserted
    objects: [sub_type_insert_input!]!

    # on conflict condition
    on_conflict: sub_type_on_conflict
  ): sub_type_mutation_response

  # insert a single row into the table: "sub_type"
  insert_sub_type_one(
    # the row to be inserted
    object: sub_type_insert_input!

    # on conflict condition
    on_conflict: sub_type_on_conflict
  ): sub_type

  # insert data into the table: "ticket"
  insert_ticket(
    # the rows to be inserted
    objects: [ticket_insert_input!]!

    # on conflict condition
    on_conflict: ticket_on_conflict
  ): ticket_mutation_response

  # insert data into the table: "ticket_authors"
  insert_ticket_authors(
    # the rows to be inserted
    objects: [ticket_authors_insert_input!]!

    # on conflict condition
    on_conflict: ticket_authors_on_conflict
  ): ticket_authors_mutation_response

  # insert a single row into the table: "ticket_authors"
  insert_ticket_authors_one(
    # the row to be inserted
    object: ticket_authors_insert_input!

    # on conflict condition
    on_conflict: ticket_authors_on_conflict
  ): ticket_authors

  # insert data into the table: "ticket_institutes"
  insert_ticket_institutes(
    # the rows to be inserted
    objects: [ticket_institutes_insert_input!]!

    # on conflict condition
    on_conflict: ticket_institutes_on_conflict
  ): ticket_institutes_mutation_response

  # insert a single row into the table: "ticket_institutes"
  insert_ticket_institutes_one(
    # the row to be inserted
    object: ticket_institutes_insert_input!

    # on conflict condition
    on_conflict: ticket_institutes_on_conflict
  ): ticket_institutes

  # insert a single row into the table: "ticket"
  insert_ticket_one(
    # the row to be inserted
    object: ticket_insert_input!

    # on conflict condition
    on_conflict: ticket_on_conflict
  ): ticket

  # insert data into the table: "uploaded_file"
  insert_uploaded_file(
    # the rows to be inserted
    objects: [uploaded_file_insert_input!]!

    # on conflict condition
    on_conflict: uploaded_file_on_conflict
  ): uploaded_file_mutation_response

  # insert data into the table: "uploaded_file_file_content"
  insert_uploaded_file_file_content(
    # the rows to be inserted
    objects: [uploaded_file_file_content_insert_input!]!
  ): uploaded_file_file_content_mutation_response

  # insert a single row into the table: "uploaded_file_file_content"
  insert_uploaded_file_file_content_one(
    # the row to be inserted
    object: uploaded_file_file_content_insert_input!
  ): uploaded_file_file_content

  # insert a single row into the table: "uploaded_file"
  insert_uploaded_file_one(
    # the row to be inserted
    object: uploaded_file_insert_input!

    # on conflict condition
    on_conflict: uploaded_file_on_conflict
  ): uploaded_file

  # insert data into the table: "usage_log"
  insert_usage_log(
    # the rows to be inserted
    objects: [usage_log_insert_input!]!

    # on conflict condition
    on_conflict: usage_log_on_conflict
  ): usage_log_mutation_response

  # insert a single row into the table: "usage_log"
  insert_usage_log_one(
    # the row to be inserted
    object: usage_log_insert_input!

    # on conflict condition
    on_conflict: usage_log_on_conflict
  ): usage_log

  # insert data into the table: "user_notification_time"
  insert_user_notification_time(
    # the rows to be inserted
    objects: [user_notification_time_insert_input!]!

    # on conflict condition
    on_conflict: user_notification_time_on_conflict
  ): user_notification_time_mutation_response

  # insert a single row into the table: "user_notification_time"
  insert_user_notification_time_one(
    # the row to be inserted
    object: user_notification_time_insert_input!

    # on conflict condition
    on_conflict: user_notification_time_on_conflict
  ): user_notification_time

  # insert data into the table: "user_preferences"
  insert_user_preferences(
    # the rows to be inserted
    objects: [user_preferences_insert_input!]!

    # on conflict condition
    on_conflict: user_preferences_on_conflict
  ): user_preferences_mutation_response

  # insert a single row into the table: "user_preferences"
  insert_user_preferences_one(
    # the row to be inserted
    object: user_preferences_insert_input!

    # on conflict condition
    on_conflict: user_preferences_on_conflict
  ): user_preferences

  # insert data into the table: "users"
  insert_users(
    # the rows to be inserted
    objects: [users_insert_input!]!

    # on conflict condition
    on_conflict: users_on_conflict
  ): users_mutation_response

  # insert data into the table: "users_assistants"
  insert_users_assistants(
    # the rows to be inserted
    objects: [users_assistants_insert_input!]!
  ): users_assistants_mutation_response

  # insert a single row into the table: "users_assistants"
  insert_users_assistants_one(
    # the row to be inserted
    object: users_assistants_insert_input!
  ): users_assistants

  # insert data into the table: "users_disciplines"
  insert_users_disciplines(
    # the rows to be inserted
    objects: [users_disciplines_insert_input!]!
  ): users_disciplines_mutation_response

  # insert a single row into the table: "users_disciplines"
  insert_users_disciplines_one(
    # the row to be inserted
    object: users_disciplines_insert_input!
  ): users_disciplines

  # insert a single row into the table: "users"
  insert_users_one(
    # the row to be inserted
    object: users_insert_input!

    # on conflict condition
    on_conflict: users_on_conflict
  ): users

  # insert data into the table: "variable"
  insert_variable(
    # the rows to be inserted
    objects: [variable_insert_input!]!

    # on conflict condition
    on_conflict: variable_on_conflict
  ): variable_mutation_response

  # insert a single row into the table: "variable"
  insert_variable_one(
    # the row to be inserted
    object: variable_insert_input!

    # on conflict condition
    on_conflict: variable_on_conflict
  ): variable

  # insert data into the table: "workflow"
  insert_workflow(
    # the rows to be inserted
    objects: [workflow_insert_input!]!

    # on conflict condition
    on_conflict: workflow_on_conflict
  ): workflow_mutation_response

  # insert a single row into the table: "workflow"
  insert_workflow_one(
    # the row to be inserted
    object: workflow_insert_input!

    # on conflict condition
    on_conflict: workflow_on_conflict
  ): workflow

  # insert data into the table: "workflow_status"
  insert_workflow_status(
    # the rows to be inserted
    objects: [workflow_status_insert_input!]!

    # on conflict condition
    on_conflict: workflow_status_on_conflict
  ): workflow_status_mutation_response

  # insert a single row into the table: "workflow_status"
  insert_workflow_status_one(
    # the row to be inserted
    object: workflow_status_insert_input!

    # on conflict condition
    on_conflict: workflow_status_on_conflict
  ): workflow_status

  # insert data into the table: "workflow_step"
  insert_workflow_step(
    # the rows to be inserted
    objects: [workflow_step_insert_input!]!

    # on conflict condition
    on_conflict: workflow_step_on_conflict
  ): workflow_step_mutation_response

  # insert a single row into the table: "workflow_step"
  insert_workflow_step_one(
    # the row to be inserted
    object: workflow_step_insert_input!

    # on conflict condition
    on_conflict: workflow_step_on_conflict
  ): workflow_step

  # insert data into the table: "workflow_step_status"
  insert_workflow_step_status(
    # the rows to be inserted
    objects: [workflow_step_status_insert_input!]!

    # on conflict condition
    on_conflict: workflow_step_status_on_conflict
  ): workflow_step_status_mutation_response

  # insert a single row into the table: "workflow_step_status"
  insert_workflow_step_status_one(
    # the row to be inserted
    object: workflow_step_status_insert_input!

    # on conflict condition
    on_conflict: workflow_step_status_on_conflict
  ): workflow_step_status

  # update data of the table: "achievement_property"
  update_achievement_property(
    # increments the integer columns with given value of the filtered values
    _inc: achievement_property_inc_input

    # sets the columns of the filtered rows to the given values
    _set: achievement_property_set_input

    # filter the rows which have to be updated
    where: achievement_property_bool_exp!
  ): achievement_property_mutation_response

  # update single row of the table: "achievement_property"
  update_achievement_property_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: achievement_property_inc_input

    # sets the columns of the filtered rows to the given values
    _set: achievement_property_set_input
    pk_columns: achievement_property_pk_columns_input!
  ): achievement_property

  # update data of the table: "achievement_property_listing"
  update_achievement_property_listing(
    # increments the integer columns with given value of the filtered values
    _inc: achievement_property_listing_inc_input

    # sets the columns of the filtered rows to the given values
    _set: achievement_property_listing_set_input

    # filter the rows which have to be updated
    where: achievement_property_listing_bool_exp!
  ): achievement_property_listing_mutation_response

  # update single row of the table: "achievement_property_listing"
  update_achievement_property_listing_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: achievement_property_listing_inc_input

    # sets the columns of the filtered rows to the given values
    _set: achievement_property_listing_set_input
    pk_columns: achievement_property_listing_pk_columns_input!
  ): achievement_property_listing

  # update data of the table: "achievement_property_value"
  update_achievement_property_value(
    # increments the integer columns with given value of the filtered values
    _inc: achievement_property_value_inc_input

    # sets the columns of the filtered rows to the given values
    _set: achievement_property_value_set_input

    # filter the rows which have to be updated
    where: achievement_property_value_bool_exp!
  ): achievement_property_value_mutation_response

  # update single row of the table: "achievement_property_value"
  update_achievement_property_value_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: achievement_property_value_inc_input

    # sets the columns of the filtered rows to the given values
    _set: achievement_property_value_set_input
    pk_columns: achievement_property_value_pk_columns_input!
  ): achievement_property_value

  # update data of the table: "activity_log"
  update_activity_log(
    # increments the integer columns with given value of the filtered values
    _inc: activity_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: activity_log_set_input

    # filter the rows which have to be updated
    where: activity_log_bool_exp!
  ): activity_log_mutation_response

  # update single row of the table: "activity_log"
  update_activity_log_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: activity_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: activity_log_set_input
    pk_columns: activity_log_pk_columns_input!
  ): activity_log

  # update data of the table: "address"
  update_address(
    # increments the integer columns with given value of the filtered values
    _inc: address_inc_input

    # sets the columns of the filtered rows to the given values
    _set: address_set_input

    # filter the rows which have to be updated
    where: address_bool_exp!
  ): address_mutation_response

  # update single row of the table: "address"
  update_address_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: address_inc_input

    # sets the columns of the filtered rows to the given values
    _set: address_set_input
    pk_columns: address_pk_columns_input!
  ): address

  # update data of the table: "admin_role"
  update_admin_role(
    # increments the integer columns with given value of the filtered values
    _inc: admin_role_inc_input

    # sets the columns of the filtered rows to the given values
    _set: admin_role_set_input

    # filter the rows which have to be updated
    where: admin_role_bool_exp!
  ): admin_role_mutation_response

  # update single row of the table: "admin_role"
  update_admin_role_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: admin_role_inc_input

    # sets the columns of the filtered rows to the given values
    _set: admin_role_set_input
    pk_columns: admin_role_pk_columns_input!
  ): admin_role

  # update data of the table: "affiliation"
  update_affiliation(
    # increments the integer columns with given value of the filtered values
    _inc: affiliation_inc_input

    # sets the columns of the filtered rows to the given values
    _set: affiliation_set_input

    # filter the rows which have to be updated
    where: affiliation_bool_exp!
  ): affiliation_mutation_response

  # update single row of the table: "affiliation"
  update_affiliation_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: affiliation_inc_input

    # sets the columns of the filtered rows to the given values
    _set: affiliation_set_input
    pk_columns: affiliation_pk_columns_input!
  ): affiliation

  # update data of the table: "appearance"
  update_appearance(
    # increments the integer columns with given value of the filtered values
    _inc: appearance_inc_input

    # sets the columns of the filtered rows to the given values
    _set: appearance_set_input

    # filter the rows which have to be updated
    where: appearance_bool_exp!
  ): appearance_mutation_response

  # update single row of the table: "appearance"
  update_appearance_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: appearance_inc_input

    # sets the columns of the filtered rows to the given values
    _set: appearance_set_input
    pk_columns: appearance_pk_columns_input!
  ): appearance

  # update data of the table: "authentication_failure"
  update_authentication_failure(
    # increments the integer columns with given value of the filtered values
    _inc: authentication_failure_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authentication_failure_set_input

    # filter the rows which have to be updated
    where: authentication_failure_bool_exp!
  ): authentication_failure_mutation_response

  # update single row of the table: "authentication_failure"
  update_authentication_failure_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: authentication_failure_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authentication_failure_set_input
    pk_columns: authentication_failure_pk_columns_input!
  ): authentication_failure

  # update data of the table: "author_identifier"
  update_author_identifier(
    # increments the integer columns with given value of the filtered values
    _inc: author_identifier_inc_input

    # sets the columns of the filtered rows to the given values
    _set: author_identifier_set_input

    # filter the rows which have to be updated
    where: author_identifier_bool_exp!
  ): author_identifier_mutation_response

  # update single row of the table: "author_identifier"
  update_author_identifier_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: author_identifier_inc_input

    # sets the columns of the filtered rows to the given values
    _set: author_identifier_set_input
    pk_columns: author_identifier_pk_columns_input!
  ): author_identifier

  # update data of the table: "author_name"
  update_author_name(
    # increments the integer columns with given value of the filtered values
    _inc: author_name_inc_input

    # sets the columns of the filtered rows to the given values
    _set: author_name_set_input

    # filter the rows which have to be updated
    where: author_name_bool_exp!
  ): author_name_mutation_response

  # update single row of the table: "author_name"
  update_author_name_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: author_name_inc_input

    # sets the columns of the filtered rows to the given values
    _set: author_name_set_input
    pk_columns: author_name_pk_columns_input!
  ): author_name

  # update data of the table: "authorship"
  update_authorship(
    # increments the integer columns with given value of the filtered values
    _inc: authorship_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authorship_set_input

    # filter the rows which have to be updated
    where: authorship_bool_exp!
  ): authorship_mutation_response

  # update single row of the table: "authorship"
  update_authorship_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: authorship_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authorship_set_input
    pk_columns: authorship_pk_columns_input!
  ): authorship

  # update data of the table: "authorship_organizations"
  update_authorship_organizations(
    # increments the integer columns with given value of the filtered values
    _inc: authorship_organizations_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authorship_organizations_set_input

    # filter the rows which have to be updated
    where: authorship_organizations_bool_exp!
  ): authorship_organizations_mutation_response

  # update data of the table: "authorship_type"
  update_authorship_type(
    # increments the integer columns with given value of the filtered values
    _inc: authorship_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authorship_type_set_input

    # filter the rows which have to be updated
    where: authorship_type_bool_exp!
  ): authorship_type_mutation_response

  # update single row of the table: "authorship_type"
  update_authorship_type_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: authorship_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authorship_type_set_input
    pk_columns: authorship_type_pk_columns_input!
  ): authorship_type

  # update data of the table: "authorship_type_sub_types_allowed"
  update_authorship_type_sub_types_allowed(
    # increments the integer columns with given value of the filtered values
    _inc: authorship_type_sub_types_allowed_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authorship_type_sub_types_allowed_set_input

    # filter the rows which have to be updated
    where: authorship_type_sub_types_allowed_bool_exp!
  ): authorship_type_sub_types_allowed_mutation_response

  # update data of the table: "authorship_type_types_allowed"
  update_authorship_type_types_allowed(
    # increments the integer columns with given value of the filtered values
    _inc: authorship_type_types_allowed_inc_input

    # sets the columns of the filtered rows to the given values
    _set: authorship_type_types_allowed_set_input

    # filter the rows which have to be updated
    where: authorship_type_types_allowed_bool_exp!
  ): authorship_type_types_allowed_mutation_response

  # update data of the table: "binary_content"
  update_binary_content(
    # increments the integer columns with given value of the filtered values
    _inc: binary_content_inc_input

    # sets the columns of the filtered rows to the given values
    _set: binary_content_set_input

    # filter the rows which have to be updated
    where: binary_content_bool_exp!
  ): binary_content_mutation_response

  # update single row of the table: "binary_content"
  update_binary_content_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: binary_content_inc_input

    # sets the columns of the filtered rows to the given values
    _set: binary_content_set_input
    pk_columns: binary_content_pk_columns_input!
  ): binary_content

  # update data of the table: "bulk_duplum_merge_request"
  update_bulk_duplum_merge_request(
    # increments the integer columns with given value of the filtered values
    _inc: bulk_duplum_merge_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: bulk_duplum_merge_request_set_input

    # filter the rows which have to be updated
    where: bulk_duplum_merge_request_bool_exp!
  ): bulk_duplum_merge_request_mutation_response

  # update single row of the table: "bulk_duplum_merge_request"
  update_bulk_duplum_merge_request_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: bulk_duplum_merge_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: bulk_duplum_merge_request_set_input
    pk_columns: bulk_duplum_merge_request_pk_columns_input!
  ): bulk_duplum_merge_request

  # update data of the table: "category"
  update_category(
    # increments the integer columns with given value of the filtered values
    _inc: category_inc_input

    # sets the columns of the filtered rows to the given values
    _set: category_set_input

    # filter the rows which have to be updated
    where: category_bool_exp!
  ): category_mutation_response

  # update single row of the table: "category"
  update_category_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: category_inc_input

    # sets the columns of the filtered rows to the given values
    _set: category_set_input
    pk_columns: category_pk_columns_input!
  ): category

  # update data of the table: "category_sub_types_allowed"
  update_category_sub_types_allowed(
    # increments the integer columns with given value of the filtered values
    _inc: category_sub_types_allowed_inc_input

    # sets the columns of the filtered rows to the given values
    _set: category_sub_types_allowed_set_input

    # filter the rows which have to be updated
    where: category_sub_types_allowed_bool_exp!
  ): category_sub_types_allowed_mutation_response

  # update data of the table: "category_types_allowed"
  update_category_types_allowed(
    # increments the integer columns with given value of the filtered values
    _inc: category_types_allowed_inc_input

    # sets the columns of the filtered rows to the given values
    _set: category_types_allowed_set_input

    # filter the rows which have to be updated
    where: category_types_allowed_bool_exp!
  ): category_types_allowed_mutation_response

  # update data of the table: "citation"
  update_citation(
    # increments the integer columns with given value of the filtered values
    _inc: citation_inc_input

    # sets the columns of the filtered rows to the given values
    _set: citation_set_input

    # filter the rows which have to be updated
    where: citation_bool_exp!
  ): citation_mutation_response

  # update single row of the table: "citation"
  update_citation_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: citation_inc_input

    # sets the columns of the filtered rows to the given values
    _set: citation_set_input
    pk_columns: citation_pk_columns_input!
  ): citation

  # update data of the table: "classification"
  update_classification(
    # increments the integer columns with given value of the filtered values
    _inc: classification_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_set_input

    # filter the rows which have to be updated
    where: classification_bool_exp!
  ): classification_mutation_response

  # update single row of the table: "classification"
  update_classification_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: classification_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_set_input
    pk_columns: classification_pk_columns_input!
  ): classification

  # update data of the table: "classification_external"
  update_classification_external(
    # increments the integer columns with given value of the filtered values
    _inc: classification_external_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_external_set_input

    # filter the rows which have to be updated
    where: classification_external_bool_exp!
  ): classification_external_mutation_response

  # update single row of the table: "classification_external"
  update_classification_external_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: classification_external_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_external_set_input
    pk_columns: classification_external_pk_columns_input!
  ): classification_external

  # update data of the table: "classification_external_mapped_to"
  update_classification_external_mapped_to(
    # increments the integer columns with given value of the filtered values
    _inc: classification_external_mapped_to_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_external_mapped_to_set_input

    # filter the rows which have to be updated
    where: classification_external_mapped_to_bool_exp!
  ): classification_external_mapped_to_mutation_response

  # update data of the table: "classification_parents"
  update_classification_parents(
    # increments the integer columns with given value of the filtered values
    _inc: classification_parents_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_parents_set_input

    # filter the rows which have to be updated
    where: classification_parents_bool_exp!
  ): classification_parents_mutation_response

  # update data of the table: "classification_tree"
  update_classification_tree(
    # increments the integer columns with given value of the filtered values
    _inc: classification_tree_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_tree_set_input

    # filter the rows which have to be updated
    where: classification_tree_bool_exp!
  ): classification_tree_mutation_response

  # update single row of the table: "classification_tree"
  update_classification_tree_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: classification_tree_inc_input

    # sets the columns of the filtered rows to the given values
    _set: classification_tree_set_input
    pk_columns: classification_tree_pk_columns_input!
  ): classification_tree

  # update data of the table: "conference"
  update_conference(
    # increments the integer columns with given value of the filtered values
    _inc: conference_inc_input

    # sets the columns of the filtered rows to the given values
    _set: conference_set_input

    # filter the rows which have to be updated
    where: conference_bool_exp!
  ): conference_mutation_response

  # update single row of the table: "conference"
  update_conference_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: conference_inc_input

    # sets the columns of the filtered rows to the given values
    _set: conference_set_input
    pk_columns: conference_pk_columns_input!
  ): conference

  # update data of the table: "conference_location"
  update_conference_location(
    # increments the integer columns with given value of the filtered values
    _inc: conference_location_inc_input

    # sets the columns of the filtered rows to the given values
    _set: conference_location_set_input

    # filter the rows which have to be updated
    where: conference_location_bool_exp!
  ): conference_location_mutation_response

  # update data of the table: "conference_organizers"
  update_conference_organizers(
    # increments the integer columns with given value of the filtered values
    _inc: conference_organizers_inc_input

    # sets the columns of the filtered rows to the given values
    _set: conference_organizers_set_input

    # filter the rows which have to be updated
    where: conference_organizers_bool_exp!
  ): conference_organizers_mutation_response

  # update data of the table: "cron_job"
  update_cron_job(
    # increments the integer columns with given value of the filtered values
    _inc: cron_job_inc_input

    # sets the columns of the filtered rows to the given values
    _set: cron_job_set_input

    # filter the rows which have to be updated
    where: cron_job_bool_exp!
  ): cron_job_mutation_response

  # update single row of the table: "cron_job"
  update_cron_job_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: cron_job_inc_input

    # sets the columns of the filtered rows to the given values
    _set: cron_job_set_input
    pk_columns: cron_job_pk_columns_input!
  ): cron_job

  # update data of the table: "cron_job_run_request"
  update_cron_job_run_request(
    # increments the integer columns with given value of the filtered values
    _inc: cron_job_run_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: cron_job_run_request_set_input

    # filter the rows which have to be updated
    where: cron_job_run_request_bool_exp!
  ): cron_job_run_request_mutation_response

  # update single row of the table: "cron_job_run_request"
  update_cron_job_run_request_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: cron_job_run_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: cron_job_run_request_set_input
    pk_columns: cron_job_run_request_pk_columns_input!
  ): cron_job_run_request

  # update data of the table: "degree"
  update_degree(
    # increments the integer columns with given value of the filtered values
    _inc: degree_inc_input

    # sets the columns of the filtered rows to the given values
    _set: degree_set_input

    # filter the rows which have to be updated
    where: degree_bool_exp!
  ): degree_mutation_response

  # update single row of the table: "degree"
  update_degree_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: degree_inc_input

    # sets the columns of the filtered rows to the given values
    _set: degree_set_input
    pk_columns: degree_pk_columns_input!
  ): degree

  # update data of the table: "degree_holder"
  update_degree_holder(
    # increments the integer columns with given value of the filtered values
    _inc: degree_holder_inc_input

    # sets the columns of the filtered rows to the given values
    _set: degree_holder_set_input

    # filter the rows which have to be updated
    where: degree_holder_bool_exp!
  ): degree_holder_mutation_response

  # update single row of the table: "degree_holder"
  update_degree_holder_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: degree_holder_inc_input

    # sets the columns of the filtered rows to the given values
    _set: degree_holder_set_input
    pk_columns: degree_holder_pk_columns_input!
  ): degree_holder

  # update data of the table: "discipline"
  update_discipline(
    # increments the integer columns with given value of the filtered values
    _inc: discipline_inc_input

    # sets the columns of the filtered rows to the given values
    _set: discipline_set_input

    # filter the rows which have to be updated
    where: discipline_bool_exp!
  ): discipline_mutation_response

  # update single row of the table: "discipline"
  update_discipline_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: discipline_inc_input

    # sets the columns of the filtered rows to the given values
    _set: discipline_set_input
    pk_columns: discipline_pk_columns_input!
  ): discipline

  # update data of the table: "division_containment"
  update_division_containment(
    # increments the integer columns with given value of the filtered values
    _inc: division_containment_inc_input

    # sets the columns of the filtered rows to the given values
    _set: division_containment_set_input

    # filter the rows which have to be updated
    where: division_containment_bool_exp!
  ): division_containment_mutation_response

  # update single row of the table: "division_containment"
  update_division_containment_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: division_containment_inc_input

    # sets the columns of the filtered rows to the given values
    _set: division_containment_set_input
    pk_columns: division_containment_pk_columns_input!
  ): division_containment

  # update data of the table: "duplum_desc"
  update_duplum_desc(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_desc_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_desc_set_input

    # filter the rows which have to be updated
    where: duplum_desc_bool_exp!
  ): duplum_desc_mutation_response

  # update data of the table: "duplum_desc_book_chapters_merged"
  update_duplum_desc_book_chapters_merged(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_desc_book_chapters_merged_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_desc_book_chapters_merged_set_input

    # filter the rows which have to be updated
    where: duplum_desc_book_chapters_merged_bool_exp!
  ): duplum_desc_book_chapters_merged_mutation_response

  # update single row of the table: "duplum_desc"
  update_duplum_desc_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_desc_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_desc_set_input
    pk_columns: duplum_desc_pk_columns_input!
  ): duplum_desc

  # update data of the table: "duplum_desc_citations_merged"
  update_duplum_desc_citations_merged(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_desc_citations_merged_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_desc_citations_merged_set_input

    # filter the rows which have to be updated
    where: duplum_desc_citations_merged_bool_exp!
  ): duplum_desc_citations_merged_mutation_response

  # update data of the table: "duplum_search_request"
  update_duplum_search_request(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_search_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_search_request_set_input

    # filter the rows which have to be updated
    where: duplum_search_request_bool_exp!
  ): duplum_search_request_mutation_response

  # update single row of the table: "duplum_search_request"
  update_duplum_search_request_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_search_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_search_request_set_input
    pk_columns: duplum_search_request_pk_columns_input!
  ): duplum_search_request

  # update data of the table: "duplum_search_result"
  update_duplum_search_result(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_search_result_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_search_result_set_input

    # filter the rows which have to be updated
    where: duplum_search_result_bool_exp!
  ): duplum_search_result_mutation_response

  # update single row of the table: "duplum_search_result"
  update_duplum_search_result_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: duplum_search_result_inc_input

    # sets the columns of the filtered rows to the given values
    _set: duplum_search_result_set_input
    pk_columns: duplum_search_result_pk_columns_input!
  ): duplum_search_result

  # update data of the table: "error_log"
  update_error_log(
    # increments the integer columns with given value of the filtered values
    _inc: error_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: error_log_set_input

    # filter the rows which have to be updated
    where: error_log_bool_exp!
  ): error_log_mutation_response

  # update single row of the table: "error_log"
  update_error_log_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: error_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: error_log_set_input
    pk_columns: error_log_pk_columns_input!
  ): error_log

  # update data of the table: "export_format"
  update_export_format(
    # increments the integer columns with given value of the filtered values
    _inc: export_format_inc_input

    # sets the columns of the filtered rows to the given values
    _set: export_format_set_input

    # filter the rows which have to be updated
    where: export_format_bool_exp!
  ): export_format_mutation_response

  # update single row of the table: "export_format"
  update_export_format_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: export_format_inc_input

    # sets the columns of the filtered rows to the given values
    _set: export_format_set_input
    pk_columns: export_format_pk_columns_input!
  ): export_format

  # update data of the table: "export_request"
  update_export_request(
    # increments the integer columns with given value of the filtered values
    _inc: export_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: export_request_set_input

    # filter the rows which have to be updated
    where: export_request_bool_exp!
  ): export_request_mutation_response

  # update single row of the table: "export_request"
  update_export_request_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: export_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: export_request_set_input
    pk_columns: export_request_pk_columns_input!
  ): export_request

  # update data of the table: "forum"
  update_forum(
    # increments the integer columns with given value of the filtered values
    _inc: forum_inc_input

    # sets the columns of the filtered rows to the given values
    _set: forum_set_input

    # filter the rows which have to be updated
    where: forum_bool_exp!
  ): forum_mutation_response

  # update single row of the table: "forum"
  update_forum_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: forum_inc_input

    # sets the columns of the filtered rows to the given values
    _set: forum_set_input
    pk_columns: forum_pk_columns_input!
  ): forum

  # update data of the table: "funding"
  update_funding(
    # increments the integer columns with given value of the filtered values
    _inc: funding_inc_input

    # sets the columns of the filtered rows to the given values
    _set: funding_set_input

    # filter the rows which have to be updated
    where: funding_bool_exp!
  ): funding_mutation_response

  # update single row of the table: "funding"
  update_funding_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: funding_inc_input

    # sets the columns of the filtered rows to the given values
    _set: funding_set_input
    pk_columns: funding_pk_columns_input!
  ): funding

  # update data of the table: "import_alias"
  update_import_alias(
    # increments the integer columns with given value of the filtered values
    _inc: import_alias_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_alias_set_input

    # filter the rows which have to be updated
    where: import_alias_bool_exp!
  ): import_alias_mutation_response

  # update single row of the table: "import_alias"
  update_import_alias_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: import_alias_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_alias_set_input
    pk_columns: import_alias_pk_columns_input!
  ): import_alias

  # update data of the table: "import_format"
  update_import_format(
    # increments the integer columns with given value of the filtered values
    _inc: import_format_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_format_set_input

    # filter the rows which have to be updated
    where: import_format_bool_exp!
  ): import_format_mutation_response

  # update single row of the table: "import_format"
  update_import_format_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: import_format_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_format_set_input
    pk_columns: import_format_pk_columns_input!
  ): import_format

  # update data of the table: "import_log"
  update_import_log(
    # increments the integer columns with given value of the filtered values
    _inc: import_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_log_set_input

    # filter the rows which have to be updated
    where: import_log_bool_exp!
  ): import_log_mutation_response

  # update single row of the table: "import_log"
  update_import_log_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: import_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_log_set_input
    pk_columns: import_log_pk_columns_input!
  ): import_log

  # update data of the table: "import_request"
  update_import_request(
    # increments the integer columns with given value of the filtered values
    _inc: import_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_request_set_input

    # filter the rows which have to be updated
    where: import_request_bool_exp!
  ): import_request_mutation_response

  # update single row of the table: "import_request"
  update_import_request_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: import_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_request_set_input
    pk_columns: import_request_pk_columns_input!
  ): import_request

  # update data of the table: "import_stat"
  update_import_stat(
    # increments the integer columns with given value of the filtered values
    _inc: import_stat_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_stat_set_input

    # filter the rows which have to be updated
    where: import_stat_bool_exp!
  ): import_stat_mutation_response

  # update single row of the table: "import_stat"
  update_import_stat_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: import_stat_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_stat_set_input
    pk_columns: import_stat_pk_columns_input!
  ): import_stat

  # update data of the table: "import_stat_import_error_details"
  update_import_stat_import_error_details(
    # increments the integer columns with given value of the filtered values
    _inc: import_stat_import_error_details_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_stat_import_error_details_set_input

    # filter the rows which have to be updated
    where: import_stat_import_error_details_bool_exp!
  ): import_stat_import_error_details_mutation_response

  # update data of the table: "import_stat_wos_ids"
  update_import_stat_wos_ids(
    # increments the integer columns with given value of the filtered values
    _inc: import_stat_wos_ids_inc_input

    # sets the columns of the filtered rows to the given values
    _set: import_stat_wos_ids_set_input

    # filter the rows which have to be updated
    where: import_stat_wos_ids_bool_exp!
  ): import_stat_wos_ids_mutation_response

  # update data of the table: "institute_type"
  update_institute_type(
    # increments the integer columns with given value of the filtered values
    _inc: institute_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: institute_type_set_input

    # filter the rows which have to be updated
    where: institute_type_bool_exp!
  ): institute_type_mutation_response

  # update single row of the table: "institute_type"
  update_institute_type_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: institute_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: institute_type_set_input
    pk_columns: institute_type_pk_columns_input!
  ): institute_type

  # update data of the table: "journal_successors"
  update_journal_successors(
    # increments the integer columns with given value of the filtered values
    _inc: journal_successors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: journal_successors_set_input

    # filter the rows which have to be updated
    where: journal_successors_bool_exp!
  ): journal_successors_mutation_response

  # update data of the table: "keyword"
  update_keyword(
    # increments the integer columns with given value of the filtered values
    _inc: keyword_inc_input

    # sets the columns of the filtered rows to the given values
    _set: keyword_set_input

    # filter the rows which have to be updated
    where: keyword_bool_exp!
  ): keyword_mutation_response

  # update single row of the table: "keyword"
  update_keyword_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: keyword_inc_input

    # sets the columns of the filtered rows to the given values
    _set: keyword_set_input
    pk_columns: keyword_pk_columns_input!
  ): keyword

  # update data of the table: "language"
  update_language(
    # increments the integer columns with given value of the filtered values
    _inc: language_inc_input

    # sets the columns of the filtered rows to the given values
    _set: language_set_input

    # filter the rows which have to be updated
    where: language_bool_exp!
  ): language_mutation_response

  # update single row of the table: "language"
  update_language_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: language_inc_input

    # sets the columns of the filtered rows to the given values
    _set: language_set_input
    pk_columns: language_pk_columns_input!
  ): language

  # update data of the table: "localized_message"
  update_localized_message(
    # increments the integer columns with given value of the filtered values
    _inc: localized_message_inc_input

    # sets the columns of the filtered rows to the given values
    _set: localized_message_set_input

    # filter the rows which have to be updated
    where: localized_message_bool_exp!
  ): localized_message_mutation_response

  # update single row of the table: "localized_message"
  update_localized_message_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: localized_message_inc_input

    # sets the columns of the filtered rows to the given values
    _set: localized_message_set_input
    pk_columns: localized_message_pk_columns_input!
  ): localized_message

  # update data of the table: "location"
  update_location(
    # increments the integer columns with given value of the filtered values
    _inc: location_inc_input

    # sets the columns of the filtered rows to the given values
    _set: location_set_input

    # filter the rows which have to be updated
    where: location_bool_exp!
  ): location_mutation_response

  # update single row of the table: "location"
  update_location_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: location_inc_input

    # sets the columns of the filtered rows to the given values
    _set: location_set_input
    pk_columns: location_pk_columns_input!
  ): location

  # update data of the table: "lock_list"
  update_lock_list(
    # increments the integer columns with given value of the filtered values
    _inc: lock_list_inc_input

    # sets the columns of the filtered rows to the given values
    _set: lock_list_set_input

    # filter the rows which have to be updated
    where: lock_list_bool_exp!
  ): lock_list_mutation_response

  # update single row of the table: "lock_list"
  update_lock_list_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: lock_list_inc_input

    # sets the columns of the filtered rows to the given values
    _set: lock_list_set_input
    pk_columns: lock_list_pk_columns_input!
  ): lock_list

  # update data of the table: "lock_list_delegated_admins"
  update_lock_list_delegated_admins(
    # increments the integer columns with given value of the filtered values
    _inc: lock_list_delegated_admins_inc_input

    # sets the columns of the filtered rows to the given values
    _set: lock_list_delegated_admins_set_input

    # filter the rows which have to be updated
    where: lock_list_delegated_admins_bool_exp!
  ): lock_list_delegated_admins_mutation_response

  # update data of the table: "mab_discipline"
  update_mab_discipline(
    # increments the integer columns with given value of the filtered values
    _inc: mab_discipline_inc_input

    # sets the columns of the filtered rows to the given values
    _set: mab_discipline_set_input

    # filter the rows which have to be updated
    where: mab_discipline_bool_exp!
  ): mab_discipline_mutation_response

  # update single row of the table: "mab_discipline"
  update_mab_discipline_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: mab_discipline_inc_input

    # sets the columns of the filtered rows to the given values
    _set: mab_discipline_set_input
    pk_columns: mab_discipline_pk_columns_input!
  ): mab_discipline

  # update data of the table: "mention"
  update_mention(
    # increments the integer columns with given value of the filtered values
    _inc: mention_inc_input

    # sets the columns of the filtered rows to the given values
    _set: mention_set_input

    # filter the rows which have to be updated
    where: mention_bool_exp!
  ): mention_mutation_response

  # update single row of the table: "mention"
  update_mention_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: mention_inc_input

    # sets the columns of the filtered rows to the given values
    _set: mention_set_input
    pk_columns: mention_pk_columns_input!
  ): mention

  # update data of the table: "message"
  update_message(
    # increments the integer columns with given value of the filtered values
    _inc: message_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_set_input

    # filter the rows which have to be updated
    where: message_bool_exp!
  ): message_mutation_response

  # update single row of the table: "message"
  update_message_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: message_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_set_input
    pk_columns: message_pk_columns_input!
  ): message

  # update data of the table: "message_files"
  update_message_files(
    # increments the integer columns with given value of the filtered values
    _inc: message_files_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_files_set_input

    # filter the rows which have to be updated
    where: message_files_bool_exp!
  ): message_files_mutation_response

  # update data of the table: "message_institutes"
  update_message_institutes(
    # increments the integer columns with given value of the filtered values
    _inc: message_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_institutes_set_input

    # filter the rows which have to be updated
    where: message_institutes_bool_exp!
  ): message_institutes_mutation_response

  # update single row of the table: "message_institutes"
  update_message_institutes_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: message_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_institutes_set_input
    pk_columns: message_institutes_pk_columns_input!
  ): message_institutes

  # update data of the table: "message_mailboxes"
  update_message_mailboxes(
    # increments the integer columns with given value of the filtered values
    _inc: message_mailboxes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_mailboxes_set_input

    # filter the rows which have to be updated
    where: message_mailboxes_bool_exp!
  ): message_mailboxes_mutation_response

  # update data of the table: "message_parameter"
  update_message_parameter(
    # increments the integer columns with given value of the filtered values
    _inc: message_parameter_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_parameter_set_input

    # filter the rows which have to be updated
    where: message_parameter_bool_exp!
  ): message_parameter_mutation_response

  # update single row of the table: "message_parameter"
  update_message_parameter_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: message_parameter_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_parameter_set_input
    pk_columns: message_parameter_pk_columns_input!
  ): message_parameter

  # update data of the table: "message_recipients"
  update_message_recipients(
    # increments the integer columns with given value of the filtered values
    _inc: message_recipients_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_recipients_set_input

    # filter the rows which have to be updated
    where: message_recipients_bool_exp!
  ): message_recipients_mutation_response

  # update data of the table: "message_sent"
  update_message_sent(
    # increments the integer columns with given value of the filtered values
    _inc: message_sent_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_sent_set_input

    # filter the rows which have to be updated
    where: message_sent_bool_exp!
  ): message_sent_mutation_response

  # update single row of the table: "message_sent"
  update_message_sent_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: message_sent_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_sent_set_input
    pk_columns: message_sent_pk_columns_input!
  ): message_sent

  # update data of the table: "message_template"
  update_message_template(
    # increments the integer columns with given value of the filtered values
    _inc: message_template_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_template_set_input

    # filter the rows which have to be updated
    where: message_template_bool_exp!
  ): message_template_mutation_response

  # update single row of the table: "message_template"
  update_message_template_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: message_template_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_template_set_input
    pk_columns: message_template_pk_columns_input!
  ): message_template

  # update data of the table: "message_template_parameters"
  update_message_template_parameters(
    # increments the integer columns with given value of the filtered values
    _inc: message_template_parameters_inc_input

    # sets the columns of the filtered rows to the given values
    _set: message_template_parameters_set_input

    # filter the rows which have to be updated
    where: message_template_parameters_bool_exp!
  ): message_template_parameters_mutation_response

  # update data of the table: "mycite_revision_entity"
  update_mycite_revision_entity(
    # increments the integer columns with given value of the filtered values
    _inc: mycite_revision_entity_inc_input

    # sets the columns of the filtered rows to the given values
    _set: mycite_revision_entity_set_input

    # filter the rows which have to be updated
    where: mycite_revision_entity_bool_exp!
  ): mycite_revision_entity_mutation_response

  # update single row of the table: "mycite_revision_entity"
  update_mycite_revision_entity_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: mycite_revision_entity_inc_input

    # sets the columns of the filtered rows to the given values
    _set: mycite_revision_entity_set_input
    pk_columns: mycite_revision_entity_pk_columns_input!
  ): mycite_revision_entity

  # update data of the table: "named_list"
  update_named_list(
    # increments the integer columns with given value of the filtered values
    _inc: named_list_inc_input

    # sets the columns of the filtered rows to the given values
    _set: named_list_set_input

    # filter the rows which have to be updated
    where: named_list_bool_exp!
  ): named_list_mutation_response

  # update single row of the table: "named_list"
  update_named_list_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: named_list_inc_input

    # sets the columns of the filtered rows to the given values
    _set: named_list_set_input
    pk_columns: named_list_pk_columns_input!
  ): named_list

  # update data of the table: "not_duplums"
  update_not_duplums(
    # increments the integer columns with given value of the filtered values
    _inc: not_duplums_inc_input

    # sets the columns of the filtered rows to the given values
    _set: not_duplums_set_input

    # filter the rows which have to be updated
    where: not_duplums_bool_exp!
  ): not_duplums_mutation_response

  # update single row of the table: "not_duplums"
  update_not_duplums_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: not_duplums_inc_input

    # sets the columns of the filtered rows to the given values
    _set: not_duplums_set_input
    pk_columns: not_duplums_pk_columns_input!
  ): not_duplums

  # update data of the table: "not_duplums_not_duplum_ids"
  update_not_duplums_not_duplum_ids(
    # increments the integer columns with given value of the filtered values
    _inc: not_duplums_not_duplum_ids_inc_input

    # sets the columns of the filtered rows to the given values
    _set: not_duplums_not_duplum_ids_set_input

    # filter the rows which have to be updated
    where: not_duplums_not_duplum_ids_bool_exp!
  ): not_duplums_not_duplum_ids_mutation_response

  # update data of the table: "organization"
  update_organization(
    # increments the integer columns with given value of the filtered values
    _inc: organization_inc_input

    # sets the columns of the filtered rows to the given values
    _set: organization_set_input

    # filter the rows which have to be updated
    where: organization_bool_exp!
  ): organization_mutation_response

  # update single row of the table: "organization"
  update_organization_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: organization_inc_input

    # sets the columns of the filtered rows to the given values
    _set: organization_set_input
    pk_columns: organization_pk_columns_input!
  ): organization

  # update data of the table: "organization_identifier"
  update_organization_identifier(
    # increments the integer columns with given value of the filtered values
    _inc: organization_identifier_inc_input

    # sets the columns of the filtered rows to the given values
    _set: organization_identifier_set_input

    # filter the rows which have to be updated
    where: organization_identifier_bool_exp!
  ): organization_identifier_mutation_response

  # update single row of the table: "organization_identifier"
  update_organization_identifier_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: organization_identifier_inc_input

    # sets the columns of the filtered rows to the given values
    _set: organization_identifier_set_input
    pk_columns: organization_identifier_pk_columns_input!
  ): organization_identifier

  # update data of the table: "organization_mab_disciplines"
  update_organization_mab_disciplines(
    # increments the integer columns with given value of the filtered values
    _inc: organization_mab_disciplines_inc_input

    # sets the columns of the filtered rows to the given values
    _set: organization_mab_disciplines_set_input

    # filter the rows which have to be updated
    where: organization_mab_disciplines_bool_exp!
  ): organization_mab_disciplines_mutation_response

  # update data of the table: "periodical"
  update_periodical(
    # increments the integer columns with given value of the filtered values
    _inc: periodical_inc_input

    # sets the columns of the filtered rows to the given values
    _set: periodical_set_input

    # filter the rows which have to be updated
    where: periodical_bool_exp!
  ): periodical_mutation_response

  # update single row of the table: "periodical"
  update_periodical_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: periodical_inc_input

    # sets the columns of the filtered rows to the given values
    _set: periodical_set_input
    pk_columns: periodical_pk_columns_input!
  ): periodical

  # update data of the table: "periodical_issn"
  update_periodical_issn(
    # increments the integer columns with given value of the filtered values
    _inc: periodical_issn_inc_input

    # sets the columns of the filtered rows to the given values
    _set: periodical_issn_set_input

    # filter the rows which have to be updated
    where: periodical_issn_bool_exp!
  ): periodical_issn_mutation_response

  # update single row of the table: "periodical_issn"
  update_periodical_issn_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: periodical_issn_inc_input

    # sets the columns of the filtered rows to the given values
    _set: periodical_issn_set_input
    pk_columns: periodical_issn_pk_columns_input!
  ): periodical_issn

  # update data of the table: "periodical_publishers"
  update_periodical_publishers(
    # increments the integer columns with given value of the filtered values
    _inc: periodical_publishers_inc_input

    # sets the columns of the filtered rows to the given values
    _set: periodical_publishers_set_input

    # filter the rows which have to be updated
    where: periodical_publishers_bool_exp!
  ): periodical_publishers_mutation_response

  # update data of the table: "periodical_subjects_external"
  update_periodical_subjects_external(
    # increments the integer columns with given value of the filtered values
    _inc: periodical_subjects_external_inc_input

    # sets the columns of the filtered rows to the given values
    _set: periodical_subjects_external_set_input

    # filter the rows which have to be updated
    where: periodical_subjects_external_bool_exp!
  ): periodical_subjects_external_mutation_response

  # update data of the table: "project"
  update_project(
    # increments the integer columns with given value of the filtered values
    _inc: project_inc_input

    # sets the columns of the filtered rows to the given values
    _set: project_set_input

    # filter the rows which have to be updated
    where: project_bool_exp!
  ): project_mutation_response

  # update single row of the table: "project"
  update_project_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: project_inc_input

    # sets the columns of the filtered rows to the given values
    _set: project_set_input
    pk_columns: project_pk_columns_input!
  ): project

  # update data of the table: "pub_fixer_log"
  update_pub_fixer_log(
    # increments the integer columns with given value of the filtered values
    _inc: pub_fixer_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: pub_fixer_log_set_input

    # filter the rows which have to be updated
    where: pub_fixer_log_bool_exp!
  ): pub_fixer_log_mutation_response

  # update single row of the table: "pub_fixer_log"
  update_pub_fixer_log_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: pub_fixer_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: pub_fixer_log_set_input
    pk_columns: pub_fixer_log_pk_columns_input!
  ): pub_fixer_log

  # update data of the table: "publication"
  update_publication(
    # increments the integer columns with given value of the filtered values
    _inc: publication_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_set_input

    # filter the rows which have to be updated
    where: publication_bool_exp!
  ): publication_mutation_response

  # update data of the table: "publication_authors"
  update_publication_authors(
    # increments the integer columns with given value of the filtered values
    _inc: publication_authors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_authors_set_input

    # filter the rows which have to be updated
    where: publication_authors_bool_exp!
  ): publication_authors_mutation_response

  # update single row of the table: "publication_authors"
  update_publication_authors_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_authors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_authors_set_input
    pk_columns: publication_authors_pk_columns_input!
  ): publication_authors

  # update single row of the table: "publication"
  update_publication_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_set_input
    pk_columns: publication_pk_columns_input!
  ): publication

  # update data of the table: "publication_direct_institutes"
  update_publication_direct_institutes(
    # increments the integer columns with given value of the filtered values
    _inc: publication_direct_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_direct_institutes_set_input

    # filter the rows which have to be updated
    where: publication_direct_institutes_bool_exp!
  ): publication_direct_institutes_mutation_response

  # update single row of the table: "publication_direct_institutes"
  update_publication_direct_institutes_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_direct_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_direct_institutes_set_input
    pk_columns: publication_direct_institutes_pk_columns_input!
  ): publication_direct_institutes

  # update data of the table: "publication_files"
  update_publication_files(
    # increments the integer columns with given value of the filtered values
    _inc: publication_files_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_files_set_input

    # filter the rows which have to be updated
    where: publication_files_bool_exp!
  ): publication_files_mutation_response

  # update data of the table: "publication_identifier"
  update_publication_identifier(
    # increments the integer columns with given value of the filtered values
    _inc: publication_identifier_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_identifier_set_input

    # filter the rows which have to be updated
    where: publication_identifier_bool_exp!
  ): publication_identifier_mutation_response

  # update single row of the table: "publication_identifier"
  update_publication_identifier_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_identifier_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_identifier_set_input
    pk_columns: publication_identifier_pk_columns_input!
  ): publication_identifier

  # update data of the table: "publication_institutes"
  update_publication_institutes(
    # increments the integer columns with given value of the filtered values
    _inc: publication_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_institutes_set_input

    # filter the rows which have to be updated
    where: publication_institutes_bool_exp!
  ): publication_institutes_mutation_response

  # update single row of the table: "publication_institutes"
  update_publication_institutes_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_institutes_set_input
    pk_columns: publication_institutes_pk_columns_input!
  ): publication_institutes

  # update data of the table: "publication_keywords"
  update_publication_keywords(
    # increments the integer columns with given value of the filtered values
    _inc: publication_keywords_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_keywords_set_input

    # filter the rows which have to be updated
    where: publication_keywords_bool_exp!
  ): publication_keywords_mutation_response

  # update data of the table: "publication_languages"
  update_publication_languages(
    # increments the integer columns with given value of the filtered values
    _inc: publication_languages_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_languages_set_input

    # filter the rows which have to be updated
    where: publication_languages_bool_exp!
  ): publication_languages_mutation_response

  # update data of the table: "publication_old_org_authors"
  update_publication_old_org_authors(
    # increments the integer columns with given value of the filtered values
    _inc: publication_old_org_authors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_old_org_authors_set_input

    # filter the rows which have to be updated
    where: publication_old_org_authors_bool_exp!
  ): publication_old_org_authors_mutation_response

  # update data of the table: "publication_owner_authors"
  update_publication_owner_authors(
    # increments the integer columns with given value of the filtered values
    _inc: publication_owner_authors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_owner_authors_set_input

    # filter the rows which have to be updated
    where: publication_owner_authors_bool_exp!
  ): publication_owner_authors_mutation_response

  # update single row of the table: "publication_owner_authors"
  update_publication_owner_authors_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_owner_authors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_owner_authors_set_input
    pk_columns: publication_owner_authors_pk_columns_input!
  ): publication_owner_authors

  # update data of the table: "publication_owner_institutes"
  update_publication_owner_institutes(
    # increments the integer columns with given value of the filtered values
    _inc: publication_owner_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_owner_institutes_set_input

    # filter the rows which have to be updated
    where: publication_owner_institutes_bool_exp!
  ): publication_owner_institutes_mutation_response

  # update single row of the table: "publication_owner_institutes"
  update_publication_owner_institutes_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_owner_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_owner_institutes_set_input
    pk_columns: publication_owner_institutes_pk_columns_input!
  ): publication_owner_institutes

  # update data of the table: "publication_owners"
  update_publication_owners(
    # increments the integer columns with given value of the filtered values
    _inc: publication_owners_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_owners_set_input

    # filter the rows which have to be updated
    where: publication_owners_bool_exp!
  ): publication_owners_mutation_response

  # update data of the table: "publication_published_at"
  update_publication_published_at(
    # increments the integer columns with given value of the filtered values
    _inc: publication_published_at_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_published_at_set_input

    # filter the rows which have to be updated
    where: publication_published_at_bool_exp!
  ): publication_published_at_mutation_response

  # update data of the table: "publication_publishers"
  update_publication_publishers(
    # increments the integer columns with given value of the filtered values
    _inc: publication_publishers_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_publishers_set_input

    # filter the rows which have to be updated
    where: publication_publishers_bool_exp!
  ): publication_publishers_mutation_response

  # update data of the table: "publication_ratings"
  update_publication_ratings(
    # increments the integer columns with given value of the filtered values
    _inc: publication_ratings_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_ratings_set_input

    # filter the rows which have to be updated
    where: publication_ratings_bool_exp!
  ): publication_ratings_mutation_response

  # update data of the table: "publication_source_type"
  update_publication_source_type(
    # increments the integer columns with given value of the filtered values
    _inc: publication_source_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_source_type_set_input

    # filter the rows which have to be updated
    where: publication_source_type_bool_exp!
  ): publication_source_type_mutation_response

  # update single row of the table: "publication_source_type"
  update_publication_source_type_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_source_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_source_type_set_input
    pk_columns: publication_source_type_pk_columns_input!
  ): publication_source_type

  # update data of the table: "publication_subjects"
  update_publication_subjects(
    # increments the integer columns with given value of the filtered values
    _inc: publication_subjects_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_subjects_set_input

    # filter the rows which have to be updated
    where: publication_subjects_bool_exp!
  ): publication_subjects_mutation_response

  # update data of the table: "publication_type"
  update_publication_type(
    # increments the integer columns with given value of the filtered values
    _inc: publication_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_type_set_input

    # filter the rows which have to be updated
    where: publication_type_bool_exp!
  ): publication_type_mutation_response

  # update single row of the table: "publication_type"
  update_publication_type_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publication_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publication_type_set_input
    pk_columns: publication_type_pk_columns_input!
  ): publication_type

  # update data of the table: "publisher"
  update_publisher(
    # increments the integer columns with given value of the filtered values
    _inc: publisher_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publisher_set_input

    # filter the rows which have to be updated
    where: publisher_bool_exp!
  ): publisher_mutation_response

  # update single row of the table: "publisher"
  update_publisher_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: publisher_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publisher_set_input
    pk_columns: publisher_pk_columns_input!
  ): publisher

  # update data of the table: "publisher_cities"
  update_publisher_cities(
    # increments the integer columns with given value of the filtered values
    _inc: publisher_cities_inc_input

    # sets the columns of the filtered rows to the given values
    _set: publisher_cities_set_input

    # filter the rows which have to be updated
    where: publisher_cities_bool_exp!
  ): publisher_cities_mutation_response

  # update data of the table: "query_info"
  update_query_info(
    # increments the integer columns with given value of the filtered values
    _inc: query_info_inc_input

    # sets the columns of the filtered rows to the given values
    _set: query_info_set_input

    # filter the rows which have to be updated
    where: query_info_bool_exp!
  ): query_info_mutation_response

  # update single row of the table: "query_info"
  update_query_info_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: query_info_inc_input

    # sets the columns of the filtered rows to the given values
    _set: query_info_set_input
    pk_columns: query_info_pk_columns_input!
  ): query_info

  # update data of the table: "queued_background_job"
  update_queued_background_job(
    # increments the integer columns with given value of the filtered values
    _inc: queued_background_job_inc_input

    # sets the columns of the filtered rows to the given values
    _set: queued_background_job_set_input

    # filter the rows which have to be updated
    where: queued_background_job_bool_exp!
  ): queued_background_job_mutation_response

  # update single row of the table: "queued_background_job"
  update_queued_background_job_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: queued_background_job_inc_input

    # sets the columns of the filtered rows to the given values
    _set: queued_background_job_set_input
    pk_columns: queued_background_job_pk_columns_input!
  ): queued_background_job

  # update data of the table: "rating"
  update_rating(
    # increments the integer columns with given value of the filtered values
    _inc: rating_inc_input

    # sets the columns of the filtered rows to the given values
    _set: rating_set_input

    # filter the rows which have to be updated
    where: rating_bool_exp!
  ): rating_mutation_response

  # update single row of the table: "rating"
  update_rating_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: rating_inc_input

    # sets the columns of the filtered rows to the given values
    _set: rating_set_input
    pk_columns: rating_pk_columns_input!
  ): rating

  # update data of the table: "rating_type"
  update_rating_type(
    # increments the integer columns with given value of the filtered values
    _inc: rating_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: rating_type_set_input

    # filter the rows which have to be updated
    where: rating_type_bool_exp!
  ): rating_type_mutation_response

  # update single row of the table: "rating_type"
  update_rating_type_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: rating_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: rating_type_set_input
    pk_columns: rating_type_pk_columns_input!
  ): rating_type

  # update data of the table: "recalculate_institute_ownerships_request"
  update_recalculate_institute_ownerships_request(
    # increments the integer columns with given value of the filtered values
    _inc: recalculate_institute_ownerships_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: recalculate_institute_ownerships_request_set_input

    # filter the rows which have to be updated
    where: recalculate_institute_ownerships_request_bool_exp!
  ): recalculate_institute_ownerships_request_mutation_response

  # update data of the table: "recalculate_institute_ownerships_request_affected_institutes"
  update_recalculate_institute_ownerships_request_affected_institutes(
    # increments the integer columns with given value of the filtered values
    _inc: recalculate_institute_ownerships_request_affected_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: recalculate_institute_ownerships_request_affected_institutes_set_input

    # filter the rows which have to be updated
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp!
  ): recalculate_institute_ownerships_request_affected_institutes_mutation_response

  # update single row of the table: "recalculate_institute_ownerships_request_affected_institutes"
  update_recalculate_institute_ownerships_request_affected_institutes_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: recalculate_institute_ownerships_request_affected_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: recalculate_institute_ownerships_request_affected_institutes_set_input
    pk_columns: recalculate_institute_ownerships_request_affected_institutes_pk_columns_input!
  ): recalculate_institute_ownerships_request_affected_institutes

  # update single row of the table: "recalculate_institute_ownerships_request"
  update_recalculate_institute_ownerships_request_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: recalculate_institute_ownerships_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: recalculate_institute_ownerships_request_set_input
    pk_columns: recalculate_institute_ownerships_request_pk_columns_input!
  ): recalculate_institute_ownerships_request

  # update data of the table: "reference"
  update_reference(
    # increments the integer columns with given value of the filtered values
    _inc: reference_inc_input

    # sets the columns of the filtered rows to the given values
    _set: reference_set_input

    # filter the rows which have to be updated
    where: reference_bool_exp!
  ): reference_mutation_response

  # update single row of the table: "reference"
  update_reference_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: reference_inc_input

    # sets the columns of the filtered rows to the given values
    _set: reference_set_input
    pk_columns: reference_pk_columns_input!
  ): reference

  # update data of the table: "refresh_item"
  update_refresh_item(
    # increments the integer columns with given value of the filtered values
    _inc: refresh_item_inc_input

    # sets the columns of the filtered rows to the given values
    _set: refresh_item_set_input

    # filter the rows which have to be updated
    where: refresh_item_bool_exp!
  ): refresh_item_mutation_response

  # update single row of the table: "refresh_item"
  update_refresh_item_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: refresh_item_inc_input

    # sets the columns of the filtered rows to the given values
    _set: refresh_item_set_input
    pk_columns: refresh_item_pk_columns_input!
  ): refresh_item

  # update data of the table: "refresh_log"
  update_refresh_log(
    # increments the integer columns with given value of the filtered values
    _inc: refresh_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: refresh_log_set_input

    # filter the rows which have to be updated
    where: refresh_log_bool_exp!
  ): refresh_log_mutation_response

  # update single row of the table: "refresh_log"
  update_refresh_log_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: refresh_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: refresh_log_set_input
    pk_columns: refresh_log_pk_columns_input!
  ): refresh_log

  # update data of the table: "reorg"
  update_reorg(
    # increments the integer columns with given value of the filtered values
    _inc: reorg_inc_input

    # sets the columns of the filtered rows to the given values
    _set: reorg_set_input

    # filter the rows which have to be updated
    where: reorg_bool_exp!
  ): reorg_mutation_response

  # update single row of the table: "reorg"
  update_reorg_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: reorg_inc_input

    # sets the columns of the filtered rows to the given values
    _set: reorg_set_input
    pk_columns: reorg_pk_columns_input!
  ): reorg

  # update data of the table: "reorg_type"
  update_reorg_type(
    # increments the integer columns with given value of the filtered values
    _inc: reorg_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: reorg_type_set_input

    # filter the rows which have to be updated
    where: reorg_type_bool_exp!
  ): reorg_type_mutation_response

  # update single row of the table: "reorg_type"
  update_reorg_type_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: reorg_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: reorg_type_set_input
    pk_columns: reorg_type_pk_columns_input!
  ): reorg_type

  # update data of the table: "report"
  update_report(
    # increments the integer columns with given value of the filtered values
    _inc: report_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_set_input

    # filter the rows which have to be updated
    where: report_bool_exp!
  ): report_mutation_response

  # update single row of the table: "report"
  update_report_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: report_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_set_input
    pk_columns: report_pk_columns_input!
  ): report

  # update data of the table: "report_content"
  update_report_content(
    # increments the integer columns with given value of the filtered values
    _inc: report_content_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_content_set_input

    # filter the rows which have to be updated
    where: report_content_bool_exp!
  ): report_content_mutation_response

  # update single row of the table: "report_content"
  update_report_content_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: report_content_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_content_set_input
    pk_columns: report_content_pk_columns_input!
  ): report_content

  # update data of the table: "report_content_file_content"
  update_report_content_file_content(
    # increments the integer columns with given value of the filtered values
    _inc: report_content_file_content_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_content_file_content_set_input

    # filter the rows which have to be updated
    where: report_content_file_content_bool_exp!
  ): report_content_file_content_mutation_response

  # update data of the table: "report_contents"
  update_report_contents(
    # increments the integer columns with given value of the filtered values
    _inc: report_contents_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_contents_set_input

    # filter the rows which have to be updated
    where: report_contents_bool_exp!
  ): report_contents_mutation_response

  # update data of the table: "report_parameter"
  update_report_parameter(
    # increments the integer columns with given value of the filtered values
    _inc: report_parameter_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_parameter_set_input

    # filter the rows which have to be updated
    where: report_parameter_bool_exp!
  ): report_parameter_mutation_response

  # update single row of the table: "report_parameter"
  update_report_parameter_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: report_parameter_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_parameter_set_input
    pk_columns: report_parameter_pk_columns_input!
  ): report_parameter

  # update data of the table: "report_request"
  update_report_request(
    # increments the integer columns with given value of the filtered values
    _inc: report_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_request_set_input

    # filter the rows which have to be updated
    where: report_request_bool_exp!
  ): report_request_mutation_response

  # update single row of the table: "report_request"
  update_report_request_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: report_request_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_request_set_input
    pk_columns: report_request_pk_columns_input!
  ): report_request

  # update data of the table: "report_request_queries"
  update_report_request_queries(
    # increments the integer columns with given value of the filtered values
    _inc: report_request_queries_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_request_queries_set_input

    # filter the rows which have to be updated
    where: report_request_queries_bool_exp!
  ): report_request_queries_mutation_response

  # update data of the table: "report_template"
  update_report_template(
    # increments the integer columns with given value of the filtered values
    _inc: report_template_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_template_set_input

    # filter the rows which have to be updated
    where: report_template_bool_exp!
  ): report_template_mutation_response

  # update single row of the table: "report_template"
  update_report_template_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: report_template_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_template_set_input
    pk_columns: report_template_pk_columns_input!
  ): report_template

  # update data of the table: "report_template_default_queries"
  update_report_template_default_queries(
    # increments the integer columns with given value of the filtered values
    _inc: report_template_default_queries_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_template_default_queries_set_input

    # filter the rows which have to be updated
    where: report_template_default_queries_bool_exp!
  ): report_template_default_queries_mutation_response

  # update data of the table: "report_template_language_files"
  update_report_template_language_files(
    # increments the integer columns with given value of the filtered values
    _inc: report_template_language_files_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_template_language_files_set_input

    # filter the rows which have to be updated
    where: report_template_language_files_bool_exp!
  ): report_template_language_files_mutation_response

  # update data of the table: "report_template_parameter_select"
  update_report_template_parameter_select(
    # increments the integer columns with given value of the filtered values
    _inc: report_template_parameter_select_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_template_parameter_select_set_input

    # filter the rows which have to be updated
    where: report_template_parameter_select_bool_exp!
  ): report_template_parameter_select_mutation_response

  # update single row of the table: "report_template_parameter_select"
  update_report_template_parameter_select_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: report_template_parameter_select_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_template_parameter_select_set_input
    pk_columns: report_template_parameter_select_pk_columns_input!
  ): report_template_parameter_select

  # update data of the table: "report_xml"
  update_report_xml(
    # increments the integer columns with given value of the filtered values
    _inc: report_xml_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_xml_set_input

    # filter the rows which have to be updated
    where: report_xml_bool_exp!
  ): report_xml_mutation_response

  # update single row of the table: "report_xml"
  update_report_xml_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: report_xml_inc_input

    # sets the columns of the filtered rows to the given values
    _set: report_xml_set_input
    pk_columns: report_xml_pk_columns_input!
  ): report_xml

  # update data of the table: "ris_import_error_detail"
  update_ris_import_error_detail(
    # increments the integer columns with given value of the filtered values
    _inc: ris_import_error_detail_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ris_import_error_detail_set_input

    # filter the rows which have to be updated
    where: ris_import_error_detail_bool_exp!
  ): ris_import_error_detail_mutation_response

  # update single row of the table: "ris_import_error_detail"
  update_ris_import_error_detail_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: ris_import_error_detail_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ris_import_error_detail_set_input
    pk_columns: ris_import_error_detail_pk_columns_input!
  ): ris_import_error_detail

  # update data of the table: "series_volume"
  update_series_volume(
    # increments the integer columns with given value of the filtered values
    _inc: series_volume_inc_input

    # sets the columns of the filtered rows to the given values
    _set: series_volume_set_input

    # filter the rows which have to be updated
    where: series_volume_bool_exp!
  ): series_volume_mutation_response

  # update single row of the table: "series_volume"
  update_series_volume_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: series_volume_inc_input

    # sets the columns of the filtered rows to the given values
    _set: series_volume_set_input
    pk_columns: series_volume_pk_columns_input!
  ): series_volume

  # update data of the table: "shib_id_provider"
  update_shib_id_provider(
    # increments the integer columns with given value of the filtered values
    _inc: shib_id_provider_inc_input

    # sets the columns of the filtered rows to the given values
    _set: shib_id_provider_set_input

    # filter the rows which have to be updated
    where: shib_id_provider_bool_exp!
  ): shib_id_provider_mutation_response

  # update single row of the table: "shib_id_provider"
  update_shib_id_provider_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: shib_id_provider_inc_input

    # sets the columns of the filtered rows to the given values
    _set: shib_id_provider_set_input
    pk_columns: shib_id_provider_pk_columns_input!
  ): shib_id_provider

  # update data of the table: "smart_query"
  update_smart_query(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_set_input

    # filter the rows which have to be updated
    where: smart_query_bool_exp!
  ): smart_query_mutation_response

  # update single row of the table: "smart_query"
  update_smart_query_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_set_input
    pk_columns: smart_query_pk_columns_input!
  ): smart_query

  # update data of the table: "smart_query_cond"
  update_smart_query_cond(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_cond_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_cond_set_input

    # filter the rows which have to be updated
    where: smart_query_cond_bool_exp!
  ): smart_query_cond_mutation_response

  # update single row of the table: "smart_query_cond"
  update_smart_query_cond_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_cond_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_cond_set_input
    pk_columns: smart_query_cond_pk_columns_input!
  ): smart_query_cond

  # update data of the table: "smart_query_group"
  update_smart_query_group(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_group_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_group_set_input

    # filter the rows which have to be updated
    where: smart_query_group_bool_exp!
  ): smart_query_group_mutation_response

  # update single row of the table: "smart_query_group"
  update_smart_query_group_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_group_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_group_set_input
    pk_columns: smart_query_group_pk_columns_input!
  ): smart_query_group

  # update data of the table: "smart_query_sort"
  update_smart_query_sort(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_sort_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_sort_set_input

    # filter the rows which have to be updated
    where: smart_query_sort_bool_exp!
  ): smart_query_sort_mutation_response

  # update single row of the table: "smart_query_sort"
  update_smart_query_sort_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: smart_query_sort_inc_input

    # sets the columns of the filtered rows to the given values
    _set: smart_query_sort_set_input
    pk_columns: smart_query_sort_pk_columns_input!
  ): smart_query_sort

  # update data of the table: "snippet_cache"
  update_snippet_cache(
    # increments the integer columns with given value of the filtered values
    _inc: snippet_cache_inc_input

    # sets the columns of the filtered rows to the given values
    _set: snippet_cache_set_input

    # filter the rows which have to be updated
    where: snippet_cache_bool_exp!
  ): snippet_cache_mutation_response

  # update single row of the table: "snippet_cache"
  update_snippet_cache_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: snippet_cache_inc_input

    # sets the columns of the filtered rows to the given values
    _set: snippet_cache_set_input
    pk_columns: snippet_cache_pk_columns_input!
  ): snippet_cache

  # update data of the table: "snippet_cache_status"
  update_snippet_cache_status(
    # increments the integer columns with given value of the filtered values
    _inc: snippet_cache_status_inc_input

    # sets the columns of the filtered rows to the given values
    _set: snippet_cache_status_set_input

    # filter the rows which have to be updated
    where: snippet_cache_status_bool_exp!
  ): snippet_cache_status_mutation_response

  # update single row of the table: "snippet_cache_status"
  update_snippet_cache_status_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: snippet_cache_status_inc_input

    # sets the columns of the filtered rows to the given values
    _set: snippet_cache_status_set_input
    pk_columns: snippet_cache_status_pk_columns_input!
  ): snippet_cache_status

  # update data of the table: "source"
  update_source(
    # increments the integer columns with given value of the filtered values
    _inc: source_inc_input

    # sets the columns of the filtered rows to the given values
    _set: source_set_input

    # filter the rows which have to be updated
    where: source_bool_exp!
  ): source_mutation_response

  # update data of the table: "source_allowed_institutes"
  update_source_allowed_institutes(
    # increments the integer columns with given value of the filtered values
    _inc: source_allowed_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: source_allowed_institutes_set_input

    # filter the rows which have to be updated
    where: source_allowed_institutes_bool_exp!
  ): source_allowed_institutes_mutation_response

  # update single row of the table: "source"
  update_source_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: source_inc_input

    # sets the columns of the filtered rows to the given values
    _set: source_set_input
    pk_columns: source_pk_columns_input!
  ): source

  # update data of the table: "sub_type"
  update_sub_type(
    # increments the integer columns with given value of the filtered values
    _inc: sub_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: sub_type_set_input

    # filter the rows which have to be updated
    where: sub_type_bool_exp!
  ): sub_type_mutation_response

  # update single row of the table: "sub_type"
  update_sub_type_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: sub_type_inc_input

    # sets the columns of the filtered rows to the given values
    _set: sub_type_set_input
    pk_columns: sub_type_pk_columns_input!
  ): sub_type

  # update data of the table: "ticket"
  update_ticket(
    # increments the integer columns with given value of the filtered values
    _inc: ticket_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ticket_set_input

    # filter the rows which have to be updated
    where: ticket_bool_exp!
  ): ticket_mutation_response

  # update data of the table: "ticket_authors"
  update_ticket_authors(
    # increments the integer columns with given value of the filtered values
    _inc: ticket_authors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ticket_authors_set_input

    # filter the rows which have to be updated
    where: ticket_authors_bool_exp!
  ): ticket_authors_mutation_response

  # update single row of the table: "ticket_authors"
  update_ticket_authors_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: ticket_authors_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ticket_authors_set_input
    pk_columns: ticket_authors_pk_columns_input!
  ): ticket_authors

  # update single row of the table: "ticket"
  update_ticket_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: ticket_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ticket_set_input
    pk_columns: ticket_pk_columns_input!
  ): ticket

  # update data of the table: "ticket_institutes"
  update_ticket_institutes(
    # increments the integer columns with given value of the filtered values
    _inc: ticket_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ticket_institutes_set_input

    # filter the rows which have to be updated
    where: ticket_institutes_bool_exp!
  ): ticket_institutes_mutation_response

  # update single row of the table: "ticket_institutes"
  update_ticket_institutes_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: ticket_institutes_inc_input

    # sets the columns of the filtered rows to the given values
    _set: ticket_institutes_set_input
    pk_columns: ticket_institutes_pk_columns_input!
  ): ticket_institutes

  # update data of the table: "uploaded_file"
  update_uploaded_file(
    # increments the integer columns with given value of the filtered values
    _inc: uploaded_file_inc_input

    # sets the columns of the filtered rows to the given values
    _set: uploaded_file_set_input

    # filter the rows which have to be updated
    where: uploaded_file_bool_exp!
  ): uploaded_file_mutation_response

  # update single row of the table: "uploaded_file"
  update_uploaded_file_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: uploaded_file_inc_input

    # sets the columns of the filtered rows to the given values
    _set: uploaded_file_set_input
    pk_columns: uploaded_file_pk_columns_input!
  ): uploaded_file

  # update data of the table: "uploaded_file_file_content"
  update_uploaded_file_file_content(
    # increments the integer columns with given value of the filtered values
    _inc: uploaded_file_file_content_inc_input

    # sets the columns of the filtered rows to the given values
    _set: uploaded_file_file_content_set_input

    # filter the rows which have to be updated
    where: uploaded_file_file_content_bool_exp!
  ): uploaded_file_file_content_mutation_response

  # update data of the table: "usage_log"
  update_usage_log(
    # increments the integer columns with given value of the filtered values
    _inc: usage_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: usage_log_set_input

    # filter the rows which have to be updated
    where: usage_log_bool_exp!
  ): usage_log_mutation_response

  # update single row of the table: "usage_log"
  update_usage_log_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: usage_log_inc_input

    # sets the columns of the filtered rows to the given values
    _set: usage_log_set_input
    pk_columns: usage_log_pk_columns_input!
  ): usage_log

  # update data of the table: "user_notification_time"
  update_user_notification_time(
    # increments the integer columns with given value of the filtered values
    _inc: user_notification_time_inc_input

    # sets the columns of the filtered rows to the given values
    _set: user_notification_time_set_input

    # filter the rows which have to be updated
    where: user_notification_time_bool_exp!
  ): user_notification_time_mutation_response

  # update single row of the table: "user_notification_time"
  update_user_notification_time_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: user_notification_time_inc_input

    # sets the columns of the filtered rows to the given values
    _set: user_notification_time_set_input
    pk_columns: user_notification_time_pk_columns_input!
  ): user_notification_time

  # update data of the table: "user_preferences"
  update_user_preferences(
    # increments the integer columns with given value of the filtered values
    _inc: user_preferences_inc_input

    # sets the columns of the filtered rows to the given values
    _set: user_preferences_set_input

    # filter the rows which have to be updated
    where: user_preferences_bool_exp!
  ): user_preferences_mutation_response

  # update single row of the table: "user_preferences"
  update_user_preferences_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: user_preferences_inc_input

    # sets the columns of the filtered rows to the given values
    _set: user_preferences_set_input
    pk_columns: user_preferences_pk_columns_input!
  ): user_preferences

  # update data of the table: "users"
  update_users(
    # increments the integer columns with given value of the filtered values
    _inc: users_inc_input

    # sets the columns of the filtered rows to the given values
    _set: users_set_input

    # filter the rows which have to be updated
    where: users_bool_exp!
  ): users_mutation_response

  # update data of the table: "users_assistants"
  update_users_assistants(
    # increments the integer columns with given value of the filtered values
    _inc: users_assistants_inc_input

    # sets the columns of the filtered rows to the given values
    _set: users_assistants_set_input

    # filter the rows which have to be updated
    where: users_assistants_bool_exp!
  ): users_assistants_mutation_response

  # update single row of the table: "users"
  update_users_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: users_inc_input

    # sets the columns of the filtered rows to the given values
    _set: users_set_input
    pk_columns: users_pk_columns_input!
  ): users

  # update data of the table: "users_disciplines"
  update_users_disciplines(
    # increments the integer columns with given value of the filtered values
    _inc: users_disciplines_inc_input

    # sets the columns of the filtered rows to the given values
    _set: users_disciplines_set_input

    # filter the rows which have to be updated
    where: users_disciplines_bool_exp!
  ): users_disciplines_mutation_response

  # update data of the table: "variable"
  update_variable(
    # increments the integer columns with given value of the filtered values
    _inc: variable_inc_input

    # sets the columns of the filtered rows to the given values
    _set: variable_set_input

    # filter the rows which have to be updated
    where: variable_bool_exp!
  ): variable_mutation_response

  # update single row of the table: "variable"
  update_variable_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: variable_inc_input

    # sets the columns of the filtered rows to the given values
    _set: variable_set_input
    pk_columns: variable_pk_columns_input!
  ): variable

  # update data of the table: "workflow"
  update_workflow(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_set_input

    # filter the rows which have to be updated
    where: workflow_bool_exp!
  ): workflow_mutation_response

  # update single row of the table: "workflow"
  update_workflow_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_set_input
    pk_columns: workflow_pk_columns_input!
  ): workflow

  # update data of the table: "workflow_status"
  update_workflow_status(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_status_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_status_set_input

    # filter the rows which have to be updated
    where: workflow_status_bool_exp!
  ): workflow_status_mutation_response

  # update single row of the table: "workflow_status"
  update_workflow_status_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_status_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_status_set_input
    pk_columns: workflow_status_pk_columns_input!
  ): workflow_status

  # update data of the table: "workflow_step"
  update_workflow_step(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_step_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_step_set_input

    # filter the rows which have to be updated
    where: workflow_step_bool_exp!
  ): workflow_step_mutation_response

  # update single row of the table: "workflow_step"
  update_workflow_step_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_step_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_step_set_input
    pk_columns: workflow_step_pk_columns_input!
  ): workflow_step

  # update data of the table: "workflow_step_status"
  update_workflow_step_status(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_step_status_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_step_status_set_input

    # filter the rows which have to be updated
    where: workflow_step_status_bool_exp!
  ): workflow_step_status_mutation_response

  # update single row of the table: "workflow_step_status"
  update_workflow_step_status_by_pk(
    # increments the integer columns with given value of the filtered values
    _inc: workflow_step_status_inc_input

    # sets the columns of the filtered rows to the given values
    _set: workflow_step_status_set_input
    pk_columns: workflow_step_status_pk_columns_input!
  ): workflow_step_status
}

# columns and relationships of "mycite_revision_entity"
type mycite_revision_entity {
  changedFields: String
  id: Int!
  timestamp: bigint!
}

# aggregated selection of "mycite_revision_entity"
type mycite_revision_entity_aggregate {
  aggregate: mycite_revision_entity_aggregate_fields
  nodes: [mycite_revision_entity!]!
}

# aggregate fields of "mycite_revision_entity"
type mycite_revision_entity_aggregate_fields {
  avg: mycite_revision_entity_avg_fields
  count(columns: [mycite_revision_entity_select_column!], distinct: Boolean): Int
  max: mycite_revision_entity_max_fields
  min: mycite_revision_entity_min_fields
  stddev: mycite_revision_entity_stddev_fields
  stddev_pop: mycite_revision_entity_stddev_pop_fields
  stddev_samp: mycite_revision_entity_stddev_samp_fields
  sum: mycite_revision_entity_sum_fields
  var_pop: mycite_revision_entity_var_pop_fields
  var_samp: mycite_revision_entity_var_samp_fields
  variance: mycite_revision_entity_variance_fields
}

# order by aggregate values of table "mycite_revision_entity"
input mycite_revision_entity_aggregate_order_by {
  avg: mycite_revision_entity_avg_order_by
  count: order_by
  max: mycite_revision_entity_max_order_by
  min: mycite_revision_entity_min_order_by
  stddev: mycite_revision_entity_stddev_order_by
  stddev_pop: mycite_revision_entity_stddev_pop_order_by
  stddev_samp: mycite_revision_entity_stddev_samp_order_by
  sum: mycite_revision_entity_sum_order_by
  var_pop: mycite_revision_entity_var_pop_order_by
  var_samp: mycite_revision_entity_var_samp_order_by
  variance: mycite_revision_entity_variance_order_by
}

# input type for inserting array relation for remote table "mycite_revision_entity"
input mycite_revision_entity_arr_rel_insert_input {
  data: [mycite_revision_entity_insert_input!]!
  on_conflict: mycite_revision_entity_on_conflict
}

# aggregate avg on columns
type mycite_revision_entity_avg_fields {
  id: Float
  timestamp: Float
}

# order by avg() on columns of table "mycite_revision_entity"
input mycite_revision_entity_avg_order_by {
  id: order_by
  timestamp: order_by
}

# Boolean expression to filter rows from the table "mycite_revision_entity". All fields are combined with a logical 'AND'.
input mycite_revision_entity_bool_exp {
  _and: [mycite_revision_entity_bool_exp]
  _not: mycite_revision_entity_bool_exp
  _or: [mycite_revision_entity_bool_exp]
  changedFields: String_comparison_exp
  id: Int_comparison_exp
  timestamp: bigint_comparison_exp
}

# unique or primary key constraints on table "mycite_revision_entity"
enum mycite_revision_entity_constraint {
  # unique or primary key constraint
  mycite_revision_entity_pkey
}

# input type for incrementing integer column in table "mycite_revision_entity"
input mycite_revision_entity_inc_input {
  id: Int
  timestamp: bigint
}

# input type for inserting data into table "mycite_revision_entity"
input mycite_revision_entity_insert_input {
  changedFields: String
  id: Int
  timestamp: bigint
}

# aggregate max on columns
type mycite_revision_entity_max_fields {
  changedFields: String
  id: Int
  timestamp: bigint
}

# order by max() on columns of table "mycite_revision_entity"
input mycite_revision_entity_max_order_by {
  changedFields: order_by
  id: order_by
  timestamp: order_by
}

# aggregate min on columns
type mycite_revision_entity_min_fields {
  changedFields: String
  id: Int
  timestamp: bigint
}

# order by min() on columns of table "mycite_revision_entity"
input mycite_revision_entity_min_order_by {
  changedFields: order_by
  id: order_by
  timestamp: order_by
}

# response of any mutation on the table "mycite_revision_entity"
type mycite_revision_entity_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [mycite_revision_entity!]!
}

# input type for inserting object relation for remote table "mycite_revision_entity"
input mycite_revision_entity_obj_rel_insert_input {
  data: mycite_revision_entity_insert_input!
  on_conflict: mycite_revision_entity_on_conflict
}

# on conflict condition type for table "mycite_revision_entity"
input mycite_revision_entity_on_conflict {
  constraint: mycite_revision_entity_constraint!
  update_columns: [mycite_revision_entity_update_column!]!
  where: mycite_revision_entity_bool_exp
}

# ordering options when selecting data from "mycite_revision_entity"
input mycite_revision_entity_order_by {
  changedFields: order_by
  id: order_by
  timestamp: order_by
}

# primary key columns input for table: "mycite_revision_entity"
input mycite_revision_entity_pk_columns_input {
  id: Int!
}

# select columns of table "mycite_revision_entity"
enum mycite_revision_entity_select_column {
  # column name
  changedFields

  # column name
  id

  # column name
  timestamp
}

# input type for updating data in table "mycite_revision_entity"
input mycite_revision_entity_set_input {
  changedFields: String
  id: Int
  timestamp: bigint
}

# aggregate stddev on columns
type mycite_revision_entity_stddev_fields {
  id: Float
  timestamp: Float
}

# order by stddev() on columns of table "mycite_revision_entity"
input mycite_revision_entity_stddev_order_by {
  id: order_by
  timestamp: order_by
}

# aggregate stddev_pop on columns
type mycite_revision_entity_stddev_pop_fields {
  id: Float
  timestamp: Float
}

# order by stddev_pop() on columns of table "mycite_revision_entity"
input mycite_revision_entity_stddev_pop_order_by {
  id: order_by
  timestamp: order_by
}

# aggregate stddev_samp on columns
type mycite_revision_entity_stddev_samp_fields {
  id: Float
  timestamp: Float
}

# order by stddev_samp() on columns of table "mycite_revision_entity"
input mycite_revision_entity_stddev_samp_order_by {
  id: order_by
  timestamp: order_by
}

# aggregate sum on columns
type mycite_revision_entity_sum_fields {
  id: Int
  timestamp: bigint
}

# order by sum() on columns of table "mycite_revision_entity"
input mycite_revision_entity_sum_order_by {
  id: order_by
  timestamp: order_by
}

# update columns of table "mycite_revision_entity"
enum mycite_revision_entity_update_column {
  # column name
  changedFields

  # column name
  id

  # column name
  timestamp
}

# aggregate var_pop on columns
type mycite_revision_entity_var_pop_fields {
  id: Float
  timestamp: Float
}

# order by var_pop() on columns of table "mycite_revision_entity"
input mycite_revision_entity_var_pop_order_by {
  id: order_by
  timestamp: order_by
}

# aggregate var_samp on columns
type mycite_revision_entity_var_samp_fields {
  id: Float
  timestamp: Float
}

# order by var_samp() on columns of table "mycite_revision_entity"
input mycite_revision_entity_var_samp_order_by {
  id: order_by
  timestamp: order_by
}

# aggregate variance on columns
type mycite_revision_entity_variance_fields {
  id: Float
  timestamp: Float
}

# order by variance() on columns of table "mycite_revision_entity"
input mycite_revision_entity_variance_order_by {
  id: order_by
  timestamp: order_by
}

# columns and relationships of "named_list"
type named_list {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  depth: smallint

  # An object relationship
  duplumSearchRequest: duplum_search_request
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String

  # An object relationship
  importRequest: import_request
  importRequestMtid: bigint

  # An object relationship
  importStatistics: import_stat
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  published: Boolean!
  queued: Boolean!
  refreshed: Boolean!
  seen: Boolean
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "named_list"
type named_list_aggregate {
  aggregate: named_list_aggregate_fields
  nodes: [named_list!]!
}

# aggregate fields of "named_list"
type named_list_aggregate_fields {
  avg: named_list_avg_fields
  count(columns: [named_list_select_column!], distinct: Boolean): Int
  max: named_list_max_fields
  min: named_list_min_fields
  stddev: named_list_stddev_fields
  stddev_pop: named_list_stddev_pop_fields
  stddev_samp: named_list_stddev_samp_fields
  sum: named_list_sum_fields
  var_pop: named_list_var_pop_fields
  var_samp: named_list_var_samp_fields
  variance: named_list_variance_fields
}

# order by aggregate values of table "named_list"
input named_list_aggregate_order_by {
  avg: named_list_avg_order_by
  count: order_by
  max: named_list_max_order_by
  min: named_list_min_order_by
  stddev: named_list_stddev_order_by
  stddev_pop: named_list_stddev_pop_order_by
  stddev_samp: named_list_stddev_samp_order_by
  sum: named_list_sum_order_by
  var_pop: named_list_var_pop_order_by
  var_samp: named_list_var_samp_order_by
  variance: named_list_variance_order_by
}

# input type for inserting array relation for remote table "named_list"
input named_list_arr_rel_insert_input {
  data: [named_list_insert_input!]!
  on_conflict: named_list_on_conflict
}

# aggregate avg on columns
type named_list_avg_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "named_list"
input named_list_avg_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "named_list". All fields are combined with a logical 'AND'.
input named_list_bool_exp {
  _and: [named_list_bool_exp]
  _not: named_list_bool_exp
  _or: [named_list_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  aux: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  count: Int_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  depth: smallint_comparison_exp
  duplumSearchRequest: duplum_search_request_bool_exp
  elementType: String_comparison_exp
  error: Int_comparison_exp
  format: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  importRequest: import_request_bool_exp
  importRequestMtid: bigint_comparison_exp
  importStatistics: import_stat_bool_exp
  importStatisticsMtid: bigint_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  language: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  list: String_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  position: Int_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  seen: Boolean_comparison_exp
  status: Int_comparison_exp
  tag: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "named_list"
enum named_list_constraint {
  # unique or primary key constraint
  named_list_pkey
}

# input type for incrementing integer column in table "named_list"
input named_list_inc_input {
  approverMtid: bigint
  count: Int
  creator: bigint
  depth: smallint
  error: Int
  format: Int
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  position: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "named_list"
input named_list_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  depth: smallint
  duplumSearchRequest: duplum_search_request_obj_rel_insert_input
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequest: import_request_obj_rel_insert_input
  importRequestMtid: bigint
  importStatistics: import_stat_obj_rel_insert_input
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type named_list_max_fields {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "named_list"
input named_list_max_order_by {
  approved: order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  depth: order_by
  elementType: order_by
  error: order_by
  format: order_by
  hint: order_by
  hintEng: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  position: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type named_list_min_fields {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "named_list"
input named_list_min_order_by {
  approved: order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  depth: order_by
  elementType: order_by
  error: order_by
  format: order_by
  hint: order_by
  hintEng: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  position: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "named_list"
type named_list_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [named_list!]!
}

# input type for inserting object relation for remote table "named_list"
input named_list_obj_rel_insert_input {
  data: named_list_insert_input!
  on_conflict: named_list_on_conflict
}

# on conflict condition type for table "named_list"
input named_list_on_conflict {
  constraint: named_list_constraint!
  update_columns: [named_list_update_column!]!
  where: named_list_bool_exp
}

# ordering options when selecting data from "named_list"
input named_list_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  depth: order_by
  duplumSearchRequest: duplum_search_request_order_by
  elementType: order_by
  error: order_by
  format: order_by
  hint: order_by
  hintEng: order_by
  importRequest: import_request_order_by
  importRequestMtid: order_by
  importStatistics: import_stat_order_by
  importStatisticsMtid: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  position: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  queued: order_by
  refreshed: order_by
  seen: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "named_list"
input named_list_pk_columns_input {
  mtid: bigint!
}

# select columns of table "named_list"
enum named_list_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  aux

  # column name
  comment

  # column name
  comment2

  # column name
  count

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  depth

  # column name
  elementType

  # column name
  error

  # column name
  format

  # column name
  hint

  # column name
  hintEng

  # column name
  importRequestMtid

  # column name
  importStatisticsMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  position

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "named_list"
input named_list_set_input {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  format: Int
  hint: String
  hintEng: String
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  position: Int
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type named_list_stddev_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "named_list"
input named_list_stddev_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type named_list_stddev_pop_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "named_list"
input named_list_stddev_pop_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type named_list_stddev_samp_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "named_list"
input named_list_stddev_samp_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type named_list_sum_fields {
  approverMtid: bigint
  count: Int
  creator: bigint
  depth: smallint
  error: Int
  format: Int
  importRequestMtid: bigint
  importStatisticsMtid: bigint
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  position: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "named_list"
input named_list_sum_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "named_list"
enum named_list_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  aux

  # column name
  comment

  # column name
  comment2

  # column name
  count

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  depth

  # column name
  elementType

  # column name
  error

  # column name
  format

  # column name
  hint

  # column name
  hintEng

  # column name
  importRequestMtid

  # column name
  importStatisticsMtid

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  position

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type named_list_var_pop_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "named_list"
input named_list_var_pop_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type named_list_var_samp_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "named_list"
input named_list_var_samp_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type named_list_variance_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  format: Float
  importRequestMtid: Float
  importStatisticsMtid: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  position: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "named_list"
input named_list_variance_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  format: order_by
  importRequestMtid: order_by
  importStatisticsMtid: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  position: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "not_duplums"
type not_duplums {
  id: bigint!

  # An array relationship
  notDuplumIds(
    # distinct select on columns
    distinct_on: [not_duplums_not_duplum_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_not_duplum_ids_order_by!]

    # filter the rows returned
    where: not_duplums_not_duplum_ids_bool_exp
  ): [not_duplums_not_duplum_ids!]!

  # An aggregated array relationship
  notDuplumIds_aggregate(
    # distinct select on columns
    distinct_on: [not_duplums_not_duplum_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_not_duplum_ids_order_by!]

    # filter the rows returned
    where: not_duplums_not_duplum_ids_bool_exp
  ): not_duplums_not_duplum_ids_aggregate!
  objectMtid: bigint
  objectType: String
  oldId: Int
}

# aggregated selection of "not_duplums"
type not_duplums_aggregate {
  aggregate: not_duplums_aggregate_fields
  nodes: [not_duplums!]!
}

# aggregate fields of "not_duplums"
type not_duplums_aggregate_fields {
  avg: not_duplums_avg_fields
  count(columns: [not_duplums_select_column!], distinct: Boolean): Int
  max: not_duplums_max_fields
  min: not_duplums_min_fields
  stddev: not_duplums_stddev_fields
  stddev_pop: not_duplums_stddev_pop_fields
  stddev_samp: not_duplums_stddev_samp_fields
  sum: not_duplums_sum_fields
  var_pop: not_duplums_var_pop_fields
  var_samp: not_duplums_var_samp_fields
  variance: not_duplums_variance_fields
}

# order by aggregate values of table "not_duplums"
input not_duplums_aggregate_order_by {
  avg: not_duplums_avg_order_by
  count: order_by
  max: not_duplums_max_order_by
  min: not_duplums_min_order_by
  stddev: not_duplums_stddev_order_by
  stddev_pop: not_duplums_stddev_pop_order_by
  stddev_samp: not_duplums_stddev_samp_order_by
  sum: not_duplums_sum_order_by
  var_pop: not_duplums_var_pop_order_by
  var_samp: not_duplums_var_samp_order_by
  variance: not_duplums_variance_order_by
}

# input type for inserting array relation for remote table "not_duplums"
input not_duplums_arr_rel_insert_input {
  data: [not_duplums_insert_input!]!
  on_conflict: not_duplums_on_conflict
}

# aggregate avg on columns
type not_duplums_avg_fields {
  id: Float
  objectMtid: Float
  oldId: Float
}

# order by avg() on columns of table "not_duplums"
input not_duplums_avg_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

# Boolean expression to filter rows from the table "not_duplums". All fields are combined with a logical 'AND'.
input not_duplums_bool_exp {
  _and: [not_duplums_bool_exp]
  _not: not_duplums_bool_exp
  _or: [not_duplums_bool_exp]
  id: bigint_comparison_exp
  notDuplumIds: not_duplums_not_duplum_ids_bool_exp
  objectMtid: bigint_comparison_exp
  objectType: String_comparison_exp
  oldId: Int_comparison_exp
}

# unique or primary key constraints on table "not_duplums"
enum not_duplums_constraint {
  # unique or primary key constraint
  not_duplums_pkey
}

# input type for incrementing integer column in table "not_duplums"
input not_duplums_inc_input {
  id: bigint
  objectMtid: bigint
  oldId: Int
}

# input type for inserting data into table "not_duplums"
input not_duplums_insert_input {
  id: bigint
  notDuplumIds: not_duplums_not_duplum_ids_arr_rel_insert_input
  objectMtid: bigint
  objectType: String
  oldId: Int
}

# aggregate max on columns
type not_duplums_max_fields {
  id: bigint
  objectMtid: bigint
  objectType: String
  oldId: Int
}

# order by max() on columns of table "not_duplums"
input not_duplums_max_order_by {
  id: order_by
  objectMtid: order_by
  objectType: order_by
  oldId: order_by
}

# aggregate min on columns
type not_duplums_min_fields {
  id: bigint
  objectMtid: bigint
  objectType: String
  oldId: Int
}

# order by min() on columns of table "not_duplums"
input not_duplums_min_order_by {
  id: order_by
  objectMtid: order_by
  objectType: order_by
  oldId: order_by
}

# response of any mutation on the table "not_duplums"
type not_duplums_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [not_duplums!]!
}

# columns and relationships of "not_duplums_not_duplum_ids"
type not_duplums_not_duplum_ids {
  not_duplum_ids: bigint
  not_duplums_id: bigint!
}

# aggregated selection of "not_duplums_not_duplum_ids"
type not_duplums_not_duplum_ids_aggregate {
  aggregate: not_duplums_not_duplum_ids_aggregate_fields
  nodes: [not_duplums_not_duplum_ids!]!
}

# aggregate fields of "not_duplums_not_duplum_ids"
type not_duplums_not_duplum_ids_aggregate_fields {
  avg: not_duplums_not_duplum_ids_avg_fields
  count(columns: [not_duplums_not_duplum_ids_select_column!], distinct: Boolean): Int
  max: not_duplums_not_duplum_ids_max_fields
  min: not_duplums_not_duplum_ids_min_fields
  stddev: not_duplums_not_duplum_ids_stddev_fields
  stddev_pop: not_duplums_not_duplum_ids_stddev_pop_fields
  stddev_samp: not_duplums_not_duplum_ids_stddev_samp_fields
  sum: not_duplums_not_duplum_ids_sum_fields
  var_pop: not_duplums_not_duplum_ids_var_pop_fields
  var_samp: not_duplums_not_duplum_ids_var_samp_fields
  variance: not_duplums_not_duplum_ids_variance_fields
}

# order by aggregate values of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_aggregate_order_by {
  avg: not_duplums_not_duplum_ids_avg_order_by
  count: order_by
  max: not_duplums_not_duplum_ids_max_order_by
  min: not_duplums_not_duplum_ids_min_order_by
  stddev: not_duplums_not_duplum_ids_stddev_order_by
  stddev_pop: not_duplums_not_duplum_ids_stddev_pop_order_by
  stddev_samp: not_duplums_not_duplum_ids_stddev_samp_order_by
  sum: not_duplums_not_duplum_ids_sum_order_by
  var_pop: not_duplums_not_duplum_ids_var_pop_order_by
  var_samp: not_duplums_not_duplum_ids_var_samp_order_by
  variance: not_duplums_not_duplum_ids_variance_order_by
}

# input type for inserting array relation for remote table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_arr_rel_insert_input {
  data: [not_duplums_not_duplum_ids_insert_input!]!
}

# aggregate avg on columns
type not_duplums_not_duplum_ids_avg_fields {
  not_duplum_ids: Float
  not_duplums_id: Float
}

# order by avg() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_avg_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# Boolean expression to filter rows from the table "not_duplums_not_duplum_ids". All fields are combined with a logical 'AND'.
input not_duplums_not_duplum_ids_bool_exp {
  _and: [not_duplums_not_duplum_ids_bool_exp]
  _not: not_duplums_not_duplum_ids_bool_exp
  _or: [not_duplums_not_duplum_ids_bool_exp]
  not_duplum_ids: bigint_comparison_exp
  not_duplums_id: bigint_comparison_exp
}

# input type for incrementing integer column in table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_inc_input {
  not_duplum_ids: bigint
  not_duplums_id: bigint
}

# input type for inserting data into table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_insert_input {
  not_duplum_ids: bigint
  not_duplums_id: bigint
}

# aggregate max on columns
type not_duplums_not_duplum_ids_max_fields {
  not_duplum_ids: bigint
  not_duplums_id: bigint
}

# order by max() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_max_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# aggregate min on columns
type not_duplums_not_duplum_ids_min_fields {
  not_duplum_ids: bigint
  not_duplums_id: bigint
}

# order by min() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_min_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# response of any mutation on the table "not_duplums_not_duplum_ids"
type not_duplums_not_duplum_ids_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [not_duplums_not_duplum_ids!]!
}

# input type for inserting object relation for remote table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_obj_rel_insert_input {
  data: not_duplums_not_duplum_ids_insert_input!
}

# ordering options when selecting data from "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# select columns of table "not_duplums_not_duplum_ids"
enum not_duplums_not_duplum_ids_select_column {
  # column name
  not_duplum_ids

  # column name
  not_duplums_id
}

# input type for updating data in table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_set_input {
  not_duplum_ids: bigint
  not_duplums_id: bigint
}

# aggregate stddev on columns
type not_duplums_not_duplum_ids_stddev_fields {
  not_duplum_ids: Float
  not_duplums_id: Float
}

# order by stddev() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_stddev_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# aggregate stddev_pop on columns
type not_duplums_not_duplum_ids_stddev_pop_fields {
  not_duplum_ids: Float
  not_duplums_id: Float
}

# order by stddev_pop() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_stddev_pop_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# aggregate stddev_samp on columns
type not_duplums_not_duplum_ids_stddev_samp_fields {
  not_duplum_ids: Float
  not_duplums_id: Float
}

# order by stddev_samp() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_stddev_samp_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# aggregate sum on columns
type not_duplums_not_duplum_ids_sum_fields {
  not_duplum_ids: bigint
  not_duplums_id: bigint
}

# order by sum() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_sum_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# aggregate var_pop on columns
type not_duplums_not_duplum_ids_var_pop_fields {
  not_duplum_ids: Float
  not_duplums_id: Float
}

# order by var_pop() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_var_pop_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# aggregate var_samp on columns
type not_duplums_not_duplum_ids_var_samp_fields {
  not_duplum_ids: Float
  not_duplums_id: Float
}

# order by var_samp() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_var_samp_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# aggregate variance on columns
type not_duplums_not_duplum_ids_variance_fields {
  not_duplum_ids: Float
  not_duplums_id: Float
}

# order by variance() on columns of table "not_duplums_not_duplum_ids"
input not_duplums_not_duplum_ids_variance_order_by {
  not_duplum_ids: order_by
  not_duplums_id: order_by
}

# input type for inserting object relation for remote table "not_duplums"
input not_duplums_obj_rel_insert_input {
  data: not_duplums_insert_input!
  on_conflict: not_duplums_on_conflict
}

# on conflict condition type for table "not_duplums"
input not_duplums_on_conflict {
  constraint: not_duplums_constraint!
  update_columns: [not_duplums_update_column!]!
  where: not_duplums_bool_exp
}

# ordering options when selecting data from "not_duplums"
input not_duplums_order_by {
  id: order_by
  notDuplumIds_aggregate: not_duplums_not_duplum_ids_aggregate_order_by
  objectMtid: order_by
  objectType: order_by
  oldId: order_by
}

# primary key columns input for table: "not_duplums"
input not_duplums_pk_columns_input {
  id: bigint!
}

# select columns of table "not_duplums"
enum not_duplums_select_column {
  # column name
  id

  # column name
  objectMtid

  # column name
  objectType

  # column name
  oldId
}

# input type for updating data in table "not_duplums"
input not_duplums_set_input {
  id: bigint
  objectMtid: bigint
  objectType: String
  oldId: Int
}

# aggregate stddev on columns
type not_duplums_stddev_fields {
  id: Float
  objectMtid: Float
  oldId: Float
}

# order by stddev() on columns of table "not_duplums"
input not_duplums_stddev_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

# aggregate stddev_pop on columns
type not_duplums_stddev_pop_fields {
  id: Float
  objectMtid: Float
  oldId: Float
}

# order by stddev_pop() on columns of table "not_duplums"
input not_duplums_stddev_pop_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

# aggregate stddev_samp on columns
type not_duplums_stddev_samp_fields {
  id: Float
  objectMtid: Float
  oldId: Float
}

# order by stddev_samp() on columns of table "not_duplums"
input not_duplums_stddev_samp_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

# aggregate sum on columns
type not_duplums_sum_fields {
  id: bigint
  objectMtid: bigint
  oldId: Int
}

# order by sum() on columns of table "not_duplums"
input not_duplums_sum_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

# update columns of table "not_duplums"
enum not_duplums_update_column {
  # column name
  id

  # column name
  objectMtid

  # column name
  objectType

  # column name
  oldId
}

# aggregate var_pop on columns
type not_duplums_var_pop_fields {
  id: Float
  objectMtid: Float
  oldId: Float
}

# order by var_pop() on columns of table "not_duplums"
input not_duplums_var_pop_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

# aggregate var_samp on columns
type not_duplums_var_samp_fields {
  id: Float
  objectMtid: Float
  oldId: Float
}

# order by var_samp() on columns of table "not_duplums"
input not_duplums_var_samp_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

# aggregate variance on columns
type not_duplums_variance_fields {
  id: Float
  objectMtid: Float
  oldId: Float
}

# order by variance() on columns of table "not_duplums"
input not_duplums_variance_order_by {
  id: order_by
  objectMtid: order_by
  oldId: order_by
}

scalar oid

# expression to compare columns of type oid. All fields are combined with logical 'AND'.
input oid_comparison_exp {
  _eq: oid
  _gt: oid
  _gte: oid
  _in: [oid!]
  _is_null: Boolean
  _lt: oid
  _lte: oid
  _neq: oid
  _nin: [oid!]
}

# column ordering options
enum order_by {
  # in the ascending order, nulls last
  asc

  # in the ascending order, nulls first
  asc_nulls_first

  # in the ascending order, nulls last
  asc_nulls_last

  # in the descending order, nulls first
  desc

  # in the descending order, nulls first
  desc_nulls_first

  # in the descending order, nulls last
  desc_nulls_last
}

# columns and relationships of "organization"
type organization {
  MTAcode: String
  abbreviation: String
  abbreviationEng: String
  abbreviationLoc: String

  # An array relationship
  affiliations(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): [affiliation!]!

  # An aggregated array relationship
  affiliations_aggregate(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): affiliation_aggregate!
  aggregation: Boolean
  allowInstForum: Boolean!
  allowOnlineRegistration: Boolean

  # An array relationship
  ancestors(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): [reorg!]!

  # An aggregated array relationship
  ancestors_aggregate(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): reorg_aggregate!
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  authorCount: Int

  # An array relationship
  children(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): [division_containment!]!
  childrenCount: Int

  # An aggregated array relationship
  children_aggregate(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): division_containment_aggregate!
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  collaboration: Boolean!
  comment: String
  comment2: String
  contact: String
  contactInfo: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  doiCitationCount: Int
  dtype: String!
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  fax: String
  foreignEditionCitationCount: Int
  fromDate: timestamp
  hidden: Boolean!

  # An array relationship
  identifiers(
    # distinct select on columns
    distinct_on: [organization_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_identifier_order_by!]

    # filter the rows returned
    where: organization_identifier_bool_exp
  ): [organization_identifier!]!

  # An aggregated array relationship
  identifiers_aggregate(
    # distinct select on columns
    distinct_on: [organization_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_identifier_order_by!]

    # filter the rows returned
    where: organization_identifier_bool_exp
  ): organization_identifier_aggregate!
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locatedAbroad: Boolean
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users

  # An array relationship
  mabDisciplines(
    # distinct select on columns
    distinct_on: [organization_mab_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_mab_disciplines_order_by!]

    # filter the rows returned
    where: organization_mab_disciplines_bool_exp
  ): [organization_mab_disciplines!]!

  # An aggregated array relationship
  mabDisciplines_aggregate(
    # distinct select on columns
    distinct_on: [organization_mab_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_mab_disciplines_order_by!]

    # filter the rows returned
    where: organization_mab_disciplines_bool_exp
  ): organization_mab_disciplines_aggregate!

  # An array relationship
  mailAddress(
    # distinct select on columns
    distinct_on: [address_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [address_order_by!]

    # filter the rows returned
    where: address_bool_exp
  ): [address!]!

  # An aggregated array relationship
  mailAddress_aggregate(
    # distinct select on columns
    distinct_on: [address_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [address_order_by!]

    # filter the rows returned
    where: address_bool_exp
  ): address_aggregate!
  mtid: bigint!
  name: String
  nameEng: String
  nameLoc: String
  nationalOriginCitationCount: Int
  neptunId: String
  offlineRegistrationGuide: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An array relationship
  parent(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): [division_containment!]!

  # An aggregated array relationship
  parent_aggregate(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): division_containment_aggregate!
  phone: String
  poBox: String
  prevValid: bigint
  pubStats: String
  publicFrom: timestamp
  publicationCount: Int
  published: Boolean!
  pubsCompleteEnd: date
  pubsCompleteStart: date
  refreshed: Boolean!
  root: Boolean
  scopusCitationCount: Int
  status: Int

  # An array relationship
  successors(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): [reorg!]!

  # An aggregated array relationship
  successors_aggregate(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): reorg_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  toDate: timestamp

  # An object relationship
  type: institute_type
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int!
  url: String
  validFromYear: smallint
  validToYear: smallint
  virtual: Boolean
  wosCitationCount: Int
}

# aggregated selection of "organization"
type organization_aggregate {
  aggregate: organization_aggregate_fields
  nodes: [organization!]!
}

# aggregate fields of "organization"
type organization_aggregate_fields {
  avg: organization_avg_fields
  count(columns: [organization_select_column!], distinct: Boolean): Int
  max: organization_max_fields
  min: organization_min_fields
  stddev: organization_stddev_fields
  stddev_pop: organization_stddev_pop_fields
  stddev_samp: organization_stddev_samp_fields
  sum: organization_sum_fields
  var_pop: organization_var_pop_fields
  var_samp: organization_var_samp_fields
  variance: organization_variance_fields
}

# order by aggregate values of table "organization"
input organization_aggregate_order_by {
  avg: organization_avg_order_by
  count: order_by
  max: organization_max_order_by
  min: organization_min_order_by
  stddev: organization_stddev_order_by
  stddev_pop: organization_stddev_pop_order_by
  stddev_samp: organization_stddev_samp_order_by
  sum: organization_sum_order_by
  var_pop: organization_var_pop_order_by
  var_samp: organization_var_samp_order_by
  variance: organization_variance_order_by
}

# input type for inserting array relation for remote table "organization"
input organization_arr_rel_insert_input {
  data: [organization_insert_input!]!
  on_conflict: organization_on_conflict
}

# aggregate avg on columns
type organization_avg_fields {
  approverMtid: Float
  authorCount: Float
  childrenCount: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  scopusCitationCount: Float
  status: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by avg() on columns of table "organization"
input organization_avg_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# Boolean expression to filter rows from the table "organization". All fields are combined with a logical 'AND'.
input organization_bool_exp {
  MTAcode: String_comparison_exp
  _and: [organization_bool_exp]
  _not: organization_bool_exp
  _or: [organization_bool_exp]
  abbreviation: String_comparison_exp
  abbreviationEng: String_comparison_exp
  abbreviationLoc: String_comparison_exp
  affiliations: affiliation_bool_exp
  aggregation: Boolean_comparison_exp
  allowInstForum: Boolean_comparison_exp
  allowOnlineRegistration: Boolean_comparison_exp
  ancestors: reorg_bool_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  authorCount: Int_comparison_exp
  children: division_containment_bool_exp
  childrenCount: Int_comparison_exp
  citationCount: Int_comparison_exp
  citingPubCount: Int_comparison_exp
  citsCompleteEnd: date_comparison_exp
  citsCompleteStart: date_comparison_exp
  collaboration: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  contact: String_comparison_exp
  contactInfo: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  doiCitationCount: Int_comparison_exp
  dtype: String_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  fax: String_comparison_exp
  foreignEditionCitationCount: Int_comparison_exp
  fromDate: timestamp_comparison_exp
  hidden: Boolean_comparison_exp
  identifiers: organization_identifier_bool_exp
  independentCitationCount: Int_comparison_exp
  independentCitingPubCount: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locatedAbroad: Boolean_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mabDisciplines: organization_mab_disciplines_bool_exp
  mailAddress: address_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  nameLoc: String_comparison_exp
  nationalOriginCitationCount: Int_comparison_exp
  neptunId: String_comparison_exp
  offlineRegistrationGuide: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parent: division_containment_bool_exp
  phone: String_comparison_exp
  poBox: String_comparison_exp
  prevValid: bigint_comparison_exp
  pubStats: String_comparison_exp
  publicFrom: timestamp_comparison_exp
  publicationCount: Int_comparison_exp
  published: Boolean_comparison_exp
  pubsCompleteEnd: date_comparison_exp
  pubsCompleteStart: date_comparison_exp
  refreshed: Boolean_comparison_exp
  root: Boolean_comparison_exp
  scopusCitationCount: Int_comparison_exp
  status: Int_comparison_exp
  successors: reorg_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  toDate: timestamp_comparison_exp
  type: institute_type_bool_exp
  typeMtid: bigint_comparison_exp
  unhandledCitationCount: Int_comparison_exp
  unhandledCitingPubCount: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  url: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  virtual: Boolean_comparison_exp
  wosCitationCount: Int_comparison_exp
}

# unique or primary key constraints on table "organization"
enum organization_constraint {
  # unique or primary key constraint
  organization_pkey
}

# columns and relationships of "organization_identifier"
type organization_identifier {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp

  # An object relationship
  organization: organization
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  source: source
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "organization_identifier"
type organization_identifier_aggregate {
  aggregate: organization_identifier_aggregate_fields
  nodes: [organization_identifier!]!
}

# aggregate fields of "organization_identifier"
type organization_identifier_aggregate_fields {
  avg: organization_identifier_avg_fields
  count(columns: [organization_identifier_select_column!], distinct: Boolean): Int
  max: organization_identifier_max_fields
  min: organization_identifier_min_fields
  stddev: organization_identifier_stddev_fields
  stddev_pop: organization_identifier_stddev_pop_fields
  stddev_samp: organization_identifier_stddev_samp_fields
  sum: organization_identifier_sum_fields
  var_pop: organization_identifier_var_pop_fields
  var_samp: organization_identifier_var_samp_fields
  variance: organization_identifier_variance_fields
}

# order by aggregate values of table "organization_identifier"
input organization_identifier_aggregate_order_by {
  avg: organization_identifier_avg_order_by
  count: order_by
  max: organization_identifier_max_order_by
  min: organization_identifier_min_order_by
  stddev: organization_identifier_stddev_order_by
  stddev_pop: organization_identifier_stddev_pop_order_by
  stddev_samp: organization_identifier_stddev_samp_order_by
  sum: organization_identifier_sum_order_by
  var_pop: organization_identifier_var_pop_order_by
  var_samp: organization_identifier_var_samp_order_by
  variance: organization_identifier_variance_order_by
}

# input type for inserting array relation for remote table "organization_identifier"
input organization_identifier_arr_rel_insert_input {
  data: [organization_identifier_insert_input!]!
  on_conflict: organization_identifier_on_conflict
}

# aggregate avg on columns
type organization_identifier_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "organization_identifier"
input organization_identifier_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "organization_identifier". All fields are combined with a logical 'AND'.
input organization_identifier_bool_exp {
  _and: [organization_identifier_bool_exp]
  _not: organization_identifier_bool_exp
  _or: [organization_identifier_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  idValue: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  organization: organization_bool_exp
  organizationMtid: bigint_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  source: source_bool_exp
  sourceMtid: bigint_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "organization_identifier"
enum organization_identifier_constraint {
  # unique or primary key constraint
  organization_identifier_pkey
}

# input type for incrementing integer column in table "organization_identifier"
input organization_identifier_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  organizationMtid: bigint
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "organization_identifier"
input organization_identifier_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organization: organization_obj_rel_insert_input
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  source: source_obj_rel_insert_input
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type organization_identifier_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "organization_identifier"
input organization_identifier_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type organization_identifier_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "organization_identifier"
input organization_identifier_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "organization_identifier"
type organization_identifier_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [organization_identifier!]!
}

# input type for inserting object relation for remote table "organization_identifier"
input organization_identifier_obj_rel_insert_input {
  data: organization_identifier_insert_input!
  on_conflict: organization_identifier_on_conflict
}

# on conflict condition type for table "organization_identifier"
input organization_identifier_on_conflict {
  constraint: organization_identifier_constraint!
  update_columns: [organization_identifier_update_column!]!
  where: organization_identifier_bool_exp
}

# ordering options when selecting data from "organization_identifier"
input organization_identifier_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  organization: organization_order_by
  organizationMtid: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  source: source_order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "organization_identifier"
input organization_identifier_pk_columns_input {
  mtid: bigint!
}

# select columns of table "organization_identifier"
enum organization_identifier_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  organizationMtid

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "organization_identifier"
input organization_identifier_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  organizationMtid: bigint
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type organization_identifier_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "organization_identifier"
input organization_identifier_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type organization_identifier_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "organization_identifier"
input organization_identifier_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type organization_identifier_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "organization_identifier"
input organization_identifier_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type organization_identifier_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  organizationMtid: bigint
  prevValid: bigint
  sourceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "organization_identifier"
input organization_identifier_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "organization_identifier"
enum organization_identifier_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  organizationMtid

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type organization_identifier_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "organization_identifier"
input organization_identifier_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type organization_identifier_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "organization_identifier"
input organization_identifier_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type organization_identifier_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  organizationMtid: Float
  prevValid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "organization_identifier"
input organization_identifier_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  organizationMtid: order_by
  prevValid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# input type for incrementing integer column in table "organization"
input organization_inc_input {
  approverMtid: bigint
  authorCount: Int
  childrenCount: Int
  citationCount: Int
  citingPubCount: Int
  creator: bigint
  doiCitationCount: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  foreignEditionCitationCount: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  oldId: Int
  prevValid: bigint
  publicationCount: Int
  scopusCitationCount: Int
  status: Int
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# input type for inserting data into table "organization"
input organization_insert_input {
  MTAcode: String
  abbreviation: String
  abbreviationEng: String
  abbreviationLoc: String
  affiliations: affiliation_arr_rel_insert_input
  aggregation: Boolean
  allowInstForum: Boolean
  allowOnlineRegistration: Boolean
  ancestors: reorg_arr_rel_insert_input
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  authorCount: Int
  children: division_containment_arr_rel_insert_input
  childrenCount: Int
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  collaboration: Boolean
  comment: String
  comment2: String
  contact: String
  contactInfo: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  fax: String
  foreignEditionCitationCount: Int
  fromDate: timestamp
  hidden: Boolean
  identifiers: organization_identifier_arr_rel_insert_input
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locatedAbroad: Boolean
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mabDisciplines: organization_mab_disciplines_arr_rel_insert_input
  mailAddress: address_arr_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  nameLoc: String
  nationalOriginCitationCount: Int
  neptunId: String
  offlineRegistrationGuide: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parent: division_containment_arr_rel_insert_input
  phone: String
  poBox: String
  prevValid: bigint
  pubStats: String
  publicFrom: timestamp
  publicationCount: Int
  published: Boolean
  pubsCompleteEnd: date
  pubsCompleteStart: date
  refreshed: Boolean
  root: Boolean
  scopusCitationCount: Int
  status: Int
  successors: reorg_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  toDate: timestamp
  type: institute_type_obj_rel_insert_input
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  virtual: Boolean
  wosCitationCount: Int
}

# columns and relationships of "organization_mab_disciplines"
type organization_mab_disciplines {
  instituteMtid: bigint!

  # An object relationship
  mabDiscipline: mab_discipline!
  mabDisciplinesMtid: bigint!
}

# aggregated selection of "organization_mab_disciplines"
type organization_mab_disciplines_aggregate {
  aggregate: organization_mab_disciplines_aggregate_fields
  nodes: [organization_mab_disciplines!]!
}

# aggregate fields of "organization_mab_disciplines"
type organization_mab_disciplines_aggregate_fields {
  avg: organization_mab_disciplines_avg_fields
  count(columns: [organization_mab_disciplines_select_column!], distinct: Boolean): Int
  max: organization_mab_disciplines_max_fields
  min: organization_mab_disciplines_min_fields
  stddev: organization_mab_disciplines_stddev_fields
  stddev_pop: organization_mab_disciplines_stddev_pop_fields
  stddev_samp: organization_mab_disciplines_stddev_samp_fields
  sum: organization_mab_disciplines_sum_fields
  var_pop: organization_mab_disciplines_var_pop_fields
  var_samp: organization_mab_disciplines_var_samp_fields
  variance: organization_mab_disciplines_variance_fields
}

# order by aggregate values of table "organization_mab_disciplines"
input organization_mab_disciplines_aggregate_order_by {
  avg: organization_mab_disciplines_avg_order_by
  count: order_by
  max: organization_mab_disciplines_max_order_by
  min: organization_mab_disciplines_min_order_by
  stddev: organization_mab_disciplines_stddev_order_by
  stddev_pop: organization_mab_disciplines_stddev_pop_order_by
  stddev_samp: organization_mab_disciplines_stddev_samp_order_by
  sum: organization_mab_disciplines_sum_order_by
  var_pop: organization_mab_disciplines_var_pop_order_by
  var_samp: organization_mab_disciplines_var_samp_order_by
  variance: organization_mab_disciplines_variance_order_by
}

# input type for inserting array relation for remote table "organization_mab_disciplines"
input organization_mab_disciplines_arr_rel_insert_input {
  data: [organization_mab_disciplines_insert_input!]!
}

# aggregate avg on columns
type organization_mab_disciplines_avg_fields {
  instituteMtid: Float
  mabDisciplinesMtid: Float
}

# order by avg() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_avg_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# Boolean expression to filter rows from the table "organization_mab_disciplines".
# All fields are combined with a logical 'AND'.
input organization_mab_disciplines_bool_exp {
  _and: [organization_mab_disciplines_bool_exp]
  _not: organization_mab_disciplines_bool_exp
  _or: [organization_mab_disciplines_bool_exp]
  instituteMtid: bigint_comparison_exp
  mabDiscipline: mab_discipline_bool_exp
  mabDisciplinesMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "organization_mab_disciplines"
input organization_mab_disciplines_inc_input {
  instituteMtid: bigint
  mabDisciplinesMtid: bigint
}

# input type for inserting data into table "organization_mab_disciplines"
input organization_mab_disciplines_insert_input {
  instituteMtid: bigint
  mabDiscipline: mab_discipline_obj_rel_insert_input
  mabDisciplinesMtid: bigint
}

# aggregate max on columns
type organization_mab_disciplines_max_fields {
  instituteMtid: bigint
  mabDisciplinesMtid: bigint
}

# order by max() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_max_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate min on columns
type organization_mab_disciplines_min_fields {
  instituteMtid: bigint
  mabDisciplinesMtid: bigint
}

# order by min() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_min_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# response of any mutation on the table "organization_mab_disciplines"
type organization_mab_disciplines_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [organization_mab_disciplines!]!
}

# input type for inserting object relation for remote table "organization_mab_disciplines"
input organization_mab_disciplines_obj_rel_insert_input {
  data: organization_mab_disciplines_insert_input!
}

# ordering options when selecting data from "organization_mab_disciplines"
input organization_mab_disciplines_order_by {
  instituteMtid: order_by
  mabDiscipline: mab_discipline_order_by
  mabDisciplinesMtid: order_by
}

# select columns of table "organization_mab_disciplines"
enum organization_mab_disciplines_select_column {
  # column name
  instituteMtid

  # column name
  mabDisciplinesMtid
}

# input type for updating data in table "organization_mab_disciplines"
input organization_mab_disciplines_set_input {
  instituteMtid: bigint
  mabDisciplinesMtid: bigint
}

# aggregate stddev on columns
type organization_mab_disciplines_stddev_fields {
  instituteMtid: Float
  mabDisciplinesMtid: Float
}

# order by stddev() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_stddev_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate stddev_pop on columns
type organization_mab_disciplines_stddev_pop_fields {
  instituteMtid: Float
  mabDisciplinesMtid: Float
}

# order by stddev_pop() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_stddev_pop_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate stddev_samp on columns
type organization_mab_disciplines_stddev_samp_fields {
  instituteMtid: Float
  mabDisciplinesMtid: Float
}

# order by stddev_samp() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_stddev_samp_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate sum on columns
type organization_mab_disciplines_sum_fields {
  instituteMtid: bigint
  mabDisciplinesMtid: bigint
}

# order by sum() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_sum_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate var_pop on columns
type organization_mab_disciplines_var_pop_fields {
  instituteMtid: Float
  mabDisciplinesMtid: Float
}

# order by var_pop() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_var_pop_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate var_samp on columns
type organization_mab_disciplines_var_samp_fields {
  instituteMtid: Float
  mabDisciplinesMtid: Float
}

# order by var_samp() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_var_samp_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate variance on columns
type organization_mab_disciplines_variance_fields {
  instituteMtid: Float
  mabDisciplinesMtid: Float
}

# order by variance() on columns of table "organization_mab_disciplines"
input organization_mab_disciplines_variance_order_by {
  instituteMtid: order_by
  mabDisciplinesMtid: order_by
}

# aggregate max on columns
type organization_max_fields {
  MTAcode: String
  abbreviation: String
  abbreviationEng: String
  abbreviationLoc: String
  approved: timestamp
  approverMtid: bigint
  authorCount: Int
  childrenCount: Int
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  comment: String
  comment2: String
  contact: String
  contactInfo: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fax: String
  foreignEditionCitationCount: Int
  fromDate: timestamp
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  nameLoc: String
  nationalOriginCitationCount: Int
  neptunId: String
  offlineRegistrationGuide: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phone: String
  poBox: String
  prevValid: bigint
  pubStats: String
  publicFrom: timestamp
  publicationCount: Int
  pubsCompleteEnd: date
  pubsCompleteStart: date
  scopusCitationCount: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  toDate: timestamp
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# order by max() on columns of table "organization"
input organization_max_order_by {
  MTAcode: order_by
  abbreviation: order_by
  abbreviationEng: order_by
  abbreviationLoc: order_by
  approved: order_by
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  citsCompleteEnd: order_by
  citsCompleteStart: order_by
  comment: order_by
  comment2: order_by
  contact: order_by
  contactInfo: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fax: order_by
  foreignEditionCitationCount: order_by
  fromDate: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  nameLoc: order_by
  nationalOriginCitationCount: order_by
  neptunId: order_by
  offlineRegistrationGuide: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  phone: order_by
  poBox: order_by
  prevValid: order_by
  pubStats: order_by
  publicFrom: order_by
  publicationCount: order_by
  pubsCompleteEnd: order_by
  pubsCompleteStart: order_by
  scopusCitationCount: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  toDate: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate min on columns
type organization_min_fields {
  MTAcode: String
  abbreviation: String
  abbreviationEng: String
  abbreviationLoc: String
  approved: timestamp
  approverMtid: bigint
  authorCount: Int
  childrenCount: Int
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  comment: String
  comment2: String
  contact: String
  contactInfo: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fax: String
  foreignEditionCitationCount: Int
  fromDate: timestamp
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  nameLoc: String
  nationalOriginCitationCount: Int
  neptunId: String
  offlineRegistrationGuide: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phone: String
  poBox: String
  prevValid: bigint
  pubStats: String
  publicFrom: timestamp
  publicationCount: Int
  pubsCompleteEnd: date
  pubsCompleteStart: date
  scopusCitationCount: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  toDate: timestamp
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# order by min() on columns of table "organization"
input organization_min_order_by {
  MTAcode: order_by
  abbreviation: order_by
  abbreviationEng: order_by
  abbreviationLoc: order_by
  approved: order_by
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  citsCompleteEnd: order_by
  citsCompleteStart: order_by
  comment: order_by
  comment2: order_by
  contact: order_by
  contactInfo: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fax: order_by
  foreignEditionCitationCount: order_by
  fromDate: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  nameLoc: order_by
  nationalOriginCitationCount: order_by
  neptunId: order_by
  offlineRegistrationGuide: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  phone: order_by
  poBox: order_by
  prevValid: order_by
  pubStats: order_by
  publicFrom: order_by
  publicationCount: order_by
  pubsCompleteEnd: order_by
  pubsCompleteStart: order_by
  scopusCitationCount: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  toDate: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# response of any mutation on the table "organization"
type organization_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [organization!]!
}

# input type for inserting object relation for remote table "organization"
input organization_obj_rel_insert_input {
  data: organization_insert_input!
  on_conflict: organization_on_conflict
}

# on conflict condition type for table "organization"
input organization_on_conflict {
  constraint: organization_constraint!
  update_columns: [organization_update_column!]!
  where: organization_bool_exp
}

# ordering options when selecting data from "organization"
input organization_order_by {
  MTAcode: order_by
  abbreviation: order_by
  abbreviationEng: order_by
  abbreviationLoc: order_by
  affiliations_aggregate: affiliation_aggregate_order_by
  aggregation: order_by
  allowInstForum: order_by
  allowOnlineRegistration: order_by
  ancestors_aggregate: reorg_aggregate_order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  children_aggregate: division_containment_aggregate_order_by
  citationCount: order_by
  citingPubCount: order_by
  citsCompleteEnd: order_by
  citsCompleteStart: order_by
  collaboration: order_by
  comment: order_by
  comment2: order_by
  contact: order_by
  contactInfo: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fax: order_by
  foreignEditionCitationCount: order_by
  fromDate: order_by
  hidden: order_by
  identifiers_aggregate: organization_identifier_aggregate_order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locatedAbroad: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mabDisciplines_aggregate: organization_mab_disciplines_aggregate_order_by
  mailAddress_aggregate: address_aggregate_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  nameLoc: order_by
  nationalOriginCitationCount: order_by
  neptunId: order_by
  offlineRegistrationGuide: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parent_aggregate: division_containment_aggregate_order_by
  phone: order_by
  poBox: order_by
  prevValid: order_by
  pubStats: order_by
  publicFrom: order_by
  publicationCount: order_by
  published: order_by
  pubsCompleteEnd: order_by
  pubsCompleteStart: order_by
  refreshed: order_by
  root: order_by
  scopusCitationCount: order_by
  status: order_by
  successors_aggregate: reorg_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  toDate: order_by
  type: institute_type_order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
  virtual: order_by
  wosCitationCount: order_by
}

# primary key columns input for table: "organization"
input organization_pk_columns_input {
  mtid: bigint!
}

# select columns of table "organization"
enum organization_select_column {
  # column name
  MTAcode

  # column name
  abbreviation

  # column name
  abbreviationEng

  # column name
  abbreviationLoc

  # column name
  aggregation

  # column name
  allowInstForum

  # column name
  allowOnlineRegistration

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorCount

  # column name
  childrenCount

  # column name
  citationCount

  # column name
  citingPubCount

  # column name
  citsCompleteEnd

  # column name
  citsCompleteStart

  # column name
  collaboration

  # column name
  comment

  # column name
  comment2

  # column name
  contact

  # column name
  contactInfo

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doiCitationCount

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fax

  # column name
  foreignEditionCitationCount

  # column name
  fromDate

  # column name
  hidden

  # column name
  independentCitationCount

  # column name
  independentCitingPubCount

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locatedAbroad

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  nameLoc

  # column name
  nationalOriginCitationCount

  # column name
  neptunId

  # column name
  offlineRegistrationGuide

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  phone

  # column name
  poBox

  # column name
  prevValid

  # column name
  pubStats

  # column name
  publicFrom

  # column name
  publicationCount

  # column name
  published

  # column name
  pubsCompleteEnd

  # column name
  pubsCompleteStart

  # column name
  refreshed

  # column name
  root

  # column name
  scopusCitationCount

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  toDate

  # column name
  typeMtid

  # column name
  unhandledCitationCount

  # column name
  unhandledCitingPubCount

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  virtual

  # column name
  wosCitationCount
}

# input type for updating data in table "organization"
input organization_set_input {
  MTAcode: String
  abbreviation: String
  abbreviationEng: String
  abbreviationLoc: String
  aggregation: Boolean
  allowInstForum: Boolean
  allowOnlineRegistration: Boolean
  approved: timestamp
  approverMtid: bigint
  authorCount: Int
  childrenCount: Int
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  collaboration: Boolean
  comment: String
  comment2: String
  contact: String
  contactInfo: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fax: String
  foreignEditionCitationCount: Int
  fromDate: timestamp
  hidden: Boolean
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locatedAbroad: Boolean
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  nameLoc: String
  nationalOriginCitationCount: Int
  neptunId: String
  offlineRegistrationGuide: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phone: String
  poBox: String
  prevValid: bigint
  pubStats: String
  publicFrom: timestamp
  publicationCount: Int
  published: Boolean
  pubsCompleteEnd: date
  pubsCompleteStart: date
  refreshed: Boolean
  root: Boolean
  scopusCitationCount: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  toDate: timestamp
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  virtual: Boolean
  wosCitationCount: Int
}

# aggregate stddev on columns
type organization_stddev_fields {
  approverMtid: Float
  authorCount: Float
  childrenCount: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  scopusCitationCount: Float
  status: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by stddev() on columns of table "organization"
input organization_stddev_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate stddev_pop on columns
type organization_stddev_pop_fields {
  approverMtid: Float
  authorCount: Float
  childrenCount: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  scopusCitationCount: Float
  status: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by stddev_pop() on columns of table "organization"
input organization_stddev_pop_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate stddev_samp on columns
type organization_stddev_samp_fields {
  approverMtid: Float
  authorCount: Float
  childrenCount: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  scopusCitationCount: Float
  status: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by stddev_samp() on columns of table "organization"
input organization_stddev_samp_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate sum on columns
type organization_sum_fields {
  approverMtid: bigint
  authorCount: Int
  childrenCount: Int
  citationCount: Int
  citingPubCount: Int
  creator: bigint
  doiCitationCount: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  foreignEditionCitationCount: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  oldId: Int
  prevValid: bigint
  publicationCount: Int
  scopusCitationCount: Int
  status: Int
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# order by sum() on columns of table "organization"
input organization_sum_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# update columns of table "organization"
enum organization_update_column {
  # column name
  MTAcode

  # column name
  abbreviation

  # column name
  abbreviationEng

  # column name
  abbreviationLoc

  # column name
  aggregation

  # column name
  allowInstForum

  # column name
  allowOnlineRegistration

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorCount

  # column name
  childrenCount

  # column name
  citationCount

  # column name
  citingPubCount

  # column name
  citsCompleteEnd

  # column name
  citsCompleteStart

  # column name
  collaboration

  # column name
  comment

  # column name
  comment2

  # column name
  contact

  # column name
  contactInfo

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doiCitationCount

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fax

  # column name
  foreignEditionCitationCount

  # column name
  fromDate

  # column name
  hidden

  # column name
  independentCitationCount

  # column name
  independentCitingPubCount

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locatedAbroad

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  nameLoc

  # column name
  nationalOriginCitationCount

  # column name
  neptunId

  # column name
  offlineRegistrationGuide

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  phone

  # column name
  poBox

  # column name
  prevValid

  # column name
  pubStats

  # column name
  publicFrom

  # column name
  publicationCount

  # column name
  published

  # column name
  pubsCompleteEnd

  # column name
  pubsCompleteStart

  # column name
  refreshed

  # column name
  root

  # column name
  scopusCitationCount

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  toDate

  # column name
  typeMtid

  # column name
  unhandledCitationCount

  # column name
  unhandledCitingPubCount

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  virtual

  # column name
  wosCitationCount
}

# aggregate var_pop on columns
type organization_var_pop_fields {
  approverMtid: Float
  authorCount: Float
  childrenCount: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  scopusCitationCount: Float
  status: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by var_pop() on columns of table "organization"
input organization_var_pop_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate var_samp on columns
type organization_var_samp_fields {
  approverMtid: Float
  authorCount: Float
  childrenCount: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  scopusCitationCount: Float
  status: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by var_samp() on columns of table "organization"
input organization_var_samp_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate variance on columns
type organization_variance_fields {
  approverMtid: Float
  authorCount: Float
  childrenCount: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  scopusCitationCount: Float
  status: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by variance() on columns of table "organization"
input organization_variance_order_by {
  approverMtid: order_by
  authorCount: order_by
  childrenCount: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  scopusCitationCount: order_by
  status: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# columns and relationships of "periodical"
type periodical {
  abbreviated: String
  altNames: String

  # An array relationship
  ancestors(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): [journal_successors!]!

  # An aggregated array relationship
  ancestors_aggregate(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): journal_successors_aggregate!
  annual: Boolean!
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  checkDone: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  digitalOnly: Boolean!
  dtype: String!
  duplumKey: String
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  eIssn: String
  endYear: smallint
  error: Int
  fromCitation: Boolean!
  homepage: String
  hungarian: Boolean!

  # An array relationship
  issns(
    # distinct select on columns
    distinct_on: [periodical_issn_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_issn_order_by!]

    # filter the rows returned
    where: periodical_issn_bool_exp
  ): [periodical_issn!]!
  issnsForSort: String

  # An aggregated array relationship
  issns_aggregate(
    # distinct select on columns
    distinct_on: [periodical_issn_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_issn_order_by!]

    # filter the rows returned
    where: periodical_issn_bool_exp
  ): periodical_issn_aggregate!
  labelEng: String
  labelHun: String
  lang: Int
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  noIF: Boolean!
  noISSN: Boolean!
  noVolumeInfo: Boolean!
  nonScientific: Boolean!
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  openAccessEnd: smallint
  openAccessStart: smallint
  otype: String
  pIssn: String
  permaLink: String
  predator: Int
  prevValid: bigint
  publicationCount: Int!
  published: Boolean!

  # An array relationship
  publishers(
    # distinct select on columns
    distinct_on: [periodical_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_publishers_order_by!]

    # filter the rows returned
    where: periodical_publishers_bool_exp
  ): [periodical_publishers!]!
  publishersForSort: String

  # An aggregated array relationship
  publishers_aggregate(
    # distinct select on columns
    distinct_on: [periodical_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_publishers_order_by!]

    # filter the rows returned
    where: periodical_publishers_bool_exp
  ): periodical_publishers_aggregate!

  # An array relationship
  ratings(
    # distinct select on columns
    distinct_on: [rating_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_order_by!]

    # filter the rows returned
    where: rating_bool_exp
  ): [rating!]!

  # An aggregated array relationship
  ratings_aggregate(
    # distinct select on columns
    distinct_on: [rating_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_order_by!]

    # filter the rows returned
    where: rating_bool_exp
  ): rating_aggregate!
  refreshed: Boolean!
  restartPageNumberingByIssue: Boolean
  reviewType: Int
  reviewedEndYear: smallint
  reviewedStartYear: smallint
  sciIndexed: Boolean!
  sciType: Int
  scopusIndexed: Boolean!
  series: Boolean!

  # An object relationship
  sjrJournal: periodical
  sjrJournalMtid: bigint
  sjrUrl: String
  source: String
  startYear: smallint
  status: Int
  subTitle: String

  # An array relationship
  subjectsExternal(
    # distinct select on columns
    distinct_on: [periodical_subjects_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_subjects_external_order_by!]

    # filter the rows returned
    where: periodical_subjects_external_bool_exp
  ): [periodical_subjects_external!]!

  # An aggregated array relationship
  subjectsExternal_aggregate(
    # distinct select on columns
    distinct_on: [periodical_subjects_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_subjects_external_order_by!]

    # filter the rows returned
    where: periodical_subjects_external_bool_exp
  ): periodical_subjects_external_aggregate!

  # An array relationship
  successors(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): [journal_successors!]!

  # An aggregated array relationship
  successors_aggregate(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): journal_successors_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporary: Boolean!
  temporaryAddDate: timestamp

  # An object relationship
  temporaryBy: users
  temporaryByForSort: String
  temporaryByMtid: bigint
  title: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint

  # An array relationship
  volumes(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): [series_volume!]!

  # An aggregated array relationship
  volumes_aggregate(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): series_volume_aggregate!
}

# aggregated selection of "periodical"
type periodical_aggregate {
  aggregate: periodical_aggregate_fields
  nodes: [periodical!]!
}

# aggregate fields of "periodical"
type periodical_aggregate_fields {
  avg: periodical_avg_fields
  count(columns: [periodical_select_column!], distinct: Boolean): Int
  max: periodical_max_fields
  min: periodical_min_fields
  stddev: periodical_stddev_fields
  stddev_pop: periodical_stddev_pop_fields
  stddev_samp: periodical_stddev_samp_fields
  sum: periodical_sum_fields
  var_pop: periodical_var_pop_fields
  var_samp: periodical_var_samp_fields
  variance: periodical_variance_fields
}

# order by aggregate values of table "periodical"
input periodical_aggregate_order_by {
  avg: periodical_avg_order_by
  count: order_by
  max: periodical_max_order_by
  min: periodical_min_order_by
  stddev: periodical_stddev_order_by
  stddev_pop: periodical_stddev_pop_order_by
  stddev_samp: periodical_stddev_samp_order_by
  sum: periodical_sum_order_by
  var_pop: periodical_var_pop_order_by
  var_samp: periodical_var_samp_order_by
  variance: periodical_variance_order_by
}

# input type for inserting array relation for remote table "periodical"
input periodical_arr_rel_insert_input {
  data: [periodical_insert_input!]!
  on_conflict: periodical_on_conflict
}

# aggregate avg on columns
type periodical_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  endYear: Float
  error: Float
  lang: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  openAccess: Float
  openAccessEnd: Float
  openAccessStart: Float
  predator: Float
  prevValid: Float
  publicationCount: Float
  reviewType: Float
  reviewedEndYear: Float
  reviewedStartYear: Float
  sciType: Float
  sjrJournalMtid: Float
  startYear: Float
  status: Float
  temporaryByMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "periodical"
input periodical_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "periodical". All fields are combined with a logical 'AND'.
input periodical_bool_exp {
  _and: [periodical_bool_exp]
  _not: periodical_bool_exp
  _or: [periodical_bool_exp]
  abbreviated: String_comparison_exp
  altNames: String_comparison_exp
  ancestors: journal_successors_bool_exp
  annual: Boolean_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  checkDone: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  digitalOnly: Boolean_comparison_exp
  dtype: String_comparison_exp
  duplumKey: String_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  eIssn: String_comparison_exp
  endYear: smallint_comparison_exp
  error: Int_comparison_exp
  fromCitation: Boolean_comparison_exp
  homepage: String_comparison_exp
  hungarian: Boolean_comparison_exp
  issns: periodical_issn_bool_exp
  issnsForSort: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lang: Int_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  noIF: Boolean_comparison_exp
  noISSN: Boolean_comparison_exp
  noVolumeInfo: Boolean_comparison_exp
  nonScientific: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  openAccess: Int_comparison_exp
  openAccessEnd: smallint_comparison_exp
  openAccessStart: smallint_comparison_exp
  otype: String_comparison_exp
  pIssn: String_comparison_exp
  permaLink: String_comparison_exp
  predator: Int_comparison_exp
  prevValid: bigint_comparison_exp
  publicationCount: Int_comparison_exp
  published: Boolean_comparison_exp
  publishers: periodical_publishers_bool_exp
  publishersForSort: String_comparison_exp
  ratings: rating_bool_exp
  refreshed: Boolean_comparison_exp
  restartPageNumberingByIssue: Boolean_comparison_exp
  reviewType: Int_comparison_exp
  reviewedEndYear: smallint_comparison_exp
  reviewedStartYear: smallint_comparison_exp
  sciIndexed: Boolean_comparison_exp
  sciType: Int_comparison_exp
  scopusIndexed: Boolean_comparison_exp
  series: Boolean_comparison_exp
  sjrJournal: periodical_bool_exp
  sjrJournalMtid: bigint_comparison_exp
  sjrUrl: String_comparison_exp
  source: String_comparison_exp
  startYear: smallint_comparison_exp
  status: Int_comparison_exp
  subTitle: String_comparison_exp
  subjectsExternal: periodical_subjects_external_bool_exp
  successors: journal_successors_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  temporary: Boolean_comparison_exp
  temporaryAddDate: timestamp_comparison_exp
  temporaryBy: users_bool_exp
  temporaryByForSort: String_comparison_exp
  temporaryByMtid: bigint_comparison_exp
  title: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  volumes: series_volume_bool_exp
}

# unique or primary key constraints on table "periodical"
enum periodical_constraint {
  # unique or primary key constraint
  periodical_pkey
}

# input type for incrementing integer column in table "periodical"
input periodical_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  endYear: smallint
  error: Int
  lang: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  openAccess: Int
  openAccessEnd: smallint
  openAccessStart: smallint
  predator: Int
  prevValid: bigint
  publicationCount: Int
  reviewType: Int
  reviewedEndYear: smallint
  reviewedStartYear: smallint
  sciType: Int
  sjrJournalMtid: bigint
  startYear: smallint
  status: Int
  temporaryByMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "periodical"
input periodical_insert_input {
  abbreviated: String
  altNames: String
  ancestors: journal_successors_arr_rel_insert_input
  annual: Boolean
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  checkDone: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  digitalOnly: Boolean
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  eIssn: String
  endYear: smallint
  error: Int
  fromCitation: Boolean
  homepage: String
  hungarian: Boolean
  issns: periodical_issn_arr_rel_insert_input
  issnsForSort: String
  labelEng: String
  labelHun: String
  lang: Int
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  noIF: Boolean
  noISSN: Boolean
  noVolumeInfo: Boolean
  nonScientific: Boolean
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  openAccessEnd: smallint
  openAccessStart: smallint
  otype: String
  pIssn: String
  permaLink: String
  predator: Int
  prevValid: bigint
  publicationCount: Int
  published: Boolean
  publishers: periodical_publishers_arr_rel_insert_input
  publishersForSort: String
  ratings: rating_arr_rel_insert_input
  refreshed: Boolean
  restartPageNumberingByIssue: Boolean
  reviewType: Int
  reviewedEndYear: smallint
  reviewedStartYear: smallint
  sciIndexed: Boolean
  sciType: Int
  scopusIndexed: Boolean
  series: Boolean
  sjrJournal: periodical_obj_rel_insert_input
  sjrJournalMtid: bigint
  sjrUrl: String
  source: String
  startYear: smallint
  status: Int
  subTitle: String
  subjectsExternal: periodical_subjects_external_arr_rel_insert_input
  successors: journal_successors_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporary: Boolean
  temporaryAddDate: timestamp
  temporaryBy: users_obj_rel_insert_input
  temporaryByForSort: String
  temporaryByMtid: bigint
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  volumes: series_volume_arr_rel_insert_input
}

# columns and relationships of "periodical_issn"
type periodical_issn {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  flag: smallint!
  issn: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An object relationship
  periodical: periodical
  periodicalMtid: bigint
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "periodical_issn"
type periodical_issn_aggregate {
  aggregate: periodical_issn_aggregate_fields
  nodes: [periodical_issn!]!
}

# aggregate fields of "periodical_issn"
type periodical_issn_aggregate_fields {
  avg: periodical_issn_avg_fields
  count(columns: [periodical_issn_select_column!], distinct: Boolean): Int
  max: periodical_issn_max_fields
  min: periodical_issn_min_fields
  stddev: periodical_issn_stddev_fields
  stddev_pop: periodical_issn_stddev_pop_fields
  stddev_samp: periodical_issn_stddev_samp_fields
  sum: periodical_issn_sum_fields
  var_pop: periodical_issn_var_pop_fields
  var_samp: periodical_issn_var_samp_fields
  variance: periodical_issn_variance_fields
}

# order by aggregate values of table "periodical_issn"
input periodical_issn_aggregate_order_by {
  avg: periodical_issn_avg_order_by
  count: order_by
  max: periodical_issn_max_order_by
  min: periodical_issn_min_order_by
  stddev: periodical_issn_stddev_order_by
  stddev_pop: periodical_issn_stddev_pop_order_by
  stddev_samp: periodical_issn_stddev_samp_order_by
  sum: periodical_issn_sum_order_by
  var_pop: periodical_issn_var_pop_order_by
  var_samp: periodical_issn_var_samp_order_by
  variance: periodical_issn_variance_order_by
}

# input type for inserting array relation for remote table "periodical_issn"
input periodical_issn_arr_rel_insert_input {
  data: [periodical_issn_insert_input!]!
  on_conflict: periodical_issn_on_conflict
}

# aggregate avg on columns
type periodical_issn_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  flag: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "periodical_issn"
input periodical_issn_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "periodical_issn". All fields are combined with a logical 'AND'.
input periodical_issn_bool_exp {
  _and: [periodical_issn_bool_exp]
  _not: periodical_issn_bool_exp
  _or: [periodical_issn_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  flag: smallint_comparison_exp
  issn: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  periodical: periodical_bool_exp
  periodicalMtid: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "periodical_issn"
enum periodical_issn_constraint {
  # unique or primary key constraint
  periodical_issn_pkey
}

# input type for incrementing integer column in table "periodical_issn"
input periodical_issn_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  flag: smallint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  periodicalMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "periodical_issn"
input periodical_issn_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  flag: smallint
  issn: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodical: periodical_obj_rel_insert_input
  periodicalMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type periodical_issn_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  flag: smallint
  issn: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodicalMtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "periodical_issn"
input periodical_issn_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  flag: order_by
  issn: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type periodical_issn_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  flag: smallint
  issn: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodicalMtid: bigint
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "periodical_issn"
input periodical_issn_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  flag: order_by
  issn: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "periodical_issn"
type periodical_issn_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [periodical_issn!]!
}

# input type for inserting object relation for remote table "periodical_issn"
input periodical_issn_obj_rel_insert_input {
  data: periodical_issn_insert_input!
  on_conflict: periodical_issn_on_conflict
}

# on conflict condition type for table "periodical_issn"
input periodical_issn_on_conflict {
  constraint: periodical_issn_constraint!
  update_columns: [periodical_issn_update_column!]!
  where: periodical_issn_bool_exp
}

# ordering options when selecting data from "periodical_issn"
input periodical_issn_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  flag: order_by
  issn: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  periodical: periodical_order_by
  periodicalMtid: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "periodical_issn"
input periodical_issn_pk_columns_input {
  mtid: bigint!
}

# select columns of table "periodical_issn"
enum periodical_issn_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  flag

  # column name
  issn

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  periodicalMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "periodical_issn"
input periodical_issn_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  flag: smallint
  issn: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodicalMtid: bigint
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type periodical_issn_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  flag: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "periodical_issn"
input periodical_issn_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type periodical_issn_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  flag: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "periodical_issn"
input periodical_issn_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type periodical_issn_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  flag: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "periodical_issn"
input periodical_issn_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type periodical_issn_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  flag: smallint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  periodicalMtid: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "periodical_issn"
input periodical_issn_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "periodical_issn"
enum periodical_issn_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  flag

  # column name
  issn

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  periodicalMtid

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type periodical_issn_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  flag: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "periodical_issn"
input periodical_issn_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type periodical_issn_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  flag: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "periodical_issn"
input periodical_issn_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type periodical_issn_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  flag: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "periodical_issn"
input periodical_issn_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  flag: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate max on columns
type periodical_max_fields {
  abbreviated: String
  altNames: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  eIssn: String
  endYear: smallint
  error: Int
  homepage: String
  issnsForSort: String
  labelEng: String
  labelHun: String
  lang: Int
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  openAccessEnd: smallint
  openAccessStart: smallint
  otype: String
  pIssn: String
  permaLink: String
  predator: Int
  prevValid: bigint
  publicationCount: Int
  publishersForSort: String
  reviewType: Int
  reviewedEndYear: smallint
  reviewedStartYear: smallint
  sciType: Int
  sjrJournalMtid: bigint
  sjrUrl: String
  source: String
  startYear: smallint
  status: Int
  subTitle: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporaryAddDate: timestamp
  temporaryByForSort: String
  temporaryByMtid: bigint
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "periodical"
input periodical_max_order_by {
  abbreviated: order_by
  altNames: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  duplumKey: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  eIssn: order_by
  endYear: order_by
  error: order_by
  homepage: order_by
  issnsForSort: order_by
  labelEng: order_by
  labelHun: order_by
  lang: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  otype: order_by
  pIssn: order_by
  permaLink: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  publishersForSort: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  sjrUrl: order_by
  source: order_by
  startYear: order_by
  status: order_by
  subTitle: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  temporaryAddDate: order_by
  temporaryByForSort: order_by
  temporaryByMtid: order_by
  title: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type periodical_min_fields {
  abbreviated: String
  altNames: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  eIssn: String
  endYear: smallint
  error: Int
  homepage: String
  issnsForSort: String
  labelEng: String
  labelHun: String
  lang: Int
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  openAccessEnd: smallint
  openAccessStart: smallint
  otype: String
  pIssn: String
  permaLink: String
  predator: Int
  prevValid: bigint
  publicationCount: Int
  publishersForSort: String
  reviewType: Int
  reviewedEndYear: smallint
  reviewedStartYear: smallint
  sciType: Int
  sjrJournalMtid: bigint
  sjrUrl: String
  source: String
  startYear: smallint
  status: Int
  subTitle: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporaryAddDate: timestamp
  temporaryByForSort: String
  temporaryByMtid: bigint
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "periodical"
input periodical_min_order_by {
  abbreviated: order_by
  altNames: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  duplumKey: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  eIssn: order_by
  endYear: order_by
  error: order_by
  homepage: order_by
  issnsForSort: order_by
  labelEng: order_by
  labelHun: order_by
  lang: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  otype: order_by
  pIssn: order_by
  permaLink: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  publishersForSort: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  sjrUrl: order_by
  source: order_by
  startYear: order_by
  status: order_by
  subTitle: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  temporaryAddDate: order_by
  temporaryByForSort: order_by
  temporaryByMtid: order_by
  title: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "periodical"
type periodical_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [periodical!]!
}

# input type for inserting object relation for remote table "periodical"
input periodical_obj_rel_insert_input {
  data: periodical_insert_input!
  on_conflict: periodical_on_conflict
}

# on conflict condition type for table "periodical"
input periodical_on_conflict {
  constraint: periodical_constraint!
  update_columns: [periodical_update_column!]!
  where: periodical_bool_exp
}

# ordering options when selecting data from "periodical"
input periodical_order_by {
  abbreviated: order_by
  altNames: order_by
  ancestors_aggregate: journal_successors_aggregate_order_by
  annual: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  checkDone: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  digitalOnly: order_by
  dtype: order_by
  duplumKey: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  eIssn: order_by
  endYear: order_by
  error: order_by
  fromCitation: order_by
  homepage: order_by
  hungarian: order_by
  issnsForSort: order_by
  issns_aggregate: periodical_issn_aggregate_order_by
  labelEng: order_by
  labelHun: order_by
  lang: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  noIF: order_by
  noISSN: order_by
  noVolumeInfo: order_by
  nonScientific: order_by
  oldId: order_by
  oldTimestamp: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  otype: order_by
  pIssn: order_by
  permaLink: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  published: order_by
  publishersForSort: order_by
  publishers_aggregate: periodical_publishers_aggregate_order_by
  ratings_aggregate: rating_aggregate_order_by
  refreshed: order_by
  restartPageNumberingByIssue: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciIndexed: order_by
  sciType: order_by
  scopusIndexed: order_by
  series: order_by
  sjrJournal: periodical_order_by
  sjrJournalMtid: order_by
  sjrUrl: order_by
  source: order_by
  startYear: order_by
  status: order_by
  subTitle: order_by
  subjectsExternal_aggregate: periodical_subjects_external_aggregate_order_by
  successors_aggregate: journal_successors_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  temporary: order_by
  temporaryAddDate: order_by
  temporaryBy: users_order_by
  temporaryByForSort: order_by
  temporaryByMtid: order_by
  title: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  volumes_aggregate: series_volume_aggregate_order_by
}

# primary key columns input for table: "periodical"
input periodical_pk_columns_input {
  mtid: bigint!
}

# columns and relationships of "periodical_publishers"
type periodical_publishers {
  periodicalMtid: bigint!

  # An object relationship
  publisher: publisher!
  publishersMtid: bigint!
}

# aggregated selection of "periodical_publishers"
type periodical_publishers_aggregate {
  aggregate: periodical_publishers_aggregate_fields
  nodes: [periodical_publishers!]!
}

# aggregate fields of "periodical_publishers"
type periodical_publishers_aggregate_fields {
  avg: periodical_publishers_avg_fields
  count(columns: [periodical_publishers_select_column!], distinct: Boolean): Int
  max: periodical_publishers_max_fields
  min: periodical_publishers_min_fields
  stddev: periodical_publishers_stddev_fields
  stddev_pop: periodical_publishers_stddev_pop_fields
  stddev_samp: periodical_publishers_stddev_samp_fields
  sum: periodical_publishers_sum_fields
  var_pop: periodical_publishers_var_pop_fields
  var_samp: periodical_publishers_var_samp_fields
  variance: periodical_publishers_variance_fields
}

# order by aggregate values of table "periodical_publishers"
input periodical_publishers_aggregate_order_by {
  avg: periodical_publishers_avg_order_by
  count: order_by
  max: periodical_publishers_max_order_by
  min: periodical_publishers_min_order_by
  stddev: periodical_publishers_stddev_order_by
  stddev_pop: periodical_publishers_stddev_pop_order_by
  stddev_samp: periodical_publishers_stddev_samp_order_by
  sum: periodical_publishers_sum_order_by
  var_pop: periodical_publishers_var_pop_order_by
  var_samp: periodical_publishers_var_samp_order_by
  variance: periodical_publishers_variance_order_by
}

# input type for inserting array relation for remote table "periodical_publishers"
input periodical_publishers_arr_rel_insert_input {
  data: [periodical_publishers_insert_input!]!
}

# aggregate avg on columns
type periodical_publishers_avg_fields {
  periodicalMtid: Float
  publishersMtid: Float
}

# order by avg() on columns of table "periodical_publishers"
input periodical_publishers_avg_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# Boolean expression to filter rows from the table "periodical_publishers". All fields are combined with a logical 'AND'.
input periodical_publishers_bool_exp {
  _and: [periodical_publishers_bool_exp]
  _not: periodical_publishers_bool_exp
  _or: [periodical_publishers_bool_exp]
  periodicalMtid: bigint_comparison_exp
  publisher: publisher_bool_exp
  publishersMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "periodical_publishers"
input periodical_publishers_inc_input {
  periodicalMtid: bigint
  publishersMtid: bigint
}

# input type for inserting data into table "periodical_publishers"
input periodical_publishers_insert_input {
  periodicalMtid: bigint
  publisher: publisher_obj_rel_insert_input
  publishersMtid: bigint
}

# aggregate max on columns
type periodical_publishers_max_fields {
  periodicalMtid: bigint
  publishersMtid: bigint
}

# order by max() on columns of table "periodical_publishers"
input periodical_publishers_max_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# aggregate min on columns
type periodical_publishers_min_fields {
  periodicalMtid: bigint
  publishersMtid: bigint
}

# order by min() on columns of table "periodical_publishers"
input periodical_publishers_min_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# response of any mutation on the table "periodical_publishers"
type periodical_publishers_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [periodical_publishers!]!
}

# input type for inserting object relation for remote table "periodical_publishers"
input periodical_publishers_obj_rel_insert_input {
  data: periodical_publishers_insert_input!
}

# ordering options when selecting data from "periodical_publishers"
input periodical_publishers_order_by {
  periodicalMtid: order_by
  publisher: publisher_order_by
  publishersMtid: order_by
}

# select columns of table "periodical_publishers"
enum periodical_publishers_select_column {
  # column name
  periodicalMtid

  # column name
  publishersMtid
}

# input type for updating data in table "periodical_publishers"
input periodical_publishers_set_input {
  periodicalMtid: bigint
  publishersMtid: bigint
}

# aggregate stddev on columns
type periodical_publishers_stddev_fields {
  periodicalMtid: Float
  publishersMtid: Float
}

# order by stddev() on columns of table "periodical_publishers"
input periodical_publishers_stddev_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# aggregate stddev_pop on columns
type periodical_publishers_stddev_pop_fields {
  periodicalMtid: Float
  publishersMtid: Float
}

# order by stddev_pop() on columns of table "periodical_publishers"
input periodical_publishers_stddev_pop_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# aggregate stddev_samp on columns
type periodical_publishers_stddev_samp_fields {
  periodicalMtid: Float
  publishersMtid: Float
}

# order by stddev_samp() on columns of table "periodical_publishers"
input periodical_publishers_stddev_samp_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# aggregate sum on columns
type periodical_publishers_sum_fields {
  periodicalMtid: bigint
  publishersMtid: bigint
}

# order by sum() on columns of table "periodical_publishers"
input periodical_publishers_sum_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# aggregate var_pop on columns
type periodical_publishers_var_pop_fields {
  periodicalMtid: Float
  publishersMtid: Float
}

# order by var_pop() on columns of table "periodical_publishers"
input periodical_publishers_var_pop_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# aggregate var_samp on columns
type periodical_publishers_var_samp_fields {
  periodicalMtid: Float
  publishersMtid: Float
}

# order by var_samp() on columns of table "periodical_publishers"
input periodical_publishers_var_samp_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# aggregate variance on columns
type periodical_publishers_variance_fields {
  periodicalMtid: Float
  publishersMtid: Float
}

# order by variance() on columns of table "periodical_publishers"
input periodical_publishers_variance_order_by {
  periodicalMtid: order_by
  publishersMtid: order_by
}

# select columns of table "periodical"
enum periodical_select_column {
  # column name
  abbreviated

  # column name
  altNames

  # column name
  annual

  # column name
  approved

  # column name
  approverMtid

  # column name
  checkDone

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  digitalOnly

  # column name
  dtype

  # column name
  duplumKey

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  eIssn

  # column name
  endYear

  # column name
  error

  # column name
  fromCitation

  # column name
  homepage

  # column name
  hungarian

  # column name
  issnsForSort

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lang

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  noIF

  # column name
  noISSN

  # column name
  noVolumeInfo

  # column name
  nonScientific

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  openAccess

  # column name
  openAccessEnd

  # column name
  openAccessStart

  # column name
  otype

  # column name
  pIssn

  # column name
  permaLink

  # column name
  predator

  # column name
  prevValid

  # column name
  publicationCount

  # column name
  published

  # column name
  publishersForSort

  # column name
  refreshed

  # column name
  restartPageNumberingByIssue

  # column name
  reviewType

  # column name
  reviewedEndYear

  # column name
  reviewedStartYear

  # column name
  sciIndexed

  # column name
  sciType

  # column name
  scopusIndexed

  # column name
  series

  # column name
  sjrJournalMtid

  # column name
  sjrUrl

  # column name
  source

  # column name
  startYear

  # column name
  status

  # column name
  subTitle

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  temporary

  # column name
  temporaryAddDate

  # column name
  temporaryByForSort

  # column name
  temporaryByMtid

  # column name
  title

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "periodical"
input periodical_set_input {
  abbreviated: String
  altNames: String
  annual: Boolean
  approved: timestamp
  approverMtid: bigint
  checkDone: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  digitalOnly: Boolean
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  eIssn: String
  endYear: smallint
  error: Int
  fromCitation: Boolean
  homepage: String
  hungarian: Boolean
  issnsForSort: String
  labelEng: String
  labelHun: String
  lang: Int
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  noIF: Boolean
  noISSN: Boolean
  noVolumeInfo: Boolean
  nonScientific: Boolean
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  openAccessEnd: smallint
  openAccessStart: smallint
  otype: String
  pIssn: String
  permaLink: String
  predator: Int
  prevValid: bigint
  publicationCount: Int
  published: Boolean
  publishersForSort: String
  refreshed: Boolean
  restartPageNumberingByIssue: Boolean
  reviewType: Int
  reviewedEndYear: smallint
  reviewedStartYear: smallint
  sciIndexed: Boolean
  sciType: Int
  scopusIndexed: Boolean
  series: Boolean
  sjrJournalMtid: bigint
  sjrUrl: String
  source: String
  startYear: smallint
  status: Int
  subTitle: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporary: Boolean
  temporaryAddDate: timestamp
  temporaryByForSort: String
  temporaryByMtid: bigint
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type periodical_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  endYear: Float
  error: Float
  lang: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  openAccess: Float
  openAccessEnd: Float
  openAccessStart: Float
  predator: Float
  prevValid: Float
  publicationCount: Float
  reviewType: Float
  reviewedEndYear: Float
  reviewedStartYear: Float
  sciType: Float
  sjrJournalMtid: Float
  startYear: Float
  status: Float
  temporaryByMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "periodical"
input periodical_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type periodical_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  endYear: Float
  error: Float
  lang: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  openAccess: Float
  openAccessEnd: Float
  openAccessStart: Float
  predator: Float
  prevValid: Float
  publicationCount: Float
  reviewType: Float
  reviewedEndYear: Float
  reviewedStartYear: Float
  sciType: Float
  sjrJournalMtid: Float
  startYear: Float
  status: Float
  temporaryByMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "periodical"
input periodical_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type periodical_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  endYear: Float
  error: Float
  lang: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  openAccess: Float
  openAccessEnd: Float
  openAccessStart: Float
  predator: Float
  prevValid: Float
  publicationCount: Float
  reviewType: Float
  reviewedEndYear: Float
  reviewedStartYear: Float
  sciType: Float
  sjrJournalMtid: Float
  startYear: Float
  status: Float
  temporaryByMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "periodical"
input periodical_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "periodical_subjects_external"
type periodical_subjects_external {
  # An object relationship
  classificationExternal: classification_external!
  periodicalMtid: bigint!
  subjectsExternalMtid: bigint!
}

# aggregated selection of "periodical_subjects_external"
type periodical_subjects_external_aggregate {
  aggregate: periodical_subjects_external_aggregate_fields
  nodes: [periodical_subjects_external!]!
}

# aggregate fields of "periodical_subjects_external"
type periodical_subjects_external_aggregate_fields {
  avg: periodical_subjects_external_avg_fields
  count(columns: [periodical_subjects_external_select_column!], distinct: Boolean): Int
  max: periodical_subjects_external_max_fields
  min: periodical_subjects_external_min_fields
  stddev: periodical_subjects_external_stddev_fields
  stddev_pop: periodical_subjects_external_stddev_pop_fields
  stddev_samp: periodical_subjects_external_stddev_samp_fields
  sum: periodical_subjects_external_sum_fields
  var_pop: periodical_subjects_external_var_pop_fields
  var_samp: periodical_subjects_external_var_samp_fields
  variance: periodical_subjects_external_variance_fields
}

# order by aggregate values of table "periodical_subjects_external"
input periodical_subjects_external_aggregate_order_by {
  avg: periodical_subjects_external_avg_order_by
  count: order_by
  max: periodical_subjects_external_max_order_by
  min: periodical_subjects_external_min_order_by
  stddev: periodical_subjects_external_stddev_order_by
  stddev_pop: periodical_subjects_external_stddev_pop_order_by
  stddev_samp: periodical_subjects_external_stddev_samp_order_by
  sum: periodical_subjects_external_sum_order_by
  var_pop: periodical_subjects_external_var_pop_order_by
  var_samp: periodical_subjects_external_var_samp_order_by
  variance: periodical_subjects_external_variance_order_by
}

# input type for inserting array relation for remote table "periodical_subjects_external"
input periodical_subjects_external_arr_rel_insert_input {
  data: [periodical_subjects_external_insert_input!]!
}

# aggregate avg on columns
type periodical_subjects_external_avg_fields {
  periodicalMtid: Float
  subjectsExternalMtid: Float
}

# order by avg() on columns of table "periodical_subjects_external"
input periodical_subjects_external_avg_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# Boolean expression to filter rows from the table "periodical_subjects_external".
# All fields are combined with a logical 'AND'.
input periodical_subjects_external_bool_exp {
  _and: [periodical_subjects_external_bool_exp]
  _not: periodical_subjects_external_bool_exp
  _or: [periodical_subjects_external_bool_exp]
  classificationExternal: classification_external_bool_exp
  periodicalMtid: bigint_comparison_exp
  subjectsExternalMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "periodical_subjects_external"
input periodical_subjects_external_inc_input {
  periodicalMtid: bigint
  subjectsExternalMtid: bigint
}

# input type for inserting data into table "periodical_subjects_external"
input periodical_subjects_external_insert_input {
  classificationExternal: classification_external_obj_rel_insert_input
  periodicalMtid: bigint
  subjectsExternalMtid: bigint
}

# aggregate max on columns
type periodical_subjects_external_max_fields {
  periodicalMtid: bigint
  subjectsExternalMtid: bigint
}

# order by max() on columns of table "periodical_subjects_external"
input periodical_subjects_external_max_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate min on columns
type periodical_subjects_external_min_fields {
  periodicalMtid: bigint
  subjectsExternalMtid: bigint
}

# order by min() on columns of table "periodical_subjects_external"
input periodical_subjects_external_min_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# response of any mutation on the table "periodical_subjects_external"
type periodical_subjects_external_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [periodical_subjects_external!]!
}

# input type for inserting object relation for remote table "periodical_subjects_external"
input periodical_subjects_external_obj_rel_insert_input {
  data: periodical_subjects_external_insert_input!
}

# ordering options when selecting data from "periodical_subjects_external"
input periodical_subjects_external_order_by {
  classificationExternal: classification_external_order_by
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# select columns of table "periodical_subjects_external"
enum periodical_subjects_external_select_column {
  # column name
  periodicalMtid

  # column name
  subjectsExternalMtid
}

# input type for updating data in table "periodical_subjects_external"
input periodical_subjects_external_set_input {
  periodicalMtid: bigint
  subjectsExternalMtid: bigint
}

# aggregate stddev on columns
type periodical_subjects_external_stddev_fields {
  periodicalMtid: Float
  subjectsExternalMtid: Float
}

# order by stddev() on columns of table "periodical_subjects_external"
input periodical_subjects_external_stddev_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate stddev_pop on columns
type periodical_subjects_external_stddev_pop_fields {
  periodicalMtid: Float
  subjectsExternalMtid: Float
}

# order by stddev_pop() on columns of table "periodical_subjects_external"
input periodical_subjects_external_stddev_pop_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate stddev_samp on columns
type periodical_subjects_external_stddev_samp_fields {
  periodicalMtid: Float
  subjectsExternalMtid: Float
}

# order by stddev_samp() on columns of table "periodical_subjects_external"
input periodical_subjects_external_stddev_samp_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate sum on columns
type periodical_subjects_external_sum_fields {
  periodicalMtid: bigint
  subjectsExternalMtid: bigint
}

# order by sum() on columns of table "periodical_subjects_external"
input periodical_subjects_external_sum_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate var_pop on columns
type periodical_subjects_external_var_pop_fields {
  periodicalMtid: Float
  subjectsExternalMtid: Float
}

# order by var_pop() on columns of table "periodical_subjects_external"
input periodical_subjects_external_var_pop_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate var_samp on columns
type periodical_subjects_external_var_samp_fields {
  periodicalMtid: Float
  subjectsExternalMtid: Float
}

# order by var_samp() on columns of table "periodical_subjects_external"
input periodical_subjects_external_var_samp_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate variance on columns
type periodical_subjects_external_variance_fields {
  periodicalMtid: Float
  subjectsExternalMtid: Float
}

# order by variance() on columns of table "periodical_subjects_external"
input periodical_subjects_external_variance_order_by {
  periodicalMtid: order_by
  subjectsExternalMtid: order_by
}

# aggregate sum on columns
type periodical_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  endYear: smallint
  error: Int
  lang: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  openAccess: Int
  openAccessEnd: smallint
  openAccessStart: smallint
  predator: Int
  prevValid: bigint
  publicationCount: Int
  reviewType: Int
  reviewedEndYear: smallint
  reviewedStartYear: smallint
  sciType: Int
  sjrJournalMtid: bigint
  startYear: smallint
  status: Int
  temporaryByMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "periodical"
input periodical_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "periodical"
enum periodical_update_column {
  # column name
  abbreviated

  # column name
  altNames

  # column name
  annual

  # column name
  approved

  # column name
  approverMtid

  # column name
  checkDone

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  digitalOnly

  # column name
  dtype

  # column name
  duplumKey

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  eIssn

  # column name
  endYear

  # column name
  error

  # column name
  fromCitation

  # column name
  homepage

  # column name
  hungarian

  # column name
  issnsForSort

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lang

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  noIF

  # column name
  noISSN

  # column name
  noVolumeInfo

  # column name
  nonScientific

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  openAccess

  # column name
  openAccessEnd

  # column name
  openAccessStart

  # column name
  otype

  # column name
  pIssn

  # column name
  permaLink

  # column name
  predator

  # column name
  prevValid

  # column name
  publicationCount

  # column name
  published

  # column name
  publishersForSort

  # column name
  refreshed

  # column name
  restartPageNumberingByIssue

  # column name
  reviewType

  # column name
  reviewedEndYear

  # column name
  reviewedStartYear

  # column name
  sciIndexed

  # column name
  sciType

  # column name
  scopusIndexed

  # column name
  series

  # column name
  sjrJournalMtid

  # column name
  sjrUrl

  # column name
  source

  # column name
  startYear

  # column name
  status

  # column name
  subTitle

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  temporary

  # column name
  temporaryAddDate

  # column name
  temporaryByForSort

  # column name
  temporaryByMtid

  # column name
  title

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type periodical_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  endYear: Float
  error: Float
  lang: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  openAccess: Float
  openAccessEnd: Float
  openAccessStart: Float
  predator: Float
  prevValid: Float
  publicationCount: Float
  reviewType: Float
  reviewedEndYear: Float
  reviewedStartYear: Float
  sciType: Float
  sjrJournalMtid: Float
  startYear: Float
  status: Float
  temporaryByMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "periodical"
input periodical_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type periodical_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  endYear: Float
  error: Float
  lang: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  openAccess: Float
  openAccessEnd: Float
  openAccessStart: Float
  predator: Float
  prevValid: Float
  publicationCount: Float
  reviewType: Float
  reviewedEndYear: Float
  reviewedStartYear: Float
  sciType: Float
  sjrJournalMtid: Float
  startYear: Float
  status: Float
  temporaryByMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "periodical"
input periodical_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type periodical_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  endYear: Float
  error: Float
  lang: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  openAccess: Float
  openAccessEnd: Float
  openAccessStart: Float
  predator: Float
  prevValid: Float
  publicationCount: Float
  reviewType: Float
  reviewedEndYear: Float
  reviewedStartYear: Float
  sciType: Float
  sjrJournalMtid: Float
  startYear: Float
  status: Float
  temporaryByMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "periodical"
input periodical_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  endYear: order_by
  error: order_by
  lang: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  openAccess: order_by
  openAccessEnd: order_by
  openAccessStart: order_by
  predator: order_by
  prevValid: order_by
  publicationCount: order_by
  reviewType: order_by
  reviewedEndYear: order_by
  reviewedStartYear: order_by
  sciType: order_by
  sjrJournalMtid: order_by
  startYear: order_by
  status: order_by
  temporaryByMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "project"
type project {
  acronym: String
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  fundRef: String

  # An object relationship
  funder: organization
  funderMtid: bigint
  grantNumber: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "project"
type project_aggregate {
  aggregate: project_aggregate_fields
  nodes: [project!]!
}

# aggregate fields of "project"
type project_aggregate_fields {
  avg: project_avg_fields
  count(columns: [project_select_column!], distinct: Boolean): Int
  max: project_max_fields
  min: project_min_fields
  stddev: project_stddev_fields
  stddev_pop: project_stddev_pop_fields
  stddev_samp: project_stddev_samp_fields
  sum: project_sum_fields
  var_pop: project_var_pop_fields
  var_samp: project_var_samp_fields
  variance: project_variance_fields
}

# order by aggregate values of table "project"
input project_aggregate_order_by {
  avg: project_avg_order_by
  count: order_by
  max: project_max_order_by
  min: project_min_order_by
  stddev: project_stddev_order_by
  stddev_pop: project_stddev_pop_order_by
  stddev_samp: project_stddev_samp_order_by
  sum: project_sum_order_by
  var_pop: project_var_pop_order_by
  var_samp: project_var_samp_order_by
  variance: project_variance_order_by
}

# input type for inserting array relation for remote table "project"
input project_arr_rel_insert_input {
  data: [project_insert_input!]!
  on_conflict: project_on_conflict
}

# aggregate avg on columns
type project_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  funderMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "project"
input project_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "project". All fields are combined with a logical 'AND'.
input project_bool_exp {
  _and: [project_bool_exp]
  _not: project_bool_exp
  _or: [project_bool_exp]
  acronym: String_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  fundRef: String_comparison_exp
  funder: organization_bool_exp
  funderMtid: bigint_comparison_exp
  grantNumber: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "project"
enum project_constraint {
  # unique or primary key constraint
  project_pkey
}

# input type for incrementing integer column in table "project"
input project_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  funderMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "project"
input project_insert_input {
  acronym: String
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  fundRef: String
  funder: organization_obj_rel_insert_input
  funderMtid: bigint
  grantNumber: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type project_max_fields {
  acronym: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fundRef: String
  funderMtid: bigint
  grantNumber: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "project"
input project_max_order_by {
  acronym: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fundRef: order_by
  funderMtid: order_by
  grantNumber: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type project_min_fields {
  acronym: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fundRef: String
  funderMtid: bigint
  grantNumber: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "project"
input project_min_order_by {
  acronym: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fundRef: order_by
  funderMtid: order_by
  grantNumber: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "project"
type project_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [project!]!
}

# input type for inserting object relation for remote table "project"
input project_obj_rel_insert_input {
  data: project_insert_input!
  on_conflict: project_on_conflict
}

# on conflict condition type for table "project"
input project_on_conflict {
  constraint: project_constraint!
  update_columns: [project_update_column!]!
  where: project_bool_exp
}

# ordering options when selecting data from "project"
input project_order_by {
  acronym: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fundRef: order_by
  funder: organization_order_by
  funderMtid: order_by
  grantNumber: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "project"
input project_pk_columns_input {
  mtid: bigint!
}

# select columns of table "project"
enum project_select_column {
  # column name
  acronym

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fundRef

  # column name
  funderMtid

  # column name
  grantNumber

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "project"
input project_set_input {
  acronym: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fundRef: String
  funderMtid: bigint
  grantNumber: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type project_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  funderMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "project"
input project_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type project_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  funderMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "project"
input project_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type project_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  funderMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "project"
input project_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type project_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  funderMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "project"
input project_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "project"
enum project_update_column {
  # column name
  acronym

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fundRef

  # column name
  funderMtid

  # column name
  grantNumber

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type project_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  funderMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "project"
input project_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type project_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  funderMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "project"
input project_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type project_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  funderMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "project"
input project_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  funderMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "pub_fixer_log"
type pub_fixer_log {
  duration: bigint
  id: bigint!
  idsCopied: String
  log: String
  mtid: bigint
  otype: String
  survivorMtid: bigint
  timestamp: timestamp
  warn: String
}

# aggregated selection of "pub_fixer_log"
type pub_fixer_log_aggregate {
  aggregate: pub_fixer_log_aggregate_fields
  nodes: [pub_fixer_log!]!
}

# aggregate fields of "pub_fixer_log"
type pub_fixer_log_aggregate_fields {
  avg: pub_fixer_log_avg_fields
  count(columns: [pub_fixer_log_select_column!], distinct: Boolean): Int
  max: pub_fixer_log_max_fields
  min: pub_fixer_log_min_fields
  stddev: pub_fixer_log_stddev_fields
  stddev_pop: pub_fixer_log_stddev_pop_fields
  stddev_samp: pub_fixer_log_stddev_samp_fields
  sum: pub_fixer_log_sum_fields
  var_pop: pub_fixer_log_var_pop_fields
  var_samp: pub_fixer_log_var_samp_fields
  variance: pub_fixer_log_variance_fields
}

# order by aggregate values of table "pub_fixer_log"
input pub_fixer_log_aggregate_order_by {
  avg: pub_fixer_log_avg_order_by
  count: order_by
  max: pub_fixer_log_max_order_by
  min: pub_fixer_log_min_order_by
  stddev: pub_fixer_log_stddev_order_by
  stddev_pop: pub_fixer_log_stddev_pop_order_by
  stddev_samp: pub_fixer_log_stddev_samp_order_by
  sum: pub_fixer_log_sum_order_by
  var_pop: pub_fixer_log_var_pop_order_by
  var_samp: pub_fixer_log_var_samp_order_by
  variance: pub_fixer_log_variance_order_by
}

# input type for inserting array relation for remote table "pub_fixer_log"
input pub_fixer_log_arr_rel_insert_input {
  data: [pub_fixer_log_insert_input!]!
  on_conflict: pub_fixer_log_on_conflict
}

# aggregate avg on columns
type pub_fixer_log_avg_fields {
  duration: Float
  id: Float
  mtid: Float
  survivorMtid: Float
}

# order by avg() on columns of table "pub_fixer_log"
input pub_fixer_log_avg_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# Boolean expression to filter rows from the table "pub_fixer_log". All fields are combined with a logical 'AND'.
input pub_fixer_log_bool_exp {
  _and: [pub_fixer_log_bool_exp]
  _not: pub_fixer_log_bool_exp
  _or: [pub_fixer_log_bool_exp]
  duration: bigint_comparison_exp
  id: bigint_comparison_exp
  idsCopied: String_comparison_exp
  log: String_comparison_exp
  mtid: bigint_comparison_exp
  otype: String_comparison_exp
  survivorMtid: bigint_comparison_exp
  timestamp: timestamp_comparison_exp
  warn: String_comparison_exp
}

# unique or primary key constraints on table "pub_fixer_log"
enum pub_fixer_log_constraint {
  # unique or primary key constraint
  pub_fixer_log_pkey
}

# input type for incrementing integer column in table "pub_fixer_log"
input pub_fixer_log_inc_input {
  duration: bigint
  id: bigint
  mtid: bigint
  survivorMtid: bigint
}

# input type for inserting data into table "pub_fixer_log"
input pub_fixer_log_insert_input {
  duration: bigint
  id: bigint
  idsCopied: String
  log: String
  mtid: bigint
  otype: String
  survivorMtid: bigint
  timestamp: timestamp
  warn: String
}

# aggregate max on columns
type pub_fixer_log_max_fields {
  duration: bigint
  id: bigint
  idsCopied: String
  log: String
  mtid: bigint
  otype: String
  survivorMtid: bigint
  timestamp: timestamp
  warn: String
}

# order by max() on columns of table "pub_fixer_log"
input pub_fixer_log_max_order_by {
  duration: order_by
  id: order_by
  idsCopied: order_by
  log: order_by
  mtid: order_by
  otype: order_by
  survivorMtid: order_by
  timestamp: order_by
  warn: order_by
}

# aggregate min on columns
type pub_fixer_log_min_fields {
  duration: bigint
  id: bigint
  idsCopied: String
  log: String
  mtid: bigint
  otype: String
  survivorMtid: bigint
  timestamp: timestamp
  warn: String
}

# order by min() on columns of table "pub_fixer_log"
input pub_fixer_log_min_order_by {
  duration: order_by
  id: order_by
  idsCopied: order_by
  log: order_by
  mtid: order_by
  otype: order_by
  survivorMtid: order_by
  timestamp: order_by
  warn: order_by
}

# response of any mutation on the table "pub_fixer_log"
type pub_fixer_log_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [pub_fixer_log!]!
}

# input type for inserting object relation for remote table "pub_fixer_log"
input pub_fixer_log_obj_rel_insert_input {
  data: pub_fixer_log_insert_input!
  on_conflict: pub_fixer_log_on_conflict
}

# on conflict condition type for table "pub_fixer_log"
input pub_fixer_log_on_conflict {
  constraint: pub_fixer_log_constraint!
  update_columns: [pub_fixer_log_update_column!]!
  where: pub_fixer_log_bool_exp
}

# ordering options when selecting data from "pub_fixer_log"
input pub_fixer_log_order_by {
  duration: order_by
  id: order_by
  idsCopied: order_by
  log: order_by
  mtid: order_by
  otype: order_by
  survivorMtid: order_by
  timestamp: order_by
  warn: order_by
}

# primary key columns input for table: "pub_fixer_log"
input pub_fixer_log_pk_columns_input {
  id: bigint!
}

# select columns of table "pub_fixer_log"
enum pub_fixer_log_select_column {
  # column name
  duration

  # column name
  id

  # column name
  idsCopied

  # column name
  log

  # column name
  mtid

  # column name
  otype

  # column name
  survivorMtid

  # column name
  timestamp

  # column name
  warn
}

# input type for updating data in table "pub_fixer_log"
input pub_fixer_log_set_input {
  duration: bigint
  id: bigint
  idsCopied: String
  log: String
  mtid: bigint
  otype: String
  survivorMtid: bigint
  timestamp: timestamp
  warn: String
}

# aggregate stddev on columns
type pub_fixer_log_stddev_fields {
  duration: Float
  id: Float
  mtid: Float
  survivorMtid: Float
}

# order by stddev() on columns of table "pub_fixer_log"
input pub_fixer_log_stddev_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# aggregate stddev_pop on columns
type pub_fixer_log_stddev_pop_fields {
  duration: Float
  id: Float
  mtid: Float
  survivorMtid: Float
}

# order by stddev_pop() on columns of table "pub_fixer_log"
input pub_fixer_log_stddev_pop_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# aggregate stddev_samp on columns
type pub_fixer_log_stddev_samp_fields {
  duration: Float
  id: Float
  mtid: Float
  survivorMtid: Float
}

# order by stddev_samp() on columns of table "pub_fixer_log"
input pub_fixer_log_stddev_samp_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# aggregate sum on columns
type pub_fixer_log_sum_fields {
  duration: bigint
  id: bigint
  mtid: bigint
  survivorMtid: bigint
}

# order by sum() on columns of table "pub_fixer_log"
input pub_fixer_log_sum_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# update columns of table "pub_fixer_log"
enum pub_fixer_log_update_column {
  # column name
  duration

  # column name
  id

  # column name
  idsCopied

  # column name
  log

  # column name
  mtid

  # column name
  otype

  # column name
  survivorMtid

  # column name
  timestamp

  # column name
  warn
}

# aggregate var_pop on columns
type pub_fixer_log_var_pop_fields {
  duration: Float
  id: Float
  mtid: Float
  survivorMtid: Float
}

# order by var_pop() on columns of table "pub_fixer_log"
input pub_fixer_log_var_pop_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# aggregate var_samp on columns
type pub_fixer_log_var_samp_fields {
  duration: Float
  id: Float
  mtid: Float
  survivorMtid: Float
}

# order by var_samp() on columns of table "pub_fixer_log"
input pub_fixer_log_var_samp_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# aggregate variance on columns
type pub_fixer_log_variance_fields {
  duration: Float
  id: Float
  mtid: Float
  survivorMtid: Float
}

# order by variance() on columns of table "pub_fixer_log"
input pub_fixer_log_variance_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  survivorMtid: order_by
}

# columns and relationships of "publication"
type publication {
  abstractText: String
  acceptanceYear: smallint
  adminApproved: timestamp

  # An object relationship
  adminApprover: users
  adminApproverForSort: String
  adminApproverMtid: bigint
  altTitles: String
  applicationYear: smallint
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  authorCount: Int!

  # An array relationship
  authors(
    # distinct select on columns
    distinct_on: [publication_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_authors_order_by!]

    # filter the rows returned
    where: publication_authors_bool_exp
  ): [publication_authors!]!

  # An aggregated array relationship
  authors_aggregate(
    # distinct select on columns
    distinct_on: [publication_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_authors_order_by!]

    # filter the rows returned
    where: publication_authors_bool_exp
  ): publication_authors_aggregate!

  # An array relationship
  authorships(
    # distinct select on columns
    distinct_on: [authorship_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_order_by!]

    # filter the rows returned
    where: authorship_bool_exp
  ): [authorship!]!

  # An aggregated array relationship
  authorships_aggregate(
    # distinct select on columns
    distinct_on: [authorship_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_order_by!]

    # filter the rows returned
    where: authorship_bool_exp
  ): authorship_aggregate!

  # An object relationship
  book: publication
  bookMtid: bigint
  bulkDuplumSearchDone: Boolean
  caseNumber: String

  # An object relationship
  category: category
  categoryForSort: String
  categoryMtid: bigint
  chapterCount: Int

  # An array relationship
  chapters(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): [publication!]!

  # An aggregated array relationship
  chapters_aggregate(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): publication_aggregate!
  checked: timestamp

  # An object relationship
  checker: users
  checkerMtid: bigint
  citation: Boolean!
  citationCount: Int!
  citationCountUnpublished: Int!
  citationCountWoOther: Int!

  # An array relationship
  citations(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): [citation!]!

  # An aggregated array relationship
  citations_aggregate(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): citation_aggregate!
  citedCount: Int!
  citedPubCount: Int!

  # An array relationship
  cites(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): [citation!]!

  # An aggregated array relationship
  cites_aggregate(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): citation_aggregate!
  citingPubCount: Int!
  citingPubCountWoOther: Int
  collaboration: Int
  comment: String
  comment2: String

  # An object relationship
  conference: conference
  conferenceMtid: bigint
  conferencePublication: Boolean
  consultant: String
  consultant2: String

  # An object relationship
  consultantAuthor: users

  # An object relationship
  consultantAuthor2: users
  consultantAuthor2Mtid: bigint
  consultantAuthorMtid: bigint
  contributorCount: Int!
  core: Boolean!

  # An object relationship
  country: location
  countryMtid: bigint
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  description0: String
  description1: String
  description2: String
  description3: String
  description4: String
  description5: String
  digital: Boolean
  directInstituteCount: Int

  # An array relationship
  directInstitutes(
    # distinct select on columns
    distinct_on: [publication_direct_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_direct_institutes_order_by!]

    # filter the rows returned
    where: publication_direct_institutes_bool_exp
  ): [publication_direct_institutes!]!
  directInstitutesForSort: String

  # An aggregated array relationship
  directInstitutes_aggregate(
    # distinct select on columns
    distinct_on: [publication_direct_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_direct_institutes_order_by!]

    # filter the rows returned
    where: publication_direct_institutes_bool_exp
  ): publication_direct_institutes_aggregate!

  # An object relationship
  discipline: discipline
  disciplineMtid: bigint
  doiCitationCount: Int!
  dtype: String!
  duplumKey: String
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  editionNumber: Int
  endDate: date
  error: Int
  externalSource: String

  # An array relationship
  files(
    # distinct select on columns
    distinct_on: [publication_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_files_order_by!]

    # filter the rows returned
    where: publication_files_bool_exp
  ): [publication_files!]!

  # An aggregated array relationship
  files_aggregate(
    # distinct select on columns
    distinct_on: [publication_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_files_order_by!]

    # filter the rows returned
    where: publication_files_bool_exp
  ): publication_files_aggregate!
  firstAuthor: String
  firstPage: String
  firstPageOrInternalIdForSort: String
  foreignEdition: Boolean
  foreignEditionCitationCount: Int
  foreignLanguage: Boolean
  fromCitation: Boolean
  fullPublication: Boolean

  # An array relationship
  fundings(
    # distinct select on columns
    distinct_on: [funding_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [funding_order_by!]

    # filter the rows returned
    where: funding_bool_exp
  ): [funding!]!

  # An aggregated array relationship
  fundings_aggregate(
    # distinct select on columns
    distinct_on: [funding_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [funding_order_by!]

    # filter the rows returned
    where: funding_bool_exp
  ): funding_aggregate!
  group_mtid: bigint
  hasCitationDuplums: Boolean!

  # An array relationship
  identifiers(
    # distinct select on columns
    distinct_on: [publication_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_identifier_order_by!]

    # filter the rows returned
    where: publication_identifier_bool_exp
  ): [publication_identifier!]!

  # An aggregated array relationship
  identifiers_aggregate(
    # distinct select on columns
    distinct_on: [publication_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_identifier_order_by!]

    # filter the rows returned
    where: publication_identifier_bool_exp
  ): publication_identifier_aggregate!

  # An object relationship
  ifRating: rating
  ifRatingMtid: bigint
  impactFactor: Float
  inSelectedPubs: String
  independentCitCountWoOther: Int!
  independentCitationCount: Int!
  independentCitingPubCount: Int!
  independentCitingPubCountWoOther: Int

  # An array relationship
  institutes(
    # distinct select on columns
    distinct_on: [publication_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_institutes_order_by!]

    # filter the rows returned
    where: publication_institutes_bool_exp
  ): [publication_institutes!]!

  # An aggregated array relationship
  institutes_aggregate(
    # distinct select on columns
    distinct_on: [publication_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_institutes_order_by!]

    # filter the rows returned
    where: publication_institutes_bool_exp
  ): publication_institutes_aggregate!
  internalId: String
  ipc: String
  issue: String

  # An object relationship
  journal: periodical
  journalForSort: String
  journalMtid: bigint
  journalName: String

  # An array relationship
  keywords(
    # distinct select on columns
    distinct_on: [publication_keywords_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_keywords_order_by!]

    # filter the rows returned
    where: publication_keywords_bool_exp
  ): [publication_keywords!]!

  # An aggregated array relationship
  keywords_aggregate(
    # distinct select on columns
    distinct_on: [publication_keywords_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_keywords_order_by!]

    # filter the rows returned
    where: publication_keywords_bool_exp
  ): publication_keywords_aggregate!
  labelEng: String
  labelHun: String

  # An array relationship
  languages(
    # distinct select on columns
    distinct_on: [publication_languages_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_languages_order_by!]

    # filter the rows returned
    where: publication_languages_bool_exp
  ): [publication_languages!]!
  languagesForSort: String

  # An aggregated array relationship
  languages_aggregate(
    # distinct select on columns
    distinct_on: [publication_languages_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_languages_order_by!]

    # filter the rows returned
    where: publication_languages_bool_exp
  ): publication_languages_aggregate!
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastPage: String
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users

  # An object relationship
  mabDiscipline: mab_discipline
  mabDisciplineMtid: bigint
  missingAuthor: Boolean
  mtid: bigint!
  nationalOrigin: Boolean
  nationalOriginCitationCount: Int
  number: String

  # An object relationship
  oaByAuthor: users
  oaByAuthorMtid: bigint
  oaCheckDate: date
  oaEmbargoDate: date
  oaFree: Boolean!
  oaLink: String
  oaType: Int
  oaTypeDisp: Int
  oldId: Int

  # An array relationship
  oldOrgAuthors(
    # distinct select on columns
    distinct_on: [publication_old_org_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_old_org_authors_order_by!]

    # filter the rows returned
    where: publication_old_org_authors_bool_exp
  ): [publication_old_org_authors!]!

  # An aggregated array relationship
  oldOrgAuthors_aggregate(
    # distinct select on columns
    distinct_on: [publication_old_org_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_old_org_authors_order_by!]

    # filter the rows returned
    where: publication_old_org_authors_bool_exp
  ): publication_old_org_authors_aggregate!
  oldTimestamp: timestamp
  otype: String
  ownerAuthorCount: Int!

  # An array relationship
  ownerAuthors(
    # distinct select on columns
    distinct_on: [publication_owner_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_authors_order_by!]

    # filter the rows returned
    where: publication_owner_authors_bool_exp
  ): [publication_owner_authors!]!

  # An aggregated array relationship
  ownerAuthors_aggregate(
    # distinct select on columns
    distinct_on: [publication_owner_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_authors_order_by!]

    # filter the rows returned
    where: publication_owner_authors_bool_exp
  ): publication_owner_authors_aggregate!
  ownerInstituteCount: Int!

  # An array relationship
  ownerInstitutes(
    # distinct select on columns
    distinct_on: [publication_owner_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_institutes_order_by!]

    # filter the rows returned
    where: publication_owner_institutes_bool_exp
  ): [publication_owner_institutes!]!

  # An aggregated array relationship
  ownerInstitutes_aggregate(
    # distinct select on columns
    distinct_on: [publication_owner_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_institutes_order_by!]

    # filter the rows returned
    where: publication_owner_institutes_bool_exp
  ): publication_owner_institutes_aggregate!

  # An array relationship
  owners(
    # distinct select on columns
    distinct_on: [publication_owners_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owners_order_by!]

    # filter the rows returned
    where: publication_owners_bool_exp
  ): [publication_owners!]!

  # An aggregated array relationship
  owners_aggregate(
    # distinct select on columns
    distinct_on: [publication_owners_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owners_order_by!]

    # filter the rows returned
    where: publication_owners_bool_exp
  ): publication_owners_aggregate!
  packet: String
  pageLength: Int

  # An object relationship
  patentCountry: location
  patentCountryMtid: bigint
  prevValid: bigint
  printed: Boolean

  # An array relationship
  properties(
    # distinct select on columns
    distinct_on: [achievement_property_value_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_value_order_by!]

    # filter the rows returned
    where: achievement_property_value_bool_exp
  ): [achievement_property_value!]!

  # An aggregated array relationship
  properties_aggregate(
    # distinct select on columns
    distinct_on: [achievement_property_value_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_value_order_by!]

    # filter the rows returned
    where: achievement_property_value_bool_exp
  ): achievement_property_value_aggregate!
  pubStats: String
  publicationPending: Boolean!
  publishDate: timestamp
  published: Boolean!

  # An array relationship
  publishedAt(
    # distinct select on columns
    distinct_on: [publication_published_at_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_published_at_order_by!]

    # filter the rows returned
    where: publication_published_at_bool_exp
  ): [publication_published_at!]!

  # An aggregated array relationship
  publishedAt_aggregate(
    # distinct select on columns
    distinct_on: [publication_published_at_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_published_at_order_by!]

    # filter the rows returned
    where: publication_published_at_bool_exp
  ): publication_published_at_aggregate!
  publishedYear: smallint
  publishedYearEnd: smallint

  # An array relationship
  publishers(
    # distinct select on columns
    distinct_on: [publication_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_publishers_order_by!]

    # filter the rows returned
    where: publication_publishers_bool_exp
  ): [publication_publishers!]!

  # An aggregated array relationship
  publishers_aggregate(
    # distinct select on columns
    distinct_on: [publication_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_publishers_order_by!]

    # filter the rows returned
    where: publication_publishers_bool_exp
  ): publication_publishers_aggregate!

  # An array relationship
  ratings(
    # distinct select on columns
    distinct_on: [publication_ratings_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_ratings_order_by!]

    # filter the rows returned
    where: publication_ratings_bool_exp
  ): [publication_ratings!]!
  ratingsForSort: Int

  # An aggregated array relationship
  ratings_aggregate(
    # distinct select on columns
    distinct_on: [publication_ratings_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_ratings_order_by!]

    # filter the rows returned
    where: publication_ratings_bool_exp
  ): publication_ratings_aggregate!
  referenceList: String

  # An array relationship
  references(
    # distinct select on columns
    distinct_on: [reference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reference_order_by!]

    # filter the rows returned
    where: reference_bool_exp
  ): [reference!]!

  # An aggregated array relationship
  references_aggregate(
    # distinct select on columns
    distinct_on: [reference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reference_order_by!]

    # filter the rows returned
    where: reference_bool_exp
  ): reference_aggregate!
  refreshed: Boolean!
  reviewer: String
  school: String
  scopusCitationCount: Int!
  selfCitationCount: Int

  # An array relationship
  seriesMembers(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): [series_volume!]!

  # An aggregated array relationship
  seriesMembers_aggregate(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): series_volume_aggregate!
  sourceOfData: String
  sourceYear: smallint
  startDate: date
  status: Int

  # An object relationship
  subSubType: publication_type
  subSubTypeMtid: bigint
  subTitle: String

  # An object relationship
  subType: sub_type
  subTypeForSort: String
  subTypeMtid: bigint

  # An array relationship
  subjects(
    # distinct select on columns
    distinct_on: [publication_subjects_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_subjects_order_by!]

    # filter the rows returned
    where: publication_subjects_bool_exp
  ): [publication_subjects!]!

  # An aggregated array relationship
  subjects_aggregate(
    # distinct select on columns
    distinct_on: [publication_subjects_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_subjects_order_by!]

    # filter the rows returned
    where: publication_subjects_bool_exp
  ): publication_subjects_aggregate!
  submissionNumber: String
  submissionYear: smallint
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String

  # An object relationship
  type: publication_type
  typeForSort: String
  typeMtid: bigint
  unhandledCitationCount: Int!
  unhandledCitingPubCount: Int!
  unhandledTickets: Int!
  unprocessedData: String
  userChangeableUntil: timestamp
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp

  # An object relationship
  validator: users
  validatorForSort: String
  validatorMtid: bigint
  volume: String
  volumeNumber: String
  volumeTitle: String
  wosCitationCount: Int!
}

# aggregated selection of "publication"
type publication_aggregate {
  aggregate: publication_aggregate_fields
  nodes: [publication!]!
}

# aggregate fields of "publication"
type publication_aggregate_fields {
  avg: publication_avg_fields
  count(columns: [publication_select_column!], distinct: Boolean): Int
  max: publication_max_fields
  min: publication_min_fields
  stddev: publication_stddev_fields
  stddev_pop: publication_stddev_pop_fields
  stddev_samp: publication_stddev_samp_fields
  sum: publication_sum_fields
  var_pop: publication_var_pop_fields
  var_samp: publication_var_samp_fields
  variance: publication_variance_fields
}

# order by aggregate values of table "publication"
input publication_aggregate_order_by {
  avg: publication_avg_order_by
  count: order_by
  max: publication_max_order_by
  min: publication_min_order_by
  stddev: publication_stddev_order_by
  stddev_pop: publication_stddev_pop_order_by
  stddev_samp: publication_stddev_samp_order_by
  sum: publication_sum_order_by
  var_pop: publication_var_pop_order_by
  var_samp: publication_var_samp_order_by
  variance: publication_variance_order_by
}

# input type for inserting array relation for remote table "publication"
input publication_arr_rel_insert_input {
  data: [publication_insert_input!]!
  on_conflict: publication_on_conflict
}

# columns and relationships of "publication_authors"
type publication_authors {
  authorsMtid: bigint!
  publicationMtid: bigint!

  # An object relationship
  users: users!
}

# aggregated selection of "publication_authors"
type publication_authors_aggregate {
  aggregate: publication_authors_aggregate_fields
  nodes: [publication_authors!]!
}

# aggregate fields of "publication_authors"
type publication_authors_aggregate_fields {
  avg: publication_authors_avg_fields
  count(columns: [publication_authors_select_column!], distinct: Boolean): Int
  max: publication_authors_max_fields
  min: publication_authors_min_fields
  stddev: publication_authors_stddev_fields
  stddev_pop: publication_authors_stddev_pop_fields
  stddev_samp: publication_authors_stddev_samp_fields
  sum: publication_authors_sum_fields
  var_pop: publication_authors_var_pop_fields
  var_samp: publication_authors_var_samp_fields
  variance: publication_authors_variance_fields
}

# order by aggregate values of table "publication_authors"
input publication_authors_aggregate_order_by {
  avg: publication_authors_avg_order_by
  count: order_by
  max: publication_authors_max_order_by
  min: publication_authors_min_order_by
  stddev: publication_authors_stddev_order_by
  stddev_pop: publication_authors_stddev_pop_order_by
  stddev_samp: publication_authors_stddev_samp_order_by
  sum: publication_authors_sum_order_by
  var_pop: publication_authors_var_pop_order_by
  var_samp: publication_authors_var_samp_order_by
  variance: publication_authors_variance_order_by
}

# input type for inserting array relation for remote table "publication_authors"
input publication_authors_arr_rel_insert_input {
  data: [publication_authors_insert_input!]!
  on_conflict: publication_authors_on_conflict
}

# aggregate avg on columns
type publication_authors_avg_fields {
  authorsMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_authors"
input publication_authors_avg_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_authors". All fields are combined with a logical 'AND'.
input publication_authors_bool_exp {
  _and: [publication_authors_bool_exp]
  _not: publication_authors_bool_exp
  _or: [publication_authors_bool_exp]
  authorsMtid: bigint_comparison_exp
  publicationMtid: bigint_comparison_exp
  users: users_bool_exp
}

# unique or primary key constraints on table "publication_authors"
enum publication_authors_constraint {
  # unique or primary key constraint
  publication_authors_pkey
}

# input type for incrementing integer column in table "publication_authors"
input publication_authors_inc_input {
  authorsMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_authors"
input publication_authors_insert_input {
  authorsMtid: bigint
  publicationMtid: bigint
  users: users_obj_rel_insert_input
}

# aggregate max on columns
type publication_authors_max_fields {
  authorsMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_authors"
input publication_authors_max_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_authors_min_fields {
  authorsMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_authors"
input publication_authors_min_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_authors"
type publication_authors_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_authors!]!
}

# input type for inserting object relation for remote table "publication_authors"
input publication_authors_obj_rel_insert_input {
  data: publication_authors_insert_input!
  on_conflict: publication_authors_on_conflict
}

# on conflict condition type for table "publication_authors"
input publication_authors_on_conflict {
  constraint: publication_authors_constraint!
  update_columns: [publication_authors_update_column!]!
  where: publication_authors_bool_exp
}

# ordering options when selecting data from "publication_authors"
input publication_authors_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
  users: users_order_by
}

# primary key columns input for table: "publication_authors"
input publication_authors_pk_columns_input {
  authorsMtid: bigint!
  publicationMtid: bigint!
}

# select columns of table "publication_authors"
enum publication_authors_select_column {
  # column name
  authorsMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_authors"
input publication_authors_set_input {
  authorsMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_authors_stddev_fields {
  authorsMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_authors"
input publication_authors_stddev_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_authors_stddev_pop_fields {
  authorsMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_authors"
input publication_authors_stddev_pop_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_authors_stddev_samp_fields {
  authorsMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_authors"
input publication_authors_stddev_samp_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_authors_sum_fields {
  authorsMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_authors"
input publication_authors_sum_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# update columns of table "publication_authors"
enum publication_authors_update_column {
  # column name
  authorsMtid

  # column name
  publicationMtid
}

# aggregate var_pop on columns
type publication_authors_var_pop_fields {
  authorsMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_authors"
input publication_authors_var_pop_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_authors_var_samp_fields {
  authorsMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_authors"
input publication_authors_var_samp_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_authors_variance_fields {
  authorsMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_authors"
input publication_authors_variance_order_by {
  authorsMtid: order_by
  publicationMtid: order_by
}

# aggregate avg on columns
type publication_avg_fields {
  acceptanceYear: Float
  adminApproverMtid: Float
  applicationYear: Float
  approverMtid: Float
  authorCount: Float
  bookMtid: Float
  categoryMtid: Float
  chapterCount: Float
  checkerMtid: Float
  citationCount: Float
  citationCountUnpublished: Float
  citationCountWoOther: Float
  citedCount: Float
  citedPubCount: Float
  citingPubCount: Float
  citingPubCountWoOther: Float
  collaboration: Float
  conferenceMtid: Float
  consultantAuthor2Mtid: Float
  consultantAuthorMtid: Float
  contributorCount: Float
  countryMtid: Float
  creator: Float
  directInstituteCount: Float
  disciplineMtid: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  editionNumber: Float
  error: Float
  foreignEditionCitationCount: Float
  group_mtid: Float
  ifRatingMtid: Float
  impactFactor: Float
  independentCitCountWoOther: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  independentCitingPubCountWoOther: Float
  journalMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mabDisciplineMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oaByAuthorMtid: Float
  oaType: Float
  oaTypeDisp: Float
  oldId: Float
  ownerAuthorCount: Float
  ownerInstituteCount: Float
  pageLength: Float
  patentCountryMtid: Float
  prevValid: Float
  publishedYear: Float
  publishedYearEnd: Float
  ratingsForSort: Float
  scopusCitationCount: Float
  selfCitationCount: Float
  sourceYear: Float
  status: Float
  subSubTypeMtid: Float
  subTypeMtid: Float
  submissionYear: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
  wosCitationCount: Float
}

# order by avg() on columns of table "publication"
input publication_avg_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# Boolean expression to filter rows from the table "publication". All fields are combined with a logical 'AND'.
input publication_bool_exp {
  _and: [publication_bool_exp]
  _not: publication_bool_exp
  _or: [publication_bool_exp]
  abstractText: String_comparison_exp
  acceptanceYear: smallint_comparison_exp
  adminApproved: timestamp_comparison_exp
  adminApprover: users_bool_exp
  adminApproverForSort: String_comparison_exp
  adminApproverMtid: bigint_comparison_exp
  altTitles: String_comparison_exp
  applicationYear: smallint_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  authorCount: Int_comparison_exp
  authors: publication_authors_bool_exp
  authorships: authorship_bool_exp
  book: publication_bool_exp
  bookMtid: bigint_comparison_exp
  bulkDuplumSearchDone: Boolean_comparison_exp
  caseNumber: String_comparison_exp
  category: category_bool_exp
  categoryForSort: String_comparison_exp
  categoryMtid: bigint_comparison_exp
  chapterCount: Int_comparison_exp
  chapters: publication_bool_exp
  checked: timestamp_comparison_exp
  checker: users_bool_exp
  checkerMtid: bigint_comparison_exp
  citation: Boolean_comparison_exp
  citationCount: Int_comparison_exp
  citationCountUnpublished: Int_comparison_exp
  citationCountWoOther: Int_comparison_exp
  citations: citation_bool_exp
  citedCount: Int_comparison_exp
  citedPubCount: Int_comparison_exp
  cites: citation_bool_exp
  citingPubCount: Int_comparison_exp
  citingPubCountWoOther: Int_comparison_exp
  collaboration: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  conference: conference_bool_exp
  conferenceMtid: bigint_comparison_exp
  conferencePublication: Boolean_comparison_exp
  consultant: String_comparison_exp
  consultant2: String_comparison_exp
  consultantAuthor: users_bool_exp
  consultantAuthor2: users_bool_exp
  consultantAuthor2Mtid: bigint_comparison_exp
  consultantAuthorMtid: bigint_comparison_exp
  contributorCount: Int_comparison_exp
  core: Boolean_comparison_exp
  country: location_bool_exp
  countryMtid: bigint_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  description0: String_comparison_exp
  description1: String_comparison_exp
  description2: String_comparison_exp
  description3: String_comparison_exp
  description4: String_comparison_exp
  description5: String_comparison_exp
  digital: Boolean_comparison_exp
  directInstituteCount: Int_comparison_exp
  directInstitutes: publication_direct_institutes_bool_exp
  directInstitutesForSort: String_comparison_exp
  discipline: discipline_bool_exp
  disciplineMtid: bigint_comparison_exp
  doiCitationCount: Int_comparison_exp
  dtype: String_comparison_exp
  duplumKey: String_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  editionNumber: Int_comparison_exp
  endDate: date_comparison_exp
  error: Int_comparison_exp
  externalSource: String_comparison_exp
  files: publication_files_bool_exp
  firstAuthor: String_comparison_exp
  firstPage: String_comparison_exp
  firstPageOrInternalIdForSort: String_comparison_exp
  foreignEdition: Boolean_comparison_exp
  foreignEditionCitationCount: Int_comparison_exp
  foreignLanguage: Boolean_comparison_exp
  fromCitation: Boolean_comparison_exp
  fullPublication: Boolean_comparison_exp
  fundings: funding_bool_exp
  group_mtid: bigint_comparison_exp
  hasCitationDuplums: Boolean_comparison_exp
  identifiers: publication_identifier_bool_exp
  ifRating: rating_bool_exp
  ifRatingMtid: bigint_comparison_exp
  impactFactor: Float_comparison_exp
  inSelectedPubs: String_comparison_exp
  independentCitCountWoOther: Int_comparison_exp
  independentCitationCount: Int_comparison_exp
  independentCitingPubCount: Int_comparison_exp
  independentCitingPubCountWoOther: Int_comparison_exp
  institutes: publication_institutes_bool_exp
  internalId: String_comparison_exp
  ipc: String_comparison_exp
  issue: String_comparison_exp
  journal: periodical_bool_exp
  journalForSort: String_comparison_exp
  journalMtid: bigint_comparison_exp
  journalName: String_comparison_exp
  keywords: publication_keywords_bool_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  languages: publication_languages_bool_exp
  languagesForSort: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastPage: String_comparison_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mabDiscipline: mab_discipline_bool_exp
  mabDisciplineMtid: bigint_comparison_exp
  missingAuthor: Boolean_comparison_exp
  mtid: bigint_comparison_exp
  nationalOrigin: Boolean_comparison_exp
  nationalOriginCitationCount: Int_comparison_exp
  number: String_comparison_exp
  oaByAuthor: users_bool_exp
  oaByAuthorMtid: bigint_comparison_exp
  oaCheckDate: date_comparison_exp
  oaEmbargoDate: date_comparison_exp
  oaFree: Boolean_comparison_exp
  oaLink: String_comparison_exp
  oaType: Int_comparison_exp
  oaTypeDisp: Int_comparison_exp
  oldId: Int_comparison_exp
  oldOrgAuthors: publication_old_org_authors_bool_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  ownerAuthorCount: Int_comparison_exp
  ownerAuthors: publication_owner_authors_bool_exp
  ownerInstituteCount: Int_comparison_exp
  ownerInstitutes: publication_owner_institutes_bool_exp
  owners: publication_owners_bool_exp
  packet: String_comparison_exp
  pageLength: Int_comparison_exp
  patentCountry: location_bool_exp
  patentCountryMtid: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  printed: Boolean_comparison_exp
  properties: achievement_property_value_bool_exp
  pubStats: String_comparison_exp
  publicationPending: Boolean_comparison_exp
  publishDate: timestamp_comparison_exp
  published: Boolean_comparison_exp
  publishedAt: publication_published_at_bool_exp
  publishedYear: smallint_comparison_exp
  publishedYearEnd: smallint_comparison_exp
  publishers: publication_publishers_bool_exp
  ratings: publication_ratings_bool_exp
  ratingsForSort: Int_comparison_exp
  referenceList: String_comparison_exp
  references: reference_bool_exp
  refreshed: Boolean_comparison_exp
  reviewer: String_comparison_exp
  school: String_comparison_exp
  scopusCitationCount: Int_comparison_exp
  selfCitationCount: Int_comparison_exp
  seriesMembers: series_volume_bool_exp
  sourceOfData: String_comparison_exp
  sourceYear: smallint_comparison_exp
  startDate: date_comparison_exp
  status: Int_comparison_exp
  subSubType: publication_type_bool_exp
  subSubTypeMtid: bigint_comparison_exp
  subTitle: String_comparison_exp
  subType: sub_type_bool_exp
  subTypeForSort: String_comparison_exp
  subTypeMtid: bigint_comparison_exp
  subjects: publication_subjects_bool_exp
  submissionNumber: String_comparison_exp
  submissionYear: smallint_comparison_exp
  tempLocked: timestamp_comparison_exp
  tempLockerIdString: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  title: String_comparison_exp
  type: publication_type_bool_exp
  typeForSort: String_comparison_exp
  typeMtid: bigint_comparison_exp
  unhandledCitationCount: Int_comparison_exp
  unhandledCitingPubCount: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  unprocessedData: String_comparison_exp
  userChangeableUntil: timestamp_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  validated: timestamp_comparison_exp
  validator: users_bool_exp
  validatorForSort: String_comparison_exp
  validatorMtid: bigint_comparison_exp
  volume: String_comparison_exp
  volumeNumber: String_comparison_exp
  volumeTitle: String_comparison_exp
  wosCitationCount: Int_comparison_exp
}

# unique or primary key constraints on table "publication"
enum publication_constraint {
  # unique or primary key constraint
  publication_pkey
}

# columns and relationships of "publication_direct_institutes"
type publication_direct_institutes {
  directInstitutesMtid: bigint!

  # An object relationship
  organization: organization!
  publicationMtid: bigint!
}

# aggregated selection of "publication_direct_institutes"
type publication_direct_institutes_aggregate {
  aggregate: publication_direct_institutes_aggregate_fields
  nodes: [publication_direct_institutes!]!
}

# aggregate fields of "publication_direct_institutes"
type publication_direct_institutes_aggregate_fields {
  avg: publication_direct_institutes_avg_fields
  count(columns: [publication_direct_institutes_select_column!], distinct: Boolean): Int
  max: publication_direct_institutes_max_fields
  min: publication_direct_institutes_min_fields
  stddev: publication_direct_institutes_stddev_fields
  stddev_pop: publication_direct_institutes_stddev_pop_fields
  stddev_samp: publication_direct_institutes_stddev_samp_fields
  sum: publication_direct_institutes_sum_fields
  var_pop: publication_direct_institutes_var_pop_fields
  var_samp: publication_direct_institutes_var_samp_fields
  variance: publication_direct_institutes_variance_fields
}

# order by aggregate values of table "publication_direct_institutes"
input publication_direct_institutes_aggregate_order_by {
  avg: publication_direct_institutes_avg_order_by
  count: order_by
  max: publication_direct_institutes_max_order_by
  min: publication_direct_institutes_min_order_by
  stddev: publication_direct_institutes_stddev_order_by
  stddev_pop: publication_direct_institutes_stddev_pop_order_by
  stddev_samp: publication_direct_institutes_stddev_samp_order_by
  sum: publication_direct_institutes_sum_order_by
  var_pop: publication_direct_institutes_var_pop_order_by
  var_samp: publication_direct_institutes_var_samp_order_by
  variance: publication_direct_institutes_variance_order_by
}

# input type for inserting array relation for remote table "publication_direct_institutes"
input publication_direct_institutes_arr_rel_insert_input {
  data: [publication_direct_institutes_insert_input!]!
  on_conflict: publication_direct_institutes_on_conflict
}

# aggregate avg on columns
type publication_direct_institutes_avg_fields {
  directInstitutesMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_direct_institutes"
input publication_direct_institutes_avg_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table
# "publication_direct_institutes". All fields are combined with a logical 'AND'.
input publication_direct_institutes_bool_exp {
  _and: [publication_direct_institutes_bool_exp]
  _not: publication_direct_institutes_bool_exp
  _or: [publication_direct_institutes_bool_exp]
  directInstitutesMtid: bigint_comparison_exp
  organization: organization_bool_exp
  publicationMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "publication_direct_institutes"
enum publication_direct_institutes_constraint {
  # unique or primary key constraint
  publication_direct_institutes_pkey
}

# input type for incrementing integer column in table "publication_direct_institutes"
input publication_direct_institutes_inc_input {
  directInstitutesMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_direct_institutes"
input publication_direct_institutes_insert_input {
  directInstitutesMtid: bigint
  organization: organization_obj_rel_insert_input
  publicationMtid: bigint
}

# aggregate max on columns
type publication_direct_institutes_max_fields {
  directInstitutesMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_direct_institutes"
input publication_direct_institutes_max_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_direct_institutes_min_fields {
  directInstitutesMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_direct_institutes"
input publication_direct_institutes_min_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_direct_institutes"
type publication_direct_institutes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_direct_institutes!]!
}

# input type for inserting object relation for remote table "publication_direct_institutes"
input publication_direct_institutes_obj_rel_insert_input {
  data: publication_direct_institutes_insert_input!
  on_conflict: publication_direct_institutes_on_conflict
}

# on conflict condition type for table "publication_direct_institutes"
input publication_direct_institutes_on_conflict {
  constraint: publication_direct_institutes_constraint!
  update_columns: [publication_direct_institutes_update_column!]!
  where: publication_direct_institutes_bool_exp
}

# ordering options when selecting data from "publication_direct_institutes"
input publication_direct_institutes_order_by {
  directInstitutesMtid: order_by
  organization: organization_order_by
  publicationMtid: order_by
}

# primary key columns input for table: "publication_direct_institutes"
input publication_direct_institutes_pk_columns_input {
  directInstitutesMtid: bigint!
  publicationMtid: bigint!
}

# select columns of table "publication_direct_institutes"
enum publication_direct_institutes_select_column {
  # column name
  directInstitutesMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_direct_institutes"
input publication_direct_institutes_set_input {
  directInstitutesMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_direct_institutes_stddev_fields {
  directInstitutesMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_direct_institutes"
input publication_direct_institutes_stddev_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_direct_institutes_stddev_pop_fields {
  directInstitutesMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_direct_institutes"
input publication_direct_institutes_stddev_pop_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_direct_institutes_stddev_samp_fields {
  directInstitutesMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_direct_institutes"
input publication_direct_institutes_stddev_samp_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_direct_institutes_sum_fields {
  directInstitutesMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_direct_institutes"
input publication_direct_institutes_sum_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# update columns of table "publication_direct_institutes"
enum publication_direct_institutes_update_column {
  # column name
  directInstitutesMtid

  # column name
  publicationMtid
}

# aggregate var_pop on columns
type publication_direct_institutes_var_pop_fields {
  directInstitutesMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_direct_institutes"
input publication_direct_institutes_var_pop_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_direct_institutes_var_samp_fields {
  directInstitutesMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_direct_institutes"
input publication_direct_institutes_var_samp_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_direct_institutes_variance_fields {
  directInstitutesMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_direct_institutes"
input publication_direct_institutes_variance_order_by {
  directInstitutesMtid: order_by
  publicationMtid: order_by
}

# columns and relationships of "publication_files"
type publication_files {
  filesMtid: bigint!
  publicationMtid: bigint!

  # An object relationship
  uploadedFile: uploaded_file!
}

# aggregated selection of "publication_files"
type publication_files_aggregate {
  aggregate: publication_files_aggregate_fields
  nodes: [publication_files!]!
}

# aggregate fields of "publication_files"
type publication_files_aggregate_fields {
  avg: publication_files_avg_fields
  count(columns: [publication_files_select_column!], distinct: Boolean): Int
  max: publication_files_max_fields
  min: publication_files_min_fields
  stddev: publication_files_stddev_fields
  stddev_pop: publication_files_stddev_pop_fields
  stddev_samp: publication_files_stddev_samp_fields
  sum: publication_files_sum_fields
  var_pop: publication_files_var_pop_fields
  var_samp: publication_files_var_samp_fields
  variance: publication_files_variance_fields
}

# order by aggregate values of table "publication_files"
input publication_files_aggregate_order_by {
  avg: publication_files_avg_order_by
  count: order_by
  max: publication_files_max_order_by
  min: publication_files_min_order_by
  stddev: publication_files_stddev_order_by
  stddev_pop: publication_files_stddev_pop_order_by
  stddev_samp: publication_files_stddev_samp_order_by
  sum: publication_files_sum_order_by
  var_pop: publication_files_var_pop_order_by
  var_samp: publication_files_var_samp_order_by
  variance: publication_files_variance_order_by
}

# input type for inserting array relation for remote table "publication_files"
input publication_files_arr_rel_insert_input {
  data: [publication_files_insert_input!]!
  on_conflict: publication_files_on_conflict
}

# aggregate avg on columns
type publication_files_avg_fields {
  filesMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_files"
input publication_files_avg_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_files". All fields are combined with a logical 'AND'.
input publication_files_bool_exp {
  _and: [publication_files_bool_exp]
  _not: publication_files_bool_exp
  _or: [publication_files_bool_exp]
  filesMtid: bigint_comparison_exp
  publicationMtid: bigint_comparison_exp
  uploadedFile: uploaded_file_bool_exp
}

# unique or primary key constraints on table "publication_files"
enum publication_files_constraint {
  # unique or primary key constraint
  uk_5a2vm8xjqoik0u19irdhfdk98
}

# input type for incrementing integer column in table "publication_files"
input publication_files_inc_input {
  filesMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_files"
input publication_files_insert_input {
  filesMtid: bigint
  publicationMtid: bigint
  uploadedFile: uploaded_file_obj_rel_insert_input
}

# aggregate max on columns
type publication_files_max_fields {
  filesMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_files"
input publication_files_max_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_files_min_fields {
  filesMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_files"
input publication_files_min_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_files"
type publication_files_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_files!]!
}

# input type for inserting object relation for remote table "publication_files"
input publication_files_obj_rel_insert_input {
  data: publication_files_insert_input!
  on_conflict: publication_files_on_conflict
}

# on conflict condition type for table "publication_files"
input publication_files_on_conflict {
  constraint: publication_files_constraint!
  update_columns: [publication_files_update_column!]!
  where: publication_files_bool_exp
}

# ordering options when selecting data from "publication_files"
input publication_files_order_by {
  filesMtid: order_by
  publicationMtid: order_by
  uploadedFile: uploaded_file_order_by
}

# select columns of table "publication_files"
enum publication_files_select_column {
  # column name
  filesMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_files"
input publication_files_set_input {
  filesMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_files_stddev_fields {
  filesMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_files"
input publication_files_stddev_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_files_stddev_pop_fields {
  filesMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_files"
input publication_files_stddev_pop_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_files_stddev_samp_fields {
  filesMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_files"
input publication_files_stddev_samp_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_files_sum_fields {
  filesMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_files"
input publication_files_sum_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# update columns of table "publication_files"
enum publication_files_update_column {
  # column name
  filesMtid

  # column name
  publicationMtid
}

# aggregate var_pop on columns
type publication_files_var_pop_fields {
  filesMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_files"
input publication_files_var_pop_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_files_var_samp_fields {
  filesMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_files"
input publication_files_var_samp_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_files_variance_fields {
  filesMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_files"
input publication_files_variance_order_by {
  filesMtid: order_by
  publicationMtid: order_by
}

# columns and relationships of "publication_identifier"
type publication_identifier {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastImport: timestamp
  lastImportReal: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oaByAuthor: Boolean
  oaCheckDate: date
  oaEmbargoDate: date
  oaFree: Boolean
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint

  # An object relationship
  publication: publication
  publicationMtid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  source: source
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unchecked: Boolean
  unhandledTickets: Int!
  uploadedFileIds: String
  uploadedUrl: String
  validFromYear: smallint
  validState: Int
  validToYear: smallint
  validated: timestamp

  # An object relationship
  validator: users
  validatorMtid: bigint
}

# aggregated selection of "publication_identifier"
type publication_identifier_aggregate {
  aggregate: publication_identifier_aggregate_fields
  nodes: [publication_identifier!]!
}

# aggregate fields of "publication_identifier"
type publication_identifier_aggregate_fields {
  avg: publication_identifier_avg_fields
  count(columns: [publication_identifier_select_column!], distinct: Boolean): Int
  max: publication_identifier_max_fields
  min: publication_identifier_min_fields
  stddev: publication_identifier_stddev_fields
  stddev_pop: publication_identifier_stddev_pop_fields
  stddev_samp: publication_identifier_stddev_samp_fields
  sum: publication_identifier_sum_fields
  var_pop: publication_identifier_var_pop_fields
  var_samp: publication_identifier_var_samp_fields
  variance: publication_identifier_variance_fields
}

# order by aggregate values of table "publication_identifier"
input publication_identifier_aggregate_order_by {
  avg: publication_identifier_avg_order_by
  count: order_by
  max: publication_identifier_max_order_by
  min: publication_identifier_min_order_by
  stddev: publication_identifier_stddev_order_by
  stddev_pop: publication_identifier_stddev_pop_order_by
  stddev_samp: publication_identifier_stddev_samp_order_by
  sum: publication_identifier_sum_order_by
  var_pop: publication_identifier_var_pop_order_by
  var_samp: publication_identifier_var_samp_order_by
  variance: publication_identifier_variance_order_by
}

# input type for inserting array relation for remote table "publication_identifier"
input publication_identifier_arr_rel_insert_input {
  data: [publication_identifier_insert_input!]!
  on_conflict: publication_identifier_on_conflict
}

# aggregate avg on columns
type publication_identifier_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validState: Float
  validToYear: Float
  validatorMtid: Float
}

# order by avg() on columns of table "publication_identifier"
input publication_identifier_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# Boolean expression to filter rows from the table "publication_identifier". All fields are combined with a logical 'AND'.
input publication_identifier_bool_exp {
  _and: [publication_identifier_bool_exp]
  _not: publication_identifier_bool_exp
  _or: [publication_identifier_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  idValue: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastImport: timestamp_comparison_exp
  lastImportReal: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oaByAuthor: Boolean_comparison_exp
  oaCheckDate: date_comparison_exp
  oaEmbargoDate: date_comparison_exp
  oaFree: Boolean_comparison_exp
  oaType: Int_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  publication: publication_bool_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  source: source_bool_exp
  sourceMtid: bigint_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unchecked: Boolean_comparison_exp
  unhandledTickets: Int_comparison_exp
  uploadedFileIds: String_comparison_exp
  uploadedUrl: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validState: Int_comparison_exp
  validToYear: smallint_comparison_exp
  validated: timestamp_comparison_exp
  validator: users_bool_exp
  validatorMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "publication_identifier"
enum publication_identifier_constraint {
  # unique or primary key constraint
  publication_identifier_pkey
}

# input type for incrementing integer column in table "publication_identifier"
input publication_identifier_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oaType: Int
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  sourceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validState: Int
  validToYear: smallint
  validatorMtid: bigint
}

# input type for inserting data into table "publication_identifier"
input publication_identifier_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastImport: timestamp
  lastImportReal: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oaByAuthor: Boolean
  oaCheckDate: date
  oaEmbargoDate: date
  oaFree: Boolean
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publication: publication_obj_rel_insert_input
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  source: source_obj_rel_insert_input
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unchecked: Boolean
  unhandledTickets: Int
  uploadedFileIds: String
  uploadedUrl: String
  validFromYear: smallint
  validState: Int
  validToYear: smallint
  validated: timestamp
  validator: users_obj_rel_insert_input
  validatorMtid: bigint
}

# aggregate max on columns
type publication_identifier_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastImport: timestamp
  lastImportReal: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oaCheckDate: date
  oaEmbargoDate: date
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  uploadedFileIds: String
  uploadedUrl: String
  validFromYear: smallint
  validState: Int
  validToYear: smallint
  validated: timestamp
  validatorMtid: bigint
}

# order by max() on columns of table "publication_identifier"
input publication_identifier_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastImport: order_by
  lastImportReal: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oaCheckDate: order_by
  oaEmbargoDate: order_by
  oaType: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  uploadedFileIds: order_by
  uploadedUrl: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validated: order_by
  validatorMtid: order_by
}

# aggregate min on columns
type publication_identifier_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastImport: timestamp
  lastImportReal: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oaCheckDate: date
  oaEmbargoDate: date
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  uploadedFileIds: String
  uploadedUrl: String
  validFromYear: smallint
  validState: Int
  validToYear: smallint
  validated: timestamp
  validatorMtid: bigint
}

# order by min() on columns of table "publication_identifier"
input publication_identifier_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastImport: order_by
  lastImportReal: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oaCheckDate: order_by
  oaEmbargoDate: order_by
  oaType: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  uploadedFileIds: order_by
  uploadedUrl: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validated: order_by
  validatorMtid: order_by
}

# response of any mutation on the table "publication_identifier"
type publication_identifier_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_identifier!]!
}

# input type for inserting object relation for remote table "publication_identifier"
input publication_identifier_obj_rel_insert_input {
  data: publication_identifier_insert_input!
  on_conflict: publication_identifier_on_conflict
}

# on conflict condition type for table "publication_identifier"
input publication_identifier_on_conflict {
  constraint: publication_identifier_constraint!
  update_columns: [publication_identifier_update_column!]!
  where: publication_identifier_bool_exp
}

# ordering options when selecting data from "publication_identifier"
input publication_identifier_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  idValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastImport: order_by
  lastImportReal: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oaByAuthor: order_by
  oaCheckDate: order_by
  oaEmbargoDate: order_by
  oaFree: order_by
  oaType: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publication: publication_order_by
  publicationMtid: order_by
  published: order_by
  refreshed: order_by
  source: source_order_by
  sourceMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unchecked: order_by
  unhandledTickets: order_by
  uploadedFileIds: order_by
  uploadedUrl: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validated: order_by
  validator: users_order_by
  validatorMtid: order_by
}

# primary key columns input for table: "publication_identifier"
input publication_identifier_pk_columns_input {
  mtid: bigint!
}

# select columns of table "publication_identifier"
enum publication_identifier_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastImport

  # column name
  lastImportReal

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oaByAuthor

  # column name
  oaCheckDate

  # column name
  oaEmbargoDate

  # column name
  oaFree

  # column name
  oaType

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unchecked

  # column name
  unhandledTickets

  # column name
  uploadedFileIds

  # column name
  uploadedUrl

  # column name
  validFromYear

  # column name
  validState

  # column name
  validToYear

  # column name
  validated

  # column name
  validatorMtid
}

# input type for updating data in table "publication_identifier"
input publication_identifier_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idValue: String
  labelEng: String
  labelHun: String
  lastImport: timestamp
  lastImportReal: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oaByAuthor: Boolean
  oaCheckDate: date
  oaEmbargoDate: date
  oaFree: Boolean
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  sourceMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unchecked: Boolean
  unhandledTickets: Int
  uploadedFileIds: String
  uploadedUrl: String
  validFromYear: smallint
  validState: Int
  validToYear: smallint
  validated: timestamp
  validatorMtid: bigint
}

# aggregate stddev on columns
type publication_identifier_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validState: Float
  validToYear: Float
  validatorMtid: Float
}

# order by stddev() on columns of table "publication_identifier"
input publication_identifier_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate stddev_pop on columns
type publication_identifier_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validState: Float
  validToYear: Float
  validatorMtid: Float
}

# order by stddev_pop() on columns of table "publication_identifier"
input publication_identifier_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate stddev_samp on columns
type publication_identifier_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validState: Float
  validToYear: Float
  validatorMtid: Float
}

# order by stddev_samp() on columns of table "publication_identifier"
input publication_identifier_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate sum on columns
type publication_identifier_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oaType: Int
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  sourceMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validState: Int
  validToYear: smallint
  validatorMtid: bigint
}

# order by sum() on columns of table "publication_identifier"
input publication_identifier_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# update columns of table "publication_identifier"
enum publication_identifier_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastImport

  # column name
  lastImportReal

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oaByAuthor

  # column name
  oaCheckDate

  # column name
  oaEmbargoDate

  # column name
  oaFree

  # column name
  oaType

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  sourceMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unchecked

  # column name
  unhandledTickets

  # column name
  uploadedFileIds

  # column name
  uploadedUrl

  # column name
  validFromYear

  # column name
  validState

  # column name
  validToYear

  # column name
  validated

  # column name
  validatorMtid
}

# aggregate var_pop on columns
type publication_identifier_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validState: Float
  validToYear: Float
  validatorMtid: Float
}

# order by var_pop() on columns of table "publication_identifier"
input publication_identifier_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate var_samp on columns
type publication_identifier_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validState: Float
  validToYear: Float
  validatorMtid: Float
}

# order by var_samp() on columns of table "publication_identifier"
input publication_identifier_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# aggregate variance on columns
type publication_identifier_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  sourceMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validState: Float
  validToYear: Float
  validatorMtid: Float
}

# order by variance() on columns of table "publication_identifier"
input publication_identifier_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  sourceMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validState: order_by
  validToYear: order_by
  validatorMtid: order_by
}

# input type for incrementing integer column in table "publication"
input publication_inc_input {
  acceptanceYear: smallint
  adminApproverMtid: bigint
  applicationYear: smallint
  approverMtid: bigint
  authorCount: Int
  bookMtid: bigint
  categoryMtid: bigint
  chapterCount: Int
  checkerMtid: bigint
  citationCount: Int
  citationCountUnpublished: Int
  citationCountWoOther: Int
  citedCount: Int
  citedPubCount: Int
  citingPubCount: Int
  citingPubCountWoOther: Int
  collaboration: Int
  conferenceMtid: bigint
  consultantAuthor2Mtid: bigint
  consultantAuthorMtid: bigint
  contributorCount: Int
  countryMtid: bigint
  creator: bigint
  directInstituteCount: Int
  disciplineMtid: bigint
  doiCitationCount: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  editionNumber: Int
  error: Int
  foreignEditionCitationCount: Int
  group_mtid: bigint
  ifRatingMtid: bigint
  impactFactor: Float
  independentCitCountWoOther: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  independentCitingPubCountWoOther: Int
  journalMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mabDisciplineMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  oaByAuthorMtid: bigint
  oaType: Int
  oaTypeDisp: Int
  oldId: Int
  ownerAuthorCount: Int
  ownerInstituteCount: Int
  pageLength: Int
  patentCountryMtid: bigint
  prevValid: bigint
  publishedYear: smallint
  publishedYearEnd: smallint
  ratingsForSort: Int
  scopusCitationCount: Int
  selfCitationCount: Int
  sourceYear: smallint
  status: Int
  subSubTypeMtid: bigint
  subTypeMtid: bigint
  submissionYear: smallint
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validatorMtid: bigint
  wosCitationCount: Int
}

# input type for inserting data into table "publication"
input publication_insert_input {
  abstractText: String
  acceptanceYear: smallint
  adminApproved: timestamp
  adminApprover: users_obj_rel_insert_input
  adminApproverForSort: String
  adminApproverMtid: bigint
  altTitles: String
  applicationYear: smallint
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  authorCount: Int
  authors: publication_authors_arr_rel_insert_input
  authorships: authorship_arr_rel_insert_input
  book: publication_obj_rel_insert_input
  bookMtid: bigint
  bulkDuplumSearchDone: Boolean
  caseNumber: String
  category: category_obj_rel_insert_input
  categoryForSort: String
  categoryMtid: bigint
  chapterCount: Int
  chapters: publication_arr_rel_insert_input
  checked: timestamp
  checker: users_obj_rel_insert_input
  checkerMtid: bigint
  citation: Boolean
  citationCount: Int
  citationCountUnpublished: Int
  citationCountWoOther: Int
  citations: citation_arr_rel_insert_input
  citedCount: Int
  citedPubCount: Int
  cites: citation_arr_rel_insert_input
  citingPubCount: Int
  citingPubCountWoOther: Int
  collaboration: Int
  comment: String
  comment2: String
  conference: conference_obj_rel_insert_input
  conferenceMtid: bigint
  conferencePublication: Boolean
  consultant: String
  consultant2: String
  consultantAuthor: users_obj_rel_insert_input
  consultantAuthor2: users_obj_rel_insert_input
  consultantAuthor2Mtid: bigint
  consultantAuthorMtid: bigint
  contributorCount: Int
  core: Boolean
  country: location_obj_rel_insert_input
  countryMtid: bigint
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  description0: String
  description1: String
  description2: String
  description3: String
  description4: String
  description5: String
  digital: Boolean
  directInstituteCount: Int
  directInstitutes: publication_direct_institutes_arr_rel_insert_input
  directInstitutesForSort: String
  discipline: discipline_obj_rel_insert_input
  disciplineMtid: bigint
  doiCitationCount: Int
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  editionNumber: Int
  endDate: date
  error: Int
  externalSource: String
  files: publication_files_arr_rel_insert_input
  firstAuthor: String
  firstPage: String
  firstPageOrInternalIdForSort: String
  foreignEdition: Boolean
  foreignEditionCitationCount: Int
  foreignLanguage: Boolean
  fromCitation: Boolean
  fullPublication: Boolean
  fundings: funding_arr_rel_insert_input
  group_mtid: bigint
  hasCitationDuplums: Boolean
  identifiers: publication_identifier_arr_rel_insert_input
  ifRating: rating_obj_rel_insert_input
  ifRatingMtid: bigint
  impactFactor: Float
  inSelectedPubs: String
  independentCitCountWoOther: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  independentCitingPubCountWoOther: Int
  institutes: publication_institutes_arr_rel_insert_input
  internalId: String
  ipc: String
  issue: String
  journal: periodical_obj_rel_insert_input
  journalForSort: String
  journalMtid: bigint
  journalName: String
  keywords: publication_keywords_arr_rel_insert_input
  labelEng: String
  labelHun: String
  languages: publication_languages_arr_rel_insert_input
  languagesForSort: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastPage: String
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mabDiscipline: mab_discipline_obj_rel_insert_input
  mabDisciplineMtid: bigint
  missingAuthor: Boolean
  mtid: bigint
  nationalOrigin: Boolean
  nationalOriginCitationCount: Int
  number: String
  oaByAuthor: users_obj_rel_insert_input
  oaByAuthorMtid: bigint
  oaCheckDate: date
  oaEmbargoDate: date
  oaFree: Boolean
  oaLink: String
  oaType: Int
  oaTypeDisp: Int
  oldId: Int
  oldOrgAuthors: publication_old_org_authors_arr_rel_insert_input
  oldTimestamp: timestamp
  otype: String
  ownerAuthorCount: Int
  ownerAuthors: publication_owner_authors_arr_rel_insert_input
  ownerInstituteCount: Int
  ownerInstitutes: publication_owner_institutes_arr_rel_insert_input
  owners: publication_owners_arr_rel_insert_input
  packet: String
  pageLength: Int
  patentCountry: location_obj_rel_insert_input
  patentCountryMtid: bigint
  prevValid: bigint
  printed: Boolean
  properties: achievement_property_value_arr_rel_insert_input
  pubStats: String
  publicationPending: Boolean
  publishDate: timestamp
  published: Boolean
  publishedAt: publication_published_at_arr_rel_insert_input
  publishedYear: smallint
  publishedYearEnd: smallint
  publishers: publication_publishers_arr_rel_insert_input
  ratings: publication_ratings_arr_rel_insert_input
  ratingsForSort: Int
  referenceList: String
  references: reference_arr_rel_insert_input
  refreshed: Boolean
  reviewer: String
  school: String
  scopusCitationCount: Int
  selfCitationCount: Int
  seriesMembers: series_volume_arr_rel_insert_input
  sourceOfData: String
  sourceYear: smallint
  startDate: date
  status: Int
  subSubType: publication_type_obj_rel_insert_input
  subSubTypeMtid: bigint
  subTitle: String
  subType: sub_type_obj_rel_insert_input
  subTypeForSort: String
  subTypeMtid: bigint
  subjects: publication_subjects_arr_rel_insert_input
  submissionNumber: String
  submissionYear: smallint
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  type: publication_type_obj_rel_insert_input
  typeForSort: String
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  unprocessedData: String
  userChangeableUntil: timestamp
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validator: users_obj_rel_insert_input
  validatorForSort: String
  validatorMtid: bigint
  volume: String
  volumeNumber: String
  volumeTitle: String
  wosCitationCount: Int
}

# columns and relationships of "publication_institutes"
type publication_institutes {
  institutesMtid: bigint!

  # An object relationship
  organization: organization!
  publicationMtid: bigint!
}

# aggregated selection of "publication_institutes"
type publication_institutes_aggregate {
  aggregate: publication_institutes_aggregate_fields
  nodes: [publication_institutes!]!
}

# aggregate fields of "publication_institutes"
type publication_institutes_aggregate_fields {
  avg: publication_institutes_avg_fields
  count(columns: [publication_institutes_select_column!], distinct: Boolean): Int
  max: publication_institutes_max_fields
  min: publication_institutes_min_fields
  stddev: publication_institutes_stddev_fields
  stddev_pop: publication_institutes_stddev_pop_fields
  stddev_samp: publication_institutes_stddev_samp_fields
  sum: publication_institutes_sum_fields
  var_pop: publication_institutes_var_pop_fields
  var_samp: publication_institutes_var_samp_fields
  variance: publication_institutes_variance_fields
}

# order by aggregate values of table "publication_institutes"
input publication_institutes_aggregate_order_by {
  avg: publication_institutes_avg_order_by
  count: order_by
  max: publication_institutes_max_order_by
  min: publication_institutes_min_order_by
  stddev: publication_institutes_stddev_order_by
  stddev_pop: publication_institutes_stddev_pop_order_by
  stddev_samp: publication_institutes_stddev_samp_order_by
  sum: publication_institutes_sum_order_by
  var_pop: publication_institutes_var_pop_order_by
  var_samp: publication_institutes_var_samp_order_by
  variance: publication_institutes_variance_order_by
}

# input type for inserting array relation for remote table "publication_institutes"
input publication_institutes_arr_rel_insert_input {
  data: [publication_institutes_insert_input!]!
  on_conflict: publication_institutes_on_conflict
}

# aggregate avg on columns
type publication_institutes_avg_fields {
  institutesMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_institutes"
input publication_institutes_avg_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_institutes". All fields are combined with a logical 'AND'.
input publication_institutes_bool_exp {
  _and: [publication_institutes_bool_exp]
  _not: publication_institutes_bool_exp
  _or: [publication_institutes_bool_exp]
  institutesMtid: bigint_comparison_exp
  organization: organization_bool_exp
  publicationMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "publication_institutes"
enum publication_institutes_constraint {
  # unique or primary key constraint
  publication_institutes_pkey
}

# input type for incrementing integer column in table "publication_institutes"
input publication_institutes_inc_input {
  institutesMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_institutes"
input publication_institutes_insert_input {
  institutesMtid: bigint
  organization: organization_obj_rel_insert_input
  publicationMtid: bigint
}

# aggregate max on columns
type publication_institutes_max_fields {
  institutesMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_institutes"
input publication_institutes_max_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_institutes_min_fields {
  institutesMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_institutes"
input publication_institutes_min_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_institutes"
type publication_institutes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_institutes!]!
}

# input type for inserting object relation for remote table "publication_institutes"
input publication_institutes_obj_rel_insert_input {
  data: publication_institutes_insert_input!
  on_conflict: publication_institutes_on_conflict
}

# on conflict condition type for table "publication_institutes"
input publication_institutes_on_conflict {
  constraint: publication_institutes_constraint!
  update_columns: [publication_institutes_update_column!]!
  where: publication_institutes_bool_exp
}

# ordering options when selecting data from "publication_institutes"
input publication_institutes_order_by {
  institutesMtid: order_by
  organization: organization_order_by
  publicationMtid: order_by
}

# primary key columns input for table: "publication_institutes"
input publication_institutes_pk_columns_input {
  institutesMtid: bigint!
  publicationMtid: bigint!
}

# select columns of table "publication_institutes"
enum publication_institutes_select_column {
  # column name
  institutesMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_institutes"
input publication_institutes_set_input {
  institutesMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_institutes_stddev_fields {
  institutesMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_institutes"
input publication_institutes_stddev_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_institutes_stddev_pop_fields {
  institutesMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_institutes"
input publication_institutes_stddev_pop_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_institutes_stddev_samp_fields {
  institutesMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_institutes"
input publication_institutes_stddev_samp_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_institutes_sum_fields {
  institutesMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_institutes"
input publication_institutes_sum_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# update columns of table "publication_institutes"
enum publication_institutes_update_column {
  # column name
  institutesMtid

  # column name
  publicationMtid
}

# aggregate var_pop on columns
type publication_institutes_var_pop_fields {
  institutesMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_institutes"
input publication_institutes_var_pop_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_institutes_var_samp_fields {
  institutesMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_institutes"
input publication_institutes_var_samp_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_institutes_variance_fields {
  institutesMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_institutes"
input publication_institutes_variance_order_by {
  institutesMtid: order_by
  publicationMtid: order_by
}

# columns and relationships of "publication_keywords"
type publication_keywords {
  # An object relationship
  keyword: keyword!
  keywordsMtid: bigint!
  publicationMtid: bigint!
}

# aggregated selection of "publication_keywords"
type publication_keywords_aggregate {
  aggregate: publication_keywords_aggregate_fields
  nodes: [publication_keywords!]!
}

# aggregate fields of "publication_keywords"
type publication_keywords_aggregate_fields {
  avg: publication_keywords_avg_fields
  count(columns: [publication_keywords_select_column!], distinct: Boolean): Int
  max: publication_keywords_max_fields
  min: publication_keywords_min_fields
  stddev: publication_keywords_stddev_fields
  stddev_pop: publication_keywords_stddev_pop_fields
  stddev_samp: publication_keywords_stddev_samp_fields
  sum: publication_keywords_sum_fields
  var_pop: publication_keywords_var_pop_fields
  var_samp: publication_keywords_var_samp_fields
  variance: publication_keywords_variance_fields
}

# order by aggregate values of table "publication_keywords"
input publication_keywords_aggregate_order_by {
  avg: publication_keywords_avg_order_by
  count: order_by
  max: publication_keywords_max_order_by
  min: publication_keywords_min_order_by
  stddev: publication_keywords_stddev_order_by
  stddev_pop: publication_keywords_stddev_pop_order_by
  stddev_samp: publication_keywords_stddev_samp_order_by
  sum: publication_keywords_sum_order_by
  var_pop: publication_keywords_var_pop_order_by
  var_samp: publication_keywords_var_samp_order_by
  variance: publication_keywords_variance_order_by
}

# input type for inserting array relation for remote table "publication_keywords"
input publication_keywords_arr_rel_insert_input {
  data: [publication_keywords_insert_input!]!
}

# aggregate avg on columns
type publication_keywords_avg_fields {
  keywordsMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_keywords"
input publication_keywords_avg_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_keywords". All fields are combined with a logical 'AND'.
input publication_keywords_bool_exp {
  _and: [publication_keywords_bool_exp]
  _not: publication_keywords_bool_exp
  _or: [publication_keywords_bool_exp]
  keyword: keyword_bool_exp
  keywordsMtid: bigint_comparison_exp
  publicationMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_keywords"
input publication_keywords_inc_input {
  keywordsMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_keywords"
input publication_keywords_insert_input {
  keyword: keyword_obj_rel_insert_input
  keywordsMtid: bigint
  publicationMtid: bigint
}

# aggregate max on columns
type publication_keywords_max_fields {
  keywordsMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_keywords"
input publication_keywords_max_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_keywords_min_fields {
  keywordsMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_keywords"
input publication_keywords_min_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_keywords"
type publication_keywords_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_keywords!]!
}

# input type for inserting object relation for remote table "publication_keywords"
input publication_keywords_obj_rel_insert_input {
  data: publication_keywords_insert_input!
}

# ordering options when selecting data from "publication_keywords"
input publication_keywords_order_by {
  keyword: keyword_order_by
  keywordsMtid: order_by
  publicationMtid: order_by
}

# select columns of table "publication_keywords"
enum publication_keywords_select_column {
  # column name
  keywordsMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_keywords"
input publication_keywords_set_input {
  keywordsMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_keywords_stddev_fields {
  keywordsMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_keywords"
input publication_keywords_stddev_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_keywords_stddev_pop_fields {
  keywordsMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_keywords"
input publication_keywords_stddev_pop_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_keywords_stddev_samp_fields {
  keywordsMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_keywords"
input publication_keywords_stddev_samp_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_keywords_sum_fields {
  keywordsMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_keywords"
input publication_keywords_sum_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# aggregate var_pop on columns
type publication_keywords_var_pop_fields {
  keywordsMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_keywords"
input publication_keywords_var_pop_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_keywords_var_samp_fields {
  keywordsMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_keywords"
input publication_keywords_var_samp_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_keywords_variance_fields {
  keywordsMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_keywords"
input publication_keywords_variance_order_by {
  keywordsMtid: order_by
  publicationMtid: order_by
}

# columns and relationships of "publication_languages"
type publication_languages {
  # An object relationship
  language: language!
  languagesMtid: bigint!
  publicationMtid: bigint!
}

# aggregated selection of "publication_languages"
type publication_languages_aggregate {
  aggregate: publication_languages_aggregate_fields
  nodes: [publication_languages!]!
}

# aggregate fields of "publication_languages"
type publication_languages_aggregate_fields {
  avg: publication_languages_avg_fields
  count(columns: [publication_languages_select_column!], distinct: Boolean): Int
  max: publication_languages_max_fields
  min: publication_languages_min_fields
  stddev: publication_languages_stddev_fields
  stddev_pop: publication_languages_stddev_pop_fields
  stddev_samp: publication_languages_stddev_samp_fields
  sum: publication_languages_sum_fields
  var_pop: publication_languages_var_pop_fields
  var_samp: publication_languages_var_samp_fields
  variance: publication_languages_variance_fields
}

# order by aggregate values of table "publication_languages"
input publication_languages_aggregate_order_by {
  avg: publication_languages_avg_order_by
  count: order_by
  max: publication_languages_max_order_by
  min: publication_languages_min_order_by
  stddev: publication_languages_stddev_order_by
  stddev_pop: publication_languages_stddev_pop_order_by
  stddev_samp: publication_languages_stddev_samp_order_by
  sum: publication_languages_sum_order_by
  var_pop: publication_languages_var_pop_order_by
  var_samp: publication_languages_var_samp_order_by
  variance: publication_languages_variance_order_by
}

# input type for inserting array relation for remote table "publication_languages"
input publication_languages_arr_rel_insert_input {
  data: [publication_languages_insert_input!]!
}

# aggregate avg on columns
type publication_languages_avg_fields {
  languagesMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_languages"
input publication_languages_avg_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_languages". All fields are combined with a logical 'AND'.
input publication_languages_bool_exp {
  _and: [publication_languages_bool_exp]
  _not: publication_languages_bool_exp
  _or: [publication_languages_bool_exp]
  language: language_bool_exp
  languagesMtid: bigint_comparison_exp
  publicationMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_languages"
input publication_languages_inc_input {
  languagesMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_languages"
input publication_languages_insert_input {
  language: language_obj_rel_insert_input
  languagesMtid: bigint
  publicationMtid: bigint
}

# aggregate max on columns
type publication_languages_max_fields {
  languagesMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_languages"
input publication_languages_max_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_languages_min_fields {
  languagesMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_languages"
input publication_languages_min_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_languages"
type publication_languages_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_languages!]!
}

# input type for inserting object relation for remote table "publication_languages"
input publication_languages_obj_rel_insert_input {
  data: publication_languages_insert_input!
}

# ordering options when selecting data from "publication_languages"
input publication_languages_order_by {
  language: language_order_by
  languagesMtid: order_by
  publicationMtid: order_by
}

# select columns of table "publication_languages"
enum publication_languages_select_column {
  # column name
  languagesMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_languages"
input publication_languages_set_input {
  languagesMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_languages_stddev_fields {
  languagesMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_languages"
input publication_languages_stddev_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_languages_stddev_pop_fields {
  languagesMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_languages"
input publication_languages_stddev_pop_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_languages_stddev_samp_fields {
  languagesMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_languages"
input publication_languages_stddev_samp_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_languages_sum_fields {
  languagesMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_languages"
input publication_languages_sum_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate var_pop on columns
type publication_languages_var_pop_fields {
  languagesMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_languages"
input publication_languages_var_pop_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_languages_var_samp_fields {
  languagesMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_languages"
input publication_languages_var_samp_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_languages_variance_fields {
  languagesMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_languages"
input publication_languages_variance_order_by {
  languagesMtid: order_by
  publicationMtid: order_by
}

# aggregate max on columns
type publication_max_fields {
  abstractText: String
  acceptanceYear: smallint
  adminApproved: timestamp
  adminApproverForSort: String
  adminApproverMtid: bigint
  altTitles: String
  applicationYear: smallint
  approved: timestamp
  approverMtid: bigint
  authorCount: Int
  bookMtid: bigint
  caseNumber: String
  categoryForSort: String
  categoryMtid: bigint
  chapterCount: Int
  checked: timestamp
  checkerMtid: bigint
  citationCount: Int
  citationCountUnpublished: Int
  citationCountWoOther: Int
  citedCount: Int
  citedPubCount: Int
  citingPubCount: Int
  citingPubCountWoOther: Int
  collaboration: Int
  comment: String
  comment2: String
  conferenceMtid: bigint
  consultant: String
  consultant2: String
  consultantAuthor2Mtid: bigint
  consultantAuthorMtid: bigint
  contributorCount: Int
  countryMtid: bigint
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  description0: String
  description1: String
  description2: String
  description3: String
  description4: String
  description5: String
  directInstituteCount: Int
  directInstitutesForSort: String
  disciplineMtid: bigint
  doiCitationCount: Int
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  editionNumber: Int
  endDate: date
  error: Int
  externalSource: String
  firstAuthor: String
  firstPage: String
  firstPageOrInternalIdForSort: String
  foreignEditionCitationCount: Int
  group_mtid: bigint
  ifRatingMtid: bigint
  impactFactor: Float
  inSelectedPubs: String
  independentCitCountWoOther: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  independentCitingPubCountWoOther: Int
  internalId: String
  ipc: String
  issue: String
  journalForSort: String
  journalMtid: bigint
  journalName: String
  labelEng: String
  labelHun: String
  languagesForSort: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastPage: String
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mabDisciplineMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  number: String
  oaByAuthorMtid: bigint
  oaCheckDate: date
  oaEmbargoDate: date
  oaLink: String
  oaType: Int
  oaTypeDisp: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerAuthorCount: Int
  ownerInstituteCount: Int
  packet: String
  pageLength: Int
  patentCountryMtid: bigint
  prevValid: bigint
  pubStats: String
  publishDate: timestamp
  publishedYear: smallint
  publishedYearEnd: smallint
  ratingsForSort: Int
  referenceList: String
  reviewer: String
  school: String
  scopusCitationCount: Int
  selfCitationCount: Int
  sourceOfData: String
  sourceYear: smallint
  startDate: date
  status: Int
  subSubTypeMtid: bigint
  subTitle: String
  subTypeForSort: String
  subTypeMtid: bigint
  submissionNumber: String
  submissionYear: smallint
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  typeForSort: String
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  unprocessedData: String
  userChangeableUntil: timestamp
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validatorForSort: String
  validatorMtid: bigint
  volume: String
  volumeNumber: String
  volumeTitle: String
  wosCitationCount: Int
}

# order by max() on columns of table "publication"
input publication_max_order_by {
  abstractText: order_by
  acceptanceYear: order_by
  adminApproved: order_by
  adminApproverForSort: order_by
  adminApproverMtid: order_by
  altTitles: order_by
  applicationYear: order_by
  approved: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  caseNumber: order_by
  categoryForSort: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checked: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  comment: order_by
  comment2: order_by
  conferenceMtid: order_by
  consultant: order_by
  consultant2: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  description0: order_by
  description1: order_by
  description2: order_by
  description3: order_by
  description4: order_by
  description5: order_by
  directInstituteCount: order_by
  directInstitutesForSort: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumKey: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  endDate: order_by
  error: order_by
  externalSource: order_by
  firstAuthor: order_by
  firstPage: order_by
  firstPageOrInternalIdForSort: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  inSelectedPubs: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  internalId: order_by
  ipc: order_by
  issue: order_by
  journalForSort: order_by
  journalMtid: order_by
  journalName: order_by
  labelEng: order_by
  labelHun: order_by
  languagesForSort: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastPage: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  number: order_by
  oaByAuthorMtid: order_by
  oaCheckDate: order_by
  oaEmbargoDate: order_by
  oaLink: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  packet: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  pubStats: order_by
  publishDate: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  referenceList: order_by
  reviewer: order_by
  school: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceOfData: order_by
  sourceYear: order_by
  startDate: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTitle: order_by
  subTypeForSort: order_by
  subTypeMtid: order_by
  submissionNumber: order_by
  submissionYear: order_by
  tempLocked: order_by
  tempLockerIdString: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  title: order_by
  typeForSort: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  unprocessedData: order_by
  userChangeableUntil: order_by
  validFromYear: order_by
  validToYear: order_by
  validated: order_by
  validatorForSort: order_by
  validatorMtid: order_by
  volume: order_by
  volumeNumber: order_by
  volumeTitle: order_by
  wosCitationCount: order_by
}

# aggregate min on columns
type publication_min_fields {
  abstractText: String
  acceptanceYear: smallint
  adminApproved: timestamp
  adminApproverForSort: String
  adminApproverMtid: bigint
  altTitles: String
  applicationYear: smallint
  approved: timestamp
  approverMtid: bigint
  authorCount: Int
  bookMtid: bigint
  caseNumber: String
  categoryForSort: String
  categoryMtid: bigint
  chapterCount: Int
  checked: timestamp
  checkerMtid: bigint
  citationCount: Int
  citationCountUnpublished: Int
  citationCountWoOther: Int
  citedCount: Int
  citedPubCount: Int
  citingPubCount: Int
  citingPubCountWoOther: Int
  collaboration: Int
  comment: String
  comment2: String
  conferenceMtid: bigint
  consultant: String
  consultant2: String
  consultantAuthor2Mtid: bigint
  consultantAuthorMtid: bigint
  contributorCount: Int
  countryMtid: bigint
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  description0: String
  description1: String
  description2: String
  description3: String
  description4: String
  description5: String
  directInstituteCount: Int
  directInstitutesForSort: String
  disciplineMtid: bigint
  doiCitationCount: Int
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  editionNumber: Int
  endDate: date
  error: Int
  externalSource: String
  firstAuthor: String
  firstPage: String
  firstPageOrInternalIdForSort: String
  foreignEditionCitationCount: Int
  group_mtid: bigint
  ifRatingMtid: bigint
  impactFactor: Float
  inSelectedPubs: String
  independentCitCountWoOther: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  independentCitingPubCountWoOther: Int
  internalId: String
  ipc: String
  issue: String
  journalForSort: String
  journalMtid: bigint
  journalName: String
  labelEng: String
  labelHun: String
  languagesForSort: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastPage: String
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mabDisciplineMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  number: String
  oaByAuthorMtid: bigint
  oaCheckDate: date
  oaEmbargoDate: date
  oaLink: String
  oaType: Int
  oaTypeDisp: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerAuthorCount: Int
  ownerInstituteCount: Int
  packet: String
  pageLength: Int
  patentCountryMtid: bigint
  prevValid: bigint
  pubStats: String
  publishDate: timestamp
  publishedYear: smallint
  publishedYearEnd: smallint
  ratingsForSort: Int
  referenceList: String
  reviewer: String
  school: String
  scopusCitationCount: Int
  selfCitationCount: Int
  sourceOfData: String
  sourceYear: smallint
  startDate: date
  status: Int
  subSubTypeMtid: bigint
  subTitle: String
  subTypeForSort: String
  subTypeMtid: bigint
  submissionNumber: String
  submissionYear: smallint
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  typeForSort: String
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  unprocessedData: String
  userChangeableUntil: timestamp
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validatorForSort: String
  validatorMtid: bigint
  volume: String
  volumeNumber: String
  volumeTitle: String
  wosCitationCount: Int
}

# order by min() on columns of table "publication"
input publication_min_order_by {
  abstractText: order_by
  acceptanceYear: order_by
  adminApproved: order_by
  adminApproverForSort: order_by
  adminApproverMtid: order_by
  altTitles: order_by
  applicationYear: order_by
  approved: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  caseNumber: order_by
  categoryForSort: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checked: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  comment: order_by
  comment2: order_by
  conferenceMtid: order_by
  consultant: order_by
  consultant2: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  description0: order_by
  description1: order_by
  description2: order_by
  description3: order_by
  description4: order_by
  description5: order_by
  directInstituteCount: order_by
  directInstitutesForSort: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumKey: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  endDate: order_by
  error: order_by
  externalSource: order_by
  firstAuthor: order_by
  firstPage: order_by
  firstPageOrInternalIdForSort: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  inSelectedPubs: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  internalId: order_by
  ipc: order_by
  issue: order_by
  journalForSort: order_by
  journalMtid: order_by
  journalName: order_by
  labelEng: order_by
  labelHun: order_by
  languagesForSort: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastPage: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  number: order_by
  oaByAuthorMtid: order_by
  oaCheckDate: order_by
  oaEmbargoDate: order_by
  oaLink: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  packet: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  pubStats: order_by
  publishDate: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  referenceList: order_by
  reviewer: order_by
  school: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceOfData: order_by
  sourceYear: order_by
  startDate: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTitle: order_by
  subTypeForSort: order_by
  subTypeMtid: order_by
  submissionNumber: order_by
  submissionYear: order_by
  tempLocked: order_by
  tempLockerIdString: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  title: order_by
  typeForSort: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  unprocessedData: order_by
  userChangeableUntil: order_by
  validFromYear: order_by
  validToYear: order_by
  validated: order_by
  validatorForSort: order_by
  validatorMtid: order_by
  volume: order_by
  volumeNumber: order_by
  volumeTitle: order_by
  wosCitationCount: order_by
}

# response of any mutation on the table "publication"
type publication_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication!]!
}

# input type for inserting object relation for remote table "publication"
input publication_obj_rel_insert_input {
  data: publication_insert_input!
  on_conflict: publication_on_conflict
}

# columns and relationships of "publication_old_org_authors"
type publication_old_org_authors {
  oldOrgAuthorsMtid: bigint!

  # An object relationship
  organization: organization!
  publicationMtid: bigint!
}

# aggregated selection of "publication_old_org_authors"
type publication_old_org_authors_aggregate {
  aggregate: publication_old_org_authors_aggregate_fields
  nodes: [publication_old_org_authors!]!
}

# aggregate fields of "publication_old_org_authors"
type publication_old_org_authors_aggregate_fields {
  avg: publication_old_org_authors_avg_fields
  count(columns: [publication_old_org_authors_select_column!], distinct: Boolean): Int
  max: publication_old_org_authors_max_fields
  min: publication_old_org_authors_min_fields
  stddev: publication_old_org_authors_stddev_fields
  stddev_pop: publication_old_org_authors_stddev_pop_fields
  stddev_samp: publication_old_org_authors_stddev_samp_fields
  sum: publication_old_org_authors_sum_fields
  var_pop: publication_old_org_authors_var_pop_fields
  var_samp: publication_old_org_authors_var_samp_fields
  variance: publication_old_org_authors_variance_fields
}

# order by aggregate values of table "publication_old_org_authors"
input publication_old_org_authors_aggregate_order_by {
  avg: publication_old_org_authors_avg_order_by
  count: order_by
  max: publication_old_org_authors_max_order_by
  min: publication_old_org_authors_min_order_by
  stddev: publication_old_org_authors_stddev_order_by
  stddev_pop: publication_old_org_authors_stddev_pop_order_by
  stddev_samp: publication_old_org_authors_stddev_samp_order_by
  sum: publication_old_org_authors_sum_order_by
  var_pop: publication_old_org_authors_var_pop_order_by
  var_samp: publication_old_org_authors_var_samp_order_by
  variance: publication_old_org_authors_variance_order_by
}

# input type for inserting array relation for remote table "publication_old_org_authors"
input publication_old_org_authors_arr_rel_insert_input {
  data: [publication_old_org_authors_insert_input!]!
}

# aggregate avg on columns
type publication_old_org_authors_avg_fields {
  oldOrgAuthorsMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_old_org_authors"
input publication_old_org_authors_avg_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_old_org_authors".
# All fields are combined with a logical 'AND'.
input publication_old_org_authors_bool_exp {
  _and: [publication_old_org_authors_bool_exp]
  _not: publication_old_org_authors_bool_exp
  _or: [publication_old_org_authors_bool_exp]
  oldOrgAuthorsMtid: bigint_comparison_exp
  organization: organization_bool_exp
  publicationMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_old_org_authors"
input publication_old_org_authors_inc_input {
  oldOrgAuthorsMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_old_org_authors"
input publication_old_org_authors_insert_input {
  oldOrgAuthorsMtid: bigint
  organization: organization_obj_rel_insert_input
  publicationMtid: bigint
}

# aggregate max on columns
type publication_old_org_authors_max_fields {
  oldOrgAuthorsMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_old_org_authors"
input publication_old_org_authors_max_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_old_org_authors_min_fields {
  oldOrgAuthorsMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_old_org_authors"
input publication_old_org_authors_min_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_old_org_authors"
type publication_old_org_authors_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_old_org_authors!]!
}

# input type for inserting object relation for remote table "publication_old_org_authors"
input publication_old_org_authors_obj_rel_insert_input {
  data: publication_old_org_authors_insert_input!
}

# ordering options when selecting data from "publication_old_org_authors"
input publication_old_org_authors_order_by {
  oldOrgAuthorsMtid: order_by
  organization: organization_order_by
  publicationMtid: order_by
}

# select columns of table "publication_old_org_authors"
enum publication_old_org_authors_select_column {
  # column name
  oldOrgAuthorsMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_old_org_authors"
input publication_old_org_authors_set_input {
  oldOrgAuthorsMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_old_org_authors_stddev_fields {
  oldOrgAuthorsMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_old_org_authors"
input publication_old_org_authors_stddev_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_old_org_authors_stddev_pop_fields {
  oldOrgAuthorsMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_old_org_authors"
input publication_old_org_authors_stddev_pop_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_old_org_authors_stddev_samp_fields {
  oldOrgAuthorsMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_old_org_authors"
input publication_old_org_authors_stddev_samp_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_old_org_authors_sum_fields {
  oldOrgAuthorsMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_old_org_authors"
input publication_old_org_authors_sum_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate var_pop on columns
type publication_old_org_authors_var_pop_fields {
  oldOrgAuthorsMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_old_org_authors"
input publication_old_org_authors_var_pop_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_old_org_authors_var_samp_fields {
  oldOrgAuthorsMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_old_org_authors"
input publication_old_org_authors_var_samp_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_old_org_authors_variance_fields {
  oldOrgAuthorsMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_old_org_authors"
input publication_old_org_authors_variance_order_by {
  oldOrgAuthorsMtid: order_by
  publicationMtid: order_by
}

# on conflict condition type for table "publication"
input publication_on_conflict {
  constraint: publication_constraint!
  update_columns: [publication_update_column!]!
  where: publication_bool_exp
}

# ordering options when selecting data from "publication"
input publication_order_by {
  abstractText: order_by
  acceptanceYear: order_by
  adminApproved: order_by
  adminApprover: users_order_by
  adminApproverForSort: order_by
  adminApproverMtid: order_by
  altTitles: order_by
  applicationYear: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  authorCount: order_by
  authors_aggregate: publication_authors_aggregate_order_by
  authorships_aggregate: authorship_aggregate_order_by
  book: publication_order_by
  bookMtid: order_by
  bulkDuplumSearchDone: order_by
  caseNumber: order_by
  category: category_order_by
  categoryForSort: order_by
  categoryMtid: order_by
  chapterCount: order_by
  chapters_aggregate: publication_aggregate_order_by
  checked: order_by
  checker: users_order_by
  checkerMtid: order_by
  citation: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citations_aggregate: citation_aggregate_order_by
  citedCount: order_by
  citedPubCount: order_by
  cites_aggregate: citation_aggregate_order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  comment: order_by
  comment2: order_by
  conference: conference_order_by
  conferenceMtid: order_by
  conferencePublication: order_by
  consultant: order_by
  consultant2: order_by
  consultantAuthor: users_order_by
  consultantAuthor2: users_order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  core: order_by
  country: location_order_by
  countryMtid: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  description0: order_by
  description1: order_by
  description2: order_by
  description3: order_by
  description4: order_by
  description5: order_by
  digital: order_by
  directInstituteCount: order_by
  directInstitutesForSort: order_by
  directInstitutes_aggregate: publication_direct_institutes_aggregate_order_by
  discipline: discipline_order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumKey: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  endDate: order_by
  error: order_by
  externalSource: order_by
  files_aggregate: publication_files_aggregate_order_by
  firstAuthor: order_by
  firstPage: order_by
  firstPageOrInternalIdForSort: order_by
  foreignEdition: order_by
  foreignEditionCitationCount: order_by
  foreignLanguage: order_by
  fromCitation: order_by
  fullPublication: order_by
  fundings_aggregate: funding_aggregate_order_by
  group_mtid: order_by
  hasCitationDuplums: order_by
  identifiers_aggregate: publication_identifier_aggregate_order_by
  ifRating: rating_order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  inSelectedPubs: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  institutes_aggregate: publication_institutes_aggregate_order_by
  internalId: order_by
  ipc: order_by
  issue: order_by
  journal: periodical_order_by
  journalForSort: order_by
  journalMtid: order_by
  journalName: order_by
  keywords_aggregate: publication_keywords_aggregate_order_by
  labelEng: order_by
  labelHun: order_by
  languagesForSort: order_by
  languages_aggregate: publication_languages_aggregate_order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastPage: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mabDiscipline: mab_discipline_order_by
  mabDisciplineMtid: order_by
  missingAuthor: order_by
  mtid: order_by
  nationalOrigin: order_by
  nationalOriginCitationCount: order_by
  number: order_by
  oaByAuthor: users_order_by
  oaByAuthorMtid: order_by
  oaCheckDate: order_by
  oaEmbargoDate: order_by
  oaFree: order_by
  oaLink: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  oldOrgAuthors_aggregate: publication_old_org_authors_aggregate_order_by
  oldTimestamp: order_by
  otype: order_by
  ownerAuthorCount: order_by
  ownerAuthors_aggregate: publication_owner_authors_aggregate_order_by
  ownerInstituteCount: order_by
  ownerInstitutes_aggregate: publication_owner_institutes_aggregate_order_by
  owners_aggregate: publication_owners_aggregate_order_by
  packet: order_by
  pageLength: order_by
  patentCountry: location_order_by
  patentCountryMtid: order_by
  prevValid: order_by
  printed: order_by
  properties_aggregate: achievement_property_value_aggregate_order_by
  pubStats: order_by
  publicationPending: order_by
  publishDate: order_by
  published: order_by
  publishedAt_aggregate: publication_published_at_aggregate_order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  publishers_aggregate: publication_publishers_aggregate_order_by
  ratingsForSort: order_by
  ratings_aggregate: publication_ratings_aggregate_order_by
  referenceList: order_by
  references_aggregate: reference_aggregate_order_by
  refreshed: order_by
  reviewer: order_by
  school: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  seriesMembers_aggregate: series_volume_aggregate_order_by
  sourceOfData: order_by
  sourceYear: order_by
  startDate: order_by
  status: order_by
  subSubType: publication_type_order_by
  subSubTypeMtid: order_by
  subTitle: order_by
  subType: sub_type_order_by
  subTypeForSort: order_by
  subTypeMtid: order_by
  subjects_aggregate: publication_subjects_aggregate_order_by
  submissionNumber: order_by
  submissionYear: order_by
  tempLocked: order_by
  tempLockerIdString: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  title: order_by
  type: publication_type_order_by
  typeForSort: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  unprocessedData: order_by
  userChangeableUntil: order_by
  validFromYear: order_by
  validToYear: order_by
  validated: order_by
  validator: users_order_by
  validatorForSort: order_by
  validatorMtid: order_by
  volume: order_by
  volumeNumber: order_by
  volumeTitle: order_by
  wosCitationCount: order_by
}

# columns and relationships of "publication_owner_authors"
type publication_owner_authors {
  ownerAuthorsMtid: bigint!
  publicationMtid: bigint!

  # An object relationship
  users: users!
}

# aggregated selection of "publication_owner_authors"
type publication_owner_authors_aggregate {
  aggregate: publication_owner_authors_aggregate_fields
  nodes: [publication_owner_authors!]!
}

# aggregate fields of "publication_owner_authors"
type publication_owner_authors_aggregate_fields {
  avg: publication_owner_authors_avg_fields
  count(columns: [publication_owner_authors_select_column!], distinct: Boolean): Int
  max: publication_owner_authors_max_fields
  min: publication_owner_authors_min_fields
  stddev: publication_owner_authors_stddev_fields
  stddev_pop: publication_owner_authors_stddev_pop_fields
  stddev_samp: publication_owner_authors_stddev_samp_fields
  sum: publication_owner_authors_sum_fields
  var_pop: publication_owner_authors_var_pop_fields
  var_samp: publication_owner_authors_var_samp_fields
  variance: publication_owner_authors_variance_fields
}

# order by aggregate values of table "publication_owner_authors"
input publication_owner_authors_aggregate_order_by {
  avg: publication_owner_authors_avg_order_by
  count: order_by
  max: publication_owner_authors_max_order_by
  min: publication_owner_authors_min_order_by
  stddev: publication_owner_authors_stddev_order_by
  stddev_pop: publication_owner_authors_stddev_pop_order_by
  stddev_samp: publication_owner_authors_stddev_samp_order_by
  sum: publication_owner_authors_sum_order_by
  var_pop: publication_owner_authors_var_pop_order_by
  var_samp: publication_owner_authors_var_samp_order_by
  variance: publication_owner_authors_variance_order_by
}

# input type for inserting array relation for remote table "publication_owner_authors"
input publication_owner_authors_arr_rel_insert_input {
  data: [publication_owner_authors_insert_input!]!
  on_conflict: publication_owner_authors_on_conflict
}

# aggregate avg on columns
type publication_owner_authors_avg_fields {
  ownerAuthorsMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_owner_authors"
input publication_owner_authors_avg_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_owner_authors". All fields are combined with a logical 'AND'.
input publication_owner_authors_bool_exp {
  _and: [publication_owner_authors_bool_exp]
  _not: publication_owner_authors_bool_exp
  _or: [publication_owner_authors_bool_exp]
  ownerAuthorsMtid: bigint_comparison_exp
  publicationMtid: bigint_comparison_exp
  users: users_bool_exp
}

# unique or primary key constraints on table "publication_owner_authors"
enum publication_owner_authors_constraint {
  # unique or primary key constraint
  publication_owner_authors_pkey
}

# input type for incrementing integer column in table "publication_owner_authors"
input publication_owner_authors_inc_input {
  ownerAuthorsMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_owner_authors"
input publication_owner_authors_insert_input {
  ownerAuthorsMtid: bigint
  publicationMtid: bigint
  users: users_obj_rel_insert_input
}

# aggregate max on columns
type publication_owner_authors_max_fields {
  ownerAuthorsMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_owner_authors"
input publication_owner_authors_max_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_owner_authors_min_fields {
  ownerAuthorsMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_owner_authors"
input publication_owner_authors_min_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_owner_authors"
type publication_owner_authors_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_owner_authors!]!
}

# input type for inserting object relation for remote table "publication_owner_authors"
input publication_owner_authors_obj_rel_insert_input {
  data: publication_owner_authors_insert_input!
  on_conflict: publication_owner_authors_on_conflict
}

# on conflict condition type for table "publication_owner_authors"
input publication_owner_authors_on_conflict {
  constraint: publication_owner_authors_constraint!
  update_columns: [publication_owner_authors_update_column!]!
  where: publication_owner_authors_bool_exp
}

# ordering options when selecting data from "publication_owner_authors"
input publication_owner_authors_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
  users: users_order_by
}

# primary key columns input for table: "publication_owner_authors"
input publication_owner_authors_pk_columns_input {
  ownerAuthorsMtid: bigint!
  publicationMtid: bigint!
}

# select columns of table "publication_owner_authors"
enum publication_owner_authors_select_column {
  # column name
  ownerAuthorsMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_owner_authors"
input publication_owner_authors_set_input {
  ownerAuthorsMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_owner_authors_stddev_fields {
  ownerAuthorsMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_owner_authors"
input publication_owner_authors_stddev_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_owner_authors_stddev_pop_fields {
  ownerAuthorsMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_owner_authors"
input publication_owner_authors_stddev_pop_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_owner_authors_stddev_samp_fields {
  ownerAuthorsMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_owner_authors"
input publication_owner_authors_stddev_samp_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_owner_authors_sum_fields {
  ownerAuthorsMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_owner_authors"
input publication_owner_authors_sum_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# update columns of table "publication_owner_authors"
enum publication_owner_authors_update_column {
  # column name
  ownerAuthorsMtid

  # column name
  publicationMtid
}

# aggregate var_pop on columns
type publication_owner_authors_var_pop_fields {
  ownerAuthorsMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_owner_authors"
input publication_owner_authors_var_pop_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_owner_authors_var_samp_fields {
  ownerAuthorsMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_owner_authors"
input publication_owner_authors_var_samp_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_owner_authors_variance_fields {
  ownerAuthorsMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_owner_authors"
input publication_owner_authors_variance_order_by {
  ownerAuthorsMtid: order_by
  publicationMtid: order_by
}

# columns and relationships of "publication_owner_institutes"
type publication_owner_institutes {
  # An object relationship
  organization: organization!
  ownerInstitutesMtid: bigint!
  publicationMtid: bigint!
}

# aggregated selection of "publication_owner_institutes"
type publication_owner_institutes_aggregate {
  aggregate: publication_owner_institutes_aggregate_fields
  nodes: [publication_owner_institutes!]!
}

# aggregate fields of "publication_owner_institutes"
type publication_owner_institutes_aggregate_fields {
  avg: publication_owner_institutes_avg_fields
  count(columns: [publication_owner_institutes_select_column!], distinct: Boolean): Int
  max: publication_owner_institutes_max_fields
  min: publication_owner_institutes_min_fields
  stddev: publication_owner_institutes_stddev_fields
  stddev_pop: publication_owner_institutes_stddev_pop_fields
  stddev_samp: publication_owner_institutes_stddev_samp_fields
  sum: publication_owner_institutes_sum_fields
  var_pop: publication_owner_institutes_var_pop_fields
  var_samp: publication_owner_institutes_var_samp_fields
  variance: publication_owner_institutes_variance_fields
}

# order by aggregate values of table "publication_owner_institutes"
input publication_owner_institutes_aggregate_order_by {
  avg: publication_owner_institutes_avg_order_by
  count: order_by
  max: publication_owner_institutes_max_order_by
  min: publication_owner_institutes_min_order_by
  stddev: publication_owner_institutes_stddev_order_by
  stddev_pop: publication_owner_institutes_stddev_pop_order_by
  stddev_samp: publication_owner_institutes_stddev_samp_order_by
  sum: publication_owner_institutes_sum_order_by
  var_pop: publication_owner_institutes_var_pop_order_by
  var_samp: publication_owner_institutes_var_samp_order_by
  variance: publication_owner_institutes_variance_order_by
}

# input type for inserting array relation for remote table "publication_owner_institutes"
input publication_owner_institutes_arr_rel_insert_input {
  data: [publication_owner_institutes_insert_input!]!
  on_conflict: publication_owner_institutes_on_conflict
}

# aggregate avg on columns
type publication_owner_institutes_avg_fields {
  ownerInstitutesMtid: Float
  publicationMtid: Float
}

# order by avg() on columns of table "publication_owner_institutes"
input publication_owner_institutes_avg_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# Boolean expression to filter rows from the table "publication_owner_institutes".
# All fields are combined with a logical 'AND'.
input publication_owner_institutes_bool_exp {
  _and: [publication_owner_institutes_bool_exp]
  _not: publication_owner_institutes_bool_exp
  _or: [publication_owner_institutes_bool_exp]
  organization: organization_bool_exp
  ownerInstitutesMtid: bigint_comparison_exp
  publicationMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "publication_owner_institutes"
enum publication_owner_institutes_constraint {
  # unique or primary key constraint
  publication_owner_institutes_pkey
}

# input type for incrementing integer column in table "publication_owner_institutes"
input publication_owner_institutes_inc_input {
  ownerInstitutesMtid: bigint
  publicationMtid: bigint
}

# input type for inserting data into table "publication_owner_institutes"
input publication_owner_institutes_insert_input {
  organization: organization_obj_rel_insert_input
  ownerInstitutesMtid: bigint
  publicationMtid: bigint
}

# aggregate max on columns
type publication_owner_institutes_max_fields {
  ownerInstitutesMtid: bigint
  publicationMtid: bigint
}

# order by max() on columns of table "publication_owner_institutes"
input publication_owner_institutes_max_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate min on columns
type publication_owner_institutes_min_fields {
  ownerInstitutesMtid: bigint
  publicationMtid: bigint
}

# order by min() on columns of table "publication_owner_institutes"
input publication_owner_institutes_min_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# response of any mutation on the table "publication_owner_institutes"
type publication_owner_institutes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_owner_institutes!]!
}

# input type for inserting object relation for remote table "publication_owner_institutes"
input publication_owner_institutes_obj_rel_insert_input {
  data: publication_owner_institutes_insert_input!
  on_conflict: publication_owner_institutes_on_conflict
}

# on conflict condition type for table "publication_owner_institutes"
input publication_owner_institutes_on_conflict {
  constraint: publication_owner_institutes_constraint!
  update_columns: [publication_owner_institutes_update_column!]!
  where: publication_owner_institutes_bool_exp
}

# ordering options when selecting data from "publication_owner_institutes"
input publication_owner_institutes_order_by {
  organization: organization_order_by
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# primary key columns input for table: "publication_owner_institutes"
input publication_owner_institutes_pk_columns_input {
  ownerInstitutesMtid: bigint!
  publicationMtid: bigint!
}

# select columns of table "publication_owner_institutes"
enum publication_owner_institutes_select_column {
  # column name
  ownerInstitutesMtid

  # column name
  publicationMtid
}

# input type for updating data in table "publication_owner_institutes"
input publication_owner_institutes_set_input {
  ownerInstitutesMtid: bigint
  publicationMtid: bigint
}

# aggregate stddev on columns
type publication_owner_institutes_stddev_fields {
  ownerInstitutesMtid: Float
  publicationMtid: Float
}

# order by stddev() on columns of table "publication_owner_institutes"
input publication_owner_institutes_stddev_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_pop on columns
type publication_owner_institutes_stddev_pop_fields {
  ownerInstitutesMtid: Float
  publicationMtid: Float
}

# order by stddev_pop() on columns of table "publication_owner_institutes"
input publication_owner_institutes_stddev_pop_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate stddev_samp on columns
type publication_owner_institutes_stddev_samp_fields {
  ownerInstitutesMtid: Float
  publicationMtid: Float
}

# order by stddev_samp() on columns of table "publication_owner_institutes"
input publication_owner_institutes_stddev_samp_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate sum on columns
type publication_owner_institutes_sum_fields {
  ownerInstitutesMtid: bigint
  publicationMtid: bigint
}

# order by sum() on columns of table "publication_owner_institutes"
input publication_owner_institutes_sum_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# update columns of table "publication_owner_institutes"
enum publication_owner_institutes_update_column {
  # column name
  ownerInstitutesMtid

  # column name
  publicationMtid
}

# aggregate var_pop on columns
type publication_owner_institutes_var_pop_fields {
  ownerInstitutesMtid: Float
  publicationMtid: Float
}

# order by var_pop() on columns of table "publication_owner_institutes"
input publication_owner_institutes_var_pop_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate var_samp on columns
type publication_owner_institutes_var_samp_fields {
  ownerInstitutesMtid: Float
  publicationMtid: Float
}

# order by var_samp() on columns of table "publication_owner_institutes"
input publication_owner_institutes_var_samp_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# aggregate variance on columns
type publication_owner_institutes_variance_fields {
  ownerInstitutesMtid: Float
  publicationMtid: Float
}

# order by variance() on columns of table "publication_owner_institutes"
input publication_owner_institutes_variance_order_by {
  ownerInstitutesMtid: order_by
  publicationMtid: order_by
}

# columns and relationships of "publication_owners"
type publication_owners {
  owners: bigint
  publication_mtid: bigint!
}

# aggregated selection of "publication_owners"
type publication_owners_aggregate {
  aggregate: publication_owners_aggregate_fields
  nodes: [publication_owners!]!
}

# aggregate fields of "publication_owners"
type publication_owners_aggregate_fields {
  avg: publication_owners_avg_fields
  count(columns: [publication_owners_select_column!], distinct: Boolean): Int
  max: publication_owners_max_fields
  min: publication_owners_min_fields
  stddev: publication_owners_stddev_fields
  stddev_pop: publication_owners_stddev_pop_fields
  stddev_samp: publication_owners_stddev_samp_fields
  sum: publication_owners_sum_fields
  var_pop: publication_owners_var_pop_fields
  var_samp: publication_owners_var_samp_fields
  variance: publication_owners_variance_fields
}

# order by aggregate values of table "publication_owners"
input publication_owners_aggregate_order_by {
  avg: publication_owners_avg_order_by
  count: order_by
  max: publication_owners_max_order_by
  min: publication_owners_min_order_by
  stddev: publication_owners_stddev_order_by
  stddev_pop: publication_owners_stddev_pop_order_by
  stddev_samp: publication_owners_stddev_samp_order_by
  sum: publication_owners_sum_order_by
  var_pop: publication_owners_var_pop_order_by
  var_samp: publication_owners_var_samp_order_by
  variance: publication_owners_variance_order_by
}

# input type for inserting array relation for remote table "publication_owners"
input publication_owners_arr_rel_insert_input {
  data: [publication_owners_insert_input!]!
}

# aggregate avg on columns
type publication_owners_avg_fields {
  owners: Float
  publication_mtid: Float
}

# order by avg() on columns of table "publication_owners"
input publication_owners_avg_order_by {
  owners: order_by
  publication_mtid: order_by
}

# Boolean expression to filter rows from the table "publication_owners". All fields are combined with a logical 'AND'.
input publication_owners_bool_exp {
  _and: [publication_owners_bool_exp]
  _not: publication_owners_bool_exp
  _or: [publication_owners_bool_exp]
  owners: bigint_comparison_exp
  publication_mtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_owners"
input publication_owners_inc_input {
  owners: bigint
  publication_mtid: bigint
}

# input type for inserting data into table "publication_owners"
input publication_owners_insert_input {
  owners: bigint
  publication_mtid: bigint
}

# aggregate max on columns
type publication_owners_max_fields {
  owners: bigint
  publication_mtid: bigint
}

# order by max() on columns of table "publication_owners"
input publication_owners_max_order_by {
  owners: order_by
  publication_mtid: order_by
}

# aggregate min on columns
type publication_owners_min_fields {
  owners: bigint
  publication_mtid: bigint
}

# order by min() on columns of table "publication_owners"
input publication_owners_min_order_by {
  owners: order_by
  publication_mtid: order_by
}

# response of any mutation on the table "publication_owners"
type publication_owners_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_owners!]!
}

# input type for inserting object relation for remote table "publication_owners"
input publication_owners_obj_rel_insert_input {
  data: publication_owners_insert_input!
}

# ordering options when selecting data from "publication_owners"
input publication_owners_order_by {
  owners: order_by
  publication_mtid: order_by
}

# select columns of table "publication_owners"
enum publication_owners_select_column {
  # column name
  owners

  # column name
  publication_mtid
}

# input type for updating data in table "publication_owners"
input publication_owners_set_input {
  owners: bigint
  publication_mtid: bigint
}

# aggregate stddev on columns
type publication_owners_stddev_fields {
  owners: Float
  publication_mtid: Float
}

# order by stddev() on columns of table "publication_owners"
input publication_owners_stddev_order_by {
  owners: order_by
  publication_mtid: order_by
}

# aggregate stddev_pop on columns
type publication_owners_stddev_pop_fields {
  owners: Float
  publication_mtid: Float
}

# order by stddev_pop() on columns of table "publication_owners"
input publication_owners_stddev_pop_order_by {
  owners: order_by
  publication_mtid: order_by
}

# aggregate stddev_samp on columns
type publication_owners_stddev_samp_fields {
  owners: Float
  publication_mtid: Float
}

# order by stddev_samp() on columns of table "publication_owners"
input publication_owners_stddev_samp_order_by {
  owners: order_by
  publication_mtid: order_by
}

# aggregate sum on columns
type publication_owners_sum_fields {
  owners: bigint
  publication_mtid: bigint
}

# order by sum() on columns of table "publication_owners"
input publication_owners_sum_order_by {
  owners: order_by
  publication_mtid: order_by
}

# aggregate var_pop on columns
type publication_owners_var_pop_fields {
  owners: Float
  publication_mtid: Float
}

# order by var_pop() on columns of table "publication_owners"
input publication_owners_var_pop_order_by {
  owners: order_by
  publication_mtid: order_by
}

# aggregate var_samp on columns
type publication_owners_var_samp_fields {
  owners: Float
  publication_mtid: Float
}

# order by var_samp() on columns of table "publication_owners"
input publication_owners_var_samp_order_by {
  owners: order_by
  publication_mtid: order_by
}

# aggregate variance on columns
type publication_owners_variance_fields {
  owners: Float
  publication_mtid: Float
}

# order by variance() on columns of table "publication_owners"
input publication_owners_variance_order_by {
  owners: order_by
  publication_mtid: order_by
}

# primary key columns input for table: "publication"
input publication_pk_columns_input {
  mtid: bigint!
}

# columns and relationships of "publication_published_at"
type publication_published_at {
  listPosition: Int

  # An object relationship
  location: location!
  publicationMtid: bigint!
  publishedAtMtid: bigint!
}

# aggregated selection of "publication_published_at"
type publication_published_at_aggregate {
  aggregate: publication_published_at_aggregate_fields
  nodes: [publication_published_at!]!
}

# aggregate fields of "publication_published_at"
type publication_published_at_aggregate_fields {
  avg: publication_published_at_avg_fields
  count(columns: [publication_published_at_select_column!], distinct: Boolean): Int
  max: publication_published_at_max_fields
  min: publication_published_at_min_fields
  stddev: publication_published_at_stddev_fields
  stddev_pop: publication_published_at_stddev_pop_fields
  stddev_samp: publication_published_at_stddev_samp_fields
  sum: publication_published_at_sum_fields
  var_pop: publication_published_at_var_pop_fields
  var_samp: publication_published_at_var_samp_fields
  variance: publication_published_at_variance_fields
}

# order by aggregate values of table "publication_published_at"
input publication_published_at_aggregate_order_by {
  avg: publication_published_at_avg_order_by
  count: order_by
  max: publication_published_at_max_order_by
  min: publication_published_at_min_order_by
  stddev: publication_published_at_stddev_order_by
  stddev_pop: publication_published_at_stddev_pop_order_by
  stddev_samp: publication_published_at_stddev_samp_order_by
  sum: publication_published_at_sum_order_by
  var_pop: publication_published_at_var_pop_order_by
  var_samp: publication_published_at_var_samp_order_by
  variance: publication_published_at_variance_order_by
}

# input type for inserting array relation for remote table "publication_published_at"
input publication_published_at_arr_rel_insert_input {
  data: [publication_published_at_insert_input!]!
}

# aggregate avg on columns
type publication_published_at_avg_fields {
  listPosition: Float
  publicationMtid: Float
  publishedAtMtid: Float
}

# order by avg() on columns of table "publication_published_at"
input publication_published_at_avg_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# Boolean expression to filter rows from the table "publication_published_at". All fields are combined with a logical 'AND'.
input publication_published_at_bool_exp {
  _and: [publication_published_at_bool_exp]
  _not: publication_published_at_bool_exp
  _or: [publication_published_at_bool_exp]
  listPosition: Int_comparison_exp
  location: location_bool_exp
  publicationMtid: bigint_comparison_exp
  publishedAtMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_published_at"
input publication_published_at_inc_input {
  listPosition: Int
  publicationMtid: bigint
  publishedAtMtid: bigint
}

# input type for inserting data into table "publication_published_at"
input publication_published_at_insert_input {
  listPosition: Int
  location: location_obj_rel_insert_input
  publicationMtid: bigint
  publishedAtMtid: bigint
}

# aggregate max on columns
type publication_published_at_max_fields {
  listPosition: Int
  publicationMtid: bigint
  publishedAtMtid: bigint
}

# order by max() on columns of table "publication_published_at"
input publication_published_at_max_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# aggregate min on columns
type publication_published_at_min_fields {
  listPosition: Int
  publicationMtid: bigint
  publishedAtMtid: bigint
}

# order by min() on columns of table "publication_published_at"
input publication_published_at_min_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# response of any mutation on the table "publication_published_at"
type publication_published_at_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_published_at!]!
}

# input type for inserting object relation for remote table "publication_published_at"
input publication_published_at_obj_rel_insert_input {
  data: publication_published_at_insert_input!
}

# ordering options when selecting data from "publication_published_at"
input publication_published_at_order_by {
  listPosition: order_by
  location: location_order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# select columns of table "publication_published_at"
enum publication_published_at_select_column {
  # column name
  listPosition

  # column name
  publicationMtid

  # column name
  publishedAtMtid
}

# input type for updating data in table "publication_published_at"
input publication_published_at_set_input {
  listPosition: Int
  publicationMtid: bigint
  publishedAtMtid: bigint
}

# aggregate stddev on columns
type publication_published_at_stddev_fields {
  listPosition: Float
  publicationMtid: Float
  publishedAtMtid: Float
}

# order by stddev() on columns of table "publication_published_at"
input publication_published_at_stddev_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# aggregate stddev_pop on columns
type publication_published_at_stddev_pop_fields {
  listPosition: Float
  publicationMtid: Float
  publishedAtMtid: Float
}

# order by stddev_pop() on columns of table "publication_published_at"
input publication_published_at_stddev_pop_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# aggregate stddev_samp on columns
type publication_published_at_stddev_samp_fields {
  listPosition: Float
  publicationMtid: Float
  publishedAtMtid: Float
}

# order by stddev_samp() on columns of table "publication_published_at"
input publication_published_at_stddev_samp_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# aggregate sum on columns
type publication_published_at_sum_fields {
  listPosition: Int
  publicationMtid: bigint
  publishedAtMtid: bigint
}

# order by sum() on columns of table "publication_published_at"
input publication_published_at_sum_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# aggregate var_pop on columns
type publication_published_at_var_pop_fields {
  listPosition: Float
  publicationMtid: Float
  publishedAtMtid: Float
}

# order by var_pop() on columns of table "publication_published_at"
input publication_published_at_var_pop_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# aggregate var_samp on columns
type publication_published_at_var_samp_fields {
  listPosition: Float
  publicationMtid: Float
  publishedAtMtid: Float
}

# order by var_samp() on columns of table "publication_published_at"
input publication_published_at_var_samp_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# aggregate variance on columns
type publication_published_at_variance_fields {
  listPosition: Float
  publicationMtid: Float
  publishedAtMtid: Float
}

# order by variance() on columns of table "publication_published_at"
input publication_published_at_variance_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishedAtMtid: order_by
}

# columns and relationships of "publication_publishers"
type publication_publishers {
  listPosition: Int
  publicationMtid: bigint!

  # An object relationship
  publisher: publisher!
  publishersMtid: bigint!
}

# aggregated selection of "publication_publishers"
type publication_publishers_aggregate {
  aggregate: publication_publishers_aggregate_fields
  nodes: [publication_publishers!]!
}

# aggregate fields of "publication_publishers"
type publication_publishers_aggregate_fields {
  avg: publication_publishers_avg_fields
  count(columns: [publication_publishers_select_column!], distinct: Boolean): Int
  max: publication_publishers_max_fields
  min: publication_publishers_min_fields
  stddev: publication_publishers_stddev_fields
  stddev_pop: publication_publishers_stddev_pop_fields
  stddev_samp: publication_publishers_stddev_samp_fields
  sum: publication_publishers_sum_fields
  var_pop: publication_publishers_var_pop_fields
  var_samp: publication_publishers_var_samp_fields
  variance: publication_publishers_variance_fields
}

# order by aggregate values of table "publication_publishers"
input publication_publishers_aggregate_order_by {
  avg: publication_publishers_avg_order_by
  count: order_by
  max: publication_publishers_max_order_by
  min: publication_publishers_min_order_by
  stddev: publication_publishers_stddev_order_by
  stddev_pop: publication_publishers_stddev_pop_order_by
  stddev_samp: publication_publishers_stddev_samp_order_by
  sum: publication_publishers_sum_order_by
  var_pop: publication_publishers_var_pop_order_by
  var_samp: publication_publishers_var_samp_order_by
  variance: publication_publishers_variance_order_by
}

# input type for inserting array relation for remote table "publication_publishers"
input publication_publishers_arr_rel_insert_input {
  data: [publication_publishers_insert_input!]!
}

# aggregate avg on columns
type publication_publishers_avg_fields {
  listPosition: Float
  publicationMtid: Float
  publishersMtid: Float
}

# order by avg() on columns of table "publication_publishers"
input publication_publishers_avg_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# Boolean expression to filter rows from the table "publication_publishers". All fields are combined with a logical 'AND'.
input publication_publishers_bool_exp {
  _and: [publication_publishers_bool_exp]
  _not: publication_publishers_bool_exp
  _or: [publication_publishers_bool_exp]
  listPosition: Int_comparison_exp
  publicationMtid: bigint_comparison_exp
  publisher: publisher_bool_exp
  publishersMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_publishers"
input publication_publishers_inc_input {
  listPosition: Int
  publicationMtid: bigint
  publishersMtid: bigint
}

# input type for inserting data into table "publication_publishers"
input publication_publishers_insert_input {
  listPosition: Int
  publicationMtid: bigint
  publisher: publisher_obj_rel_insert_input
  publishersMtid: bigint
}

# aggregate max on columns
type publication_publishers_max_fields {
  listPosition: Int
  publicationMtid: bigint
  publishersMtid: bigint
}

# order by max() on columns of table "publication_publishers"
input publication_publishers_max_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# aggregate min on columns
type publication_publishers_min_fields {
  listPosition: Int
  publicationMtid: bigint
  publishersMtid: bigint
}

# order by min() on columns of table "publication_publishers"
input publication_publishers_min_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# response of any mutation on the table "publication_publishers"
type publication_publishers_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_publishers!]!
}

# input type for inserting object relation for remote table "publication_publishers"
input publication_publishers_obj_rel_insert_input {
  data: publication_publishers_insert_input!
}

# ordering options when selecting data from "publication_publishers"
input publication_publishers_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publisher: publisher_order_by
  publishersMtid: order_by
}

# select columns of table "publication_publishers"
enum publication_publishers_select_column {
  # column name
  listPosition

  # column name
  publicationMtid

  # column name
  publishersMtid
}

# input type for updating data in table "publication_publishers"
input publication_publishers_set_input {
  listPosition: Int
  publicationMtid: bigint
  publishersMtid: bigint
}

# aggregate stddev on columns
type publication_publishers_stddev_fields {
  listPosition: Float
  publicationMtid: Float
  publishersMtid: Float
}

# order by stddev() on columns of table "publication_publishers"
input publication_publishers_stddev_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# aggregate stddev_pop on columns
type publication_publishers_stddev_pop_fields {
  listPosition: Float
  publicationMtid: Float
  publishersMtid: Float
}

# order by stddev_pop() on columns of table "publication_publishers"
input publication_publishers_stddev_pop_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# aggregate stddev_samp on columns
type publication_publishers_stddev_samp_fields {
  listPosition: Float
  publicationMtid: Float
  publishersMtid: Float
}

# order by stddev_samp() on columns of table "publication_publishers"
input publication_publishers_stddev_samp_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# aggregate sum on columns
type publication_publishers_sum_fields {
  listPosition: Int
  publicationMtid: bigint
  publishersMtid: bigint
}

# order by sum() on columns of table "publication_publishers"
input publication_publishers_sum_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# aggregate var_pop on columns
type publication_publishers_var_pop_fields {
  listPosition: Float
  publicationMtid: Float
  publishersMtid: Float
}

# order by var_pop() on columns of table "publication_publishers"
input publication_publishers_var_pop_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# aggregate var_samp on columns
type publication_publishers_var_samp_fields {
  listPosition: Float
  publicationMtid: Float
  publishersMtid: Float
}

# order by var_samp() on columns of table "publication_publishers"
input publication_publishers_var_samp_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# aggregate variance on columns
type publication_publishers_variance_fields {
  listPosition: Float
  publicationMtid: Float
  publishersMtid: Float
}

# order by variance() on columns of table "publication_publishers"
input publication_publishers_variance_order_by {
  listPosition: order_by
  publicationMtid: order_by
  publishersMtid: order_by
}

# columns and relationships of "publication_ratings"
type publication_ratings {
  publicationMtid: bigint!

  # An object relationship
  rating: rating!
  ratingsMtid: bigint!
}

# aggregated selection of "publication_ratings"
type publication_ratings_aggregate {
  aggregate: publication_ratings_aggregate_fields
  nodes: [publication_ratings!]!
}

# aggregate fields of "publication_ratings"
type publication_ratings_aggregate_fields {
  avg: publication_ratings_avg_fields
  count(columns: [publication_ratings_select_column!], distinct: Boolean): Int
  max: publication_ratings_max_fields
  min: publication_ratings_min_fields
  stddev: publication_ratings_stddev_fields
  stddev_pop: publication_ratings_stddev_pop_fields
  stddev_samp: publication_ratings_stddev_samp_fields
  sum: publication_ratings_sum_fields
  var_pop: publication_ratings_var_pop_fields
  var_samp: publication_ratings_var_samp_fields
  variance: publication_ratings_variance_fields
}

# order by aggregate values of table "publication_ratings"
input publication_ratings_aggregate_order_by {
  avg: publication_ratings_avg_order_by
  count: order_by
  max: publication_ratings_max_order_by
  min: publication_ratings_min_order_by
  stddev: publication_ratings_stddev_order_by
  stddev_pop: publication_ratings_stddev_pop_order_by
  stddev_samp: publication_ratings_stddev_samp_order_by
  sum: publication_ratings_sum_order_by
  var_pop: publication_ratings_var_pop_order_by
  var_samp: publication_ratings_var_samp_order_by
  variance: publication_ratings_variance_order_by
}

# input type for inserting array relation for remote table "publication_ratings"
input publication_ratings_arr_rel_insert_input {
  data: [publication_ratings_insert_input!]!
}

# aggregate avg on columns
type publication_ratings_avg_fields {
  publicationMtid: Float
  ratingsMtid: Float
}

# order by avg() on columns of table "publication_ratings"
input publication_ratings_avg_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# Boolean expression to filter rows from the table "publication_ratings". All fields are combined with a logical 'AND'.
input publication_ratings_bool_exp {
  _and: [publication_ratings_bool_exp]
  _not: publication_ratings_bool_exp
  _or: [publication_ratings_bool_exp]
  publicationMtid: bigint_comparison_exp
  rating: rating_bool_exp
  ratingsMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_ratings"
input publication_ratings_inc_input {
  publicationMtid: bigint
  ratingsMtid: bigint
}

# input type for inserting data into table "publication_ratings"
input publication_ratings_insert_input {
  publicationMtid: bigint
  rating: rating_obj_rel_insert_input
  ratingsMtid: bigint
}

# aggregate max on columns
type publication_ratings_max_fields {
  publicationMtid: bigint
  ratingsMtid: bigint
}

# order by max() on columns of table "publication_ratings"
input publication_ratings_max_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# aggregate min on columns
type publication_ratings_min_fields {
  publicationMtid: bigint
  ratingsMtid: bigint
}

# order by min() on columns of table "publication_ratings"
input publication_ratings_min_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# response of any mutation on the table "publication_ratings"
type publication_ratings_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_ratings!]!
}

# input type for inserting object relation for remote table "publication_ratings"
input publication_ratings_obj_rel_insert_input {
  data: publication_ratings_insert_input!
}

# ordering options when selecting data from "publication_ratings"
input publication_ratings_order_by {
  publicationMtid: order_by
  rating: rating_order_by
  ratingsMtid: order_by
}

# select columns of table "publication_ratings"
enum publication_ratings_select_column {
  # column name
  publicationMtid

  # column name
  ratingsMtid
}

# input type for updating data in table "publication_ratings"
input publication_ratings_set_input {
  publicationMtid: bigint
  ratingsMtid: bigint
}

# aggregate stddev on columns
type publication_ratings_stddev_fields {
  publicationMtid: Float
  ratingsMtid: Float
}

# order by stddev() on columns of table "publication_ratings"
input publication_ratings_stddev_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# aggregate stddev_pop on columns
type publication_ratings_stddev_pop_fields {
  publicationMtid: Float
  ratingsMtid: Float
}

# order by stddev_pop() on columns of table "publication_ratings"
input publication_ratings_stddev_pop_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# aggregate stddev_samp on columns
type publication_ratings_stddev_samp_fields {
  publicationMtid: Float
  ratingsMtid: Float
}

# order by stddev_samp() on columns of table "publication_ratings"
input publication_ratings_stddev_samp_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# aggregate sum on columns
type publication_ratings_sum_fields {
  publicationMtid: bigint
  ratingsMtid: bigint
}

# order by sum() on columns of table "publication_ratings"
input publication_ratings_sum_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# aggregate var_pop on columns
type publication_ratings_var_pop_fields {
  publicationMtid: Float
  ratingsMtid: Float
}

# order by var_pop() on columns of table "publication_ratings"
input publication_ratings_var_pop_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# aggregate var_samp on columns
type publication_ratings_var_samp_fields {
  publicationMtid: Float
  ratingsMtid: Float
}

# order by var_samp() on columns of table "publication_ratings"
input publication_ratings_var_samp_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# aggregate variance on columns
type publication_ratings_variance_fields {
  publicationMtid: Float
  ratingsMtid: Float
}

# order by variance() on columns of table "publication_ratings"
input publication_ratings_variance_order_by {
  publicationMtid: order_by
  ratingsMtid: order_by
}

# select columns of table "publication"
enum publication_select_column {
  # column name
  abstractText

  # column name
  acceptanceYear

  # column name
  adminApproved

  # column name
  adminApproverForSort

  # column name
  adminApproverMtid

  # column name
  altTitles

  # column name
  applicationYear

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorCount

  # column name
  bookMtid

  # column name
  bulkDuplumSearchDone

  # column name
  caseNumber

  # column name
  categoryForSort

  # column name
  categoryMtid

  # column name
  chapterCount

  # column name
  checked

  # column name
  checkerMtid

  # column name
  citation

  # column name
  citationCount

  # column name
  citationCountUnpublished

  # column name
  citationCountWoOther

  # column name
  citedCount

  # column name
  citedPubCount

  # column name
  citingPubCount

  # column name
  citingPubCountWoOther

  # column name
  collaboration

  # column name
  comment

  # column name
  comment2

  # column name
  conferenceMtid

  # column name
  conferencePublication

  # column name
  consultant

  # column name
  consultant2

  # column name
  consultantAuthor2Mtid

  # column name
  consultantAuthorMtid

  # column name
  contributorCount

  # column name
  core

  # column name
  countryMtid

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  description0

  # column name
  description1

  # column name
  description2

  # column name
  description3

  # column name
  description4

  # column name
  description5

  # column name
  digital

  # column name
  directInstituteCount

  # column name
  directInstitutesForSort

  # column name
  disciplineMtid

  # column name
  doiCitationCount

  # column name
  dtype

  # column name
  duplumKey

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  editionNumber

  # column name
  endDate

  # column name
  error

  # column name
  externalSource

  # column name
  firstAuthor

  # column name
  firstPage

  # column name
  firstPageOrInternalIdForSort

  # column name
  foreignEdition

  # column name
  foreignEditionCitationCount

  # column name
  foreignLanguage

  # column name
  fromCitation

  # column name
  fullPublication

  # column name
  group_mtid

  # column name
  hasCitationDuplums

  # column name
  ifRatingMtid

  # column name
  impactFactor

  # column name
  inSelectedPubs

  # column name
  independentCitCountWoOther

  # column name
  independentCitationCount

  # column name
  independentCitingPubCount

  # column name
  independentCitingPubCountWoOther

  # column name
  internalId

  # column name
  ipc

  # column name
  issue

  # column name
  journalForSort

  # column name
  journalMtid

  # column name
  journalName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  languagesForSort

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastPage

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mabDisciplineMtid

  # column name
  missingAuthor

  # column name
  mtid

  # column name
  nationalOrigin

  # column name
  nationalOriginCitationCount

  # column name
  number

  # column name
  oaByAuthorMtid

  # column name
  oaCheckDate

  # column name
  oaEmbargoDate

  # column name
  oaFree

  # column name
  oaLink

  # column name
  oaType

  # column name
  oaTypeDisp

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerAuthorCount

  # column name
  ownerInstituteCount

  # column name
  packet

  # column name
  pageLength

  # column name
  patentCountryMtid

  # column name
  prevValid

  # column name
  printed

  # column name
  pubStats

  # column name
  publicationPending

  # column name
  publishDate

  # column name
  published

  # column name
  publishedYear

  # column name
  publishedYearEnd

  # column name
  ratingsForSort

  # column name
  referenceList

  # column name
  refreshed

  # column name
  reviewer

  # column name
  school

  # column name
  scopusCitationCount

  # column name
  selfCitationCount

  # column name
  sourceOfData

  # column name
  sourceYear

  # column name
  startDate

  # column name
  status

  # column name
  subSubTypeMtid

  # column name
  subTitle

  # column name
  subTypeForSort

  # column name
  subTypeMtid

  # column name
  submissionNumber

  # column name
  submissionYear

  # column name
  tempLocked

  # column name
  tempLockerIdString

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  title

  # column name
  typeForSort

  # column name
  typeMtid

  # column name
  unhandledCitationCount

  # column name
  unhandledCitingPubCount

  # column name
  unhandledTickets

  # column name
  unprocessedData

  # column name
  userChangeableUntil

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  validated

  # column name
  validatorForSort

  # column name
  validatorMtid

  # column name
  volume

  # column name
  volumeNumber

  # column name
  volumeTitle

  # column name
  wosCitationCount
}

# input type for updating data in table "publication"
input publication_set_input {
  abstractText: String
  acceptanceYear: smallint
  adminApproved: timestamp
  adminApproverForSort: String
  adminApproverMtid: bigint
  altTitles: String
  applicationYear: smallint
  approved: timestamp
  approverMtid: bigint
  authorCount: Int
  bookMtid: bigint
  bulkDuplumSearchDone: Boolean
  caseNumber: String
  categoryForSort: String
  categoryMtid: bigint
  chapterCount: Int
  checked: timestamp
  checkerMtid: bigint
  citation: Boolean
  citationCount: Int
  citationCountUnpublished: Int
  citationCountWoOther: Int
  citedCount: Int
  citedPubCount: Int
  citingPubCount: Int
  citingPubCountWoOther: Int
  collaboration: Int
  comment: String
  comment2: String
  conferenceMtid: bigint
  conferencePublication: Boolean
  consultant: String
  consultant2: String
  consultantAuthor2Mtid: bigint
  consultantAuthorMtid: bigint
  contributorCount: Int
  core: Boolean
  countryMtid: bigint
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  description0: String
  description1: String
  description2: String
  description3: String
  description4: String
  description5: String
  digital: Boolean
  directInstituteCount: Int
  directInstitutesForSort: String
  disciplineMtid: bigint
  doiCitationCount: Int
  dtype: String
  duplumKey: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  editionNumber: Int
  endDate: date
  error: Int
  externalSource: String
  firstAuthor: String
  firstPage: String
  firstPageOrInternalIdForSort: String
  foreignEdition: Boolean
  foreignEditionCitationCount: Int
  foreignLanguage: Boolean
  fromCitation: Boolean
  fullPublication: Boolean
  group_mtid: bigint
  hasCitationDuplums: Boolean
  ifRatingMtid: bigint
  impactFactor: Float
  inSelectedPubs: String
  independentCitCountWoOther: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  independentCitingPubCountWoOther: Int
  internalId: String
  ipc: String
  issue: String
  journalForSort: String
  journalMtid: bigint
  journalName: String
  labelEng: String
  labelHun: String
  languagesForSort: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastPage: String
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mabDisciplineMtid: bigint
  missingAuthor: Boolean
  mtid: bigint
  nationalOrigin: Boolean
  nationalOriginCitationCount: Int
  number: String
  oaByAuthorMtid: bigint
  oaCheckDate: date
  oaEmbargoDate: date
  oaFree: Boolean
  oaLink: String
  oaType: Int
  oaTypeDisp: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerAuthorCount: Int
  ownerInstituteCount: Int
  packet: String
  pageLength: Int
  patentCountryMtid: bigint
  prevValid: bigint
  printed: Boolean
  pubStats: String
  publicationPending: Boolean
  publishDate: timestamp
  published: Boolean
  publishedYear: smallint
  publishedYearEnd: smallint
  ratingsForSort: Int
  referenceList: String
  refreshed: Boolean
  reviewer: String
  school: String
  scopusCitationCount: Int
  selfCitationCount: Int
  sourceOfData: String
  sourceYear: smallint
  startDate: date
  status: Int
  subSubTypeMtid: bigint
  subTitle: String
  subTypeForSort: String
  subTypeMtid: bigint
  submissionNumber: String
  submissionYear: smallint
  tempLocked: timestamp
  tempLockerIdString: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  typeForSort: String
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  unprocessedData: String
  userChangeableUntil: timestamp
  validFromYear: smallint
  validToYear: smallint
  validated: timestamp
  validatorForSort: String
  validatorMtid: bigint
  volume: String
  volumeNumber: String
  volumeTitle: String
  wosCitationCount: Int
}

# columns and relationships of "publication_source_type"
type publication_source_type {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mayHaveOa: Boolean
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "publication_source_type"
type publication_source_type_aggregate {
  aggregate: publication_source_type_aggregate_fields
  nodes: [publication_source_type!]!
}

# aggregate fields of "publication_source_type"
type publication_source_type_aggregate_fields {
  avg: publication_source_type_avg_fields
  count(columns: [publication_source_type_select_column!], distinct: Boolean): Int
  max: publication_source_type_max_fields
  min: publication_source_type_min_fields
  stddev: publication_source_type_stddev_fields
  stddev_pop: publication_source_type_stddev_pop_fields
  stddev_samp: publication_source_type_stddev_samp_fields
  sum: publication_source_type_sum_fields
  var_pop: publication_source_type_var_pop_fields
  var_samp: publication_source_type_var_samp_fields
  variance: publication_source_type_variance_fields
}

# order by aggregate values of table "publication_source_type"
input publication_source_type_aggregate_order_by {
  avg: publication_source_type_avg_order_by
  count: order_by
  max: publication_source_type_max_order_by
  min: publication_source_type_min_order_by
  stddev: publication_source_type_stddev_order_by
  stddev_pop: publication_source_type_stddev_pop_order_by
  stddev_samp: publication_source_type_stddev_samp_order_by
  sum: publication_source_type_sum_order_by
  var_pop: publication_source_type_var_pop_order_by
  var_samp: publication_source_type_var_samp_order_by
  variance: publication_source_type_variance_order_by
}

# input type for inserting array relation for remote table "publication_source_type"
input publication_source_type_arr_rel_insert_input {
  data: [publication_source_type_insert_input!]!
  on_conflict: publication_source_type_on_conflict
}

# aggregate avg on columns
type publication_source_type_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "publication_source_type"
input publication_source_type_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "publication_source_type". All fields are combined with a logical 'AND'.
input publication_source_type_bool_exp {
  _and: [publication_source_type_bool_exp]
  _not: publication_source_type_bool_exp
  _or: [publication_source_type_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  code: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mayHaveOa: Boolean_comparison_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "publication_source_type"
enum publication_source_type_constraint {
  # unique or primary key constraint
  publication_source_type_pkey
}

# input type for incrementing integer column in table "publication_source_type"
input publication_source_type_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "publication_source_type"
input publication_source_type_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mayHaveOa: Boolean
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type publication_source_type_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "publication_source_type"
input publication_source_type_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type publication_source_type_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "publication_source_type"
input publication_source_type_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "publication_source_type"
type publication_source_type_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_source_type!]!
}

# input type for inserting object relation for remote table "publication_source_type"
input publication_source_type_obj_rel_insert_input {
  data: publication_source_type_insert_input!
  on_conflict: publication_source_type_on_conflict
}

# on conflict condition type for table "publication_source_type"
input publication_source_type_on_conflict {
  constraint: publication_source_type_constraint!
  update_columns: [publication_source_type_update_column!]!
  where: publication_source_type_bool_exp
}

# ordering options when selecting data from "publication_source_type"
input publication_source_type_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mayHaveOa: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "publication_source_type"
input publication_source_type_pk_columns_input {
  mtid: bigint!
}

# select columns of table "publication_source_type"
enum publication_source_type_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mayHaveOa

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "publication_source_type"
input publication_source_type_set_input {
  approved: timestamp
  approverMtid: bigint
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mayHaveOa: Boolean
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type publication_source_type_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "publication_source_type"
input publication_source_type_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type publication_source_type_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "publication_source_type"
input publication_source_type_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type publication_source_type_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "publication_source_type"
input publication_source_type_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type publication_source_type_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "publication_source_type"
input publication_source_type_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "publication_source_type"
enum publication_source_type_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mayHaveOa

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type publication_source_type_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "publication_source_type"
input publication_source_type_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type publication_source_type_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "publication_source_type"
input publication_source_type_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type publication_source_type_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "publication_source_type"
input publication_source_type_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev on columns
type publication_stddev_fields {
  acceptanceYear: Float
  adminApproverMtid: Float
  applicationYear: Float
  approverMtid: Float
  authorCount: Float
  bookMtid: Float
  categoryMtid: Float
  chapterCount: Float
  checkerMtid: Float
  citationCount: Float
  citationCountUnpublished: Float
  citationCountWoOther: Float
  citedCount: Float
  citedPubCount: Float
  citingPubCount: Float
  citingPubCountWoOther: Float
  collaboration: Float
  conferenceMtid: Float
  consultantAuthor2Mtid: Float
  consultantAuthorMtid: Float
  contributorCount: Float
  countryMtid: Float
  creator: Float
  directInstituteCount: Float
  disciplineMtid: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  editionNumber: Float
  error: Float
  foreignEditionCitationCount: Float
  group_mtid: Float
  ifRatingMtid: Float
  impactFactor: Float
  independentCitCountWoOther: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  independentCitingPubCountWoOther: Float
  journalMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mabDisciplineMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oaByAuthorMtid: Float
  oaType: Float
  oaTypeDisp: Float
  oldId: Float
  ownerAuthorCount: Float
  ownerInstituteCount: Float
  pageLength: Float
  patentCountryMtid: Float
  prevValid: Float
  publishedYear: Float
  publishedYearEnd: Float
  ratingsForSort: Float
  scopusCitationCount: Float
  selfCitationCount: Float
  sourceYear: Float
  status: Float
  subSubTypeMtid: Float
  subTypeMtid: Float
  submissionYear: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
  wosCitationCount: Float
}

# order by stddev() on columns of table "publication"
input publication_stddev_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# aggregate stddev_pop on columns
type publication_stddev_pop_fields {
  acceptanceYear: Float
  adminApproverMtid: Float
  applicationYear: Float
  approverMtid: Float
  authorCount: Float
  bookMtid: Float
  categoryMtid: Float
  chapterCount: Float
  checkerMtid: Float
  citationCount: Float
  citationCountUnpublished: Float
  citationCountWoOther: Float
  citedCount: Float
  citedPubCount: Float
  citingPubCount: Float
  citingPubCountWoOther: Float
  collaboration: Float
  conferenceMtid: Float
  consultantAuthor2Mtid: Float
  consultantAuthorMtid: Float
  contributorCount: Float
  countryMtid: Float
  creator: Float
  directInstituteCount: Float
  disciplineMtid: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  editionNumber: Float
  error: Float
  foreignEditionCitationCount: Float
  group_mtid: Float
  ifRatingMtid: Float
  impactFactor: Float
  independentCitCountWoOther: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  independentCitingPubCountWoOther: Float
  journalMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mabDisciplineMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oaByAuthorMtid: Float
  oaType: Float
  oaTypeDisp: Float
  oldId: Float
  ownerAuthorCount: Float
  ownerInstituteCount: Float
  pageLength: Float
  patentCountryMtid: Float
  prevValid: Float
  publishedYear: Float
  publishedYearEnd: Float
  ratingsForSort: Float
  scopusCitationCount: Float
  selfCitationCount: Float
  sourceYear: Float
  status: Float
  subSubTypeMtid: Float
  subTypeMtid: Float
  submissionYear: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
  wosCitationCount: Float
}

# order by stddev_pop() on columns of table "publication"
input publication_stddev_pop_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# aggregate stddev_samp on columns
type publication_stddev_samp_fields {
  acceptanceYear: Float
  adminApproverMtid: Float
  applicationYear: Float
  approverMtid: Float
  authorCount: Float
  bookMtid: Float
  categoryMtid: Float
  chapterCount: Float
  checkerMtid: Float
  citationCount: Float
  citationCountUnpublished: Float
  citationCountWoOther: Float
  citedCount: Float
  citedPubCount: Float
  citingPubCount: Float
  citingPubCountWoOther: Float
  collaboration: Float
  conferenceMtid: Float
  consultantAuthor2Mtid: Float
  consultantAuthorMtid: Float
  contributorCount: Float
  countryMtid: Float
  creator: Float
  directInstituteCount: Float
  disciplineMtid: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  editionNumber: Float
  error: Float
  foreignEditionCitationCount: Float
  group_mtid: Float
  ifRatingMtid: Float
  impactFactor: Float
  independentCitCountWoOther: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  independentCitingPubCountWoOther: Float
  journalMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mabDisciplineMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oaByAuthorMtid: Float
  oaType: Float
  oaTypeDisp: Float
  oldId: Float
  ownerAuthorCount: Float
  ownerInstituteCount: Float
  pageLength: Float
  patentCountryMtid: Float
  prevValid: Float
  publishedYear: Float
  publishedYearEnd: Float
  ratingsForSort: Float
  scopusCitationCount: Float
  selfCitationCount: Float
  sourceYear: Float
  status: Float
  subSubTypeMtid: Float
  subTypeMtid: Float
  submissionYear: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
  wosCitationCount: Float
}

# order by stddev_samp() on columns of table "publication"
input publication_stddev_samp_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# columns and relationships of "publication_subjects"
type publication_subjects {
  # An object relationship
  classification: classification!
  publicationMtid: bigint!
  subjectsMtid: bigint!
}

# aggregated selection of "publication_subjects"
type publication_subjects_aggregate {
  aggregate: publication_subjects_aggregate_fields
  nodes: [publication_subjects!]!
}

# aggregate fields of "publication_subjects"
type publication_subjects_aggregate_fields {
  avg: publication_subjects_avg_fields
  count(columns: [publication_subjects_select_column!], distinct: Boolean): Int
  max: publication_subjects_max_fields
  min: publication_subjects_min_fields
  stddev: publication_subjects_stddev_fields
  stddev_pop: publication_subjects_stddev_pop_fields
  stddev_samp: publication_subjects_stddev_samp_fields
  sum: publication_subjects_sum_fields
  var_pop: publication_subjects_var_pop_fields
  var_samp: publication_subjects_var_samp_fields
  variance: publication_subjects_variance_fields
}

# order by aggregate values of table "publication_subjects"
input publication_subjects_aggregate_order_by {
  avg: publication_subjects_avg_order_by
  count: order_by
  max: publication_subjects_max_order_by
  min: publication_subjects_min_order_by
  stddev: publication_subjects_stddev_order_by
  stddev_pop: publication_subjects_stddev_pop_order_by
  stddev_samp: publication_subjects_stddev_samp_order_by
  sum: publication_subjects_sum_order_by
  var_pop: publication_subjects_var_pop_order_by
  var_samp: publication_subjects_var_samp_order_by
  variance: publication_subjects_variance_order_by
}

# input type for inserting array relation for remote table "publication_subjects"
input publication_subjects_arr_rel_insert_input {
  data: [publication_subjects_insert_input!]!
}

# aggregate avg on columns
type publication_subjects_avg_fields {
  publicationMtid: Float
  subjectsMtid: Float
}

# order by avg() on columns of table "publication_subjects"
input publication_subjects_avg_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# Boolean expression to filter rows from the table "publication_subjects". All fields are combined with a logical 'AND'.
input publication_subjects_bool_exp {
  _and: [publication_subjects_bool_exp]
  _not: publication_subjects_bool_exp
  _or: [publication_subjects_bool_exp]
  classification: classification_bool_exp
  publicationMtid: bigint_comparison_exp
  subjectsMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publication_subjects"
input publication_subjects_inc_input {
  publicationMtid: bigint
  subjectsMtid: bigint
}

# input type for inserting data into table "publication_subjects"
input publication_subjects_insert_input {
  classification: classification_obj_rel_insert_input
  publicationMtid: bigint
  subjectsMtid: bigint
}

# aggregate max on columns
type publication_subjects_max_fields {
  publicationMtid: bigint
  subjectsMtid: bigint
}

# order by max() on columns of table "publication_subjects"
input publication_subjects_max_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate min on columns
type publication_subjects_min_fields {
  publicationMtid: bigint
  subjectsMtid: bigint
}

# order by min() on columns of table "publication_subjects"
input publication_subjects_min_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# response of any mutation on the table "publication_subjects"
type publication_subjects_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_subjects!]!
}

# input type for inserting object relation for remote table "publication_subjects"
input publication_subjects_obj_rel_insert_input {
  data: publication_subjects_insert_input!
}

# ordering options when selecting data from "publication_subjects"
input publication_subjects_order_by {
  classification: classification_order_by
  publicationMtid: order_by
  subjectsMtid: order_by
}

# select columns of table "publication_subjects"
enum publication_subjects_select_column {
  # column name
  publicationMtid

  # column name
  subjectsMtid
}

# input type for updating data in table "publication_subjects"
input publication_subjects_set_input {
  publicationMtid: bigint
  subjectsMtid: bigint
}

# aggregate stddev on columns
type publication_subjects_stddev_fields {
  publicationMtid: Float
  subjectsMtid: Float
}

# order by stddev() on columns of table "publication_subjects"
input publication_subjects_stddev_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate stddev_pop on columns
type publication_subjects_stddev_pop_fields {
  publicationMtid: Float
  subjectsMtid: Float
}

# order by stddev_pop() on columns of table "publication_subjects"
input publication_subjects_stddev_pop_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate stddev_samp on columns
type publication_subjects_stddev_samp_fields {
  publicationMtid: Float
  subjectsMtid: Float
}

# order by stddev_samp() on columns of table "publication_subjects"
input publication_subjects_stddev_samp_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate sum on columns
type publication_subjects_sum_fields {
  publicationMtid: bigint
  subjectsMtid: bigint
}

# order by sum() on columns of table "publication_subjects"
input publication_subjects_sum_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate var_pop on columns
type publication_subjects_var_pop_fields {
  publicationMtid: Float
  subjectsMtid: Float
}

# order by var_pop() on columns of table "publication_subjects"
input publication_subjects_var_pop_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate var_samp on columns
type publication_subjects_var_samp_fields {
  publicationMtid: Float
  subjectsMtid: Float
}

# order by var_samp() on columns of table "publication_subjects"
input publication_subjects_var_samp_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate variance on columns
type publication_subjects_variance_fields {
  publicationMtid: Float
  subjectsMtid: Float
}

# order by variance() on columns of table "publication_subjects"
input publication_subjects_variance_order_by {
  publicationMtid: order_by
  subjectsMtid: order_by
}

# aggregate sum on columns
type publication_sum_fields {
  acceptanceYear: smallint
  adminApproverMtid: bigint
  applicationYear: smallint
  approverMtid: bigint
  authorCount: Int
  bookMtid: bigint
  categoryMtid: bigint
  chapterCount: Int
  checkerMtid: bigint
  citationCount: Int
  citationCountUnpublished: Int
  citationCountWoOther: Int
  citedCount: Int
  citedPubCount: Int
  citingPubCount: Int
  citingPubCountWoOther: Int
  collaboration: Int
  conferenceMtid: bigint
  consultantAuthor2Mtid: bigint
  consultantAuthorMtid: bigint
  contributorCount: Int
  countryMtid: bigint
  creator: bigint
  directInstituteCount: Int
  disciplineMtid: bigint
  doiCitationCount: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  editionNumber: Int
  error: Int
  foreignEditionCitationCount: Int
  group_mtid: bigint
  ifRatingMtid: bigint
  impactFactor: Float
  independentCitCountWoOther: Int
  independentCitationCount: Int
  independentCitingPubCount: Int
  independentCitingPubCountWoOther: Int
  journalMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mabDisciplineMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  oaByAuthorMtid: bigint
  oaType: Int
  oaTypeDisp: Int
  oldId: Int
  ownerAuthorCount: Int
  ownerInstituteCount: Int
  pageLength: Int
  patentCountryMtid: bigint
  prevValid: bigint
  publishedYear: smallint
  publishedYearEnd: smallint
  ratingsForSort: Int
  scopusCitationCount: Int
  selfCitationCount: Int
  sourceYear: smallint
  status: Int
  subSubTypeMtid: bigint
  subTypeMtid: bigint
  submissionYear: smallint
  typeMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  validatorMtid: bigint
  wosCitationCount: Int
}

# order by sum() on columns of table "publication"
input publication_sum_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# columns and relationships of "publication_type"
type publication_type {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An array relationship
  categories(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): [category_types_allowed!]!

  # An aggregated array relationship
  categories_aggregate(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): category_types_allowed_aggregate!
  code: Int!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean!
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  risExportName: String
  shortName: String
  status: Int

  # An array relationship
  subTypes(
    # distinct select on columns
    distinct_on: [sub_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [sub_type_order_by!]

    # filter the rows returned
    where: sub_type_bool_exp
  ): [sub_type!]!

  # An aggregated array relationship
  subTypes_aggregate(
    # distinct select on columns
    distinct_on: [sub_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [sub_type_order_by!]

    # filter the rows returned
    where: sub_type_bool_exp
  ): sub_type_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "publication_type"
type publication_type_aggregate {
  aggregate: publication_type_aggregate_fields
  nodes: [publication_type!]!
}

# aggregate fields of "publication_type"
type publication_type_aggregate_fields {
  avg: publication_type_avg_fields
  count(columns: [publication_type_select_column!], distinct: Boolean): Int
  max: publication_type_max_fields
  min: publication_type_min_fields
  stddev: publication_type_stddev_fields
  stddev_pop: publication_type_stddev_pop_fields
  stddev_samp: publication_type_stddev_samp_fields
  sum: publication_type_sum_fields
  var_pop: publication_type_var_pop_fields
  var_samp: publication_type_var_samp_fields
  variance: publication_type_variance_fields
}

# order by aggregate values of table "publication_type"
input publication_type_aggregate_order_by {
  avg: publication_type_avg_order_by
  count: order_by
  max: publication_type_max_order_by
  min: publication_type_min_order_by
  stddev: publication_type_stddev_order_by
  stddev_pop: publication_type_stddev_pop_order_by
  stddev_samp: publication_type_stddev_samp_order_by
  sum: publication_type_sum_order_by
  var_pop: publication_type_var_pop_order_by
  var_samp: publication_type_var_samp_order_by
  variance: publication_type_variance_order_by
}

# input type for inserting array relation for remote table "publication_type"
input publication_type_arr_rel_insert_input {
  data: [publication_type_insert_input!]!
  on_conflict: publication_type_on_conflict
}

# aggregate avg on columns
type publication_type_avg_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "publication_type"
input publication_type_avg_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "publication_type". All fields are combined with a logical 'AND'.
input publication_type_bool_exp {
  _and: [publication_type_bool_exp]
  _not: publication_type_bool_exp
  _or: [publication_type_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  categories: category_types_allowed_bool_exp
  code: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  excludeFromOaStats: Boolean_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  otypeName: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  risExportName: String_comparison_exp
  shortName: String_comparison_exp
  status: Int_comparison_exp
  subTypes: sub_type_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "publication_type"
enum publication_type_constraint {
  # unique or primary key constraint
  publication_type_pkey
}

# input type for incrementing integer column in table "publication_type"
input publication_type_inc_input {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "publication_type"
input publication_type_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  categories: category_types_allowed_arr_rel_insert_input
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  risExportName: String
  shortName: String
  status: Int
  subTypes: sub_type_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type publication_type_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  risExportName: String
  shortName: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "publication_type"
input publication_type_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  otypeName: order_by
  prevValid: order_by
  risExportName: order_by
  shortName: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type publication_type_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  risExportName: String
  shortName: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "publication_type"
input publication_type_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  otypeName: order_by
  prevValid: order_by
  risExportName: order_by
  shortName: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "publication_type"
type publication_type_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publication_type!]!
}

# input type for inserting object relation for remote table "publication_type"
input publication_type_obj_rel_insert_input {
  data: publication_type_insert_input!
  on_conflict: publication_type_on_conflict
}

# on conflict condition type for table "publication_type"
input publication_type_on_conflict {
  constraint: publication_type_constraint!
  update_columns: [publication_type_update_column!]!
  where: publication_type_bool_exp
}

# ordering options when selecting data from "publication_type"
input publication_type_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  categories_aggregate: category_types_allowed_aggregate_order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  excludeFromOaStats: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  otypeName: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  risExportName: order_by
  shortName: order_by
  status: order_by
  subTypes_aggregate: sub_type_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "publication_type"
input publication_type_pk_columns_input {
  mtid: bigint!
}

# select columns of table "publication_type"
enum publication_type_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  excludeFromOaStats

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  otypeName

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  risExportName

  # column name
  shortName

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "publication_type"
input publication_type_set_input {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  otypeName: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  risExportName: String
  shortName: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type publication_type_stddev_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "publication_type"
input publication_type_stddev_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type publication_type_stddev_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "publication_type"
input publication_type_stddev_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type publication_type_stddev_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "publication_type"
input publication_type_stddev_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type publication_type_sum_fields {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "publication_type"
input publication_type_sum_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "publication_type"
enum publication_type_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  excludeFromOaStats

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  otypeName

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  risExportName

  # column name
  shortName

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type publication_type_var_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "publication_type"
input publication_type_var_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type publication_type_var_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "publication_type"
input publication_type_var_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type publication_type_variance_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "publication_type"
input publication_type_variance_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "publication"
enum publication_update_column {
  # column name
  abstractText

  # column name
  acceptanceYear

  # column name
  adminApproved

  # column name
  adminApproverForSort

  # column name
  adminApproverMtid

  # column name
  altTitles

  # column name
  applicationYear

  # column name
  approved

  # column name
  approverMtid

  # column name
  authorCount

  # column name
  bookMtid

  # column name
  bulkDuplumSearchDone

  # column name
  caseNumber

  # column name
  categoryForSort

  # column name
  categoryMtid

  # column name
  chapterCount

  # column name
  checked

  # column name
  checkerMtid

  # column name
  citation

  # column name
  citationCount

  # column name
  citationCountUnpublished

  # column name
  citationCountWoOther

  # column name
  citedCount

  # column name
  citedPubCount

  # column name
  citingPubCount

  # column name
  citingPubCountWoOther

  # column name
  collaboration

  # column name
  comment

  # column name
  comment2

  # column name
  conferenceMtid

  # column name
  conferencePublication

  # column name
  consultant

  # column name
  consultant2

  # column name
  consultantAuthor2Mtid

  # column name
  consultantAuthorMtid

  # column name
  contributorCount

  # column name
  core

  # column name
  countryMtid

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  description0

  # column name
  description1

  # column name
  description2

  # column name
  description3

  # column name
  description4

  # column name
  description5

  # column name
  digital

  # column name
  directInstituteCount

  # column name
  directInstitutesForSort

  # column name
  disciplineMtid

  # column name
  doiCitationCount

  # column name
  dtype

  # column name
  duplumKey

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  editionNumber

  # column name
  endDate

  # column name
  error

  # column name
  externalSource

  # column name
  firstAuthor

  # column name
  firstPage

  # column name
  firstPageOrInternalIdForSort

  # column name
  foreignEdition

  # column name
  foreignEditionCitationCount

  # column name
  foreignLanguage

  # column name
  fromCitation

  # column name
  fullPublication

  # column name
  group_mtid

  # column name
  hasCitationDuplums

  # column name
  ifRatingMtid

  # column name
  impactFactor

  # column name
  inSelectedPubs

  # column name
  independentCitCountWoOther

  # column name
  independentCitationCount

  # column name
  independentCitingPubCount

  # column name
  independentCitingPubCountWoOther

  # column name
  internalId

  # column name
  ipc

  # column name
  issue

  # column name
  journalForSort

  # column name
  journalMtid

  # column name
  journalName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  languagesForSort

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastPage

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mabDisciplineMtid

  # column name
  missingAuthor

  # column name
  mtid

  # column name
  nationalOrigin

  # column name
  nationalOriginCitationCount

  # column name
  number

  # column name
  oaByAuthorMtid

  # column name
  oaCheckDate

  # column name
  oaEmbargoDate

  # column name
  oaFree

  # column name
  oaLink

  # column name
  oaType

  # column name
  oaTypeDisp

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerAuthorCount

  # column name
  ownerInstituteCount

  # column name
  packet

  # column name
  pageLength

  # column name
  patentCountryMtid

  # column name
  prevValid

  # column name
  printed

  # column name
  pubStats

  # column name
  publicationPending

  # column name
  publishDate

  # column name
  published

  # column name
  publishedYear

  # column name
  publishedYearEnd

  # column name
  ratingsForSort

  # column name
  referenceList

  # column name
  refreshed

  # column name
  reviewer

  # column name
  school

  # column name
  scopusCitationCount

  # column name
  selfCitationCount

  # column name
  sourceOfData

  # column name
  sourceYear

  # column name
  startDate

  # column name
  status

  # column name
  subSubTypeMtid

  # column name
  subTitle

  # column name
  subTypeForSort

  # column name
  subTypeMtid

  # column name
  submissionNumber

  # column name
  submissionYear

  # column name
  tempLocked

  # column name
  tempLockerIdString

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  title

  # column name
  typeForSort

  # column name
  typeMtid

  # column name
  unhandledCitationCount

  # column name
  unhandledCitingPubCount

  # column name
  unhandledTickets

  # column name
  unprocessedData

  # column name
  userChangeableUntil

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  validated

  # column name
  validatorForSort

  # column name
  validatorMtid

  # column name
  volume

  # column name
  volumeNumber

  # column name
  volumeTitle

  # column name
  wosCitationCount
}

# aggregate var_pop on columns
type publication_var_pop_fields {
  acceptanceYear: Float
  adminApproverMtid: Float
  applicationYear: Float
  approverMtid: Float
  authorCount: Float
  bookMtid: Float
  categoryMtid: Float
  chapterCount: Float
  checkerMtid: Float
  citationCount: Float
  citationCountUnpublished: Float
  citationCountWoOther: Float
  citedCount: Float
  citedPubCount: Float
  citingPubCount: Float
  citingPubCountWoOther: Float
  collaboration: Float
  conferenceMtid: Float
  consultantAuthor2Mtid: Float
  consultantAuthorMtid: Float
  contributorCount: Float
  countryMtid: Float
  creator: Float
  directInstituteCount: Float
  disciplineMtid: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  editionNumber: Float
  error: Float
  foreignEditionCitationCount: Float
  group_mtid: Float
  ifRatingMtid: Float
  impactFactor: Float
  independentCitCountWoOther: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  independentCitingPubCountWoOther: Float
  journalMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mabDisciplineMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oaByAuthorMtid: Float
  oaType: Float
  oaTypeDisp: Float
  oldId: Float
  ownerAuthorCount: Float
  ownerInstituteCount: Float
  pageLength: Float
  patentCountryMtid: Float
  prevValid: Float
  publishedYear: Float
  publishedYearEnd: Float
  ratingsForSort: Float
  scopusCitationCount: Float
  selfCitationCount: Float
  sourceYear: Float
  status: Float
  subSubTypeMtid: Float
  subTypeMtid: Float
  submissionYear: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
  wosCitationCount: Float
}

# order by var_pop() on columns of table "publication"
input publication_var_pop_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# aggregate var_samp on columns
type publication_var_samp_fields {
  acceptanceYear: Float
  adminApproverMtid: Float
  applicationYear: Float
  approverMtid: Float
  authorCount: Float
  bookMtid: Float
  categoryMtid: Float
  chapterCount: Float
  checkerMtid: Float
  citationCount: Float
  citationCountUnpublished: Float
  citationCountWoOther: Float
  citedCount: Float
  citedPubCount: Float
  citingPubCount: Float
  citingPubCountWoOther: Float
  collaboration: Float
  conferenceMtid: Float
  consultantAuthor2Mtid: Float
  consultantAuthorMtid: Float
  contributorCount: Float
  countryMtid: Float
  creator: Float
  directInstituteCount: Float
  disciplineMtid: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  editionNumber: Float
  error: Float
  foreignEditionCitationCount: Float
  group_mtid: Float
  ifRatingMtid: Float
  impactFactor: Float
  independentCitCountWoOther: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  independentCitingPubCountWoOther: Float
  journalMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mabDisciplineMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oaByAuthorMtid: Float
  oaType: Float
  oaTypeDisp: Float
  oldId: Float
  ownerAuthorCount: Float
  ownerInstituteCount: Float
  pageLength: Float
  patentCountryMtid: Float
  prevValid: Float
  publishedYear: Float
  publishedYearEnd: Float
  ratingsForSort: Float
  scopusCitationCount: Float
  selfCitationCount: Float
  sourceYear: Float
  status: Float
  subSubTypeMtid: Float
  subTypeMtid: Float
  submissionYear: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
  wosCitationCount: Float
}

# order by var_samp() on columns of table "publication"
input publication_var_samp_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# aggregate variance on columns
type publication_variance_fields {
  acceptanceYear: Float
  adminApproverMtid: Float
  applicationYear: Float
  approverMtid: Float
  authorCount: Float
  bookMtid: Float
  categoryMtid: Float
  chapterCount: Float
  checkerMtid: Float
  citationCount: Float
  citationCountUnpublished: Float
  citationCountWoOther: Float
  citedCount: Float
  citedPubCount: Float
  citingPubCount: Float
  citingPubCountWoOther: Float
  collaboration: Float
  conferenceMtid: Float
  consultantAuthor2Mtid: Float
  consultantAuthorMtid: Float
  contributorCount: Float
  countryMtid: Float
  creator: Float
  directInstituteCount: Float
  disciplineMtid: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  editionNumber: Float
  error: Float
  foreignEditionCitationCount: Float
  group_mtid: Float
  ifRatingMtid: Float
  impactFactor: Float
  independentCitCountWoOther: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  independentCitingPubCountWoOther: Float
  journalMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mabDisciplineMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oaByAuthorMtid: Float
  oaType: Float
  oaTypeDisp: Float
  oldId: Float
  ownerAuthorCount: Float
  ownerInstituteCount: Float
  pageLength: Float
  patentCountryMtid: Float
  prevValid: Float
  publishedYear: Float
  publishedYearEnd: Float
  ratingsForSort: Float
  scopusCitationCount: Float
  selfCitationCount: Float
  sourceYear: Float
  status: Float
  subSubTypeMtid: Float
  subTypeMtid: Float
  submissionYear: Float
  typeMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  validatorMtid: Float
  wosCitationCount: Float
}

# order by variance() on columns of table "publication"
input publication_variance_order_by {
  acceptanceYear: order_by
  adminApproverMtid: order_by
  applicationYear: order_by
  approverMtid: order_by
  authorCount: order_by
  bookMtid: order_by
  categoryMtid: order_by
  chapterCount: order_by
  checkerMtid: order_by
  citationCount: order_by
  citationCountUnpublished: order_by
  citationCountWoOther: order_by
  citedCount: order_by
  citedPubCount: order_by
  citingPubCount: order_by
  citingPubCountWoOther: order_by
  collaboration: order_by
  conferenceMtid: order_by
  consultantAuthor2Mtid: order_by
  consultantAuthorMtid: order_by
  contributorCount: order_by
  countryMtid: order_by
  creator: order_by
  directInstituteCount: order_by
  disciplineMtid: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  editionNumber: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  group_mtid: order_by
  ifRatingMtid: order_by
  impactFactor: order_by
  independentCitCountWoOther: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  independentCitingPubCountWoOther: order_by
  journalMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mabDisciplineMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oaByAuthorMtid: order_by
  oaType: order_by
  oaTypeDisp: order_by
  oldId: order_by
  ownerAuthorCount: order_by
  ownerInstituteCount: order_by
  pageLength: order_by
  patentCountryMtid: order_by
  prevValid: order_by
  publishedYear: order_by
  publishedYearEnd: order_by
  ratingsForSort: order_by
  scopusCitationCount: order_by
  selfCitationCount: order_by
  sourceYear: order_by
  status: order_by
  subSubTypeMtid: order_by
  subTypeMtid: order_by
  submissionYear: order_by
  typeMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  validatorMtid: order_by
  wosCitationCount: order_by
}

# columns and relationships of "publisher"
type publisher {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An array relationship
  cities(
    # distinct select on columns
    distinct_on: [publisher_cities_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_cities_order_by!]

    # filter the rows returned
    where: publisher_cities_bool_exp
  ): [publisher_cities!]!

  # An aggregated array relationship
  cities_aggregate(
    # distinct select on columns
    distinct_on: [publisher_cities_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_cities_order_by!]

    # filter the rows returned
    where: publisher_cities_bool_exp
  ): publisher_cities_aggregate!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  fromCitation: Boolean!

  # An object relationship
  institute: organization
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  organization: Boolean!
  otype: String
  predator: Int
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "publisher"
type publisher_aggregate {
  aggregate: publisher_aggregate_fields
  nodes: [publisher!]!
}

# aggregate fields of "publisher"
type publisher_aggregate_fields {
  avg: publisher_avg_fields
  count(columns: [publisher_select_column!], distinct: Boolean): Int
  max: publisher_max_fields
  min: publisher_min_fields
  stddev: publisher_stddev_fields
  stddev_pop: publisher_stddev_pop_fields
  stddev_samp: publisher_stddev_samp_fields
  sum: publisher_sum_fields
  var_pop: publisher_var_pop_fields
  var_samp: publisher_var_samp_fields
  variance: publisher_variance_fields
}

# order by aggregate values of table "publisher"
input publisher_aggregate_order_by {
  avg: publisher_avg_order_by
  count: order_by
  max: publisher_max_order_by
  min: publisher_min_order_by
  stddev: publisher_stddev_order_by
  stddev_pop: publisher_stddev_pop_order_by
  stddev_samp: publisher_stddev_samp_order_by
  sum: publisher_sum_order_by
  var_pop: publisher_var_pop_order_by
  var_samp: publisher_var_samp_order_by
  variance: publisher_variance_order_by
}

# input type for inserting array relation for remote table "publisher"
input publisher_arr_rel_insert_input {
  data: [publisher_insert_input!]!
  on_conflict: publisher_on_conflict
}

# aggregate avg on columns
type publisher_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  openAccess: Float
  predator: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "publisher"
input publisher_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "publisher". All fields are combined with a logical 'AND'.
input publisher_bool_exp {
  _and: [publisher_bool_exp]
  _not: publisher_bool_exp
  _or: [publisher_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  cities: publisher_cities_bool_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  fromCitation: Boolean_comparison_exp
  institute: organization_bool_exp
  instituteMtid: bigint_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oaType: Int_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  openAccess: Int_comparison_exp
  organization: Boolean_comparison_exp
  otype: String_comparison_exp
  predator: Int_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  url: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# columns and relationships of "publisher_cities"
type publisher_cities {
  citiesMtid: bigint!

  # An object relationship
  location: location!
  publisherMtid: bigint!
}

# aggregated selection of "publisher_cities"
type publisher_cities_aggregate {
  aggregate: publisher_cities_aggregate_fields
  nodes: [publisher_cities!]!
}

# aggregate fields of "publisher_cities"
type publisher_cities_aggregate_fields {
  avg: publisher_cities_avg_fields
  count(columns: [publisher_cities_select_column!], distinct: Boolean): Int
  max: publisher_cities_max_fields
  min: publisher_cities_min_fields
  stddev: publisher_cities_stddev_fields
  stddev_pop: publisher_cities_stddev_pop_fields
  stddev_samp: publisher_cities_stddev_samp_fields
  sum: publisher_cities_sum_fields
  var_pop: publisher_cities_var_pop_fields
  var_samp: publisher_cities_var_samp_fields
  variance: publisher_cities_variance_fields
}

# order by aggregate values of table "publisher_cities"
input publisher_cities_aggregate_order_by {
  avg: publisher_cities_avg_order_by
  count: order_by
  max: publisher_cities_max_order_by
  min: publisher_cities_min_order_by
  stddev: publisher_cities_stddev_order_by
  stddev_pop: publisher_cities_stddev_pop_order_by
  stddev_samp: publisher_cities_stddev_samp_order_by
  sum: publisher_cities_sum_order_by
  var_pop: publisher_cities_var_pop_order_by
  var_samp: publisher_cities_var_samp_order_by
  variance: publisher_cities_variance_order_by
}

# input type for inserting array relation for remote table "publisher_cities"
input publisher_cities_arr_rel_insert_input {
  data: [publisher_cities_insert_input!]!
}

# aggregate avg on columns
type publisher_cities_avg_fields {
  citiesMtid: Float
  publisherMtid: Float
}

# order by avg() on columns of table "publisher_cities"
input publisher_cities_avg_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# Boolean expression to filter rows from the table "publisher_cities". All fields are combined with a logical 'AND'.
input publisher_cities_bool_exp {
  _and: [publisher_cities_bool_exp]
  _not: publisher_cities_bool_exp
  _or: [publisher_cities_bool_exp]
  citiesMtid: bigint_comparison_exp
  location: location_bool_exp
  publisherMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "publisher_cities"
input publisher_cities_inc_input {
  citiesMtid: bigint
  publisherMtid: bigint
}

# input type for inserting data into table "publisher_cities"
input publisher_cities_insert_input {
  citiesMtid: bigint
  location: location_obj_rel_insert_input
  publisherMtid: bigint
}

# aggregate max on columns
type publisher_cities_max_fields {
  citiesMtid: bigint
  publisherMtid: bigint
}

# order by max() on columns of table "publisher_cities"
input publisher_cities_max_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# aggregate min on columns
type publisher_cities_min_fields {
  citiesMtid: bigint
  publisherMtid: bigint
}

# order by min() on columns of table "publisher_cities"
input publisher_cities_min_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# response of any mutation on the table "publisher_cities"
type publisher_cities_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publisher_cities!]!
}

# input type for inserting object relation for remote table "publisher_cities"
input publisher_cities_obj_rel_insert_input {
  data: publisher_cities_insert_input!
}

# ordering options when selecting data from "publisher_cities"
input publisher_cities_order_by {
  citiesMtid: order_by
  location: location_order_by
  publisherMtid: order_by
}

# select columns of table "publisher_cities"
enum publisher_cities_select_column {
  # column name
  citiesMtid

  # column name
  publisherMtid
}

# input type for updating data in table "publisher_cities"
input publisher_cities_set_input {
  citiesMtid: bigint
  publisherMtid: bigint
}

# aggregate stddev on columns
type publisher_cities_stddev_fields {
  citiesMtid: Float
  publisherMtid: Float
}

# order by stddev() on columns of table "publisher_cities"
input publisher_cities_stddev_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# aggregate stddev_pop on columns
type publisher_cities_stddev_pop_fields {
  citiesMtid: Float
  publisherMtid: Float
}

# order by stddev_pop() on columns of table "publisher_cities"
input publisher_cities_stddev_pop_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# aggregate stddev_samp on columns
type publisher_cities_stddev_samp_fields {
  citiesMtid: Float
  publisherMtid: Float
}

# order by stddev_samp() on columns of table "publisher_cities"
input publisher_cities_stddev_samp_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# aggregate sum on columns
type publisher_cities_sum_fields {
  citiesMtid: bigint
  publisherMtid: bigint
}

# order by sum() on columns of table "publisher_cities"
input publisher_cities_sum_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# aggregate var_pop on columns
type publisher_cities_var_pop_fields {
  citiesMtid: Float
  publisherMtid: Float
}

# order by var_pop() on columns of table "publisher_cities"
input publisher_cities_var_pop_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# aggregate var_samp on columns
type publisher_cities_var_samp_fields {
  citiesMtid: Float
  publisherMtid: Float
}

# order by var_samp() on columns of table "publisher_cities"
input publisher_cities_var_samp_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# aggregate variance on columns
type publisher_cities_variance_fields {
  citiesMtid: Float
  publisherMtid: Float
}

# order by variance() on columns of table "publisher_cities"
input publisher_cities_variance_order_by {
  citiesMtid: order_by
  publisherMtid: order_by
}

# unique or primary key constraints on table "publisher"
enum publisher_constraint {
  # unique or primary key constraint
  publisher_pkey
}

# input type for incrementing integer column in table "publisher"
input publisher_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oaType: Int
  oldId: Int
  openAccess: Int
  predator: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "publisher"
input publisher_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  cities: publisher_cities_arr_rel_insert_input
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  fromCitation: Boolean
  institute: organization_obj_rel_insert_input
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  organization: Boolean
  otype: String
  predator: Int
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type publisher_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  otype: String
  predator: Int
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "publisher"
input publisher_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oaType: order_by
  oldId: order_by
  oldTimestamp: order_by
  openAccess: order_by
  otype: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type publisher_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  otype: String
  predator: Int
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "publisher"
input publisher_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oaType: order_by
  oldId: order_by
  oldTimestamp: order_by
  openAccess: order_by
  otype: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "publisher"
type publisher_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [publisher!]!
}

# input type for inserting object relation for remote table "publisher"
input publisher_obj_rel_insert_input {
  data: publisher_insert_input!
  on_conflict: publisher_on_conflict
}

# on conflict condition type for table "publisher"
input publisher_on_conflict {
  constraint: publisher_constraint!
  update_columns: [publisher_update_column!]!
  where: publisher_bool_exp
}

# ordering options when selecting data from "publisher"
input publisher_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  cities_aggregate: publisher_cities_aggregate_order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  fromCitation: order_by
  institute: organization_order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oaType: order_by
  oldId: order_by
  oldTimestamp: order_by
  openAccess: order_by
  organization: order_by
  otype: order_by
  predator: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "publisher"
input publisher_pk_columns_input {
  mtid: bigint!
}

# select columns of table "publisher"
enum publisher_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fromCitation

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oaType

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  openAccess

  # column name
  organization

  # column name
  otype

  # column name
  predator

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "publisher"
input publisher_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  fromCitation: Boolean
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oaType: Int
  oldId: Int
  oldTimestamp: timestamp
  openAccess: Int
  organization: Boolean
  otype: String
  predator: Int
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type publisher_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  openAccess: Float
  predator: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "publisher"
input publisher_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type publisher_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  openAccess: Float
  predator: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "publisher"
input publisher_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type publisher_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  openAccess: Float
  predator: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "publisher"
input publisher_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type publisher_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oaType: Int
  oldId: Int
  openAccess: Int
  predator: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "publisher"
input publisher_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "publisher"
enum publisher_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  fromCitation

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oaType

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  openAccess

  # column name
  organization

  # column name
  otype

  # column name
  predator

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type publisher_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  openAccess: Float
  predator: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "publisher"
input publisher_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type publisher_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  openAccess: Float
  predator: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "publisher"
input publisher_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type publisher_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oaType: Float
  oldId: Float
  openAccess: Float
  predator: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "publisher"
input publisher_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oaType: order_by
  oldId: order_by
  openAccess: order_by
  predator: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "query_info"
type query_info {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  async: Boolean!
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  estimatedResultCount: bigint
  filterJson: String
  forceQuery: Boolean!
  format: Int
  ignoreCachedCount: Boolean
  ignoreEstimatedCount: Boolean
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean!

  # An object relationship
  query: smart_query
  queryMtid: bigint
  queued: Boolean!
  refreshed: Boolean!
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  totalResultCount: bigint
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "query_info"
type query_info_aggregate {
  aggregate: query_info_aggregate_fields
  nodes: [query_info!]!
}

# aggregate fields of "query_info"
type query_info_aggregate_fields {
  avg: query_info_avg_fields
  count(columns: [query_info_select_column!], distinct: Boolean): Int
  max: query_info_max_fields
  min: query_info_min_fields
  stddev: query_info_stddev_fields
  stddev_pop: query_info_stddev_pop_fields
  stddev_samp: query_info_stddev_samp_fields
  sum: query_info_sum_fields
  var_pop: query_info_var_pop_fields
  var_samp: query_info_var_samp_fields
  variance: query_info_variance_fields
}

# order by aggregate values of table "query_info"
input query_info_aggregate_order_by {
  avg: query_info_avg_order_by
  count: order_by
  max: query_info_max_order_by
  min: query_info_min_order_by
  stddev: query_info_stddev_order_by
  stddev_pop: query_info_stddev_pop_order_by
  stddev_samp: query_info_stddev_samp_order_by
  sum: query_info_sum_order_by
  var_pop: query_info_var_pop_order_by
  var_samp: query_info_var_samp_order_by
  variance: query_info_variance_order_by
}

# input type for inserting array relation for remote table "query_info"
input query_info_arr_rel_insert_input {
  data: [query_info_insert_input!]!
  on_conflict: query_info_on_conflict
}

# aggregate avg on columns
type query_info_avg_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  estimatedResultCount: Float
  format: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  totalResultCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "query_info"
input query_info_avg_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "query_info". All fields are combined with a logical 'AND'.
input query_info_bool_exp {
  _and: [query_info_bool_exp]
  _not: query_info_bool_exp
  _or: [query_info_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  async: Boolean_comparison_exp
  aux: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  count: Int_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  depth: smallint_comparison_exp
  elementType: String_comparison_exp
  error: Int_comparison_exp
  estimatedResultCount: bigint_comparison_exp
  filterJson: String_comparison_exp
  forceQuery: Boolean_comparison_exp
  format: Int_comparison_exp
  ignoreCachedCount: Boolean_comparison_exp
  ignoreEstimatedCount: Boolean_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  language: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  list: String_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  query: smart_query_bool_exp
  queryMtid: bigint_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  seen: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  totalResultCount: bigint_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "query_info"
enum query_info_constraint {
  # unique or primary key constraint
  query_info_pkey
}

# input type for incrementing integer column in table "query_info"
input query_info_inc_input {
  approverMtid: bigint
  count: Int
  creator: bigint
  depth: smallint
  error: Int
  estimatedResultCount: bigint
  format: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  totalResultCount: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "query_info"
input query_info_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  async: Boolean
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  estimatedResultCount: bigint
  filterJson: String
  forceQuery: Boolean
  format: Int
  ignoreCachedCount: Boolean
  ignoreEstimatedCount: Boolean
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  query: smart_query_obj_rel_insert_input
  queryMtid: bigint
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  totalResultCount: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type query_info_max_fields {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  estimatedResultCount: bigint
  filterJson: String
  format: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  queryMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  totalResultCount: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "query_info"
input query_info_max_order_by {
  approved: order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  depth: order_by
  elementType: order_by
  error: order_by
  estimatedResultCount: order_by
  filterJson: order_by
  format: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  queryMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type query_info_min_fields {
  approved: timestamp
  approverMtid: bigint
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  estimatedResultCount: bigint
  filterJson: String
  format: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  queryMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  totalResultCount: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "query_info"
input query_info_min_order_by {
  approved: order_by
  approverMtid: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  depth: order_by
  elementType: order_by
  error: order_by
  estimatedResultCount: order_by
  filterJson: order_by
  format: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  queryMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "query_info"
type query_info_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [query_info!]!
}

# input type for inserting object relation for remote table "query_info"
input query_info_obj_rel_insert_input {
  data: query_info_insert_input!
  on_conflict: query_info_on_conflict
}

# on conflict condition type for table "query_info"
input query_info_on_conflict {
  constraint: query_info_constraint!
  update_columns: [query_info_update_column!]!
  where: query_info_bool_exp
}

# ordering options when selecting data from "query_info"
input query_info_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  async: order_by
  aux: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  depth: order_by
  elementType: order_by
  error: order_by
  estimatedResultCount: order_by
  filterJson: order_by
  forceQuery: order_by
  format: order_by
  ignoreCachedCount: order_by
  ignoreEstimatedCount: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  query: smart_query_order_by
  queryMtid: order_by
  queued: order_by
  refreshed: order_by
  seen: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "query_info"
input query_info_pk_columns_input {
  mtid: bigint!
}

# select columns of table "query_info"
enum query_info_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  async

  # column name
  aux

  # column name
  comment

  # column name
  comment2

  # column name
  count

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  depth

  # column name
  elementType

  # column name
  error

  # column name
  estimatedResultCount

  # column name
  filterJson

  # column name
  forceQuery

  # column name
  format

  # column name
  ignoreCachedCount

  # column name
  ignoreEstimatedCount

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queryMtid

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  totalResultCount

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "query_info"
input query_info_set_input {
  approved: timestamp
  approverMtid: bigint
  async: Boolean
  aux: String
  comment: String
  comment2: String
  count: Int
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  depth: smallint
  elementType: String
  error: Int
  estimatedResultCount: bigint
  filterJson: String
  forceQuery: Boolean
  format: Int
  ignoreCachedCount: Boolean
  ignoreEstimatedCount: Boolean
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list: String
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queryMtid: bigint
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  totalResultCount: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type query_info_stddev_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  estimatedResultCount: Float
  format: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  totalResultCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "query_info"
input query_info_stddev_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type query_info_stddev_pop_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  estimatedResultCount: Float
  format: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  totalResultCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "query_info"
input query_info_stddev_pop_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type query_info_stddev_samp_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  estimatedResultCount: Float
  format: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  totalResultCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "query_info"
input query_info_stddev_samp_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type query_info_sum_fields {
  approverMtid: bigint
  count: Int
  creator: bigint
  depth: smallint
  error: Int
  estimatedResultCount: bigint
  format: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  totalResultCount: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "query_info"
input query_info_sum_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "query_info"
enum query_info_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  async

  # column name
  aux

  # column name
  comment

  # column name
  comment2

  # column name
  count

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  depth

  # column name
  elementType

  # column name
  error

  # column name
  estimatedResultCount

  # column name
  filterJson

  # column name
  forceQuery

  # column name
  format

  # column name
  ignoreCachedCount

  # column name
  ignoreEstimatedCount

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queryMtid

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  totalResultCount

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type query_info_var_pop_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  estimatedResultCount: Float
  format: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  totalResultCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "query_info"
input query_info_var_pop_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type query_info_var_samp_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  estimatedResultCount: Float
  format: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  totalResultCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "query_info"
input query_info_var_samp_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type query_info_variance_fields {
  approverMtid: Float
  count: Float
  creator: Float
  depth: Float
  error: Float
  estimatedResultCount: Float
  format: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  totalResultCount: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "query_info"
input query_info_variance_order_by {
  approverMtid: order_by
  count: order_by
  creator: order_by
  depth: order_by
  error: order_by
  estimatedResultCount: order_by
  format: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  totalResultCount: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# query root
type query_root {
  # fetch data from the table: "achievement_property"
  achievementProperties(
    # distinct select on columns
    distinct_on: [achievement_property_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_order_by!]

    # filter the rows returned
    where: achievement_property_bool_exp
  ): [achievement_property!]!

  # fetch data from the table: "achievement_property" using primary key columns
  achievementProperty(mtid: bigint!): achievement_property

  # fetch aggregated fields from the table: "achievement_property"
  achievementPropertyAggregate(
    # distinct select on columns
    distinct_on: [achievement_property_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_order_by!]

    # filter the rows returned
    where: achievement_property_bool_exp
  ): achievement_property_aggregate!

  # fetch data from the table: "achievement_property_listing" using primary key columns
  achievementPropertyListing(mtid: bigint!): achievement_property_listing

  # fetch aggregated fields from the table: "achievement_property_listing"
  achievementPropertyListingAggregate(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): achievement_property_listing_aggregate!

  # fetch data from the table: "achievement_property_listing"
  achievementPropertyListings(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): [achievement_property_listing!]!

  # fetch data from the table: "achievement_property_value" using primary key columns
  achievementPropertyValue(mtid: bigint!): achievement_property_value

  # fetch aggregated fields from the table: "achievement_property_value"
  achievementPropertyValueAggregate(
    # distinct select on columns
    distinct_on: [achievement_property_value_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_value_order_by!]

    # filter the rows returned
    where: achievement_property_value_bool_exp
  ): achievement_property_value_aggregate!

  # fetch data from the table: "achievement_property_value"
  achievementPropertyValues(
    # distinct select on columns
    distinct_on: [achievement_property_value_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_value_order_by!]

    # filter the rows returned
    where: achievement_property_value_bool_exp
  ): [achievement_property_value!]!

  # fetch data from the table: "activity_log" using primary key columns
  activityLog(id: bigint!): activity_log

  # fetch aggregated fields from the table: "activity_log"
  activityLogAggregate(
    # distinct select on columns
    distinct_on: [activity_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [activity_log_order_by!]

    # filter the rows returned
    where: activity_log_bool_exp
  ): activity_log_aggregate!

  # fetch data from the table: "activity_log"
  activityLogs(
    # distinct select on columns
    distinct_on: [activity_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [activity_log_order_by!]

    # filter the rows returned
    where: activity_log_bool_exp
  ): [activity_log!]!

  # fetch data from the table: "address" using primary key columns
  address(mtid: bigint!): address

  # fetch aggregated fields from the table: "address"
  addressAggregate(
    # distinct select on columns
    distinct_on: [address_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [address_order_by!]

    # filter the rows returned
    where: address_bool_exp
  ): address_aggregate!

  # fetch data from the table: "address"
  addresses(
    # distinct select on columns
    distinct_on: [address_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [address_order_by!]

    # filter the rows returned
    where: address_bool_exp
  ): [address!]!

  # fetch data from the table: "admin_role" using primary key columns
  adminRole(mtid: bigint!): admin_role

  # fetch aggregated fields from the table: "admin_role"
  adminRoleAggregate(
    # distinct select on columns
    distinct_on: [admin_role_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [admin_role_order_by!]

    # filter the rows returned
    where: admin_role_bool_exp
  ): admin_role_aggregate!

  # fetch data from the table: "admin_role"
  adminRoles(
    # distinct select on columns
    distinct_on: [admin_role_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [admin_role_order_by!]

    # filter the rows returned
    where: admin_role_bool_exp
  ): [admin_role!]!

  # fetch data from the table: "affiliation" using primary key columns
  affiliation(mtid: bigint!): affiliation

  # fetch aggregated fields from the table: "affiliation"
  affiliationAggregate(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): affiliation_aggregate!

  # fetch data from the table: "affiliation"
  affiliations(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): [affiliation!]!

  # fetch data from the table: "appearance" using primary key columns
  appearance(mtid: bigint!): appearance

  # fetch aggregated fields from the table: "appearance"
  appearanceAggregate(
    # distinct select on columns
    distinct_on: [appearance_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [appearance_order_by!]

    # filter the rows returned
    where: appearance_bool_exp
  ): appearance_aggregate!

  # fetch data from the table: "appearance"
  appearances(
    # distinct select on columns
    distinct_on: [appearance_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [appearance_order_by!]

    # filter the rows returned
    where: appearance_bool_exp
  ): [appearance!]!

  # fetch data from the table: "authentication_failure" using primary key columns
  authenticationFailure(id: bigint!): authentication_failure

  # fetch aggregated fields from the table: "authentication_failure"
  authenticationFailureAggregate(
    # distinct select on columns
    distinct_on: [authentication_failure_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authentication_failure_order_by!]

    # filter the rows returned
    where: authentication_failure_bool_exp
  ): authentication_failure_aggregate!

  # fetch data from the table: "authentication_failure"
  authenticationFailures(
    # distinct select on columns
    distinct_on: [authentication_failure_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authentication_failure_order_by!]

    # filter the rows returned
    where: authentication_failure_bool_exp
  ): [authentication_failure!]!

  # fetch data from the table: "author_identifier" using primary key columns
  authorIdentifier(mtid: bigint!): author_identifier

  # fetch aggregated fields from the table: "author_identifier"
  authorIdentifierAggregate(
    # distinct select on columns
    distinct_on: [author_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_identifier_order_by!]

    # filter the rows returned
    where: author_identifier_bool_exp
  ): author_identifier_aggregate!

  # fetch data from the table: "author_identifier"
  authorIdentifiers(
    # distinct select on columns
    distinct_on: [author_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_identifier_order_by!]

    # filter the rows returned
    where: author_identifier_bool_exp
  ): [author_identifier!]!

  # fetch data from the table: "author_name" using primary key columns
  authorName(mtid: bigint!): author_name

  # fetch aggregated fields from the table: "author_name"
  authorNameAggregate(
    # distinct select on columns
    distinct_on: [author_name_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_name_order_by!]

    # filter the rows returned
    where: author_name_bool_exp
  ): author_name_aggregate!

  # fetch data from the table: "author_name"
  authorNames(
    # distinct select on columns
    distinct_on: [author_name_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_name_order_by!]

    # filter the rows returned
    where: author_name_bool_exp
  ): [author_name!]!

  # fetch data from the table: "authorship" using primary key columns
  authorship(mtid: bigint!): authorship

  # fetch aggregated fields from the table: "authorship"
  authorshipAggregate(
    # distinct select on columns
    distinct_on: [authorship_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_order_by!]

    # filter the rows returned
    where: authorship_bool_exp
  ): authorship_aggregate!

  # fetch aggregated fields from the table: "authorship_organizations"
  authorshipOrganizationsAggregate(
    # distinct select on columns
    distinct_on: [authorship_organizations_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_organizations_order_by!]

    # filter the rows returned
    where: authorship_organizations_bool_exp
  ): authorship_organizations_aggregate!

  # fetch data from the table: "authorship_organizations"
  authorshipOrganizationses(
    # distinct select on columns
    distinct_on: [authorship_organizations_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_organizations_order_by!]

    # filter the rows returned
    where: authorship_organizations_bool_exp
  ): [authorship_organizations!]!

  # fetch data from the table: "authorship_type" using primary key columns
  authorshipType(mtid: bigint!): authorship_type

  # fetch aggregated fields from the table: "authorship_type"
  authorshipTypeAggregate(
    # distinct select on columns
    distinct_on: [authorship_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_order_by!]

    # filter the rows returned
    where: authorship_type_bool_exp
  ): authorship_type_aggregate!

  # fetch aggregated fields from the table: "authorship_type_sub_types_allowed"
  authorshipTypeSubTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [authorship_type_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_sub_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_sub_types_allowed_bool_exp
  ): authorship_type_sub_types_allowed_aggregate!

  # fetch data from the table: "authorship_type_sub_types_allowed"
  authorshipTypeSubTypesAlloweds(
    # distinct select on columns
    distinct_on: [authorship_type_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_sub_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_sub_types_allowed_bool_exp
  ): [authorship_type_sub_types_allowed!]!

  # fetch aggregated fields from the table: "authorship_type_types_allowed"
  authorshipTypeTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [authorship_type_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_types_allowed_bool_exp
  ): authorship_type_types_allowed_aggregate!

  # fetch data from the table: "authorship_type_types_allowed"
  authorshipTypeTypesAlloweds(
    # distinct select on columns
    distinct_on: [authorship_type_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_types_allowed_bool_exp
  ): [authorship_type_types_allowed!]!

  # fetch data from the table: "authorship_type"
  authorshipTypes(
    # distinct select on columns
    distinct_on: [authorship_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_order_by!]

    # filter the rows returned
    where: authorship_type_bool_exp
  ): [authorship_type!]!

  # fetch data from the table: "authorship"
  authorships(
    # distinct select on columns
    distinct_on: [authorship_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_order_by!]

    # filter the rows returned
    where: authorship_bool_exp
  ): [authorship!]!

  # fetch data from the table: "binary_content" using primary key columns
  binaryContent(id: bigint!): binary_content

  # fetch aggregated fields from the table: "binary_content"
  binaryContentAggregate(
    # distinct select on columns
    distinct_on: [binary_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [binary_content_order_by!]

    # filter the rows returned
    where: binary_content_bool_exp
  ): binary_content_aggregate!

  # fetch data from the table: "binary_content"
  binaryContents(
    # distinct select on columns
    distinct_on: [binary_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [binary_content_order_by!]

    # filter the rows returned
    where: binary_content_bool_exp
  ): [binary_content!]!

  # fetch data from the table: "bulk_duplum_merge_request" using primary key columns
  bulkDuplumMergeRequest(mtid: bigint!): bulk_duplum_merge_request

  # fetch aggregated fields from the table: "bulk_duplum_merge_request"
  bulkDuplumMergeRequestAggregate(
    # distinct select on columns
    distinct_on: [bulk_duplum_merge_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [bulk_duplum_merge_request_order_by!]

    # filter the rows returned
    where: bulk_duplum_merge_request_bool_exp
  ): bulk_duplum_merge_request_aggregate!

  # fetch data from the table: "bulk_duplum_merge_request"
  bulkDuplumMergeRequests(
    # distinct select on columns
    distinct_on: [bulk_duplum_merge_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [bulk_duplum_merge_request_order_by!]

    # filter the rows returned
    where: bulk_duplum_merge_request_bool_exp
  ): [bulk_duplum_merge_request!]!

  # fetch data from the table: "category"
  categories(
    # distinct select on columns
    distinct_on: [category_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_order_by!]

    # filter the rows returned
    where: category_bool_exp
  ): [category!]!

  # fetch data from the table: "category" using primary key columns
  category(mtid: bigint!): category

  # fetch aggregated fields from the table: "category"
  categoryAggregate(
    # distinct select on columns
    distinct_on: [category_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_order_by!]

    # filter the rows returned
    where: category_bool_exp
  ): category_aggregate!

  # fetch aggregated fields from the table: "category_sub_types_allowed"
  categorySubTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): category_sub_types_allowed_aggregate!

  # fetch data from the table: "category_sub_types_allowed"
  categorySubTypesAlloweds(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): [category_sub_types_allowed!]!

  # fetch aggregated fields from the table: "category_types_allowed"
  categoryTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): category_types_allowed_aggregate!

  # fetch data from the table: "category_types_allowed"
  categoryTypesAlloweds(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): [category_types_allowed!]!

  # fetch data from the table: "citation" using primary key columns
  citation(mtid: bigint!): citation

  # fetch aggregated fields from the table: "citation"
  citationAggregate(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): citation_aggregate!

  # fetch data from the table: "citation"
  citations(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): [citation!]!

  # fetch data from the table: "classification" using primary key columns
  classification(mtid: bigint!): classification

  # fetch aggregated fields from the table: "classification"
  classificationAggregate(
    # distinct select on columns
    distinct_on: [classification_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_order_by!]

    # filter the rows returned
    where: classification_bool_exp
  ): classification_aggregate!

  # fetch data from the table: "classification_external" using primary key columns
  classificationExternal(mtid: bigint!): classification_external

  # fetch aggregated fields from the table: "classification_external"
  classificationExternalAggregate(
    # distinct select on columns
    distinct_on: [classification_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_order_by!]

    # filter the rows returned
    where: classification_external_bool_exp
  ): classification_external_aggregate!

  # fetch aggregated fields from the table: "classification_external_mapped_to"
  classificationExternalMappedToAggregate(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): classification_external_mapped_to_aggregate!

  # fetch data from the table: "classification_external_mapped_to"
  classificationExternalMappedToes(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): [classification_external_mapped_to!]!

  # fetch data from the table: "classification_external"
  classificationExternals(
    # distinct select on columns
    distinct_on: [classification_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_order_by!]

    # filter the rows returned
    where: classification_external_bool_exp
  ): [classification_external!]!

  # fetch aggregated fields from the table: "classification_parents"
  classificationParentsAggregate(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): classification_parents_aggregate!

  # fetch data from the table: "classification_parents"
  classificationParentses(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): [classification_parents!]!

  # fetch data from the table: "classification_tree" using primary key columns
  classificationTree(mtid: bigint!): classification_tree

  # fetch aggregated fields from the table: "classification_tree"
  classificationTreeAggregate(
    # distinct select on columns
    distinct_on: [classification_tree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_tree_order_by!]

    # filter the rows returned
    where: classification_tree_bool_exp
  ): classification_tree_aggregate!

  # fetch data from the table: "classification_tree"
  classificationTrees(
    # distinct select on columns
    distinct_on: [classification_tree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_tree_order_by!]

    # filter the rows returned
    where: classification_tree_bool_exp
  ): [classification_tree!]!

  # fetch data from the table: "classification"
  classifications(
    # distinct select on columns
    distinct_on: [classification_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_order_by!]

    # filter the rows returned
    where: classification_bool_exp
  ): [classification!]!

  # fetch data from the table: "conference" using primary key columns
  conference(mtid: bigint!): conference

  # fetch aggregated fields from the table: "conference"
  conferenceAggregate(
    # distinct select on columns
    distinct_on: [conference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_order_by!]

    # filter the rows returned
    where: conference_bool_exp
  ): conference_aggregate!

  # fetch aggregated fields from the table: "conference_location"
  conferenceLocationAggregate(
    # distinct select on columns
    distinct_on: [conference_location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_location_order_by!]

    # filter the rows returned
    where: conference_location_bool_exp
  ): conference_location_aggregate!

  # fetch data from the table: "conference_location"
  conferenceLocations(
    # distinct select on columns
    distinct_on: [conference_location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_location_order_by!]

    # filter the rows returned
    where: conference_location_bool_exp
  ): [conference_location!]!

  # fetch aggregated fields from the table: "conference_organizers"
  conferenceOrganizersAggregate(
    # distinct select on columns
    distinct_on: [conference_organizers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_organizers_order_by!]

    # filter the rows returned
    where: conference_organizers_bool_exp
  ): conference_organizers_aggregate!

  # fetch data from the table: "conference_organizers"
  conferenceOrganizerses(
    # distinct select on columns
    distinct_on: [conference_organizers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_organizers_order_by!]

    # filter the rows returned
    where: conference_organizers_bool_exp
  ): [conference_organizers!]!

  # fetch data from the table: "conference"
  conferences(
    # distinct select on columns
    distinct_on: [conference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_order_by!]

    # filter the rows returned
    where: conference_bool_exp
  ): [conference!]!

  # fetch data from the table: "cron_job" using primary key columns
  cronJob(mtid: bigint!): cron_job

  # fetch aggregated fields from the table: "cron_job"
  cronJobAggregate(
    # distinct select on columns
    distinct_on: [cron_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_order_by!]

    # filter the rows returned
    where: cron_job_bool_exp
  ): cron_job_aggregate!

  # fetch data from the table: "cron_job_run_request" using primary key columns
  cronJobRunRequest(mtid: bigint!): cron_job_run_request

  # fetch aggregated fields from the table: "cron_job_run_request"
  cronJobRunRequestAggregate(
    # distinct select on columns
    distinct_on: [cron_job_run_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_run_request_order_by!]

    # filter the rows returned
    where: cron_job_run_request_bool_exp
  ): cron_job_run_request_aggregate!

  # fetch data from the table: "cron_job_run_request"
  cronJobRunRequests(
    # distinct select on columns
    distinct_on: [cron_job_run_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_run_request_order_by!]

    # filter the rows returned
    where: cron_job_run_request_bool_exp
  ): [cron_job_run_request!]!

  # fetch data from the table: "cron_job"
  cronJobs(
    # distinct select on columns
    distinct_on: [cron_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_order_by!]

    # filter the rows returned
    where: cron_job_bool_exp
  ): [cron_job!]!

  # fetch data from the table: "degree" using primary key columns
  degree(mtid: bigint!): degree

  # fetch aggregated fields from the table: "degree"
  degreeAggregate(
    # distinct select on columns
    distinct_on: [degree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_order_by!]

    # filter the rows returned
    where: degree_bool_exp
  ): degree_aggregate!

  # fetch data from the table: "degree_holder" using primary key columns
  degreeHolder(mtid: bigint!): degree_holder

  # fetch aggregated fields from the table: "degree_holder"
  degreeHolderAggregate(
    # distinct select on columns
    distinct_on: [degree_holder_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_holder_order_by!]

    # filter the rows returned
    where: degree_holder_bool_exp
  ): degree_holder_aggregate!

  # fetch data from the table: "degree_holder"
  degreeHolders(
    # distinct select on columns
    distinct_on: [degree_holder_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_holder_order_by!]

    # filter the rows returned
    where: degree_holder_bool_exp
  ): [degree_holder!]!

  # fetch data from the table: "degree"
  degrees(
    # distinct select on columns
    distinct_on: [degree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_order_by!]

    # filter the rows returned
    where: degree_bool_exp
  ): [degree!]!

  # fetch data from the table: "discipline" using primary key columns
  discipline(mtid: bigint!): discipline

  # fetch aggregated fields from the table: "discipline"
  disciplineAggregate(
    # distinct select on columns
    distinct_on: [discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [discipline_order_by!]

    # filter the rows returned
    where: discipline_bool_exp
  ): discipline_aggregate!

  # fetch data from the table: "discipline"
  disciplines(
    # distinct select on columns
    distinct_on: [discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [discipline_order_by!]

    # filter the rows returned
    where: discipline_bool_exp
  ): [discipline!]!

  # fetch data from the table: "division_containment" using primary key columns
  divisionContainment(mtid: bigint!): division_containment

  # fetch aggregated fields from the table: "division_containment"
  divisionContainmentAggregate(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): division_containment_aggregate!

  # fetch data from the table: "division_containment"
  divisionContainments(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): [division_containment!]!

  # fetch data from the table: "duplum_desc" using primary key columns
  duplumDesc(id: bigint!): duplum_desc

  # fetch aggregated fields from the table: "duplum_desc"
  duplumDescAggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_order_by!]

    # filter the rows returned
    where: duplum_desc_bool_exp
  ): duplum_desc_aggregate!

  # fetch aggregated fields from the table: "duplum_desc_book_chapters_merged"
  duplumDescBookChaptersMergedAggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_book_chapters_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_book_chapters_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_book_chapters_merged_bool_exp
  ): duplum_desc_book_chapters_merged_aggregate!

  # fetch data from the table: "duplum_desc_book_chapters_merged"
  duplumDescBookChaptersMergeds(
    # distinct select on columns
    distinct_on: [duplum_desc_book_chapters_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_book_chapters_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_book_chapters_merged_bool_exp
  ): [duplum_desc_book_chapters_merged!]!

  # fetch aggregated fields from the table: "duplum_desc_citations_merged"
  duplumDescCitationsMergedAggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_citations_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_citations_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_citations_merged_bool_exp
  ): duplum_desc_citations_merged_aggregate!

  # fetch data from the table: "duplum_desc_citations_merged"
  duplumDescCitationsMergeds(
    # distinct select on columns
    distinct_on: [duplum_desc_citations_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_citations_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_citations_merged_bool_exp
  ): [duplum_desc_citations_merged!]!

  # fetch data from the table: "duplum_desc"
  duplumDescs(
    # distinct select on columns
    distinct_on: [duplum_desc_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_order_by!]

    # filter the rows returned
    where: duplum_desc_bool_exp
  ): [duplum_desc!]!

  # fetch data from the table: "duplum_search_request" using primary key columns
  duplumSearchRequest(mtid: bigint!): duplum_search_request

  # fetch aggregated fields from the table: "duplum_search_request"
  duplumSearchRequestAggregate(
    # distinct select on columns
    distinct_on: [duplum_search_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_request_order_by!]

    # filter the rows returned
    where: duplum_search_request_bool_exp
  ): duplum_search_request_aggregate!

  # fetch data from the table: "duplum_search_request"
  duplumSearchRequests(
    # distinct select on columns
    distinct_on: [duplum_search_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_request_order_by!]

    # filter the rows returned
    where: duplum_search_request_bool_exp
  ): [duplum_search_request!]!

  # fetch data from the table: "duplum_search_result" using primary key columns
  duplumSearchResult(id: bigint!): duplum_search_result

  # fetch aggregated fields from the table: "duplum_search_result"
  duplumSearchResultAggregate(
    # distinct select on columns
    distinct_on: [duplum_search_result_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_result_order_by!]

    # filter the rows returned
    where: duplum_search_result_bool_exp
  ): duplum_search_result_aggregate!

  # fetch data from the table: "duplum_search_result"
  duplumSearchResults(
    # distinct select on columns
    distinct_on: [duplum_search_result_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_result_order_by!]

    # filter the rows returned
    where: duplum_search_result_bool_exp
  ): [duplum_search_result!]!

  # fetch data from the table: "error_log" using primary key columns
  errorLog(id: bigint!): error_log

  # fetch aggregated fields from the table: "error_log"
  errorLogAggregate(
    # distinct select on columns
    distinct_on: [error_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [error_log_order_by!]

    # filter the rows returned
    where: error_log_bool_exp
  ): error_log_aggregate!

  # fetch data from the table: "error_log"
  errorLogs(
    # distinct select on columns
    distinct_on: [error_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [error_log_order_by!]

    # filter the rows returned
    where: error_log_bool_exp
  ): [error_log!]!

  # fetch data from the table: "export_format" using primary key columns
  exportFormat(mtid: bigint!): export_format

  # fetch aggregated fields from the table: "export_format"
  exportFormatAggregate(
    # distinct select on columns
    distinct_on: [export_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_format_order_by!]

    # filter the rows returned
    where: export_format_bool_exp
  ): export_format_aggregate!

  # fetch data from the table: "export_format"
  exportFormats(
    # distinct select on columns
    distinct_on: [export_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_format_order_by!]

    # filter the rows returned
    where: export_format_bool_exp
  ): [export_format!]!

  # fetch data from the table: "export_request" using primary key columns
  exportRequest(mtid: bigint!): export_request

  # fetch aggregated fields from the table: "export_request"
  exportRequestAggregate(
    # distinct select on columns
    distinct_on: [export_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_request_order_by!]

    # filter the rows returned
    where: export_request_bool_exp
  ): export_request_aggregate!

  # fetch data from the table: "export_request"
  exportRequests(
    # distinct select on columns
    distinct_on: [export_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_request_order_by!]

    # filter the rows returned
    where: export_request_bool_exp
  ): [export_request!]!

  # fetch data from the table: "forum" using primary key columns
  forum(mtid: bigint!): forum

  # fetch aggregated fields from the table: "forum"
  forumAggregate(
    # distinct select on columns
    distinct_on: [forum_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [forum_order_by!]

    # filter the rows returned
    where: forum_bool_exp
  ): forum_aggregate!

  # fetch data from the table: "forum"
  forums(
    # distinct select on columns
    distinct_on: [forum_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [forum_order_by!]

    # filter the rows returned
    where: forum_bool_exp
  ): [forum!]!

  # fetch data from the table: "funding" using primary key columns
  funding(mtid: bigint!): funding

  # fetch aggregated fields from the table: "funding"
  fundingAggregate(
    # distinct select on columns
    distinct_on: [funding_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [funding_order_by!]

    # filter the rows returned
    where: funding_bool_exp
  ): funding_aggregate!

  # fetch data from the table: "funding"
  fundings(
    # distinct select on columns
    distinct_on: [funding_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [funding_order_by!]

    # filter the rows returned
    where: funding_bool_exp
  ): [funding!]!

  # fetch data from the table: "import_alias" using primary key columns
  importAlias(mtid: bigint!): import_alias

  # fetch aggregated fields from the table: "import_alias"
  importAliasAggregate(
    # distinct select on columns
    distinct_on: [import_alias_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_alias_order_by!]

    # filter the rows returned
    where: import_alias_bool_exp
  ): import_alias_aggregate!

  # fetch data from the table: "import_alias"
  importAliases(
    # distinct select on columns
    distinct_on: [import_alias_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_alias_order_by!]

    # filter the rows returned
    where: import_alias_bool_exp
  ): [import_alias!]!

  # fetch data from the table: "import_format" using primary key columns
  importFormat(mtid: bigint!): import_format

  # fetch aggregated fields from the table: "import_format"
  importFormatAggregate(
    # distinct select on columns
    distinct_on: [import_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_format_order_by!]

    # filter the rows returned
    where: import_format_bool_exp
  ): import_format_aggregate!

  # fetch data from the table: "import_format"
  importFormats(
    # distinct select on columns
    distinct_on: [import_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_format_order_by!]

    # filter the rows returned
    where: import_format_bool_exp
  ): [import_format!]!

  # fetch data from the table: "import_log" using primary key columns
  importLog(id: bigint!): import_log

  # fetch aggregated fields from the table: "import_log"
  importLogAggregate(
    # distinct select on columns
    distinct_on: [import_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_log_order_by!]

    # filter the rows returned
    where: import_log_bool_exp
  ): import_log_aggregate!

  # fetch data from the table: "import_log"
  importLogs(
    # distinct select on columns
    distinct_on: [import_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_log_order_by!]

    # filter the rows returned
    where: import_log_bool_exp
  ): [import_log!]!

  # fetch data from the table: "import_request" using primary key columns
  importRequest(mtid: bigint!): import_request

  # fetch aggregated fields from the table: "import_request"
  importRequestAggregate(
    # distinct select on columns
    distinct_on: [import_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_request_order_by!]

    # filter the rows returned
    where: import_request_bool_exp
  ): import_request_aggregate!

  # fetch data from the table: "import_request"
  importRequests(
    # distinct select on columns
    distinct_on: [import_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_request_order_by!]

    # filter the rows returned
    where: import_request_bool_exp
  ): [import_request!]!

  # fetch data from the table: "import_stat" using primary key columns
  importStat(mtid: bigint!): import_stat

  # fetch aggregated fields from the table: "import_stat"
  importStatAggregate(
    # distinct select on columns
    distinct_on: [import_stat_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_order_by!]

    # filter the rows returned
    where: import_stat_bool_exp
  ): import_stat_aggregate!

  # fetch aggregated fields from the table: "import_stat_import_error_details"
  importStatImportErrorDetailsAggregate(
    # distinct select on columns
    distinct_on: [import_stat_import_error_details_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_import_error_details_order_by!]

    # filter the rows returned
    where: import_stat_import_error_details_bool_exp
  ): import_stat_import_error_details_aggregate!

  # fetch data from the table: "import_stat_import_error_details"
  importStatImportErrorDetailses(
    # distinct select on columns
    distinct_on: [import_stat_import_error_details_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_import_error_details_order_by!]

    # filter the rows returned
    where: import_stat_import_error_details_bool_exp
  ): [import_stat_import_error_details!]!

  # fetch data from the table: "import_stat"
  importStats(
    # distinct select on columns
    distinct_on: [import_stat_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_order_by!]

    # filter the rows returned
    where: import_stat_bool_exp
  ): [import_stat!]!

  # fetch data from the table: "import_stat_wos_ids"
  import_stat_wos_ids(
    # distinct select on columns
    distinct_on: [import_stat_wos_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_wos_ids_order_by!]

    # filter the rows returned
    where: import_stat_wos_ids_bool_exp
  ): [import_stat_wos_ids!]!

  # fetch aggregated fields from the table: "import_stat_wos_ids"
  import_stat_wos_ids_aggregate(
    # distinct select on columns
    distinct_on: [import_stat_wos_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_wos_ids_order_by!]

    # filter the rows returned
    where: import_stat_wos_ids_bool_exp
  ): import_stat_wos_ids_aggregate!

  # fetch data from the table: "institute_type" using primary key columns
  instituteType(mtid: bigint!): institute_type

  # fetch aggregated fields from the table: "institute_type"
  instituteTypeAggregate(
    # distinct select on columns
    distinct_on: [institute_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [institute_type_order_by!]

    # filter the rows returned
    where: institute_type_bool_exp
  ): institute_type_aggregate!

  # fetch data from the table: "institute_type"
  instituteTypes(
    # distinct select on columns
    distinct_on: [institute_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [institute_type_order_by!]

    # filter the rows returned
    where: institute_type_bool_exp
  ): [institute_type!]!

  # fetch aggregated fields from the table: "journal_successors"
  journalSuccessorsAggregate(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): journal_successors_aggregate!

  # fetch data from the table: "journal_successors"
  journalSuccessorses(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): [journal_successors!]!

  # fetch data from the table: "keyword" using primary key columns
  keyword(mtid: bigint!): keyword

  # fetch aggregated fields from the table: "keyword"
  keywordAggregate(
    # distinct select on columns
    distinct_on: [keyword_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [keyword_order_by!]

    # filter the rows returned
    where: keyword_bool_exp
  ): keyword_aggregate!

  # fetch data from the table: "keyword"
  keywords(
    # distinct select on columns
    distinct_on: [keyword_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [keyword_order_by!]

    # filter the rows returned
    where: keyword_bool_exp
  ): [keyword!]!

  # fetch data from the table: "language" using primary key columns
  language(mtid: bigint!): language

  # fetch aggregated fields from the table: "language"
  languageAggregate(
    # distinct select on columns
    distinct_on: [language_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [language_order_by!]

    # filter the rows returned
    where: language_bool_exp
  ): language_aggregate!

  # fetch data from the table: "language"
  languages(
    # distinct select on columns
    distinct_on: [language_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [language_order_by!]

    # filter the rows returned
    where: language_bool_exp
  ): [language!]!

  # fetch data from the table: "localized_message" using primary key columns
  localizedMessage(mtid: bigint!): localized_message

  # fetch aggregated fields from the table: "localized_message"
  localizedMessageAggregate(
    # distinct select on columns
    distinct_on: [localized_message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [localized_message_order_by!]

    # filter the rows returned
    where: localized_message_bool_exp
  ): localized_message_aggregate!

  # fetch data from the table: "localized_message"
  localizedMessages(
    # distinct select on columns
    distinct_on: [localized_message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [localized_message_order_by!]

    # filter the rows returned
    where: localized_message_bool_exp
  ): [localized_message!]!

  # fetch data from the table: "location" using primary key columns
  location(mtid: bigint!): location

  # fetch aggregated fields from the table: "location"
  locationAggregate(
    # distinct select on columns
    distinct_on: [location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [location_order_by!]

    # filter the rows returned
    where: location_bool_exp
  ): location_aggregate!

  # fetch data from the table: "location"
  locations(
    # distinct select on columns
    distinct_on: [location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [location_order_by!]

    # filter the rows returned
    where: location_bool_exp
  ): [location!]!

  # fetch data from the table: "lock_list" using primary key columns
  lockList(mtid: bigint!): lock_list

  # fetch aggregated fields from the table: "lock_list"
  lockListAggregate(
    # distinct select on columns
    distinct_on: [lock_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_order_by!]

    # filter the rows returned
    where: lock_list_bool_exp
  ): lock_list_aggregate!

  # fetch aggregated fields from the table: "lock_list_delegated_admins"
  lockListDelegatedAdminsAggregate(
    # distinct select on columns
    distinct_on: [lock_list_delegated_admins_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_delegated_admins_order_by!]

    # filter the rows returned
    where: lock_list_delegated_admins_bool_exp
  ): lock_list_delegated_admins_aggregate!

  # fetch data from the table: "lock_list_delegated_admins"
  lockListDelegatedAdminses(
    # distinct select on columns
    distinct_on: [lock_list_delegated_admins_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_delegated_admins_order_by!]

    # filter the rows returned
    where: lock_list_delegated_admins_bool_exp
  ): [lock_list_delegated_admins!]!

  # fetch data from the table: "lock_list"
  lockLists(
    # distinct select on columns
    distinct_on: [lock_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_order_by!]

    # filter the rows returned
    where: lock_list_bool_exp
  ): [lock_list!]!

  # fetch data from the table: "mab_discipline" using primary key columns
  mabDiscipline(mtid: bigint!): mab_discipline

  # fetch aggregated fields from the table: "mab_discipline"
  mabDisciplineAggregate(
    # distinct select on columns
    distinct_on: [mab_discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mab_discipline_order_by!]

    # filter the rows returned
    where: mab_discipline_bool_exp
  ): mab_discipline_aggregate!

  # fetch data from the table: "mab_discipline"
  mabDisciplines(
    # distinct select on columns
    distinct_on: [mab_discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mab_discipline_order_by!]

    # filter the rows returned
    where: mab_discipline_bool_exp
  ): [mab_discipline!]!

  # fetch data from the table: "mention" using primary key columns
  mention(mtid: bigint!): mention

  # fetch aggregated fields from the table: "mention"
  mentionAggregate(
    # distinct select on columns
    distinct_on: [mention_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mention_order_by!]

    # filter the rows returned
    where: mention_bool_exp
  ): mention_aggregate!

  # fetch data from the table: "mention"
  mentions(
    # distinct select on columns
    distinct_on: [mention_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mention_order_by!]

    # filter the rows returned
    where: mention_bool_exp
  ): [mention!]!

  # fetch data from the table: "message" using primary key columns
  message(mtid: bigint!): message

  # fetch aggregated fields from the table: "message"
  messageAggregate(
    # distinct select on columns
    distinct_on: [message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_order_by!]

    # filter the rows returned
    where: message_bool_exp
  ): message_aggregate!

  # fetch aggregated fields from the table: "message_files"
  messageFilesAggregate(
    # distinct select on columns
    distinct_on: [message_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_files_order_by!]

    # filter the rows returned
    where: message_files_bool_exp
  ): message_files_aggregate!

  # fetch data from the table: "message_files"
  messageFileses(
    # distinct select on columns
    distinct_on: [message_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_files_order_by!]

    # filter the rows returned
    where: message_files_bool_exp
  ): [message_files!]!

  # fetch data from the table: "message_institutes" using primary key columns
  messageInstitutes(forumMessageMtid: bigint!, institutesMtid: bigint!): message_institutes

  # fetch aggregated fields from the table: "message_institutes"
  messageInstitutesAggregate(
    # distinct select on columns
    distinct_on: [message_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_institutes_order_by!]

    # filter the rows returned
    where: message_institutes_bool_exp
  ): message_institutes_aggregate!

  # fetch data from the table: "message_institutes"
  messageInstituteses(
    # distinct select on columns
    distinct_on: [message_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_institutes_order_by!]

    # filter the rows returned
    where: message_institutes_bool_exp
  ): [message_institutes!]!

  # fetch aggregated fields from the table: "message_mailboxes"
  messageMailboxesAggregate(
    # distinct select on columns
    distinct_on: [message_mailboxes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_mailboxes_order_by!]

    # filter the rows returned
    where: message_mailboxes_bool_exp
  ): message_mailboxes_aggregate!

  # fetch data from the table: "message_mailboxes"
  messageMailboxeses(
    # distinct select on columns
    distinct_on: [message_mailboxes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_mailboxes_order_by!]

    # filter the rows returned
    where: message_mailboxes_bool_exp
  ): [message_mailboxes!]!

  # fetch data from the table: "message_parameter" using primary key columns
  messageParameter(mtid: bigint!): message_parameter

  # fetch aggregated fields from the table: "message_parameter"
  messageParameterAggregate(
    # distinct select on columns
    distinct_on: [message_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_parameter_order_by!]

    # filter the rows returned
    where: message_parameter_bool_exp
  ): message_parameter_aggregate!

  # fetch data from the table: "message_parameter"
  messageParameters(
    # distinct select on columns
    distinct_on: [message_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_parameter_order_by!]

    # filter the rows returned
    where: message_parameter_bool_exp
  ): [message_parameter!]!

  # fetch aggregated fields from the table: "message_recipients"
  messageRecipientsAggregate(
    # distinct select on columns
    distinct_on: [message_recipients_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_recipients_order_by!]

    # filter the rows returned
    where: message_recipients_bool_exp
  ): message_recipients_aggregate!

  # fetch data from the table: "message_recipients"
  messageRecipientses(
    # distinct select on columns
    distinct_on: [message_recipients_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_recipients_order_by!]

    # filter the rows returned
    where: message_recipients_bool_exp
  ): [message_recipients!]!

  # fetch data from the table: "message_sent" using primary key columns
  messageSent(id: bigint!): message_sent

  # fetch aggregated fields from the table: "message_sent"
  messageSentAggregate(
    # distinct select on columns
    distinct_on: [message_sent_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_sent_order_by!]

    # filter the rows returned
    where: message_sent_bool_exp
  ): message_sent_aggregate!

  # fetch data from the table: "message_sent"
  messageSents(
    # distinct select on columns
    distinct_on: [message_sent_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_sent_order_by!]

    # filter the rows returned
    where: message_sent_bool_exp
  ): [message_sent!]!

  # fetch data from the table: "message_template" using primary key columns
  messageTemplate(mtid: bigint!): message_template

  # fetch aggregated fields from the table: "message_template"
  messageTemplateAggregate(
    # distinct select on columns
    distinct_on: [message_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_order_by!]

    # filter the rows returned
    where: message_template_bool_exp
  ): message_template_aggregate!

  # fetch aggregated fields from the table: "message_template_parameters"
  messageTemplateParametersAggregate(
    # distinct select on columns
    distinct_on: [message_template_parameters_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_parameters_order_by!]

    # filter the rows returned
    where: message_template_parameters_bool_exp
  ): message_template_parameters_aggregate!

  # fetch data from the table: "message_template_parameters"
  messageTemplateParameterses(
    # distinct select on columns
    distinct_on: [message_template_parameters_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_parameters_order_by!]

    # filter the rows returned
    where: message_template_parameters_bool_exp
  ): [message_template_parameters!]!

  # fetch data from the table: "message_template"
  messageTemplates(
    # distinct select on columns
    distinct_on: [message_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_order_by!]

    # filter the rows returned
    where: message_template_bool_exp
  ): [message_template!]!

  # fetch data from the table: "message"
  messages(
    # distinct select on columns
    distinct_on: [message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_order_by!]

    # filter the rows returned
    where: message_bool_exp
  ): [message!]!

  # fetch data from the table: "mycite_revision_entity"
  myciteRevisionEntities(
    # distinct select on columns
    distinct_on: [mycite_revision_entity_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mycite_revision_entity_order_by!]

    # filter the rows returned
    where: mycite_revision_entity_bool_exp
  ): [mycite_revision_entity!]!

  # fetch data from the table: "mycite_revision_entity" using primary key columns
  myciteRevisionEntity(id: Int!): mycite_revision_entity

  # fetch aggregated fields from the table: "mycite_revision_entity"
  myciteRevisionEntityAggregate(
    # distinct select on columns
    distinct_on: [mycite_revision_entity_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mycite_revision_entity_order_by!]

    # filter the rows returned
    where: mycite_revision_entity_bool_exp
  ): mycite_revision_entity_aggregate!

  # fetch data from the table: "named_list" using primary key columns
  namedList(mtid: bigint!): named_list

  # fetch aggregated fields from the table: "named_list"
  namedListAggregate(
    # distinct select on columns
    distinct_on: [named_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [named_list_order_by!]

    # filter the rows returned
    where: named_list_bool_exp
  ): named_list_aggregate!

  # fetch data from the table: "named_list"
  namedLists(
    # distinct select on columns
    distinct_on: [named_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [named_list_order_by!]

    # filter the rows returned
    where: named_list_bool_exp
  ): [named_list!]!

  # fetch data from the table: "not_duplums" using primary key columns
  notDuplums(id: bigint!): not_duplums

  # fetch aggregated fields from the table: "not_duplums"
  notDuplumsAggregate(
    # distinct select on columns
    distinct_on: [not_duplums_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_order_by!]

    # filter the rows returned
    where: not_duplums_bool_exp
  ): not_duplums_aggregate!

  # fetch data from the table: "not_duplums"
  notDuplumses(
    # distinct select on columns
    distinct_on: [not_duplums_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_order_by!]

    # filter the rows returned
    where: not_duplums_bool_exp
  ): [not_duplums!]!

  # fetch data from the table: "not_duplums_not_duplum_ids"
  not_duplums_not_duplum_ids(
    # distinct select on columns
    distinct_on: [not_duplums_not_duplum_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_not_duplum_ids_order_by!]

    # filter the rows returned
    where: not_duplums_not_duplum_ids_bool_exp
  ): [not_duplums_not_duplum_ids!]!

  # fetch aggregated fields from the table: "not_duplums_not_duplum_ids"
  not_duplums_not_duplum_ids_aggregate(
    # distinct select on columns
    distinct_on: [not_duplums_not_duplum_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_not_duplum_ids_order_by!]

    # filter the rows returned
    where: not_duplums_not_duplum_ids_bool_exp
  ): not_duplums_not_duplum_ids_aggregate!

  # fetch data from the table: "organization" using primary key columns
  organization(mtid: bigint!): organization

  # fetch aggregated fields from the table: "organization"
  organizationAggregate(
    # distinct select on columns
    distinct_on: [organization_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_order_by!]

    # filter the rows returned
    where: organization_bool_exp
  ): organization_aggregate!

  # fetch data from the table: "organization_identifier" using primary key columns
  organizationIdentifier(mtid: bigint!): organization_identifier

  # fetch aggregated fields from the table: "organization_identifier"
  organizationIdentifierAggregate(
    # distinct select on columns
    distinct_on: [organization_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_identifier_order_by!]

    # filter the rows returned
    where: organization_identifier_bool_exp
  ): organization_identifier_aggregate!

  # fetch data from the table: "organization_identifier"
  organizationIdentifiers(
    # distinct select on columns
    distinct_on: [organization_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_identifier_order_by!]

    # filter the rows returned
    where: organization_identifier_bool_exp
  ): [organization_identifier!]!

  # fetch aggregated fields from the table: "organization_mab_disciplines"
  organizationMabDisciplinesAggregate(
    # distinct select on columns
    distinct_on: [organization_mab_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_mab_disciplines_order_by!]

    # filter the rows returned
    where: organization_mab_disciplines_bool_exp
  ): organization_mab_disciplines_aggregate!

  # fetch data from the table: "organization_mab_disciplines"
  organizationMabDisciplineses(
    # distinct select on columns
    distinct_on: [organization_mab_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_mab_disciplines_order_by!]

    # filter the rows returned
    where: organization_mab_disciplines_bool_exp
  ): [organization_mab_disciplines!]!

  # fetch data from the table: "organization"
  organizations(
    # distinct select on columns
    distinct_on: [organization_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_order_by!]

    # filter the rows returned
    where: organization_bool_exp
  ): [organization!]!

  # fetch data from the table: "periodical" using primary key columns
  periodical(mtid: bigint!): periodical

  # fetch aggregated fields from the table: "periodical"
  periodicalAggregate(
    # distinct select on columns
    distinct_on: [periodical_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_order_by!]

    # filter the rows returned
    where: periodical_bool_exp
  ): periodical_aggregate!

  # fetch data from the table: "periodical_issn" using primary key columns
  periodicalIssn(mtid: bigint!): periodical_issn

  # fetch aggregated fields from the table: "periodical_issn"
  periodicalIssnAggregate(
    # distinct select on columns
    distinct_on: [periodical_issn_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_issn_order_by!]

    # filter the rows returned
    where: periodical_issn_bool_exp
  ): periodical_issn_aggregate!

  # fetch data from the table: "periodical_issn"
  periodicalIssns(
    # distinct select on columns
    distinct_on: [periodical_issn_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_issn_order_by!]

    # filter the rows returned
    where: periodical_issn_bool_exp
  ): [periodical_issn!]!

  # fetch aggregated fields from the table: "periodical_publishers"
  periodicalPublishersAggregate(
    # distinct select on columns
    distinct_on: [periodical_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_publishers_order_by!]

    # filter the rows returned
    where: periodical_publishers_bool_exp
  ): periodical_publishers_aggregate!

  # fetch data from the table: "periodical_publishers"
  periodicalPublisherses(
    # distinct select on columns
    distinct_on: [periodical_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_publishers_order_by!]

    # filter the rows returned
    where: periodical_publishers_bool_exp
  ): [periodical_publishers!]!

  # fetch aggregated fields from the table: "periodical_subjects_external"
  periodicalSubjectsExternalAggregate(
    # distinct select on columns
    distinct_on: [periodical_subjects_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_subjects_external_order_by!]

    # filter the rows returned
    where: periodical_subjects_external_bool_exp
  ): periodical_subjects_external_aggregate!

  # fetch data from the table: "periodical_subjects_external"
  periodicalSubjectsExternals(
    # distinct select on columns
    distinct_on: [periodical_subjects_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_subjects_external_order_by!]

    # filter the rows returned
    where: periodical_subjects_external_bool_exp
  ): [periodical_subjects_external!]!

  # fetch data from the table: "periodical"
  periodicals(
    # distinct select on columns
    distinct_on: [periodical_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_order_by!]

    # filter the rows returned
    where: periodical_bool_exp
  ): [periodical!]!

  # fetch data from the table: "project" using primary key columns
  project(mtid: bigint!): project

  # fetch aggregated fields from the table: "project"
  projectAggregate(
    # distinct select on columns
    distinct_on: [project_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [project_order_by!]

    # filter the rows returned
    where: project_bool_exp
  ): project_aggregate!

  # fetch data from the table: "project"
  projects(
    # distinct select on columns
    distinct_on: [project_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [project_order_by!]

    # filter the rows returned
    where: project_bool_exp
  ): [project!]!

  # fetch data from the table: "pub_fixer_log" using primary key columns
  pubFixerLog(id: bigint!): pub_fixer_log

  # fetch aggregated fields from the table: "pub_fixer_log"
  pubFixerLogAggregate(
    # distinct select on columns
    distinct_on: [pub_fixer_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [pub_fixer_log_order_by!]

    # filter the rows returned
    where: pub_fixer_log_bool_exp
  ): pub_fixer_log_aggregate!

  # fetch data from the table: "pub_fixer_log"
  pubFixerLogs(
    # distinct select on columns
    distinct_on: [pub_fixer_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [pub_fixer_log_order_by!]

    # filter the rows returned
    where: pub_fixer_log_bool_exp
  ): [pub_fixer_log!]!

  # fetch data from the table: "publication" using primary key columns
  publication(mtid: bigint!): publication

  # fetch aggregated fields from the table: "publication"
  publicationAggregate(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): publication_aggregate!

  # fetch data from the table: "publication_authors" using primary key columns
  publicationAuthors(authorsMtid: bigint!, publicationMtid: bigint!): publication_authors

  # fetch aggregated fields from the table: "publication_authors"
  publicationAuthorsAggregate(
    # distinct select on columns
    distinct_on: [publication_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_authors_order_by!]

    # filter the rows returned
    where: publication_authors_bool_exp
  ): publication_authors_aggregate!

  # fetch data from the table: "publication_authors"
  publicationAuthorses(
    # distinct select on columns
    distinct_on: [publication_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_authors_order_by!]

    # filter the rows returned
    where: publication_authors_bool_exp
  ): [publication_authors!]!

  # fetch data from the table: "publication_direct_institutes" using primary key columns
  publicationDirectInstitutes(directInstitutesMtid: bigint!, publicationMtid: bigint!): publication_direct_institutes

  # fetch aggregated fields from the table: "publication_direct_institutes"
  publicationDirectInstitutesAggregate(
    # distinct select on columns
    distinct_on: [publication_direct_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_direct_institutes_order_by!]

    # filter the rows returned
    where: publication_direct_institutes_bool_exp
  ): publication_direct_institutes_aggregate!

  # fetch data from the table: "publication_direct_institutes"
  publicationDirectInstituteses(
    # distinct select on columns
    distinct_on: [publication_direct_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_direct_institutes_order_by!]

    # filter the rows returned
    where: publication_direct_institutes_bool_exp
  ): [publication_direct_institutes!]!

  # fetch aggregated fields from the table: "publication_files"
  publicationFilesAggregate(
    # distinct select on columns
    distinct_on: [publication_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_files_order_by!]

    # filter the rows returned
    where: publication_files_bool_exp
  ): publication_files_aggregate!

  # fetch data from the table: "publication_files"
  publicationFileses(
    # distinct select on columns
    distinct_on: [publication_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_files_order_by!]

    # filter the rows returned
    where: publication_files_bool_exp
  ): [publication_files!]!

  # fetch data from the table: "publication_identifier" using primary key columns
  publicationIdentifier(mtid: bigint!): publication_identifier

  # fetch aggregated fields from the table: "publication_identifier"
  publicationIdentifierAggregate(
    # distinct select on columns
    distinct_on: [publication_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_identifier_order_by!]

    # filter the rows returned
    where: publication_identifier_bool_exp
  ): publication_identifier_aggregate!

  # fetch data from the table: "publication_identifier"
  publicationIdentifiers(
    # distinct select on columns
    distinct_on: [publication_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_identifier_order_by!]

    # filter the rows returned
    where: publication_identifier_bool_exp
  ): [publication_identifier!]!

  # fetch data from the table: "publication_institutes" using primary key columns
  publicationInstitutes(institutesMtid: bigint!, publicationMtid: bigint!): publication_institutes

  # fetch aggregated fields from the table: "publication_institutes"
  publicationInstitutesAggregate(
    # distinct select on columns
    distinct_on: [publication_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_institutes_order_by!]

    # filter the rows returned
    where: publication_institutes_bool_exp
  ): publication_institutes_aggregate!

  # fetch data from the table: "publication_institutes"
  publicationInstituteses(
    # distinct select on columns
    distinct_on: [publication_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_institutes_order_by!]

    # filter the rows returned
    where: publication_institutes_bool_exp
  ): [publication_institutes!]!

  # fetch aggregated fields from the table: "publication_keywords"
  publicationKeywordsAggregate(
    # distinct select on columns
    distinct_on: [publication_keywords_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_keywords_order_by!]

    # filter the rows returned
    where: publication_keywords_bool_exp
  ): publication_keywords_aggregate!

  # fetch data from the table: "publication_keywords"
  publicationKeywordses(
    # distinct select on columns
    distinct_on: [publication_keywords_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_keywords_order_by!]

    # filter the rows returned
    where: publication_keywords_bool_exp
  ): [publication_keywords!]!

  # fetch aggregated fields from the table: "publication_languages"
  publicationLanguagesAggregate(
    # distinct select on columns
    distinct_on: [publication_languages_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_languages_order_by!]

    # filter the rows returned
    where: publication_languages_bool_exp
  ): publication_languages_aggregate!

  # fetch data from the table: "publication_languages"
  publicationLanguageses(
    # distinct select on columns
    distinct_on: [publication_languages_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_languages_order_by!]

    # filter the rows returned
    where: publication_languages_bool_exp
  ): [publication_languages!]!

  # fetch aggregated fields from the table: "publication_old_org_authors"
  publicationOldOrgAuthorsAggregate(
    # distinct select on columns
    distinct_on: [publication_old_org_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_old_org_authors_order_by!]

    # filter the rows returned
    where: publication_old_org_authors_bool_exp
  ): publication_old_org_authors_aggregate!

  # fetch data from the table: "publication_old_org_authors"
  publicationOldOrgAuthorses(
    # distinct select on columns
    distinct_on: [publication_old_org_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_old_org_authors_order_by!]

    # filter the rows returned
    where: publication_old_org_authors_bool_exp
  ): [publication_old_org_authors!]!

  # fetch data from the table: "publication_owner_authors" using primary key columns
  publicationOwnerAuthors(ownerAuthorsMtid: bigint!, publicationMtid: bigint!): publication_owner_authors

  # fetch aggregated fields from the table: "publication_owner_authors"
  publicationOwnerAuthorsAggregate(
    # distinct select on columns
    distinct_on: [publication_owner_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_authors_order_by!]

    # filter the rows returned
    where: publication_owner_authors_bool_exp
  ): publication_owner_authors_aggregate!

  # fetch data from the table: "publication_owner_authors"
  publicationOwnerAuthorses(
    # distinct select on columns
    distinct_on: [publication_owner_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_authors_order_by!]

    # filter the rows returned
    where: publication_owner_authors_bool_exp
  ): [publication_owner_authors!]!

  # fetch data from the table: "publication_owner_institutes" using primary key columns
  publicationOwnerInstitutes(ownerInstitutesMtid: bigint!, publicationMtid: bigint!): publication_owner_institutes

  # fetch aggregated fields from the table: "publication_owner_institutes"
  publicationOwnerInstitutesAggregate(
    # distinct select on columns
    distinct_on: [publication_owner_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_institutes_order_by!]

    # filter the rows returned
    where: publication_owner_institutes_bool_exp
  ): publication_owner_institutes_aggregate!

  # fetch data from the table: "publication_owner_institutes"
  publicationOwnerInstituteses(
    # distinct select on columns
    distinct_on: [publication_owner_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_institutes_order_by!]

    # filter the rows returned
    where: publication_owner_institutes_bool_exp
  ): [publication_owner_institutes!]!

  # fetch aggregated fields from the table: "publication_published_at"
  publicationPublishedAtAggregate(
    # distinct select on columns
    distinct_on: [publication_published_at_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_published_at_order_by!]

    # filter the rows returned
    where: publication_published_at_bool_exp
  ): publication_published_at_aggregate!

  # fetch data from the table: "publication_published_at"
  publicationPublishedAts(
    # distinct select on columns
    distinct_on: [publication_published_at_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_published_at_order_by!]

    # filter the rows returned
    where: publication_published_at_bool_exp
  ): [publication_published_at!]!

  # fetch aggregated fields from the table: "publication_publishers"
  publicationPublishersAggregate(
    # distinct select on columns
    distinct_on: [publication_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_publishers_order_by!]

    # filter the rows returned
    where: publication_publishers_bool_exp
  ): publication_publishers_aggregate!

  # fetch data from the table: "publication_publishers"
  publicationPublisherses(
    # distinct select on columns
    distinct_on: [publication_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_publishers_order_by!]

    # filter the rows returned
    where: publication_publishers_bool_exp
  ): [publication_publishers!]!

  # fetch aggregated fields from the table: "publication_ratings"
  publicationRatingsAggregate(
    # distinct select on columns
    distinct_on: [publication_ratings_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_ratings_order_by!]

    # filter the rows returned
    where: publication_ratings_bool_exp
  ): publication_ratings_aggregate!

  # fetch data from the table: "publication_ratings"
  publicationRatingses(
    # distinct select on columns
    distinct_on: [publication_ratings_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_ratings_order_by!]

    # filter the rows returned
    where: publication_ratings_bool_exp
  ): [publication_ratings!]!

  # fetch data from the table: "publication_source_type" using primary key columns
  publicationSourceType(mtid: bigint!): publication_source_type

  # fetch aggregated fields from the table: "publication_source_type"
  publicationSourceTypeAggregate(
    # distinct select on columns
    distinct_on: [publication_source_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_source_type_order_by!]

    # filter the rows returned
    where: publication_source_type_bool_exp
  ): publication_source_type_aggregate!

  # fetch data from the table: "publication_source_type"
  publicationSourceTypes(
    # distinct select on columns
    distinct_on: [publication_source_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_source_type_order_by!]

    # filter the rows returned
    where: publication_source_type_bool_exp
  ): [publication_source_type!]!

  # fetch aggregated fields from the table: "publication_subjects"
  publicationSubjectsAggregate(
    # distinct select on columns
    distinct_on: [publication_subjects_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_subjects_order_by!]

    # filter the rows returned
    where: publication_subjects_bool_exp
  ): publication_subjects_aggregate!

  # fetch data from the table: "publication_subjects"
  publicationSubjectses(
    # distinct select on columns
    distinct_on: [publication_subjects_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_subjects_order_by!]

    # filter the rows returned
    where: publication_subjects_bool_exp
  ): [publication_subjects!]!

  # fetch data from the table: "publication_type" using primary key columns
  publicationType(mtid: bigint!): publication_type

  # fetch aggregated fields from the table: "publication_type"
  publicationTypeAggregate(
    # distinct select on columns
    distinct_on: [publication_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_type_order_by!]

    # filter the rows returned
    where: publication_type_bool_exp
  ): publication_type_aggregate!

  # fetch data from the table: "publication_type"
  publicationTypes(
    # distinct select on columns
    distinct_on: [publication_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_type_order_by!]

    # filter the rows returned
    where: publication_type_bool_exp
  ): [publication_type!]!

  # fetch data from the table: "publication_owners"
  publication_owners(
    # distinct select on columns
    distinct_on: [publication_owners_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owners_order_by!]

    # filter the rows returned
    where: publication_owners_bool_exp
  ): [publication_owners!]!

  # fetch aggregated fields from the table: "publication_owners"
  publication_owners_aggregate(
    # distinct select on columns
    distinct_on: [publication_owners_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owners_order_by!]

    # filter the rows returned
    where: publication_owners_bool_exp
  ): publication_owners_aggregate!

  # fetch data from the table: "publication"
  publications(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): [publication!]!

  # fetch data from the table: "publisher" using primary key columns
  publisher(mtid: bigint!): publisher

  # fetch aggregated fields from the table: "publisher"
  publisherAggregate(
    # distinct select on columns
    distinct_on: [publisher_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_order_by!]

    # filter the rows returned
    where: publisher_bool_exp
  ): publisher_aggregate!

  # fetch aggregated fields from the table: "publisher_cities"
  publisherCitiesAggregate(
    # distinct select on columns
    distinct_on: [publisher_cities_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_cities_order_by!]

    # filter the rows returned
    where: publisher_cities_bool_exp
  ): publisher_cities_aggregate!

  # fetch data from the table: "publisher_cities"
  publisherCitieses(
    # distinct select on columns
    distinct_on: [publisher_cities_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_cities_order_by!]

    # filter the rows returned
    where: publisher_cities_bool_exp
  ): [publisher_cities!]!

  # fetch data from the table: "publisher"
  publishers(
    # distinct select on columns
    distinct_on: [publisher_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_order_by!]

    # filter the rows returned
    where: publisher_bool_exp
  ): [publisher!]!

  # fetch data from the table: "query_info" using primary key columns
  queryInfo(mtid: bigint!): query_info

  # fetch aggregated fields from the table: "query_info"
  queryInfoAggregate(
    # distinct select on columns
    distinct_on: [query_info_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [query_info_order_by!]

    # filter the rows returned
    where: query_info_bool_exp
  ): query_info_aggregate!

  # fetch data from the table: "query_info"
  queryInfoes(
    # distinct select on columns
    distinct_on: [query_info_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [query_info_order_by!]

    # filter the rows returned
    where: query_info_bool_exp
  ): [query_info!]!

  # fetch data from the table: "queued_background_job" using primary key columns
  queuedBackgroundJob(id: bigint!): queued_background_job

  # fetch aggregated fields from the table: "queued_background_job"
  queuedBackgroundJobAggregate(
    # distinct select on columns
    distinct_on: [queued_background_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [queued_background_job_order_by!]

    # filter the rows returned
    where: queued_background_job_bool_exp
  ): queued_background_job_aggregate!

  # fetch data from the table: "queued_background_job"
  queuedBackgroundJobs(
    # distinct select on columns
    distinct_on: [queued_background_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [queued_background_job_order_by!]

    # filter the rows returned
    where: queued_background_job_bool_exp
  ): [queued_background_job!]!

  # fetch data from the table: "rating" using primary key columns
  rating(mtid: bigint!): rating

  # fetch aggregated fields from the table: "rating"
  ratingAggregate(
    # distinct select on columns
    distinct_on: [rating_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_order_by!]

    # filter the rows returned
    where: rating_bool_exp
  ): rating_aggregate!

  # fetch data from the table: "rating_type" using primary key columns
  ratingType(mtid: bigint!): rating_type

  # fetch aggregated fields from the table: "rating_type"
  ratingTypeAggregate(
    # distinct select on columns
    distinct_on: [rating_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_type_order_by!]

    # filter the rows returned
    where: rating_type_bool_exp
  ): rating_type_aggregate!

  # fetch data from the table: "rating_type"
  ratingTypes(
    # distinct select on columns
    distinct_on: [rating_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_type_order_by!]

    # filter the rows returned
    where: rating_type_bool_exp
  ): [rating_type!]!

  # fetch data from the table: "rating"
  ratings(
    # distinct select on columns
    distinct_on: [rating_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_order_by!]

    # filter the rows returned
    where: rating_bool_exp
  ): [rating!]!

  # fetch data from the table: "recalculate_institute_ownerships_request" using primary key columns
  recalculateInstituteOwnershipsRequest(mtid: bigint!): recalculate_institute_ownerships_request

  # fetch data from the table: "recalculate_institute_ownerships_request_affected_institutes" using primary key columns
  recalculateInstituteOwnershipsRequestAffectedInstitutes(affectedInstitutesMtid: bigint!, recalculateInstituteOwnershipsRequestMtid: bigint!): recalculate_institute_ownerships_request_affected_institutes

  # fetch aggregated fields from the table: "recalculate_institute_ownerships_request_affected_institutes"
  recalculateInstituteOwnershipsRequestAffectedInstitutesAggregate(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_affected_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_affected_institutes_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  ): recalculate_institute_ownerships_request_affected_institutes_aggregate!

  # fetch data from the table: "recalculate_institute_ownerships_request_affected_institutes"
  recalculateInstituteOwnershipsRequestAffectedInstituteses(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_affected_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_affected_institutes_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  ): [recalculate_institute_ownerships_request_affected_institutes!]!

  # fetch aggregated fields from the table: "recalculate_institute_ownerships_request"
  recalculateInstituteOwnershipsRequestAggregate(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_bool_exp
  ): recalculate_institute_ownerships_request_aggregate!

  # fetch data from the table: "recalculate_institute_ownerships_request"
  recalculateInstituteOwnershipsRequests(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_bool_exp
  ): [recalculate_institute_ownerships_request!]!

  # fetch data from the table: "reference" using primary key columns
  reference(mtid: bigint!): reference

  # fetch aggregated fields from the table: "reference"
  referenceAggregate(
    # distinct select on columns
    distinct_on: [reference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reference_order_by!]

    # filter the rows returned
    where: reference_bool_exp
  ): reference_aggregate!

  # fetch data from the table: "reference"
  references(
    # distinct select on columns
    distinct_on: [reference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reference_order_by!]

    # filter the rows returned
    where: reference_bool_exp
  ): [reference!]!

  # fetch data from the table: "refresh_item" using primary key columns
  refreshItem(id: String!): refresh_item

  # fetch aggregated fields from the table: "refresh_item"
  refreshItemAggregate(
    # distinct select on columns
    distinct_on: [refresh_item_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_item_order_by!]

    # filter the rows returned
    where: refresh_item_bool_exp
  ): refresh_item_aggregate!

  # fetch data from the table: "refresh_item"
  refreshItems(
    # distinct select on columns
    distinct_on: [refresh_item_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_item_order_by!]

    # filter the rows returned
    where: refresh_item_bool_exp
  ): [refresh_item!]!

  # fetch data from the table: "refresh_log" using primary key columns
  refreshLog(id: bigint!): refresh_log

  # fetch aggregated fields from the table: "refresh_log"
  refreshLogAggregate(
    # distinct select on columns
    distinct_on: [refresh_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_log_order_by!]

    # filter the rows returned
    where: refresh_log_bool_exp
  ): refresh_log_aggregate!

  # fetch data from the table: "refresh_log"
  refreshLogs(
    # distinct select on columns
    distinct_on: [refresh_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_log_order_by!]

    # filter the rows returned
    where: refresh_log_bool_exp
  ): [refresh_log!]!

  # fetch data from the table: "reorg" using primary key columns
  reorg(mtid: bigint!): reorg

  # fetch aggregated fields from the table: "reorg"
  reorgAggregate(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): reorg_aggregate!

  # fetch data from the table: "reorg_type" using primary key columns
  reorgType(mtid: bigint!): reorg_type

  # fetch aggregated fields from the table: "reorg_type"
  reorgTypeAggregate(
    # distinct select on columns
    distinct_on: [reorg_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_type_order_by!]

    # filter the rows returned
    where: reorg_type_bool_exp
  ): reorg_type_aggregate!

  # fetch data from the table: "reorg_type"
  reorgTypes(
    # distinct select on columns
    distinct_on: [reorg_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_type_order_by!]

    # filter the rows returned
    where: reorg_type_bool_exp
  ): [reorg_type!]!

  # fetch data from the table: "reorg"
  reorgs(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): [reorg!]!

  # fetch data from the table: "report" using primary key columns
  report(mtid: bigint!): report

  # fetch aggregated fields from the table: "report"
  reportAggregate(
    # distinct select on columns
    distinct_on: [report_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_order_by!]

    # filter the rows returned
    where: report_bool_exp
  ): report_aggregate!

  # fetch data from the table: "report_content" using primary key columns
  reportContent(mtid: bigint!): report_content

  # fetch aggregated fields from the table: "report_content"
  reportContentAggregate(
    # distinct select on columns
    distinct_on: [report_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_order_by!]

    # filter the rows returned
    where: report_content_bool_exp
  ): report_content_aggregate!

  # fetch aggregated fields from the table: "report_content_file_content"
  reportContentFileContentAggregate(
    # distinct select on columns
    distinct_on: [report_content_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_file_content_order_by!]

    # filter the rows returned
    where: report_content_file_content_bool_exp
  ): report_content_file_content_aggregate!

  # fetch data from the table: "report_content_file_content"
  reportContentFileContents(
    # distinct select on columns
    distinct_on: [report_content_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_file_content_order_by!]

    # filter the rows returned
    where: report_content_file_content_bool_exp
  ): [report_content_file_content!]!

  # fetch aggregated fields from the table: "report_contents"
  reportContentJoinAggregate(
    # distinct select on columns
    distinct_on: [report_contents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_contents_order_by!]

    # filter the rows returned
    where: report_contents_bool_exp
  ): report_contents_aggregate!

  # fetch data from the table: "report_contents"
  reportContentJoins(
    # distinct select on columns
    distinct_on: [report_contents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_contents_order_by!]

    # filter the rows returned
    where: report_contents_bool_exp
  ): [report_contents!]!

  # fetch data from the table: "report_content"
  reportContents(
    # distinct select on columns
    distinct_on: [report_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_order_by!]

    # filter the rows returned
    where: report_content_bool_exp
  ): [report_content!]!

  # fetch data from the table: "report_parameter" using primary key columns
  reportParameter(mtid: bigint!): report_parameter

  # fetch aggregated fields from the table: "report_parameter"
  reportParameterAggregate(
    # distinct select on columns
    distinct_on: [report_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_parameter_order_by!]

    # filter the rows returned
    where: report_parameter_bool_exp
  ): report_parameter_aggregate!

  # fetch data from the table: "report_parameter"
  reportParameters(
    # distinct select on columns
    distinct_on: [report_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_parameter_order_by!]

    # filter the rows returned
    where: report_parameter_bool_exp
  ): [report_parameter!]!

  # fetch data from the table: "report_request" using primary key columns
  reportRequest(mtid: bigint!): report_request

  # fetch aggregated fields from the table: "report_request"
  reportRequestAggregate(
    # distinct select on columns
    distinct_on: [report_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_order_by!]

    # filter the rows returned
    where: report_request_bool_exp
  ): report_request_aggregate!

  # fetch aggregated fields from the table: "report_request_queries"
  reportRequestQueriesAggregate(
    # distinct select on columns
    distinct_on: [report_request_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_queries_order_by!]

    # filter the rows returned
    where: report_request_queries_bool_exp
  ): report_request_queries_aggregate!

  # fetch data from the table: "report_request_queries"
  reportRequestQuerieses(
    # distinct select on columns
    distinct_on: [report_request_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_queries_order_by!]

    # filter the rows returned
    where: report_request_queries_bool_exp
  ): [report_request_queries!]!

  # fetch data from the table: "report_request"
  reportRequests(
    # distinct select on columns
    distinct_on: [report_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_order_by!]

    # filter the rows returned
    where: report_request_bool_exp
  ): [report_request!]!

  # fetch data from the table: "report_template" using primary key columns
  reportTemplate(mtid: bigint!): report_template

  # fetch aggregated fields from the table: "report_template"
  reportTemplateAggregate(
    # distinct select on columns
    distinct_on: [report_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_order_by!]

    # filter the rows returned
    where: report_template_bool_exp
  ): report_template_aggregate!

  # fetch aggregated fields from the table: "report_template_default_queries"
  reportTemplateDefaultQueriesAggregate(
    # distinct select on columns
    distinct_on: [report_template_default_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_default_queries_order_by!]

    # filter the rows returned
    where: report_template_default_queries_bool_exp
  ): report_template_default_queries_aggregate!

  # fetch data from the table: "report_template_default_queries"
  reportTemplateDefaultQuerieses(
    # distinct select on columns
    distinct_on: [report_template_default_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_default_queries_order_by!]

    # filter the rows returned
    where: report_template_default_queries_bool_exp
  ): [report_template_default_queries!]!

  # fetch aggregated fields from the table: "report_template_language_files"
  reportTemplateLanguageFilesAggregate(
    # distinct select on columns
    distinct_on: [report_template_language_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_language_files_order_by!]

    # filter the rows returned
    where: report_template_language_files_bool_exp
  ): report_template_language_files_aggregate!

  # fetch data from the table: "report_template_language_files"
  reportTemplateLanguageFileses(
    # distinct select on columns
    distinct_on: [report_template_language_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_language_files_order_by!]

    # filter the rows returned
    where: report_template_language_files_bool_exp
  ): [report_template_language_files!]!

  # fetch data from the table: "report_template_parameter_select" using primary key columns
  reportTemplateParameterSelect(mtid: bigint!): report_template_parameter_select

  # fetch aggregated fields from the table: "report_template_parameter_select"
  reportTemplateParameterSelectAggregate(
    # distinct select on columns
    distinct_on: [report_template_parameter_select_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_parameter_select_order_by!]

    # filter the rows returned
    where: report_template_parameter_select_bool_exp
  ): report_template_parameter_select_aggregate!

  # fetch data from the table: "report_template_parameter_select"
  reportTemplateParameterSelects(
    # distinct select on columns
    distinct_on: [report_template_parameter_select_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_parameter_select_order_by!]

    # filter the rows returned
    where: report_template_parameter_select_bool_exp
  ): [report_template_parameter_select!]!

  # fetch data from the table: "report_template"
  reportTemplates(
    # distinct select on columns
    distinct_on: [report_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_order_by!]

    # filter the rows returned
    where: report_template_bool_exp
  ): [report_template!]!

  # fetch data from the table: "report_xml" using primary key columns
  reportXml(mtid: bigint!): report_xml

  # fetch aggregated fields from the table: "report_xml"
  reportXmlAggregate(
    # distinct select on columns
    distinct_on: [report_xml_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_xml_order_by!]

    # filter the rows returned
    where: report_xml_bool_exp
  ): report_xml_aggregate!

  # fetch data from the table: "report_xml"
  reportXmls(
    # distinct select on columns
    distinct_on: [report_xml_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_xml_order_by!]

    # filter the rows returned
    where: report_xml_bool_exp
  ): [report_xml!]!

  # fetch data from the table: "report"
  reports(
    # distinct select on columns
    distinct_on: [report_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_order_by!]

    # filter the rows returned
    where: report_bool_exp
  ): [report!]!

  # fetch data from the table: "ris_import_error_detail" using primary key columns
  risImportErrorDetail(mtid: bigint!): ris_import_error_detail

  # fetch aggregated fields from the table: "ris_import_error_detail"
  risImportErrorDetailAggregate(
    # distinct select on columns
    distinct_on: [ris_import_error_detail_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ris_import_error_detail_order_by!]

    # filter the rows returned
    where: ris_import_error_detail_bool_exp
  ): ris_import_error_detail_aggregate!

  # fetch data from the table: "ris_import_error_detail"
  risImportErrorDetails(
    # distinct select on columns
    distinct_on: [ris_import_error_detail_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ris_import_error_detail_order_by!]

    # filter the rows returned
    where: ris_import_error_detail_bool_exp
  ): [ris_import_error_detail!]!

  # fetch data from the table: "series_volume" using primary key columns
  seriesVolume(mtid: bigint!): series_volume

  # fetch aggregated fields from the table: "series_volume"
  seriesVolumeAggregate(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): series_volume_aggregate!

  # fetch data from the table: "series_volume"
  seriesVolumes(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): [series_volume!]!

  # fetch data from the table: "shib_id_provider" using primary key columns
  shibIdProvider(mtid: bigint!): shib_id_provider

  # fetch aggregated fields from the table: "shib_id_provider"
  shibIdProviderAggregate(
    # distinct select on columns
    distinct_on: [shib_id_provider_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [shib_id_provider_order_by!]

    # filter the rows returned
    where: shib_id_provider_bool_exp
  ): shib_id_provider_aggregate!

  # fetch data from the table: "shib_id_provider"
  shibIdProviders(
    # distinct select on columns
    distinct_on: [shib_id_provider_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [shib_id_provider_order_by!]

    # filter the rows returned
    where: shib_id_provider_bool_exp
  ): [shib_id_provider!]!

  # fetch data from the table: "smart_query"
  smartQueries(
    # distinct select on columns
    distinct_on: [smart_query_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_order_by!]

    # filter the rows returned
    where: smart_query_bool_exp
  ): [smart_query!]!

  # fetch data from the table: "smart_query" using primary key columns
  smartQuery(mtid: bigint!): smart_query

  # fetch aggregated fields from the table: "smart_query"
  smartQueryAggregate(
    # distinct select on columns
    distinct_on: [smart_query_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_order_by!]

    # filter the rows returned
    where: smart_query_bool_exp
  ): smart_query_aggregate!

  # fetch data from the table: "smart_query_cond" using primary key columns
  smartQueryCond(mtid: bigint!): smart_query_cond

  # fetch aggregated fields from the table: "smart_query_cond"
  smartQueryCondAggregate(
    # distinct select on columns
    distinct_on: [smart_query_cond_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_cond_order_by!]

    # filter the rows returned
    where: smart_query_cond_bool_exp
  ): smart_query_cond_aggregate!

  # fetch data from the table: "smart_query_cond"
  smartQueryConds(
    # distinct select on columns
    distinct_on: [smart_query_cond_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_cond_order_by!]

    # filter the rows returned
    where: smart_query_cond_bool_exp
  ): [smart_query_cond!]!

  # fetch data from the table: "smart_query_group" using primary key columns
  smartQueryGroup(id: bigint!): smart_query_group

  # fetch aggregated fields from the table: "smart_query_group"
  smartQueryGroupAggregate(
    # distinct select on columns
    distinct_on: [smart_query_group_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_group_order_by!]

    # filter the rows returned
    where: smart_query_group_bool_exp
  ): smart_query_group_aggregate!

  # fetch data from the table: "smart_query_group"
  smartQueryGroups(
    # distinct select on columns
    distinct_on: [smart_query_group_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_group_order_by!]

    # filter the rows returned
    where: smart_query_group_bool_exp
  ): [smart_query_group!]!

  # fetch data from the table: "smart_query_sort" using primary key columns
  smartQuerySort(mtid: bigint!): smart_query_sort

  # fetch aggregated fields from the table: "smart_query_sort"
  smartQuerySortAggregate(
    # distinct select on columns
    distinct_on: [smart_query_sort_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_sort_order_by!]

    # filter the rows returned
    where: smart_query_sort_bool_exp
  ): smart_query_sort_aggregate!

  # fetch data from the table: "smart_query_sort"
  smartQuerySorts(
    # distinct select on columns
    distinct_on: [smart_query_sort_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_sort_order_by!]

    # filter the rows returned
    where: smart_query_sort_bool_exp
  ): [smart_query_sort!]!

  # fetch data from the table: "snippet_cache" using primary key columns
  snippetCache(mtid: bigint!, otype: String!): snippet_cache

  # fetch aggregated fields from the table: "snippet_cache"
  snippetCacheAggregate(
    # distinct select on columns
    distinct_on: [snippet_cache_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_order_by!]

    # filter the rows returned
    where: snippet_cache_bool_exp
  ): snippet_cache_aggregate!

  # fetch data from the table: "snippet_cache_status" using primary key columns
  snippetCacheStatus(mtid: bigint!, otype: String!): snippet_cache_status

  # fetch aggregated fields from the table: "snippet_cache_status"
  snippetCacheStatusAggregate(
    # distinct select on columns
    distinct_on: [snippet_cache_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_status_order_by!]

    # filter the rows returned
    where: snippet_cache_status_bool_exp
  ): snippet_cache_status_aggregate!

  # fetch data from the table: "snippet_cache_status"
  snippetCacheStatuses(
    # distinct select on columns
    distinct_on: [snippet_cache_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_status_order_by!]

    # filter the rows returned
    where: snippet_cache_status_bool_exp
  ): [snippet_cache_status!]!

  # fetch data from the table: "snippet_cache"
  snippetCaches(
    # distinct select on columns
    distinct_on: [snippet_cache_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_order_by!]

    # filter the rows returned
    where: snippet_cache_bool_exp
  ): [snippet_cache!]!

  # fetch data from the table: "source" using primary key columns
  source(mtid: bigint!): source

  # fetch aggregated fields from the table: "source"
  sourceAggregate(
    # distinct select on columns
    distinct_on: [source_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_order_by!]

    # filter the rows returned
    where: source_bool_exp
  ): source_aggregate!

  # fetch aggregated fields from the table: "source_allowed_institutes"
  sourceAllowedInstitutesAggregate(
    # distinct select on columns
    distinct_on: [source_allowed_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_allowed_institutes_order_by!]

    # filter the rows returned
    where: source_allowed_institutes_bool_exp
  ): source_allowed_institutes_aggregate!

  # fetch data from the table: "source_allowed_institutes"
  sourceAllowedInstituteses(
    # distinct select on columns
    distinct_on: [source_allowed_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_allowed_institutes_order_by!]

    # filter the rows returned
    where: source_allowed_institutes_bool_exp
  ): [source_allowed_institutes!]!

  # fetch data from the table: "source"
  sources(
    # distinct select on columns
    distinct_on: [source_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_order_by!]

    # filter the rows returned
    where: source_bool_exp
  ): [source!]!

  # fetch data from the table: "sub_type" using primary key columns
  subType(mtid: bigint!): sub_type

  # fetch aggregated fields from the table: "sub_type"
  subTypeAggregate(
    # distinct select on columns
    distinct_on: [sub_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [sub_type_order_by!]

    # filter the rows returned
    where: sub_type_bool_exp
  ): sub_type_aggregate!

  # fetch data from the table: "sub_type"
  subTypes(
    # distinct select on columns
    distinct_on: [sub_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [sub_type_order_by!]

    # filter the rows returned
    where: sub_type_bool_exp
  ): [sub_type!]!

  # fetch data from the table: "ticket" using primary key columns
  ticket(mtid: bigint!): ticket

  # fetch aggregated fields from the table: "ticket"
  ticketAggregate(
    # distinct select on columns
    distinct_on: [ticket_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_order_by!]

    # filter the rows returned
    where: ticket_bool_exp
  ): ticket_aggregate!

  # fetch data from the table: "ticket_authors" using primary key columns
  ticketAuthors(authorsMtid: bigint!, ticketMtid: bigint!): ticket_authors

  # fetch aggregated fields from the table: "ticket_authors"
  ticketAuthorsAggregate(
    # distinct select on columns
    distinct_on: [ticket_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_authors_order_by!]

    # filter the rows returned
    where: ticket_authors_bool_exp
  ): ticket_authors_aggregate!

  # fetch data from the table: "ticket_authors"
  ticketAuthorses(
    # distinct select on columns
    distinct_on: [ticket_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_authors_order_by!]

    # filter the rows returned
    where: ticket_authors_bool_exp
  ): [ticket_authors!]!

  # fetch data from the table: "ticket_institutes" using primary key columns
  ticketInstitutes(institutesMtid: bigint!, ticketMtid: bigint!): ticket_institutes

  # fetch aggregated fields from the table: "ticket_institutes"
  ticketInstitutesAggregate(
    # distinct select on columns
    distinct_on: [ticket_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_institutes_order_by!]

    # filter the rows returned
    where: ticket_institutes_bool_exp
  ): ticket_institutes_aggregate!

  # fetch data from the table: "ticket_institutes"
  ticketInstituteses(
    # distinct select on columns
    distinct_on: [ticket_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_institutes_order_by!]

    # filter the rows returned
    where: ticket_institutes_bool_exp
  ): [ticket_institutes!]!

  # fetch data from the table: "ticket"
  tickets(
    # distinct select on columns
    distinct_on: [ticket_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_order_by!]

    # filter the rows returned
    where: ticket_bool_exp
  ): [ticket!]!

  # fetch data from the table: "uploaded_file" using primary key columns
  uploadedFile(mtid: bigint!): uploaded_file

  # fetch aggregated fields from the table: "uploaded_file"
  uploadedFileAggregate(
    # distinct select on columns
    distinct_on: [uploaded_file_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_order_by!]

    # filter the rows returned
    where: uploaded_file_bool_exp
  ): uploaded_file_aggregate!

  # fetch aggregated fields from the table: "uploaded_file_file_content"
  uploadedFileFileContentAggregate(
    # distinct select on columns
    distinct_on: [uploaded_file_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_file_content_order_by!]

    # filter the rows returned
    where: uploaded_file_file_content_bool_exp
  ): uploaded_file_file_content_aggregate!

  # fetch data from the table: "uploaded_file_file_content"
  uploadedFileFileContents(
    # distinct select on columns
    distinct_on: [uploaded_file_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_file_content_order_by!]

    # filter the rows returned
    where: uploaded_file_file_content_bool_exp
  ): [uploaded_file_file_content!]!

  # fetch data from the table: "uploaded_file"
  uploadedFiles(
    # distinct select on columns
    distinct_on: [uploaded_file_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_order_by!]

    # filter the rows returned
    where: uploaded_file_bool_exp
  ): [uploaded_file!]!

  # fetch data from the table: "usage_log" using primary key columns
  usageLog(id: bigint!): usage_log

  # fetch aggregated fields from the table: "usage_log"
  usageLogAggregate(
    # distinct select on columns
    distinct_on: [usage_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [usage_log_order_by!]

    # filter the rows returned
    where: usage_log_bool_exp
  ): usage_log_aggregate!

  # fetch data from the table: "usage_log"
  usageLogs(
    # distinct select on columns
    distinct_on: [usage_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [usage_log_order_by!]

    # filter the rows returned
    where: usage_log_bool_exp
  ): [usage_log!]!

  # fetch data from the table: "users" using primary key columns
  user(mtid: bigint!): users

  # fetch aggregated fields from the table: "users"
  userAggregate(
    # distinct select on columns
    distinct_on: [users_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_order_by!]

    # filter the rows returned
    where: users_bool_exp
  ): users_aggregate!

  # fetch data from the table: "user_notification_time" using primary key columns
  userNotificationTime(mtid: bigint!): user_notification_time

  # fetch aggregated fields from the table: "user_notification_time"
  userNotificationTimeAggregate(
    # distinct select on columns
    distinct_on: [user_notification_time_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_notification_time_order_by!]

    # filter the rows returned
    where: user_notification_time_bool_exp
  ): user_notification_time_aggregate!

  # fetch data from the table: "user_notification_time"
  userNotificationTimes(
    # distinct select on columns
    distinct_on: [user_notification_time_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_notification_time_order_by!]

    # filter the rows returned
    where: user_notification_time_bool_exp
  ): [user_notification_time!]!

  # fetch data from the table: "user_preferences" using primary key columns
  userPreferences(mtid: bigint!): user_preferences

  # fetch aggregated fields from the table: "user_preferences"
  userPreferencesAggregate(
    # distinct select on columns
    distinct_on: [user_preferences_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_preferences_order_by!]

    # filter the rows returned
    where: user_preferences_bool_exp
  ): user_preferences_aggregate!

  # fetch data from the table: "user_preferences"
  userPreferenceses(
    # distinct select on columns
    distinct_on: [user_preferences_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_preferences_order_by!]

    # filter the rows returned
    where: user_preferences_bool_exp
  ): [user_preferences!]!

  # fetch data from the table: "users"
  users(
    # distinct select on columns
    distinct_on: [users_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_order_by!]

    # filter the rows returned
    where: users_bool_exp
  ): [users!]!

  # fetch aggregated fields from the table: "users_assistants"
  usersAssistantsAggregate(
    # distinct select on columns
    distinct_on: [users_assistants_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_assistants_order_by!]

    # filter the rows returned
    where: users_assistants_bool_exp
  ): users_assistants_aggregate!

  # fetch data from the table: "users_assistants"
  usersAssistantses(
    # distinct select on columns
    distinct_on: [users_assistants_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_assistants_order_by!]

    # filter the rows returned
    where: users_assistants_bool_exp
  ): [users_assistants!]!

  # fetch aggregated fields from the table: "users_disciplines"
  usersDisciplinesAggregate(
    # distinct select on columns
    distinct_on: [users_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_disciplines_order_by!]

    # filter the rows returned
    where: users_disciplines_bool_exp
  ): users_disciplines_aggregate!

  # fetch data from the table: "users_disciplines"
  usersDisciplineses(
    # distinct select on columns
    distinct_on: [users_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_disciplines_order_by!]

    # filter the rows returned
    where: users_disciplines_bool_exp
  ): [users_disciplines!]!

  # fetch data from the table: "variable" using primary key columns
  variable(mtid: bigint!): variable

  # fetch aggregated fields from the table: "variable"
  variableAggregate(
    # distinct select on columns
    distinct_on: [variable_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [variable_order_by!]

    # filter the rows returned
    where: variable_bool_exp
  ): variable_aggregate!

  # fetch data from the table: "variable"
  variables(
    # distinct select on columns
    distinct_on: [variable_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [variable_order_by!]

    # filter the rows returned
    where: variable_bool_exp
  ): [variable!]!

  # fetch data from the table: "workflow" using primary key columns
  workflow(mtid: bigint!): workflow

  # fetch aggregated fields from the table: "workflow"
  workflowAggregate(
    # distinct select on columns
    distinct_on: [workflow_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_order_by!]

    # filter the rows returned
    where: workflow_bool_exp
  ): workflow_aggregate!

  # fetch data from the table: "workflow_status" using primary key columns
  workflowStatus(mtid: bigint!): workflow_status

  # fetch aggregated fields from the table: "workflow_status"
  workflowStatusAggregate(
    # distinct select on columns
    distinct_on: [workflow_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_status_order_by!]

    # filter the rows returned
    where: workflow_status_bool_exp
  ): workflow_status_aggregate!

  # fetch data from the table: "workflow_status"
  workflowStatuses(
    # distinct select on columns
    distinct_on: [workflow_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_status_order_by!]

    # filter the rows returned
    where: workflow_status_bool_exp
  ): [workflow_status!]!

  # fetch data from the table: "workflow_step" using primary key columns
  workflowStep(mtid: bigint!): workflow_step

  # fetch aggregated fields from the table: "workflow_step"
  workflowStepAggregate(
    # distinct select on columns
    distinct_on: [workflow_step_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_order_by!]

    # filter the rows returned
    where: workflow_step_bool_exp
  ): workflow_step_aggregate!

  # fetch data from the table: "workflow_step_status" using primary key columns
  workflowStepStatus(mtid: bigint!): workflow_step_status

  # fetch aggregated fields from the table: "workflow_step_status"
  workflowStepStatusAggregate(
    # distinct select on columns
    distinct_on: [workflow_step_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_status_order_by!]

    # filter the rows returned
    where: workflow_step_status_bool_exp
  ): workflow_step_status_aggregate!

  # fetch data from the table: "workflow_step_status"
  workflowStepStatuses(
    # distinct select on columns
    distinct_on: [workflow_step_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_status_order_by!]

    # filter the rows returned
    where: workflow_step_status_bool_exp
  ): [workflow_step_status!]!

  # fetch data from the table: "workflow_step"
  workflowSteps(
    # distinct select on columns
    distinct_on: [workflow_step_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_order_by!]

    # filter the rows returned
    where: workflow_step_bool_exp
  ): [workflow_step!]!

  # fetch data from the table: "workflow"
  workflows(
    # distinct select on columns
    distinct_on: [workflow_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_order_by!]

    # filter the rows returned
    where: workflow_bool_exp
  ): [workflow!]!
}

# columns and relationships of "queued_background_job"
type queued_background_job {
  backendName: String
  backgroundHandledObjectId: bigint
  backgroundHandledObjectType: String
  created: timestamp
  id: bigint!
  inQueue: Boolean!
  labelConfigLang: String
  labelConfigOption: String

  # An object relationship
  starterUser: users
  starterUserMtid: bigint

  # An object relationship
  switchedUser: users
  switchedUserMtid: bigint
}

# aggregated selection of "queued_background_job"
type queued_background_job_aggregate {
  aggregate: queued_background_job_aggregate_fields
  nodes: [queued_background_job!]!
}

# aggregate fields of "queued_background_job"
type queued_background_job_aggregate_fields {
  avg: queued_background_job_avg_fields
  count(columns: [queued_background_job_select_column!], distinct: Boolean): Int
  max: queued_background_job_max_fields
  min: queued_background_job_min_fields
  stddev: queued_background_job_stddev_fields
  stddev_pop: queued_background_job_stddev_pop_fields
  stddev_samp: queued_background_job_stddev_samp_fields
  sum: queued_background_job_sum_fields
  var_pop: queued_background_job_var_pop_fields
  var_samp: queued_background_job_var_samp_fields
  variance: queued_background_job_variance_fields
}

# order by aggregate values of table "queued_background_job"
input queued_background_job_aggregate_order_by {
  avg: queued_background_job_avg_order_by
  count: order_by
  max: queued_background_job_max_order_by
  min: queued_background_job_min_order_by
  stddev: queued_background_job_stddev_order_by
  stddev_pop: queued_background_job_stddev_pop_order_by
  stddev_samp: queued_background_job_stddev_samp_order_by
  sum: queued_background_job_sum_order_by
  var_pop: queued_background_job_var_pop_order_by
  var_samp: queued_background_job_var_samp_order_by
  variance: queued_background_job_variance_order_by
}

# input type for inserting array relation for remote table "queued_background_job"
input queued_background_job_arr_rel_insert_input {
  data: [queued_background_job_insert_input!]!
  on_conflict: queued_background_job_on_conflict
}

# aggregate avg on columns
type queued_background_job_avg_fields {
  backgroundHandledObjectId: Float
  id: Float
  starterUserMtid: Float
  switchedUserMtid: Float
}

# order by avg() on columns of table "queued_background_job"
input queued_background_job_avg_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# Boolean expression to filter rows from the table "queued_background_job". All fields are combined with a logical 'AND'.
input queued_background_job_bool_exp {
  _and: [queued_background_job_bool_exp]
  _not: queued_background_job_bool_exp
  _or: [queued_background_job_bool_exp]
  backendName: String_comparison_exp
  backgroundHandledObjectId: bigint_comparison_exp
  backgroundHandledObjectType: String_comparison_exp
  created: timestamp_comparison_exp
  id: bigint_comparison_exp
  inQueue: Boolean_comparison_exp
  labelConfigLang: String_comparison_exp
  labelConfigOption: String_comparison_exp
  starterUser: users_bool_exp
  starterUserMtid: bigint_comparison_exp
  switchedUser: users_bool_exp
  switchedUserMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "queued_background_job"
enum queued_background_job_constraint {
  # unique or primary key constraint
  queued_background_job_pkey
}

# input type for incrementing integer column in table "queued_background_job"
input queued_background_job_inc_input {
  backgroundHandledObjectId: bigint
  id: bigint
  starterUserMtid: bigint
  switchedUserMtid: bigint
}

# input type for inserting data into table "queued_background_job"
input queued_background_job_insert_input {
  backendName: String
  backgroundHandledObjectId: bigint
  backgroundHandledObjectType: String
  created: timestamp
  id: bigint
  inQueue: Boolean
  labelConfigLang: String
  labelConfigOption: String
  starterUser: users_obj_rel_insert_input
  starterUserMtid: bigint
  switchedUser: users_obj_rel_insert_input
  switchedUserMtid: bigint
}

# aggregate max on columns
type queued_background_job_max_fields {
  backendName: String
  backgroundHandledObjectId: bigint
  backgroundHandledObjectType: String
  created: timestamp
  id: bigint
  labelConfigLang: String
  labelConfigOption: String
  starterUserMtid: bigint
  switchedUserMtid: bigint
}

# order by max() on columns of table "queued_background_job"
input queued_background_job_max_order_by {
  backendName: order_by
  backgroundHandledObjectId: order_by
  backgroundHandledObjectType: order_by
  created: order_by
  id: order_by
  labelConfigLang: order_by
  labelConfigOption: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# aggregate min on columns
type queued_background_job_min_fields {
  backendName: String
  backgroundHandledObjectId: bigint
  backgroundHandledObjectType: String
  created: timestamp
  id: bigint
  labelConfigLang: String
  labelConfigOption: String
  starterUserMtid: bigint
  switchedUserMtid: bigint
}

# order by min() on columns of table "queued_background_job"
input queued_background_job_min_order_by {
  backendName: order_by
  backgroundHandledObjectId: order_by
  backgroundHandledObjectType: order_by
  created: order_by
  id: order_by
  labelConfigLang: order_by
  labelConfigOption: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# response of any mutation on the table "queued_background_job"
type queued_background_job_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [queued_background_job!]!
}

# input type for inserting object relation for remote table "queued_background_job"
input queued_background_job_obj_rel_insert_input {
  data: queued_background_job_insert_input!
  on_conflict: queued_background_job_on_conflict
}

# on conflict condition type for table "queued_background_job"
input queued_background_job_on_conflict {
  constraint: queued_background_job_constraint!
  update_columns: [queued_background_job_update_column!]!
  where: queued_background_job_bool_exp
}

# ordering options when selecting data from "queued_background_job"
input queued_background_job_order_by {
  backendName: order_by
  backgroundHandledObjectId: order_by
  backgroundHandledObjectType: order_by
  created: order_by
  id: order_by
  inQueue: order_by
  labelConfigLang: order_by
  labelConfigOption: order_by
  starterUser: users_order_by
  starterUserMtid: order_by
  switchedUser: users_order_by
  switchedUserMtid: order_by
}

# primary key columns input for table: "queued_background_job"
input queued_background_job_pk_columns_input {
  id: bigint!
}

# select columns of table "queued_background_job"
enum queued_background_job_select_column {
  # column name
  backendName

  # column name
  backgroundHandledObjectId

  # column name
  backgroundHandledObjectType

  # column name
  created

  # column name
  id

  # column name
  inQueue

  # column name
  labelConfigLang

  # column name
  labelConfigOption

  # column name
  starterUserMtid

  # column name
  switchedUserMtid
}

# input type for updating data in table "queued_background_job"
input queued_background_job_set_input {
  backendName: String
  backgroundHandledObjectId: bigint
  backgroundHandledObjectType: String
  created: timestamp
  id: bigint
  inQueue: Boolean
  labelConfigLang: String
  labelConfigOption: String
  starterUserMtid: bigint
  switchedUserMtid: bigint
}

# aggregate stddev on columns
type queued_background_job_stddev_fields {
  backgroundHandledObjectId: Float
  id: Float
  starterUserMtid: Float
  switchedUserMtid: Float
}

# order by stddev() on columns of table "queued_background_job"
input queued_background_job_stddev_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# aggregate stddev_pop on columns
type queued_background_job_stddev_pop_fields {
  backgroundHandledObjectId: Float
  id: Float
  starterUserMtid: Float
  switchedUserMtid: Float
}

# order by stddev_pop() on columns of table "queued_background_job"
input queued_background_job_stddev_pop_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# aggregate stddev_samp on columns
type queued_background_job_stddev_samp_fields {
  backgroundHandledObjectId: Float
  id: Float
  starterUserMtid: Float
  switchedUserMtid: Float
}

# order by stddev_samp() on columns of table "queued_background_job"
input queued_background_job_stddev_samp_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# aggregate sum on columns
type queued_background_job_sum_fields {
  backgroundHandledObjectId: bigint
  id: bigint
  starterUserMtid: bigint
  switchedUserMtid: bigint
}

# order by sum() on columns of table "queued_background_job"
input queued_background_job_sum_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# update columns of table "queued_background_job"
enum queued_background_job_update_column {
  # column name
  backendName

  # column name
  backgroundHandledObjectId

  # column name
  backgroundHandledObjectType

  # column name
  created

  # column name
  id

  # column name
  inQueue

  # column name
  labelConfigLang

  # column name
  labelConfigOption

  # column name
  starterUserMtid

  # column name
  switchedUserMtid
}

# aggregate var_pop on columns
type queued_background_job_var_pop_fields {
  backgroundHandledObjectId: Float
  id: Float
  starterUserMtid: Float
  switchedUserMtid: Float
}

# order by var_pop() on columns of table "queued_background_job"
input queued_background_job_var_pop_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# aggregate var_samp on columns
type queued_background_job_var_samp_fields {
  backgroundHandledObjectId: Float
  id: Float
  starterUserMtid: Float
  switchedUserMtid: Float
}

# order by var_samp() on columns of table "queued_background_job"
input queued_background_job_var_samp_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# aggregate variance on columns
type queued_background_job_variance_fields {
  backgroundHandledObjectId: Float
  id: Float
  starterUserMtid: Float
  switchedUserMtid: Float
}

# order by variance() on columns of table "queued_background_job"
input queued_background_job_variance_order_by {
  backgroundHandledObjectId: order_by
  id: order_by
  starterUserMtid: order_by
  switchedUserMtid: order_by
}

# columns and relationships of "rating"
type rating {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  calculation: Int
  comment: String
  comment2: String
  country: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  errorText: String
  issn: String
  journalName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPos: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  maxPos: Int
  mtid: bigint!
  numValue: Float!
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An object relationship
  periodical: periodical
  periodicalMtid: bigint
  prevValid: bigint
  published: Boolean!
  rankValue: Float
  ranking: Int

  # An object relationship
  ratingType: rating_type
  ratingTypeMtid: bigint
  refreshed: Boolean!
  status: Int

  # An object relationship
  subject: classification_external
  subjectMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int!
  val: String
  validFromYear: smallint
  validToYear: smallint
  year: smallint
}

# aggregated selection of "rating"
type rating_aggregate {
  aggregate: rating_aggregate_fields
  nodes: [rating!]!
}

# aggregate fields of "rating"
type rating_aggregate_fields {
  avg: rating_avg_fields
  count(columns: [rating_select_column!], distinct: Boolean): Int
  max: rating_max_fields
  min: rating_min_fields
  stddev: rating_stddev_fields
  stddev_pop: rating_stddev_pop_fields
  stddev_samp: rating_stddev_samp_fields
  sum: rating_sum_fields
  var_pop: rating_var_pop_fields
  var_samp: rating_var_samp_fields
  variance: rating_variance_fields
}

# order by aggregate values of table "rating"
input rating_aggregate_order_by {
  avg: rating_avg_order_by
  count: order_by
  max: rating_max_order_by
  min: rating_min_order_by
  stddev: rating_stddev_order_by
  stddev_pop: rating_stddev_pop_order_by
  stddev_samp: rating_stddev_samp_order_by
  sum: rating_sum_order_by
  var_pop: rating_var_pop_order_by
  var_samp: rating_var_samp_order_by
  variance: rating_variance_order_by
}

# input type for inserting array relation for remote table "rating"
input rating_arr_rel_insert_input {
  data: [rating_insert_input!]!
  on_conflict: rating_on_conflict
}

# aggregate avg on columns
type rating_avg_fields {
  approverMtid: Float
  calculation: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPos: Float
  lockerMtid: Float
  maxPos: Float
  mtid: Float
  numValue: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  rankValue: Float
  ranking: Float
  ratingTypeMtid: Float
  status: Float
  subjectMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by avg() on columns of table "rating"
input rating_avg_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# Boolean expression to filter rows from the table "rating". All fields are combined with a logical 'AND'.
input rating_bool_exp {
  _and: [rating_bool_exp]
  _not: rating_bool_exp
  _or: [rating_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  calculation: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  country: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  errorText: String_comparison_exp
  issn: String_comparison_exp
  journalName: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPos: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  maxPos: Int_comparison_exp
  mtid: bigint_comparison_exp
  numValue: Float_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  periodical: periodical_bool_exp
  periodicalMtid: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  rankValue: Float_comparison_exp
  ranking: Int_comparison_exp
  ratingType: rating_type_bool_exp
  ratingTypeMtid: bigint_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  subject: classification_external_bool_exp
  subjectMtid: bigint_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  val: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  year: smallint_comparison_exp
}

# unique or primary key constraints on table "rating"
enum rating_constraint {
  # unique or primary key constraint
  rating_pkey
}

# input type for incrementing integer column in table "rating"
input rating_inc_input {
  approverMtid: bigint
  calculation: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPos: Int
  lockerMtid: bigint
  maxPos: Int
  mtid: bigint
  numValue: Float
  oldId: Int
  periodicalMtid: bigint
  prevValid: bigint
  rankValue: Float
  ranking: Int
  ratingTypeMtid: bigint
  status: Int
  subjectMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: smallint
}

# input type for inserting data into table "rating"
input rating_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  calculation: Int
  comment: String
  comment2: String
  country: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  errorText: String
  issn: String
  journalName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPos: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  maxPos: Int
  mtid: bigint
  numValue: Float
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodical: periodical_obj_rel_insert_input
  periodicalMtid: bigint
  prevValid: bigint
  published: Boolean
  rankValue: Float
  ranking: Int
  ratingType: rating_type_obj_rel_insert_input
  ratingTypeMtid: bigint
  refreshed: Boolean
  status: Int
  subject: classification_external_obj_rel_insert_input
  subjectMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  val: String
  validFromYear: smallint
  validToYear: smallint
  year: smallint
}

# aggregate max on columns
type rating_max_fields {
  approved: timestamp
  approverMtid: bigint
  calculation: Int
  comment: String
  comment2: String
  country: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  errorText: String
  issn: String
  journalName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPos: Int
  locked: timestamp
  lockerMtid: bigint
  maxPos: Int
  mtid: bigint
  numValue: Float
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodicalMtid: bigint
  prevValid: bigint
  rankValue: Float
  ranking: Int
  ratingTypeMtid: bigint
  status: Int
  subjectMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  val: String
  validFromYear: smallint
  validToYear: smallint
  year: smallint
}

# order by max() on columns of table "rating"
input rating_max_order_by {
  approved: order_by
  approverMtid: order_by
  calculation: order_by
  comment: order_by
  comment2: order_by
  country: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  errorText: order_by
  issn: order_by
  journalName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPos: order_by
  locked: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  val: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate min on columns
type rating_min_fields {
  approved: timestamp
  approverMtid: bigint
  calculation: Int
  comment: String
  comment2: String
  country: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  errorText: String
  issn: String
  journalName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPos: Int
  locked: timestamp
  lockerMtid: bigint
  maxPos: Int
  mtid: bigint
  numValue: Float
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodicalMtid: bigint
  prevValid: bigint
  rankValue: Float
  ranking: Int
  ratingTypeMtid: bigint
  status: Int
  subjectMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  val: String
  validFromYear: smallint
  validToYear: smallint
  year: smallint
}

# order by min() on columns of table "rating"
input rating_min_order_by {
  approved: order_by
  approverMtid: order_by
  calculation: order_by
  comment: order_by
  comment2: order_by
  country: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  errorText: order_by
  issn: order_by
  journalName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPos: order_by
  locked: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  val: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# response of any mutation on the table "rating"
type rating_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [rating!]!
}

# input type for inserting object relation for remote table "rating"
input rating_obj_rel_insert_input {
  data: rating_insert_input!
  on_conflict: rating_on_conflict
}

# on conflict condition type for table "rating"
input rating_on_conflict {
  constraint: rating_constraint!
  update_columns: [rating_update_column!]!
  where: rating_bool_exp
}

# ordering options when selecting data from "rating"
input rating_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  calculation: order_by
  comment: order_by
  comment2: order_by
  country: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  errorText: order_by
  issn: order_by
  journalName: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPos: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  periodical: periodical_order_by
  periodicalMtid: order_by
  prevValid: order_by
  published: order_by
  rankValue: order_by
  ranking: order_by
  ratingType: rating_type_order_by
  ratingTypeMtid: order_by
  refreshed: order_by
  status: order_by
  subject: classification_external_order_by
  subjectMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  val: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# primary key columns input for table: "rating"
input rating_pk_columns_input {
  mtid: bigint!
}

# select columns of table "rating"
enum rating_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  calculation

  # column name
  comment

  # column name
  comment2

  # column name
  country

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  errorText

  # column name
  issn

  # column name
  journalName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPos

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxPos

  # column name
  mtid

  # column name
  numValue

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  periodicalMtid

  # column name
  prevValid

  # column name
  published

  # column name
  rankValue

  # column name
  ranking

  # column name
  ratingTypeMtid

  # column name
  refreshed

  # column name
  status

  # column name
  subjectMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  val

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  year
}

# input type for updating data in table "rating"
input rating_set_input {
  approved: timestamp
  approverMtid: bigint
  calculation: Int
  comment: String
  comment2: String
  country: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  errorText: String
  issn: String
  journalName: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPos: Int
  locked: timestamp
  lockerMtid: bigint
  maxPos: Int
  mtid: bigint
  numValue: Float
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  periodicalMtid: bigint
  prevValid: bigint
  published: Boolean
  rankValue: Float
  ranking: Int
  ratingTypeMtid: bigint
  refreshed: Boolean
  status: Int
  subjectMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: String
  unhandledTickets: Int
  val: String
  validFromYear: smallint
  validToYear: smallint
  year: smallint
}

# aggregate stddev on columns
type rating_stddev_fields {
  approverMtid: Float
  calculation: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPos: Float
  lockerMtid: Float
  maxPos: Float
  mtid: Float
  numValue: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  rankValue: Float
  ranking: Float
  ratingTypeMtid: Float
  status: Float
  subjectMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev() on columns of table "rating"
input rating_stddev_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate stddev_pop on columns
type rating_stddev_pop_fields {
  approverMtid: Float
  calculation: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPos: Float
  lockerMtid: Float
  maxPos: Float
  mtid: Float
  numValue: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  rankValue: Float
  ranking: Float
  ratingTypeMtid: Float
  status: Float
  subjectMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev_pop() on columns of table "rating"
input rating_stddev_pop_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate stddev_samp on columns
type rating_stddev_samp_fields {
  approverMtid: Float
  calculation: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPos: Float
  lockerMtid: Float
  maxPos: Float
  mtid: Float
  numValue: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  rankValue: Float
  ranking: Float
  ratingTypeMtid: Float
  status: Float
  subjectMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by stddev_samp() on columns of table "rating"
input rating_stddev_samp_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate sum on columns
type rating_sum_fields {
  approverMtid: bigint
  calculation: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPos: Int
  lockerMtid: bigint
  maxPos: Int
  mtid: bigint
  numValue: Float
  oldId: Int
  periodicalMtid: bigint
  prevValid: bigint
  rankValue: Float
  ranking: Int
  ratingTypeMtid: bigint
  status: Int
  subjectMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  year: smallint
}

# order by sum() on columns of table "rating"
input rating_sum_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# columns and relationships of "rating_type"
type rating_type {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  className: String
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String

  # An object relationship
  institute: organization
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int

  # An object relationship
  subjectTree: classification_tree
  subjectTreeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "rating_type"
type rating_type_aggregate {
  aggregate: rating_type_aggregate_fields
  nodes: [rating_type!]!
}

# aggregate fields of "rating_type"
type rating_type_aggregate_fields {
  avg: rating_type_avg_fields
  count(columns: [rating_type_select_column!], distinct: Boolean): Int
  max: rating_type_max_fields
  min: rating_type_min_fields
  stddev: rating_type_stddev_fields
  stddev_pop: rating_type_stddev_pop_fields
  stddev_samp: rating_type_stddev_samp_fields
  sum: rating_type_sum_fields
  var_pop: rating_type_var_pop_fields
  var_samp: rating_type_var_samp_fields
  variance: rating_type_variance_fields
}

# order by aggregate values of table "rating_type"
input rating_type_aggregate_order_by {
  avg: rating_type_avg_order_by
  count: order_by
  max: rating_type_max_order_by
  min: rating_type_min_order_by
  stddev: rating_type_stddev_order_by
  stddev_pop: rating_type_stddev_pop_order_by
  stddev_samp: rating_type_stddev_samp_order_by
  sum: rating_type_sum_order_by
  var_pop: rating_type_var_pop_order_by
  var_samp: rating_type_var_samp_order_by
  variance: rating_type_variance_order_by
}

# input type for inserting array relation for remote table "rating_type"
input rating_type_arr_rel_insert_input {
  data: [rating_type_insert_input!]!
  on_conflict: rating_type_on_conflict
}

# aggregate avg on columns
type rating_type_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  subjectTreeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "rating_type"
input rating_type_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "rating_type". All fields are combined with a logical 'AND'.
input rating_type_bool_exp {
  _and: [rating_type_bool_exp]
  _not: rating_type_bool_exp
  _or: [rating_type_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  className: String_comparison_exp
  code: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  institute: organization_bool_exp
  instituteMtid: bigint_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  subjectTree: classification_tree_bool_exp
  subjectTreeMtid: bigint_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "rating_type"
enum rating_type_constraint {
  # unique or primary key constraint
  rating_type_pkey
}

# input type for incrementing integer column in table "rating_type"
input rating_type_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  subjectTreeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "rating_type"
input rating_type_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  className: String
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  institute: organization_obj_rel_insert_input
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  subjectTree: classification_tree_obj_rel_insert_input
  subjectTreeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type rating_type_max_fields {
  approved: timestamp
  approverMtid: bigint
  className: String
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  subjectTreeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "rating_type"
input rating_type_max_order_by {
  approved: order_by
  approverMtid: order_by
  className: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type rating_type_min_fields {
  approved: timestamp
  approverMtid: bigint
  className: String
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  subjectTreeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "rating_type"
input rating_type_min_order_by {
  approved: order_by
  approverMtid: order_by
  className: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "rating_type"
type rating_type_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [rating_type!]!
}

# input type for inserting object relation for remote table "rating_type"
input rating_type_obj_rel_insert_input {
  data: rating_type_insert_input!
  on_conflict: rating_type_on_conflict
}

# on conflict condition type for table "rating_type"
input rating_type_on_conflict {
  constraint: rating_type_constraint!
  update_columns: [rating_type_update_column!]!
  where: rating_type_bool_exp
}

# ordering options when selecting data from "rating_type"
input rating_type_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  className: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  institute: organization_order_by
  instituteMtid: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  subjectTree: classification_tree_order_by
  subjectTreeMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "rating_type"
input rating_type_pk_columns_input {
  mtid: bigint!
}

# select columns of table "rating_type"
enum rating_type_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  className

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  subjectTreeMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "rating_type"
input rating_type_set_input {
  approved: timestamp
  approverMtid: bigint
  className: String
  code: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  instituteMtid: bigint
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  subjectTreeMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type rating_type_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  subjectTreeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "rating_type"
input rating_type_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type rating_type_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  subjectTreeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "rating_type"
input rating_type_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type rating_type_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  subjectTreeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "rating_type"
input rating_type_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type rating_type_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  instituteMtid: bigint
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  subjectTreeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "rating_type"
input rating_type_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "rating_type"
enum rating_type_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  className

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  instituteMtid

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  subjectTreeMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type rating_type_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  subjectTreeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "rating_type"
input rating_type_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type rating_type_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  subjectTreeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "rating_type"
input rating_type_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type rating_type_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  instituteMtid: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  subjectTreeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "rating_type"
input rating_type_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  instituteMtid: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  subjectTreeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "rating"
enum rating_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  calculation

  # column name
  comment

  # column name
  comment2

  # column name
  country

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  errorText

  # column name
  issn

  # column name
  journalName

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPos

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxPos

  # column name
  mtid

  # column name
  numValue

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  periodicalMtid

  # column name
  prevValid

  # column name
  published

  # column name
  rankValue

  # column name
  ranking

  # column name
  ratingTypeMtid

  # column name
  refreshed

  # column name
  status

  # column name
  subjectMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  val

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  year
}

# aggregate var_pop on columns
type rating_var_pop_fields {
  approverMtid: Float
  calculation: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPos: Float
  lockerMtid: Float
  maxPos: Float
  mtid: Float
  numValue: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  rankValue: Float
  ranking: Float
  ratingTypeMtid: Float
  status: Float
  subjectMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by var_pop() on columns of table "rating"
input rating_var_pop_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate var_samp on columns
type rating_var_samp_fields {
  approverMtid: Float
  calculation: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPos: Float
  lockerMtid: Float
  maxPos: Float
  mtid: Float
  numValue: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  rankValue: Float
  ranking: Float
  ratingTypeMtid: Float
  status: Float
  subjectMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by var_samp() on columns of table "rating"
input rating_var_samp_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# aggregate variance on columns
type rating_variance_fields {
  approverMtid: Float
  calculation: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPos: Float
  lockerMtid: Float
  maxPos: Float
  mtid: Float
  numValue: Float
  oldId: Float
  periodicalMtid: Float
  prevValid: Float
  rankValue: Float
  ranking: Float
  ratingTypeMtid: Float
  status: Float
  subjectMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  year: Float
}

# order by variance() on columns of table "rating"
input rating_variance_order_by {
  approverMtid: order_by
  calculation: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPos: order_by
  lockerMtid: order_by
  maxPos: order_by
  mtid: order_by
  numValue: order_by
  oldId: order_by
  periodicalMtid: order_by
  prevValid: order_by
  rankValue: order_by
  ranking: order_by
  ratingTypeMtid: order_by
  status: order_by
  subjectMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  year: order_by
}

# columns and relationships of "recalculate_institute_ownerships_request"
type recalculate_institute_ownerships_request {
  # An array relationship
  affectedInstitutes(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_affected_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_affected_institutes_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  ): [recalculate_institute_ownerships_request_affected_institutes!]!

  # An aggregated array relationship
  affectedInstitutes_aggregate(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_affected_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_affected_institutes_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  ): recalculate_institute_ownerships_request_affected_institutes_aggregate!
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean!
  queued: Boolean!
  refreshed: Boolean!
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# columns and relationships of "recalculate_institute_ownerships_request_affected_institutes"
type recalculate_institute_ownerships_request_affected_institutes {
  affectedInstitutesMtid: bigint!

  # An object relationship
  organization: organization!
  recalculateInstituteOwnershipsRequestMtid: bigint!
}

# aggregated selection of "recalculate_institute_ownerships_request_affected_institutes"
type recalculate_institute_ownerships_request_affected_institutes_aggregate {
  aggregate: recalculate_institute_ownerships_request_affected_institutes_aggregate_fields
  nodes: [recalculate_institute_ownerships_request_affected_institutes!]!
}

# aggregate fields of "recalculate_institute_ownerships_request_affected_institutes"
type recalculate_institute_ownerships_request_affected_institutes_aggregate_fields {
  avg: recalculate_institute_ownerships_request_affected_institutes_avg_fields
  count(columns: [recalculate_institute_ownerships_request_affected_institutes_select_column!], distinct: Boolean): Int
  max: recalculate_institute_ownerships_request_affected_institutes_max_fields
  min: recalculate_institute_ownerships_request_affected_institutes_min_fields
  stddev: recalculate_institute_ownerships_request_affected_institutes_stddev_fields
  stddev_pop: recalculate_institute_ownerships_request_affected_institutes_stddev_pop_fields
  stddev_samp: recalculate_institute_ownerships_request_affected_institutes_stddev_samp_fields
  sum: recalculate_institute_ownerships_request_affected_institutes_sum_fields
  var_pop: recalculate_institute_ownerships_request_affected_institutes_var_pop_fields
  var_samp: recalculate_institute_ownerships_request_affected_institutes_var_samp_fields
  variance: recalculate_institute_ownerships_request_affected_institutes_variance_fields
}

# order by aggregate values of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_aggregate_order_by {
  avg: recalculate_institute_ownerships_request_affected_institutes_avg_order_by
  count: order_by
  max: recalculate_institute_ownerships_request_affected_institutes_max_order_by
  min: recalculate_institute_ownerships_request_affected_institutes_min_order_by
  stddev: recalculate_institute_ownerships_request_affected_institutes_stddev_order_by
  stddev_pop: recalculate_institute_ownerships_request_affected_institutes_stddev_pop_order_by
  stddev_samp: recalculate_institute_ownerships_request_affected_institutes_stddev_samp_order_by
  sum: recalculate_institute_ownerships_request_affected_institutes_sum_order_by
  var_pop: recalculate_institute_ownerships_request_affected_institutes_var_pop_order_by
  var_samp: recalculate_institute_ownerships_request_affected_institutes_var_samp_order_by
  variance: recalculate_institute_ownerships_request_affected_institutes_variance_order_by
}

# input type for inserting array relation for remote table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_arr_rel_insert_input {
  data: [recalculate_institute_ownerships_request_affected_institutes_insert_input!]!
  on_conflict: recalculate_institute_ownerships_request_affected_institutes_on_conflict
}

# aggregate avg on columns
type recalculate_institute_ownerships_request_affected_institutes_avg_fields {
  affectedInstitutesMtid: Float
  recalculateInstituteOwnershipsRequestMtid: Float
}

# order by avg() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_avg_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# Boolean expression to filter rows from the table
# "recalculate_institute_ownerships_request_affected_institutes". All fields are
# combined with a logical 'AND'.
input recalculate_institute_ownerships_request_affected_institutes_bool_exp {
  _and: [recalculate_institute_ownerships_request_affected_institutes_bool_exp]
  _not: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  _or: [recalculate_institute_ownerships_request_affected_institutes_bool_exp]
  affectedInstitutesMtid: bigint_comparison_exp
  organization: organization_bool_exp
  recalculateInstituteOwnershipsRequestMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "recalculate_institute_ownerships_request_affected_institutes"
enum recalculate_institute_ownerships_request_affected_institutes_constraint {
  # unique or primary key constraint
  recalculate_institute_ownerships_request_affected_institut_pkey

  # unique or primary key constraint
  uk_618ew34c5nur7u6s7tc56orpv
}

# input type for incrementing integer column in table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_inc_input {
  affectedInstitutesMtid: bigint
  recalculateInstituteOwnershipsRequestMtid: bigint
}

# input type for inserting data into table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_insert_input {
  affectedInstitutesMtid: bigint
  organization: organization_obj_rel_insert_input
  recalculateInstituteOwnershipsRequestMtid: bigint
}

# aggregate max on columns
type recalculate_institute_ownerships_request_affected_institutes_max_fields {
  affectedInstitutesMtid: bigint
  recalculateInstituteOwnershipsRequestMtid: bigint
}

# order by max() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_max_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# aggregate min on columns
type recalculate_institute_ownerships_request_affected_institutes_min_fields {
  affectedInstitutesMtid: bigint
  recalculateInstituteOwnershipsRequestMtid: bigint
}

# order by min() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_min_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# response of any mutation on the table "recalculate_institute_ownerships_request_affected_institutes"
type recalculate_institute_ownerships_request_affected_institutes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [recalculate_institute_ownerships_request_affected_institutes!]!
}

# input type for inserting object relation for remote table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_obj_rel_insert_input {
  data: recalculate_institute_ownerships_request_affected_institutes_insert_input!
  on_conflict: recalculate_institute_ownerships_request_affected_institutes_on_conflict
}

# on conflict condition type for table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_on_conflict {
  constraint: recalculate_institute_ownerships_request_affected_institutes_constraint!
  update_columns: [recalculate_institute_ownerships_request_affected_institutes_update_column!]!
  where: recalculate_institute_ownerships_request_affected_institutes_bool_exp
}

# ordering options when selecting data from "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_order_by {
  affectedInstitutesMtid: order_by
  organization: organization_order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# primary key columns input for table: "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_pk_columns_input {
  affectedInstitutesMtid: bigint!
  recalculateInstituteOwnershipsRequestMtid: bigint!
}

# select columns of table "recalculate_institute_ownerships_request_affected_institutes"
enum recalculate_institute_ownerships_request_affected_institutes_select_column {
  # column name
  affectedInstitutesMtid

  # column name
  recalculateInstituteOwnershipsRequestMtid
}

# input type for updating data in table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_set_input {
  affectedInstitutesMtid: bigint
  recalculateInstituteOwnershipsRequestMtid: bigint
}

# aggregate stddev on columns
type recalculate_institute_ownerships_request_affected_institutes_stddev_fields {
  affectedInstitutesMtid: Float
  recalculateInstituteOwnershipsRequestMtid: Float
}

# order by stddev() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_stddev_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# aggregate stddev_pop on columns
type recalculate_institute_ownerships_request_affected_institutes_stddev_pop_fields {
  affectedInstitutesMtid: Float
  recalculateInstituteOwnershipsRequestMtid: Float
}

# order by stddev_pop() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_stddev_pop_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# aggregate stddev_samp on columns
type recalculate_institute_ownerships_request_affected_institutes_stddev_samp_fields {
  affectedInstitutesMtid: Float
  recalculateInstituteOwnershipsRequestMtid: Float
}

# order by stddev_samp() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_stddev_samp_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# aggregate sum on columns
type recalculate_institute_ownerships_request_affected_institutes_sum_fields {
  affectedInstitutesMtid: bigint
  recalculateInstituteOwnershipsRequestMtid: bigint
}

# order by sum() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_sum_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# update columns of table "recalculate_institute_ownerships_request_affected_institutes"
enum recalculate_institute_ownerships_request_affected_institutes_update_column {
  # column name
  affectedInstitutesMtid

  # column name
  recalculateInstituteOwnershipsRequestMtid
}

# aggregate var_pop on columns
type recalculate_institute_ownerships_request_affected_institutes_var_pop_fields {
  affectedInstitutesMtid: Float
  recalculateInstituteOwnershipsRequestMtid: Float
}

# order by var_pop() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_var_pop_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# aggregate var_samp on columns
type recalculate_institute_ownerships_request_affected_institutes_var_samp_fields {
  affectedInstitutesMtid: Float
  recalculateInstituteOwnershipsRequestMtid: Float
}

# order by var_samp() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_var_samp_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# aggregate variance on columns
type recalculate_institute_ownerships_request_affected_institutes_variance_fields {
  affectedInstitutesMtid: Float
  recalculateInstituteOwnershipsRequestMtid: Float
}

# order by variance() on columns of table "recalculate_institute_ownerships_request_affected_institutes"
input recalculate_institute_ownerships_request_affected_institutes_variance_order_by {
  affectedInstitutesMtid: order_by
  recalculateInstituteOwnershipsRequestMtid: order_by
}

# aggregated selection of "recalculate_institute_ownerships_request"
type recalculate_institute_ownerships_request_aggregate {
  aggregate: recalculate_institute_ownerships_request_aggregate_fields
  nodes: [recalculate_institute_ownerships_request!]!
}

# aggregate fields of "recalculate_institute_ownerships_request"
type recalculate_institute_ownerships_request_aggregate_fields {
  avg: recalculate_institute_ownerships_request_avg_fields
  count(columns: [recalculate_institute_ownerships_request_select_column!], distinct: Boolean): Int
  max: recalculate_institute_ownerships_request_max_fields
  min: recalculate_institute_ownerships_request_min_fields
  stddev: recalculate_institute_ownerships_request_stddev_fields
  stddev_pop: recalculate_institute_ownerships_request_stddev_pop_fields
  stddev_samp: recalculate_institute_ownerships_request_stddev_samp_fields
  sum: recalculate_institute_ownerships_request_sum_fields
  var_pop: recalculate_institute_ownerships_request_var_pop_fields
  var_samp: recalculate_institute_ownerships_request_var_samp_fields
  variance: recalculate_institute_ownerships_request_variance_fields
}

# order by aggregate values of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_aggregate_order_by {
  avg: recalculate_institute_ownerships_request_avg_order_by
  count: order_by
  max: recalculate_institute_ownerships_request_max_order_by
  min: recalculate_institute_ownerships_request_min_order_by
  stddev: recalculate_institute_ownerships_request_stddev_order_by
  stddev_pop: recalculate_institute_ownerships_request_stddev_pop_order_by
  stddev_samp: recalculate_institute_ownerships_request_stddev_samp_order_by
  sum: recalculate_institute_ownerships_request_sum_order_by
  var_pop: recalculate_institute_ownerships_request_var_pop_order_by
  var_samp: recalculate_institute_ownerships_request_var_samp_order_by
  variance: recalculate_institute_ownerships_request_variance_order_by
}

# input type for inserting array relation for remote table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_arr_rel_insert_input {
  data: [recalculate_institute_ownerships_request_insert_input!]!
  on_conflict: recalculate_institute_ownerships_request_on_conflict
}

# aggregate avg on columns
type recalculate_institute_ownerships_request_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table
# "recalculate_institute_ownerships_request". All fields are combined with a logical 'AND'.
input recalculate_institute_ownerships_request_bool_exp {
  _and: [recalculate_institute_ownerships_request_bool_exp]
  _not: recalculate_institute_ownerships_request_bool_exp
  _or: [recalculate_institute_ownerships_request_bool_exp]
  affectedInstitutes: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  seen: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "recalculate_institute_ownerships_request"
enum recalculate_institute_ownerships_request_constraint {
  # unique or primary key constraint
  recalculate_institute_ownerships_request_pkey
}

# input type for incrementing integer column in table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_insert_input {
  affectedInstitutes: recalculate_institute_ownerships_request_affected_institutes_arr_rel_insert_input
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type recalculate_institute_ownerships_request_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type recalculate_institute_ownerships_request_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "recalculate_institute_ownerships_request"
type recalculate_institute_ownerships_request_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [recalculate_institute_ownerships_request!]!
}

# input type for inserting object relation for remote table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_obj_rel_insert_input {
  data: recalculate_institute_ownerships_request_insert_input!
  on_conflict: recalculate_institute_ownerships_request_on_conflict
}

# on conflict condition type for table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_on_conflict {
  constraint: recalculate_institute_ownerships_request_constraint!
  update_columns: [recalculate_institute_ownerships_request_update_column!]!
  where: recalculate_institute_ownerships_request_bool_exp
}

# ordering options when selecting data from "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_order_by {
  affectedInstitutes_aggregate: recalculate_institute_ownerships_request_affected_institutes_aggregate_order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  queued: order_by
  refreshed: order_by
  seen: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_pk_columns_input {
  mtid: bigint!
}

# select columns of table "recalculate_institute_ownerships_request"
enum recalculate_institute_ownerships_request_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  refreshed: Boolean
  seen: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type recalculate_institute_ownerships_request_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type recalculate_institute_ownerships_request_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type recalculate_institute_ownerships_request_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type recalculate_institute_ownerships_request_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "recalculate_institute_ownerships_request"
enum recalculate_institute_ownerships_request_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  refreshed

  # column name
  seen

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type recalculate_institute_ownerships_request_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type recalculate_institute_ownerships_request_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type recalculate_institute_ownerships_request_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "recalculate_institute_ownerships_request"
input recalculate_institute_ownerships_request_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "reference"
type reference {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  doi: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint

  # An object relationship
  publication: publication
  publicationMtid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  text: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "reference"
type reference_aggregate {
  aggregate: reference_aggregate_fields
  nodes: [reference!]!
}

# aggregate fields of "reference"
type reference_aggregate_fields {
  avg: reference_avg_fields
  count(columns: [reference_select_column!], distinct: Boolean): Int
  max: reference_max_fields
  min: reference_min_fields
  stddev: reference_stddev_fields
  stddev_pop: reference_stddev_pop_fields
  stddev_samp: reference_stddev_samp_fields
  sum: reference_sum_fields
  var_pop: reference_var_pop_fields
  var_samp: reference_var_samp_fields
  variance: reference_variance_fields
}

# order by aggregate values of table "reference"
input reference_aggregate_order_by {
  avg: reference_avg_order_by
  count: order_by
  max: reference_max_order_by
  min: reference_min_order_by
  stddev: reference_stddev_order_by
  stddev_pop: reference_stddev_pop_order_by
  stddev_samp: reference_stddev_samp_order_by
  sum: reference_sum_order_by
  var_pop: reference_var_pop_order_by
  var_samp: reference_var_samp_order_by
  variance: reference_variance_order_by
}

# input type for inserting array relation for remote table "reference"
input reference_arr_rel_insert_input {
  data: [reference_insert_input!]!
  on_conflict: reference_on_conflict
}

# aggregate avg on columns
type reference_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "reference"
input reference_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "reference". All fields are combined with a logical 'AND'.
input reference_bool_exp {
  _and: [reference_bool_exp]
  _not: reference_bool_exp
  _or: [reference_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  doi: String_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  publication: publication_bool_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  text: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "reference"
enum reference_constraint {
  # unique or primary key constraint
  reference_pkey
}

# input type for incrementing integer column in table "reference"
input reference_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "reference"
input reference_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  doi: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publication: publication_obj_rel_insert_input
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  text: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type reference_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  doi: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  text: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "reference"
input reference_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  doi: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  text: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type reference_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  doi: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  text: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "reference"
input reference_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  doi: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  text: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "reference"
type reference_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [reference!]!
}

# input type for inserting object relation for remote table "reference"
input reference_obj_rel_insert_input {
  data: reference_insert_input!
  on_conflict: reference_on_conflict
}

# on conflict condition type for table "reference"
input reference_on_conflict {
  constraint: reference_constraint!
  update_columns: [reference_update_column!]!
  where: reference_bool_exp
}

# ordering options when selecting data from "reference"
input reference_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  doi: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publication: publication_order_by
  publicationMtid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  text: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "reference"
input reference_pk_columns_input {
  mtid: bigint!
}

# select columns of table "reference"
enum reference_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doi

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  text

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "reference"
input reference_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  doi: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  text: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type reference_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "reference"
input reference_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type reference_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "reference"
input reference_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type reference_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "reference"
input reference_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type reference_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "reference"
input reference_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "reference"
enum reference_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doi

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  text

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type reference_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "reference"
input reference_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type reference_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "reference"
input reference_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type reference_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "reference"
input reference_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "refresh_item"
type refresh_item {
  deleted: timestamp
  id: String!
  itemCreationDate: timestamp
  itemCreator: bigint
  lastModified: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  mtid: bigint!
  needsSnippetInvalidationWhereReferenced: Boolean!
  oldId: Int
  otype: String
  priority: Int
  server: String
  snippetsInvalidated: Boolean!
  threadNumber: Int
}

# aggregated selection of "refresh_item"
type refresh_item_aggregate {
  aggregate: refresh_item_aggregate_fields
  nodes: [refresh_item!]!
}

# aggregate fields of "refresh_item"
type refresh_item_aggregate_fields {
  avg: refresh_item_avg_fields
  count(columns: [refresh_item_select_column!], distinct: Boolean): Int
  max: refresh_item_max_fields
  min: refresh_item_min_fields
  stddev: refresh_item_stddev_fields
  stddev_pop: refresh_item_stddev_pop_fields
  stddev_samp: refresh_item_stddev_samp_fields
  sum: refresh_item_sum_fields
  var_pop: refresh_item_var_pop_fields
  var_samp: refresh_item_var_samp_fields
  variance: refresh_item_variance_fields
}

# order by aggregate values of table "refresh_item"
input refresh_item_aggregate_order_by {
  avg: refresh_item_avg_order_by
  count: order_by
  max: refresh_item_max_order_by
  min: refresh_item_min_order_by
  stddev: refresh_item_stddev_order_by
  stddev_pop: refresh_item_stddev_pop_order_by
  stddev_samp: refresh_item_stddev_samp_order_by
  sum: refresh_item_sum_order_by
  var_pop: refresh_item_var_pop_order_by
  var_samp: refresh_item_var_samp_order_by
  variance: refresh_item_variance_order_by
}

# input type for inserting array relation for remote table "refresh_item"
input refresh_item_arr_rel_insert_input {
  data: [refresh_item_insert_input!]!
  on_conflict: refresh_item_on_conflict
}

# aggregate avg on columns
type refresh_item_avg_fields {
  itemCreator: Float
  mtid: Float
  oldId: Float
  priority: Float
  threadNumber: Float
}

# order by avg() on columns of table "refresh_item"
input refresh_item_avg_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# Boolean expression to filter rows from the table "refresh_item". All fields are combined with a logical 'AND'.
input refresh_item_bool_exp {
  _and: [refresh_item_bool_exp]
  _not: refresh_item_bool_exp
  _or: [refresh_item_bool_exp]
  deleted: timestamp_comparison_exp
  id: String_comparison_exp
  itemCreationDate: timestamp_comparison_exp
  itemCreator: bigint_comparison_exp
  lastModified: timestamp_comparison_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  mtid: bigint_comparison_exp
  needsSnippetInvalidationWhereReferenced: Boolean_comparison_exp
  oldId: Int_comparison_exp
  otype: String_comparison_exp
  priority: Int_comparison_exp
  server: String_comparison_exp
  snippetsInvalidated: Boolean_comparison_exp
  threadNumber: Int_comparison_exp
}

# unique or primary key constraints on table "refresh_item"
enum refresh_item_constraint {
  # unique or primary key constraint
  refresh_item_pkey
}

# input type for incrementing integer column in table "refresh_item"
input refresh_item_inc_input {
  itemCreator: bigint
  mtid: bigint
  oldId: Int
  priority: Int
  threadNumber: Int
}

# input type for inserting data into table "refresh_item"
input refresh_item_insert_input {
  deleted: timestamp
  id: String
  itemCreationDate: timestamp
  itemCreator: bigint
  lastModified: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  mtid: bigint
  needsSnippetInvalidationWhereReferenced: Boolean
  oldId: Int
  otype: String
  priority: Int
  server: String
  snippetsInvalidated: Boolean
  threadNumber: Int
}

# aggregate max on columns
type refresh_item_max_fields {
  deleted: timestamp
  id: String
  itemCreationDate: timestamp
  itemCreator: bigint
  lastModified: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  mtid: bigint
  oldId: Int
  otype: String
  priority: Int
  server: String
  threadNumber: Int
}

# order by max() on columns of table "refresh_item"
input refresh_item_max_order_by {
  deleted: order_by
  id: order_by
  itemCreationDate: order_by
  itemCreator: order_by
  lastModified: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  mtid: order_by
  oldId: order_by
  otype: order_by
  priority: order_by
  server: order_by
  threadNumber: order_by
}

# aggregate min on columns
type refresh_item_min_fields {
  deleted: timestamp
  id: String
  itemCreationDate: timestamp
  itemCreator: bigint
  lastModified: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  mtid: bigint
  oldId: Int
  otype: String
  priority: Int
  server: String
  threadNumber: Int
}

# order by min() on columns of table "refresh_item"
input refresh_item_min_order_by {
  deleted: order_by
  id: order_by
  itemCreationDate: order_by
  itemCreator: order_by
  lastModified: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  mtid: order_by
  oldId: order_by
  otype: order_by
  priority: order_by
  server: order_by
  threadNumber: order_by
}

# response of any mutation on the table "refresh_item"
type refresh_item_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [refresh_item!]!
}

# input type for inserting object relation for remote table "refresh_item"
input refresh_item_obj_rel_insert_input {
  data: refresh_item_insert_input!
  on_conflict: refresh_item_on_conflict
}

# on conflict condition type for table "refresh_item"
input refresh_item_on_conflict {
  constraint: refresh_item_constraint!
  update_columns: [refresh_item_update_column!]!
  where: refresh_item_bool_exp
}

# ordering options when selecting data from "refresh_item"
input refresh_item_order_by {
  deleted: order_by
  id: order_by
  itemCreationDate: order_by
  itemCreator: order_by
  lastModified: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  mtid: order_by
  needsSnippetInvalidationWhereReferenced: order_by
  oldId: order_by
  otype: order_by
  priority: order_by
  server: order_by
  snippetsInvalidated: order_by
  threadNumber: order_by
}

# primary key columns input for table: "refresh_item"
input refresh_item_pk_columns_input {
  id: String!
}

# select columns of table "refresh_item"
enum refresh_item_select_column {
  # column name
  deleted

  # column name
  id

  # column name
  itemCreationDate

  # column name
  itemCreator

  # column name
  lastModified

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  mtid

  # column name
  needsSnippetInvalidationWhereReferenced

  # column name
  oldId

  # column name
  otype

  # column name
  priority

  # column name
  server

  # column name
  snippetsInvalidated

  # column name
  threadNumber
}

# input type for updating data in table "refresh_item"
input refresh_item_set_input {
  deleted: timestamp
  id: String
  itemCreationDate: timestamp
  itemCreator: bigint
  lastModified: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  mtid: bigint
  needsSnippetInvalidationWhereReferenced: Boolean
  oldId: Int
  otype: String
  priority: Int
  server: String
  snippetsInvalidated: Boolean
  threadNumber: Int
}

# aggregate stddev on columns
type refresh_item_stddev_fields {
  itemCreator: Float
  mtid: Float
  oldId: Float
  priority: Float
  threadNumber: Float
}

# order by stddev() on columns of table "refresh_item"
input refresh_item_stddev_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# aggregate stddev_pop on columns
type refresh_item_stddev_pop_fields {
  itemCreator: Float
  mtid: Float
  oldId: Float
  priority: Float
  threadNumber: Float
}

# order by stddev_pop() on columns of table "refresh_item"
input refresh_item_stddev_pop_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# aggregate stddev_samp on columns
type refresh_item_stddev_samp_fields {
  itemCreator: Float
  mtid: Float
  oldId: Float
  priority: Float
  threadNumber: Float
}

# order by stddev_samp() on columns of table "refresh_item"
input refresh_item_stddev_samp_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# aggregate sum on columns
type refresh_item_sum_fields {
  itemCreator: bigint
  mtid: bigint
  oldId: Int
  priority: Int
  threadNumber: Int
}

# order by sum() on columns of table "refresh_item"
input refresh_item_sum_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# update columns of table "refresh_item"
enum refresh_item_update_column {
  # column name
  deleted

  # column name
  id

  # column name
  itemCreationDate

  # column name
  itemCreator

  # column name
  lastModified

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  mtid

  # column name
  needsSnippetInvalidationWhereReferenced

  # column name
  oldId

  # column name
  otype

  # column name
  priority

  # column name
  server

  # column name
  snippetsInvalidated

  # column name
  threadNumber
}

# aggregate var_pop on columns
type refresh_item_var_pop_fields {
  itemCreator: Float
  mtid: Float
  oldId: Float
  priority: Float
  threadNumber: Float
}

# order by var_pop() on columns of table "refresh_item"
input refresh_item_var_pop_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# aggregate var_samp on columns
type refresh_item_var_samp_fields {
  itemCreator: Float
  mtid: Float
  oldId: Float
  priority: Float
  threadNumber: Float
}

# order by var_samp() on columns of table "refresh_item"
input refresh_item_var_samp_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# aggregate variance on columns
type refresh_item_variance_fields {
  itemCreator: Float
  mtid: Float
  oldId: Float
  priority: Float
  threadNumber: Float
}

# order by variance() on columns of table "refresh_item"
input refresh_item_variance_order_by {
  itemCreator: order_by
  mtid: order_by
  oldId: order_by
  priority: order_by
  threadNumber: order_by
}

# columns and relationships of "refresh_log"
type refresh_log {
  duration: bigint
  error: String
  id: bigint!
  instant: Boolean
  mtid: bigint
  otype: String
  priority: Int
  requested: timestamp
  requester: bigint
  server: String
  stage: String
  threadNum: Int
  timestamp: timestamp
}

# aggregated selection of "refresh_log"
type refresh_log_aggregate {
  aggregate: refresh_log_aggregate_fields
  nodes: [refresh_log!]!
}

# aggregate fields of "refresh_log"
type refresh_log_aggregate_fields {
  avg: refresh_log_avg_fields
  count(columns: [refresh_log_select_column!], distinct: Boolean): Int
  max: refresh_log_max_fields
  min: refresh_log_min_fields
  stddev: refresh_log_stddev_fields
  stddev_pop: refresh_log_stddev_pop_fields
  stddev_samp: refresh_log_stddev_samp_fields
  sum: refresh_log_sum_fields
  var_pop: refresh_log_var_pop_fields
  var_samp: refresh_log_var_samp_fields
  variance: refresh_log_variance_fields
}

# order by aggregate values of table "refresh_log"
input refresh_log_aggregate_order_by {
  avg: refresh_log_avg_order_by
  count: order_by
  max: refresh_log_max_order_by
  min: refresh_log_min_order_by
  stddev: refresh_log_stddev_order_by
  stddev_pop: refresh_log_stddev_pop_order_by
  stddev_samp: refresh_log_stddev_samp_order_by
  sum: refresh_log_sum_order_by
  var_pop: refresh_log_var_pop_order_by
  var_samp: refresh_log_var_samp_order_by
  variance: refresh_log_variance_order_by
}

# input type for inserting array relation for remote table "refresh_log"
input refresh_log_arr_rel_insert_input {
  data: [refresh_log_insert_input!]!
  on_conflict: refresh_log_on_conflict
}

# aggregate avg on columns
type refresh_log_avg_fields {
  duration: Float
  id: Float
  mtid: Float
  priority: Float
  requester: Float
  threadNum: Float
}

# order by avg() on columns of table "refresh_log"
input refresh_log_avg_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# Boolean expression to filter rows from the table "refresh_log". All fields are combined with a logical 'AND'.
input refresh_log_bool_exp {
  _and: [refresh_log_bool_exp]
  _not: refresh_log_bool_exp
  _or: [refresh_log_bool_exp]
  duration: bigint_comparison_exp
  error: String_comparison_exp
  id: bigint_comparison_exp
  instant: Boolean_comparison_exp
  mtid: bigint_comparison_exp
  otype: String_comparison_exp
  priority: Int_comparison_exp
  requested: timestamp_comparison_exp
  requester: bigint_comparison_exp
  server: String_comparison_exp
  stage: String_comparison_exp
  threadNum: Int_comparison_exp
  timestamp: timestamp_comparison_exp
}

# unique or primary key constraints on table "refresh_log"
enum refresh_log_constraint {
  # unique or primary key constraint
  refresh_log_pkey
}

# input type for incrementing integer column in table "refresh_log"
input refresh_log_inc_input {
  duration: bigint
  id: bigint
  mtid: bigint
  priority: Int
  requester: bigint
  threadNum: Int
}

# input type for inserting data into table "refresh_log"
input refresh_log_insert_input {
  duration: bigint
  error: String
  id: bigint
  instant: Boolean
  mtid: bigint
  otype: String
  priority: Int
  requested: timestamp
  requester: bigint
  server: String
  stage: String
  threadNum: Int
  timestamp: timestamp
}

# aggregate max on columns
type refresh_log_max_fields {
  duration: bigint
  error: String
  id: bigint
  mtid: bigint
  otype: String
  priority: Int
  requested: timestamp
  requester: bigint
  server: String
  stage: String
  threadNum: Int
  timestamp: timestamp
}

# order by max() on columns of table "refresh_log"
input refresh_log_max_order_by {
  duration: order_by
  error: order_by
  id: order_by
  mtid: order_by
  otype: order_by
  priority: order_by
  requested: order_by
  requester: order_by
  server: order_by
  stage: order_by
  threadNum: order_by
  timestamp: order_by
}

# aggregate min on columns
type refresh_log_min_fields {
  duration: bigint
  error: String
  id: bigint
  mtid: bigint
  otype: String
  priority: Int
  requested: timestamp
  requester: bigint
  server: String
  stage: String
  threadNum: Int
  timestamp: timestamp
}

# order by min() on columns of table "refresh_log"
input refresh_log_min_order_by {
  duration: order_by
  error: order_by
  id: order_by
  mtid: order_by
  otype: order_by
  priority: order_by
  requested: order_by
  requester: order_by
  server: order_by
  stage: order_by
  threadNum: order_by
  timestamp: order_by
}

# response of any mutation on the table "refresh_log"
type refresh_log_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [refresh_log!]!
}

# input type for inserting object relation for remote table "refresh_log"
input refresh_log_obj_rel_insert_input {
  data: refresh_log_insert_input!
  on_conflict: refresh_log_on_conflict
}

# on conflict condition type for table "refresh_log"
input refresh_log_on_conflict {
  constraint: refresh_log_constraint!
  update_columns: [refresh_log_update_column!]!
  where: refresh_log_bool_exp
}

# ordering options when selecting data from "refresh_log"
input refresh_log_order_by {
  duration: order_by
  error: order_by
  id: order_by
  instant: order_by
  mtid: order_by
  otype: order_by
  priority: order_by
  requested: order_by
  requester: order_by
  server: order_by
  stage: order_by
  threadNum: order_by
  timestamp: order_by
}

# primary key columns input for table: "refresh_log"
input refresh_log_pk_columns_input {
  id: bigint!
}

# select columns of table "refresh_log"
enum refresh_log_select_column {
  # column name
  duration

  # column name
  error

  # column name
  id

  # column name
  instant

  # column name
  mtid

  # column name
  otype

  # column name
  priority

  # column name
  requested

  # column name
  requester

  # column name
  server

  # column name
  stage

  # column name
  threadNum

  # column name
  timestamp
}

# input type for updating data in table "refresh_log"
input refresh_log_set_input {
  duration: bigint
  error: String
  id: bigint
  instant: Boolean
  mtid: bigint
  otype: String
  priority: Int
  requested: timestamp
  requester: bigint
  server: String
  stage: String
  threadNum: Int
  timestamp: timestamp
}

# aggregate stddev on columns
type refresh_log_stddev_fields {
  duration: Float
  id: Float
  mtid: Float
  priority: Float
  requester: Float
  threadNum: Float
}

# order by stddev() on columns of table "refresh_log"
input refresh_log_stddev_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# aggregate stddev_pop on columns
type refresh_log_stddev_pop_fields {
  duration: Float
  id: Float
  mtid: Float
  priority: Float
  requester: Float
  threadNum: Float
}

# order by stddev_pop() on columns of table "refresh_log"
input refresh_log_stddev_pop_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# aggregate stddev_samp on columns
type refresh_log_stddev_samp_fields {
  duration: Float
  id: Float
  mtid: Float
  priority: Float
  requester: Float
  threadNum: Float
}

# order by stddev_samp() on columns of table "refresh_log"
input refresh_log_stddev_samp_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# aggregate sum on columns
type refresh_log_sum_fields {
  duration: bigint
  id: bigint
  mtid: bigint
  priority: Int
  requester: bigint
  threadNum: Int
}

# order by sum() on columns of table "refresh_log"
input refresh_log_sum_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# update columns of table "refresh_log"
enum refresh_log_update_column {
  # column name
  duration

  # column name
  error

  # column name
  id

  # column name
  instant

  # column name
  mtid

  # column name
  otype

  # column name
  priority

  # column name
  requested

  # column name
  requester

  # column name
  server

  # column name
  stage

  # column name
  threadNum

  # column name
  timestamp
}

# aggregate var_pop on columns
type refresh_log_var_pop_fields {
  duration: Float
  id: Float
  mtid: Float
  priority: Float
  requester: Float
  threadNum: Float
}

# order by var_pop() on columns of table "refresh_log"
input refresh_log_var_pop_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# aggregate var_samp on columns
type refresh_log_var_samp_fields {
  duration: Float
  id: Float
  mtid: Float
  priority: Float
  requester: Float
  threadNum: Float
}

# order by var_samp() on columns of table "refresh_log"
input refresh_log_var_samp_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# aggregate variance on columns
type refresh_log_variance_fields {
  duration: Float
  id: Float
  mtid: Float
  priority: Float
  requester: Float
  threadNum: Float
}

# order by variance() on columns of table "refresh_log"
input refresh_log_variance_order_by {
  duration: order_by
  id: order_by
  mtid: order_by
  priority: order_by
  requester: order_by
  threadNum: order_by
}

# columns and relationships of "reorg"
type reorg {
  # An object relationship
  ancestor: organization
  ancestorMtid: bigint
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  rtype: reorg_type
  rtypeMtid: bigint
  startDate: timestamp
  status: Int

  # An object relationship
  successor: organization
  successorMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "reorg"
type reorg_aggregate {
  aggregate: reorg_aggregate_fields
  nodes: [reorg!]!
}

# aggregate fields of "reorg"
type reorg_aggregate_fields {
  avg: reorg_avg_fields
  count(columns: [reorg_select_column!], distinct: Boolean): Int
  max: reorg_max_fields
  min: reorg_min_fields
  stddev: reorg_stddev_fields
  stddev_pop: reorg_stddev_pop_fields
  stddev_samp: reorg_stddev_samp_fields
  sum: reorg_sum_fields
  var_pop: reorg_var_pop_fields
  var_samp: reorg_var_samp_fields
  variance: reorg_variance_fields
}

# order by aggregate values of table "reorg"
input reorg_aggregate_order_by {
  avg: reorg_avg_order_by
  count: order_by
  max: reorg_max_order_by
  min: reorg_min_order_by
  stddev: reorg_stddev_order_by
  stddev_pop: reorg_stddev_pop_order_by
  stddev_samp: reorg_stddev_samp_order_by
  sum: reorg_sum_order_by
  var_pop: reorg_var_pop_order_by
  var_samp: reorg_var_samp_order_by
  variance: reorg_variance_order_by
}

# input type for inserting array relation for remote table "reorg"
input reorg_arr_rel_insert_input {
  data: [reorg_insert_input!]!
  on_conflict: reorg_on_conflict
}

# aggregate avg on columns
type reorg_avg_fields {
  ancestorMtid: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  rtypeMtid: Float
  status: Float
  successorMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "reorg"
input reorg_avg_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "reorg". All fields are combined with a logical 'AND'.
input reorg_bool_exp {
  _and: [reorg_bool_exp]
  _not: reorg_bool_exp
  _or: [reorg_bool_exp]
  ancestor: organization_bool_exp
  ancestorMtid: bigint_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  endDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  rtype: reorg_type_bool_exp
  rtypeMtid: bigint_comparison_exp
  startDate: timestamp_comparison_exp
  status: Int_comparison_exp
  successor: organization_bool_exp
  successorMtid: bigint_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "reorg"
enum reorg_constraint {
  # unique or primary key constraint
  reorg_pkey

  # unique or primary key constraint
  ukjhre64jm6u3louxs919i5fe2c
}

# input type for incrementing integer column in table "reorg"
input reorg_inc_input {
  ancestorMtid: bigint
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  rtypeMtid: bigint
  status: Int
  successorMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "reorg"
input reorg_insert_input {
  ancestor: organization_obj_rel_insert_input
  ancestorMtid: bigint
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  rtype: reorg_type_obj_rel_insert_input
  rtypeMtid: bigint
  startDate: timestamp
  status: Int
  successor: organization_obj_rel_insert_input
  successorMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type reorg_max_fields {
  ancestorMtid: bigint
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  rtypeMtid: bigint
  startDate: timestamp
  status: Int
  successorMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "reorg"
input reorg_max_order_by {
  ancestorMtid: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  rtypeMtid: order_by
  startDate: order_by
  status: order_by
  successorMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type reorg_min_fields {
  ancestorMtid: bigint
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  rtypeMtid: bigint
  startDate: timestamp
  status: Int
  successorMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "reorg"
input reorg_min_order_by {
  ancestorMtid: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  rtypeMtid: order_by
  startDate: order_by
  status: order_by
  successorMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "reorg"
type reorg_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [reorg!]!
}

# input type for inserting object relation for remote table "reorg"
input reorg_obj_rel_insert_input {
  data: reorg_insert_input!
  on_conflict: reorg_on_conflict
}

# on conflict condition type for table "reorg"
input reorg_on_conflict {
  constraint: reorg_constraint!
  update_columns: [reorg_update_column!]!
  where: reorg_bool_exp
}

# ordering options when selecting data from "reorg"
input reorg_order_by {
  ancestor: organization_order_by
  ancestorMtid: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  endDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  rtype: reorg_type_order_by
  rtypeMtid: order_by
  startDate: order_by
  status: order_by
  successor: organization_order_by
  successorMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "reorg"
input reorg_pk_columns_input {
  mtid: bigint!
}

# select columns of table "reorg"
enum reorg_select_column {
  # column name
  ancestorMtid

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  rtypeMtid

  # column name
  startDate

  # column name
  status

  # column name
  successorMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "reorg"
input reorg_set_input {
  ancestorMtid: bigint
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  endDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  rtypeMtid: bigint
  startDate: timestamp
  status: Int
  successorMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type reorg_stddev_fields {
  ancestorMtid: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  rtypeMtid: Float
  status: Float
  successorMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "reorg"
input reorg_stddev_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type reorg_stddev_pop_fields {
  ancestorMtid: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  rtypeMtid: Float
  status: Float
  successorMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "reorg"
input reorg_stddev_pop_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type reorg_stddev_samp_fields {
  ancestorMtid: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  rtypeMtid: Float
  status: Float
  successorMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "reorg"
input reorg_stddev_samp_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type reorg_sum_fields {
  ancestorMtid: bigint
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  rtypeMtid: bigint
  status: Int
  successorMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "reorg"
input reorg_sum_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "reorg_type"
type reorg_type {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  code: Int!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  structural: Boolean
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "reorg_type"
type reorg_type_aggregate {
  aggregate: reorg_type_aggregate_fields
  nodes: [reorg_type!]!
}

# aggregate fields of "reorg_type"
type reorg_type_aggregate_fields {
  avg: reorg_type_avg_fields
  count(columns: [reorg_type_select_column!], distinct: Boolean): Int
  max: reorg_type_max_fields
  min: reorg_type_min_fields
  stddev: reorg_type_stddev_fields
  stddev_pop: reorg_type_stddev_pop_fields
  stddev_samp: reorg_type_stddev_samp_fields
  sum: reorg_type_sum_fields
  var_pop: reorg_type_var_pop_fields
  var_samp: reorg_type_var_samp_fields
  variance: reorg_type_variance_fields
}

# order by aggregate values of table "reorg_type"
input reorg_type_aggregate_order_by {
  avg: reorg_type_avg_order_by
  count: order_by
  max: reorg_type_max_order_by
  min: reorg_type_min_order_by
  stddev: reorg_type_stddev_order_by
  stddev_pop: reorg_type_stddev_pop_order_by
  stddev_samp: reorg_type_stddev_samp_order_by
  sum: reorg_type_sum_order_by
  var_pop: reorg_type_var_pop_order_by
  var_samp: reorg_type_var_samp_order_by
  variance: reorg_type_variance_order_by
}

# input type for inserting array relation for remote table "reorg_type"
input reorg_type_arr_rel_insert_input {
  data: [reorg_type_insert_input!]!
  on_conflict: reorg_type_on_conflict
}

# aggregate avg on columns
type reorg_type_avg_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "reorg_type"
input reorg_type_avg_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "reorg_type". All fields are combined with a logical 'AND'.
input reorg_type_bool_exp {
  _and: [reorg_type_bool_exp]
  _not: reorg_type_bool_exp
  _or: [reorg_type_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  code: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  structural: Boolean_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "reorg_type"
enum reorg_type_constraint {
  # unique or primary key constraint
  reorg_type_pkey
}

# input type for incrementing integer column in table "reorg_type"
input reorg_type_inc_input {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "reorg_type"
input reorg_type_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  structural: Boolean
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type reorg_type_max_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "reorg_type"
input reorg_type_max_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type reorg_type_min_fields {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "reorg_type"
input reorg_type_min_order_by {
  approved: order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "reorg_type"
type reorg_type_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [reorg_type!]!
}

# input type for inserting object relation for remote table "reorg_type"
input reorg_type_obj_rel_insert_input {
  data: reorg_type_insert_input!
  on_conflict: reorg_type_on_conflict
}

# on conflict condition type for table "reorg_type"
input reorg_type_on_conflict {
  constraint: reorg_type_constraint!
  update_columns: [reorg_type_update_column!]!
  where: reorg_type_bool_exp
}

# ordering options when selecting data from "reorg_type"
input reorg_type_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  structural: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "reorg_type"
input reorg_type_pk_columns_input {
  mtid: bigint!
}

# select columns of table "reorg_type"
enum reorg_type_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  structural

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "reorg_type"
input reorg_type_set_input {
  approved: timestamp
  approverMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  structural: Boolean
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type reorg_type_stddev_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "reorg_type"
input reorg_type_stddev_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type reorg_type_stddev_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "reorg_type"
input reorg_type_stddev_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type reorg_type_stddev_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "reorg_type"
input reorg_type_stddev_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type reorg_type_sum_fields {
  approverMtid: bigint
  code: Int
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "reorg_type"
input reorg_type_sum_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "reorg_type"
enum reorg_type_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  structural

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type reorg_type_var_pop_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "reorg_type"
input reorg_type_var_pop_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type reorg_type_var_samp_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "reorg_type"
input reorg_type_var_samp_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type reorg_type_variance_fields {
  approverMtid: Float
  code: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "reorg_type"
input reorg_type_variance_order_by {
  approverMtid: order_by
  code: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "reorg"
enum reorg_update_column {
  # column name
  ancestorMtid

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  endDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  rtypeMtid

  # column name
  startDate

  # column name
  status

  # column name
  successorMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type reorg_var_pop_fields {
  ancestorMtid: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  rtypeMtid: Float
  status: Float
  successorMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "reorg"
input reorg_var_pop_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type reorg_var_samp_fields {
  ancestorMtid: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  rtypeMtid: Float
  status: Float
  successorMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "reorg"
input reorg_var_samp_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type reorg_variance_fields {
  ancestorMtid: Float
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  rtypeMtid: Float
  status: Float
  successorMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "reorg"
input reorg_variance_order_by {
  ancestorMtid: order_by
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  rtypeMtid: order_by
  status: order_by
  successorMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "report"
type report {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  centralAdminPublished: Boolean!
  comment: String
  comment2: String

  # An array relationship
  contents(
    # distinct select on columns
    distinct_on: [report_contents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_contents_order_by!]

    # filter the rows returned
    where: report_contents_bool_exp
  ): [report_contents!]!

  # An aggregated array relationship
  contents_aggregate(
    # distinct select on columns
    distinct_on: [report_contents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_contents_order_by!]

    # filter the rows returned
    where: report_contents_bool_exp
  ): report_contents_aggregate!
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  filename: String
  folder: String
  folderpath: String
  hint: String
  hintEng: String
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  outputType: String
  ownerInstitute: bigint
  prevValid: bigint
  progress: String
  published: Boolean!
  queued: Boolean!
  recordType: String
  refreshed: Boolean!
  reportFieldLinks: String

  # An object relationship
  reportRequest: report_request
  reportRequestMtid: bigint
  seen: Boolean
  showInPublicationView: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An object relationship
  theOwnerInstitute: organization
  thread: String
  threadId: bigint!
  threadName: String
  threadPriority: Int!
  title: String
  unhandledTickets: Int!
  url: String
  validFromYear: smallint
  validToYear: smallint
  xml_mtid: bigint
}

# aggregated selection of "report"
type report_aggregate {
  aggregate: report_aggregate_fields
  nodes: [report!]!
}

# aggregate fields of "report"
type report_aggregate_fields {
  avg: report_avg_fields
  count(columns: [report_select_column!], distinct: Boolean): Int
  max: report_max_fields
  min: report_min_fields
  stddev: report_stddev_fields
  stddev_pop: report_stddev_pop_fields
  stddev_samp: report_stddev_samp_fields
  sum: report_sum_fields
  var_pop: report_var_pop_fields
  var_samp: report_var_samp_fields
  variance: report_variance_fields
}

# order by aggregate values of table "report"
input report_aggregate_order_by {
  avg: report_avg_order_by
  count: order_by
  max: report_max_order_by
  min: report_min_order_by
  stddev: report_stddev_order_by
  stddev_pop: report_stddev_pop_order_by
  stddev_samp: report_stddev_samp_order_by
  sum: report_sum_order_by
  var_pop: report_var_pop_order_by
  var_samp: report_var_samp_order_by
  variance: report_variance_order_by
}

# input type for inserting array relation for remote table "report"
input report_arr_rel_insert_input {
  data: [report_insert_input!]!
  on_conflict: report_on_conflict
}

# aggregate avg on columns
type report_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xml_mtid: Float
}

# order by avg() on columns of table "report"
input report_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# Boolean expression to filter rows from the table "report". All fields are combined with a logical 'AND'.
input report_bool_exp {
  _and: [report_bool_exp]
  _not: report_bool_exp
  _or: [report_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  centralAdminPublished: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  contents: report_contents_bool_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  filename: String_comparison_exp
  folder: String_comparison_exp
  folderpath: String_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  jobEndDate: timestamp_comparison_exp
  jobError: String_comparison_exp
  jobException: String_comparison_exp
  jobId: bigint_comparison_exp
  jobParams: String_comparison_exp
  jobStartDate: timestamp_comparison_exp
  jobStatus: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  needsNotification: Boolean_comparison_exp
  notified: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  outputType: String_comparison_exp
  ownerInstitute: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  progress: String_comparison_exp
  published: Boolean_comparison_exp
  queued: Boolean_comparison_exp
  recordType: String_comparison_exp
  refreshed: Boolean_comparison_exp
  reportFieldLinks: String_comparison_exp
  reportRequest: report_request_bool_exp
  reportRequestMtid: bigint_comparison_exp
  seen: Boolean_comparison_exp
  showInPublicationView: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  theOwnerInstitute: organization_bool_exp
  thread: String_comparison_exp
  threadId: bigint_comparison_exp
  threadName: String_comparison_exp
  threadPriority: Int_comparison_exp
  title: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  url: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  xml_mtid: bigint_comparison_exp
}

# unique or primary key constraints on table "report"
enum report_constraint {
  # unique or primary key constraint
  report_pkey
}

# columns and relationships of "report_content"
type report_content {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int

  # An array relationship
  fileContent(
    # distinct select on columns
    distinct_on: [report_content_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_file_content_order_by!]

    # filter the rows returned
    where: report_content_file_content_bool_exp
  ): [report_content_file_content!]!

  # An aggregated array relationship
  fileContent_aggregate(
    # distinct select on columns
    distinct_on: [report_content_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_file_content_order_by!]

    # filter the rows returned
    where: report_content_file_content_bool_exp
  ): report_content_file_content_aggregate!
  filename: String
  filepath: String
  htmlPath: String
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mimeType: String
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "report_content"
type report_content_aggregate {
  aggregate: report_content_aggregate_fields
  nodes: [report_content!]!
}

# aggregate fields of "report_content"
type report_content_aggregate_fields {
  avg: report_content_avg_fields
  count(columns: [report_content_select_column!], distinct: Boolean): Int
  max: report_content_max_fields
  min: report_content_min_fields
  stddev: report_content_stddev_fields
  stddev_pop: report_content_stddev_pop_fields
  stddev_samp: report_content_stddev_samp_fields
  sum: report_content_sum_fields
  var_pop: report_content_var_pop_fields
  var_samp: report_content_var_samp_fields
  variance: report_content_variance_fields
}

# order by aggregate values of table "report_content"
input report_content_aggregate_order_by {
  avg: report_content_avg_order_by
  count: order_by
  max: report_content_max_order_by
  min: report_content_min_order_by
  stddev: report_content_stddev_order_by
  stddev_pop: report_content_stddev_pop_order_by
  stddev_samp: report_content_stddev_samp_order_by
  sum: report_content_sum_order_by
  var_pop: report_content_var_pop_order_by
  var_samp: report_content_var_samp_order_by
  variance: report_content_variance_order_by
}

# input type for inserting array relation for remote table "report_content"
input report_content_arr_rel_insert_input {
  data: [report_content_insert_input!]!
  on_conflict: report_content_on_conflict
}

# aggregate avg on columns
type report_content_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "report_content"
input report_content_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "report_content". All fields are combined with a logical 'AND'.
input report_content_bool_exp {
  _and: [report_content_bool_exp]
  _not: report_content_bool_exp
  _or: [report_content_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  fileContent: report_content_file_content_bool_exp
  filename: String_comparison_exp
  filepath: String_comparison_exp
  htmlPath: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  language: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mimeType: String_comparison_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parentId: bigint_comparison_exp
  parentType: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  size: bigint_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "report_content"
enum report_content_constraint {
  # unique or primary key constraint
  report_content_pkey
}

# columns and relationships of "report_content_file_content"
type report_content_file_content {
  # An object relationship
  binaryContent: binary_content!
  fileContentId: bigint!
  reportContentMtid: bigint!
}

# aggregated selection of "report_content_file_content"
type report_content_file_content_aggregate {
  aggregate: report_content_file_content_aggregate_fields
  nodes: [report_content_file_content!]!
}

# aggregate fields of "report_content_file_content"
type report_content_file_content_aggregate_fields {
  avg: report_content_file_content_avg_fields
  count(columns: [report_content_file_content_select_column!], distinct: Boolean): Int
  max: report_content_file_content_max_fields
  min: report_content_file_content_min_fields
  stddev: report_content_file_content_stddev_fields
  stddev_pop: report_content_file_content_stddev_pop_fields
  stddev_samp: report_content_file_content_stddev_samp_fields
  sum: report_content_file_content_sum_fields
  var_pop: report_content_file_content_var_pop_fields
  var_samp: report_content_file_content_var_samp_fields
  variance: report_content_file_content_variance_fields
}

# order by aggregate values of table "report_content_file_content"
input report_content_file_content_aggregate_order_by {
  avg: report_content_file_content_avg_order_by
  count: order_by
  max: report_content_file_content_max_order_by
  min: report_content_file_content_min_order_by
  stddev: report_content_file_content_stddev_order_by
  stddev_pop: report_content_file_content_stddev_pop_order_by
  stddev_samp: report_content_file_content_stddev_samp_order_by
  sum: report_content_file_content_sum_order_by
  var_pop: report_content_file_content_var_pop_order_by
  var_samp: report_content_file_content_var_samp_order_by
  variance: report_content_file_content_variance_order_by
}

# input type for inserting array relation for remote table "report_content_file_content"
input report_content_file_content_arr_rel_insert_input {
  data: [report_content_file_content_insert_input!]!
}

# aggregate avg on columns
type report_content_file_content_avg_fields {
  fileContentId: Float
  reportContentMtid: Float
}

# order by avg() on columns of table "report_content_file_content"
input report_content_file_content_avg_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# Boolean expression to filter rows from the table "report_content_file_content".
# All fields are combined with a logical 'AND'.
input report_content_file_content_bool_exp {
  _and: [report_content_file_content_bool_exp]
  _not: report_content_file_content_bool_exp
  _or: [report_content_file_content_bool_exp]
  binaryContent: binary_content_bool_exp
  fileContentId: bigint_comparison_exp
  reportContentMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "report_content_file_content"
input report_content_file_content_inc_input {
  fileContentId: bigint
  reportContentMtid: bigint
}

# input type for inserting data into table "report_content_file_content"
input report_content_file_content_insert_input {
  binaryContent: binary_content_obj_rel_insert_input
  fileContentId: bigint
  reportContentMtid: bigint
}

# aggregate max on columns
type report_content_file_content_max_fields {
  fileContentId: bigint
  reportContentMtid: bigint
}

# order by max() on columns of table "report_content_file_content"
input report_content_file_content_max_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# aggregate min on columns
type report_content_file_content_min_fields {
  fileContentId: bigint
  reportContentMtid: bigint
}

# order by min() on columns of table "report_content_file_content"
input report_content_file_content_min_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# response of any mutation on the table "report_content_file_content"
type report_content_file_content_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_content_file_content!]!
}

# input type for inserting object relation for remote table "report_content_file_content"
input report_content_file_content_obj_rel_insert_input {
  data: report_content_file_content_insert_input!
}

# ordering options when selecting data from "report_content_file_content"
input report_content_file_content_order_by {
  binaryContent: binary_content_order_by
  fileContentId: order_by
  reportContentMtid: order_by
}

# select columns of table "report_content_file_content"
enum report_content_file_content_select_column {
  # column name
  fileContentId

  # column name
  reportContentMtid
}

# input type for updating data in table "report_content_file_content"
input report_content_file_content_set_input {
  fileContentId: bigint
  reportContentMtid: bigint
}

# aggregate stddev on columns
type report_content_file_content_stddev_fields {
  fileContentId: Float
  reportContentMtid: Float
}

# order by stddev() on columns of table "report_content_file_content"
input report_content_file_content_stddev_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# aggregate stddev_pop on columns
type report_content_file_content_stddev_pop_fields {
  fileContentId: Float
  reportContentMtid: Float
}

# order by stddev_pop() on columns of table "report_content_file_content"
input report_content_file_content_stddev_pop_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# aggregate stddev_samp on columns
type report_content_file_content_stddev_samp_fields {
  fileContentId: Float
  reportContentMtid: Float
}

# order by stddev_samp() on columns of table "report_content_file_content"
input report_content_file_content_stddev_samp_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# aggregate sum on columns
type report_content_file_content_sum_fields {
  fileContentId: bigint
  reportContentMtid: bigint
}

# order by sum() on columns of table "report_content_file_content"
input report_content_file_content_sum_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# aggregate var_pop on columns
type report_content_file_content_var_pop_fields {
  fileContentId: Float
  reportContentMtid: Float
}

# order by var_pop() on columns of table "report_content_file_content"
input report_content_file_content_var_pop_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# aggregate var_samp on columns
type report_content_file_content_var_samp_fields {
  fileContentId: Float
  reportContentMtid: Float
}

# order by var_samp() on columns of table "report_content_file_content"
input report_content_file_content_var_samp_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# aggregate variance on columns
type report_content_file_content_variance_fields {
  fileContentId: Float
  reportContentMtid: Float
}

# order by variance() on columns of table "report_content_file_content"
input report_content_file_content_variance_order_by {
  fileContentId: order_by
  reportContentMtid: order_by
}

# input type for incrementing integer column in table "report_content"
input report_content_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentId: bigint
  prevValid: bigint
  size: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "report_content"
input report_content_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  fileContent: report_content_file_content_arr_rel_insert_input
  filename: String
  filepath: String
  htmlPath: String
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mimeType: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type report_content_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  htmlPath: String
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mimeType: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "report_content"
input report_content_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  filepath: order_by
  htmlPath: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mimeType: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentId: order_by
  parentType: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type report_content_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  htmlPath: String
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mimeType: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "report_content"
input report_content_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  filepath: order_by
  htmlPath: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mimeType: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentId: order_by
  parentType: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "report_content"
type report_content_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_content!]!
}

# input type for inserting object relation for remote table "report_content"
input report_content_obj_rel_insert_input {
  data: report_content_insert_input!
  on_conflict: report_content_on_conflict
}

# on conflict condition type for table "report_content"
input report_content_on_conflict {
  constraint: report_content_constraint!
  update_columns: [report_content_update_column!]!
  where: report_content_bool_exp
}

# ordering options when selecting data from "report_content"
input report_content_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  fileContent_aggregate: report_content_file_content_aggregate_order_by
  filename: order_by
  filepath: order_by
  htmlPath: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mimeType: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentId: order_by
  parentType: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  size: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "report_content"
input report_content_pk_columns_input {
  mtid: bigint!
}

# select columns of table "report_content"
enum report_content_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  filepath

  # column name
  htmlPath

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mimeType

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentId

  # column name
  parentType

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  size

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "report_content"
input report_content_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  htmlPath: String
  labelEng: String
  labelHun: String
  language: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mimeType: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type report_content_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "report_content"
input report_content_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type report_content_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "report_content"
input report_content_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type report_content_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "report_content"
input report_content_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type report_content_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentId: bigint
  prevValid: bigint
  size: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "report_content"
input report_content_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "report_content"
enum report_content_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  filepath

  # column name
  htmlPath

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mimeType

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentId

  # column name
  parentType

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  size

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type report_content_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "report_content"
input report_content_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type report_content_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "report_content"
input report_content_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type report_content_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "report_content"
input report_content_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "report_contents"
type report_contents {
  contentsMtid: bigint!

  # An object relationship
  reportContent: report_content!
  reportMtid: bigint!
}

# aggregated selection of "report_contents"
type report_contents_aggregate {
  aggregate: report_contents_aggregate_fields
  nodes: [report_contents!]!
}

# aggregate fields of "report_contents"
type report_contents_aggregate_fields {
  avg: report_contents_avg_fields
  count(columns: [report_contents_select_column!], distinct: Boolean): Int
  max: report_contents_max_fields
  min: report_contents_min_fields
  stddev: report_contents_stddev_fields
  stddev_pop: report_contents_stddev_pop_fields
  stddev_samp: report_contents_stddev_samp_fields
  sum: report_contents_sum_fields
  var_pop: report_contents_var_pop_fields
  var_samp: report_contents_var_samp_fields
  variance: report_contents_variance_fields
}

# order by aggregate values of table "report_contents"
input report_contents_aggregate_order_by {
  avg: report_contents_avg_order_by
  count: order_by
  max: report_contents_max_order_by
  min: report_contents_min_order_by
  stddev: report_contents_stddev_order_by
  stddev_pop: report_contents_stddev_pop_order_by
  stddev_samp: report_contents_stddev_samp_order_by
  sum: report_contents_sum_order_by
  var_pop: report_contents_var_pop_order_by
  var_samp: report_contents_var_samp_order_by
  variance: report_contents_variance_order_by
}

# input type for inserting array relation for remote table "report_contents"
input report_contents_arr_rel_insert_input {
  data: [report_contents_insert_input!]!
  on_conflict: report_contents_on_conflict
}

# aggregate avg on columns
type report_contents_avg_fields {
  contentsMtid: Float
  reportMtid: Float
}

# order by avg() on columns of table "report_contents"
input report_contents_avg_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# Boolean expression to filter rows from the table "report_contents". All fields are combined with a logical 'AND'.
input report_contents_bool_exp {
  _and: [report_contents_bool_exp]
  _not: report_contents_bool_exp
  _or: [report_contents_bool_exp]
  contentsMtid: bigint_comparison_exp
  reportContent: report_content_bool_exp
  reportMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "report_contents"
enum report_contents_constraint {
  # unique or primary key constraint
  uk_d7kwqdss9rap2ayes1om5525w
}

# input type for incrementing integer column in table "report_contents"
input report_contents_inc_input {
  contentsMtid: bigint
  reportMtid: bigint
}

# input type for inserting data into table "report_contents"
input report_contents_insert_input {
  contentsMtid: bigint
  reportContent: report_content_obj_rel_insert_input
  reportMtid: bigint
}

# aggregate max on columns
type report_contents_max_fields {
  contentsMtid: bigint
  reportMtid: bigint
}

# order by max() on columns of table "report_contents"
input report_contents_max_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# aggregate min on columns
type report_contents_min_fields {
  contentsMtid: bigint
  reportMtid: bigint
}

# order by min() on columns of table "report_contents"
input report_contents_min_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# response of any mutation on the table "report_contents"
type report_contents_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_contents!]!
}

# input type for inserting object relation for remote table "report_contents"
input report_contents_obj_rel_insert_input {
  data: report_contents_insert_input!
  on_conflict: report_contents_on_conflict
}

# on conflict condition type for table "report_contents"
input report_contents_on_conflict {
  constraint: report_contents_constraint!
  update_columns: [report_contents_update_column!]!
  where: report_contents_bool_exp
}

# ordering options when selecting data from "report_contents"
input report_contents_order_by {
  contentsMtid: order_by
  reportContent: report_content_order_by
  reportMtid: order_by
}

# select columns of table "report_contents"
enum report_contents_select_column {
  # column name
  contentsMtid

  # column name
  reportMtid
}

# input type for updating data in table "report_contents"
input report_contents_set_input {
  contentsMtid: bigint
  reportMtid: bigint
}

# aggregate stddev on columns
type report_contents_stddev_fields {
  contentsMtid: Float
  reportMtid: Float
}

# order by stddev() on columns of table "report_contents"
input report_contents_stddev_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# aggregate stddev_pop on columns
type report_contents_stddev_pop_fields {
  contentsMtid: Float
  reportMtid: Float
}

# order by stddev_pop() on columns of table "report_contents"
input report_contents_stddev_pop_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# aggregate stddev_samp on columns
type report_contents_stddev_samp_fields {
  contentsMtid: Float
  reportMtid: Float
}

# order by stddev_samp() on columns of table "report_contents"
input report_contents_stddev_samp_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# aggregate sum on columns
type report_contents_sum_fields {
  contentsMtid: bigint
  reportMtid: bigint
}

# order by sum() on columns of table "report_contents"
input report_contents_sum_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# update columns of table "report_contents"
enum report_contents_update_column {
  # column name
  contentsMtid

  # column name
  reportMtid
}

# aggregate var_pop on columns
type report_contents_var_pop_fields {
  contentsMtid: Float
  reportMtid: Float
}

# order by var_pop() on columns of table "report_contents"
input report_contents_var_pop_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# aggregate var_samp on columns
type report_contents_var_samp_fields {
  contentsMtid: Float
  reportMtid: Float
}

# order by var_samp() on columns of table "report_contents"
input report_contents_var_samp_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# aggregate variance on columns
type report_contents_variance_fields {
  contentsMtid: Float
  reportMtid: Float
}

# order by variance() on columns of table "report_contents"
input report_contents_variance_order_by {
  contentsMtid: order_by
  reportMtid: order_by
}

# input type for incrementing integer column in table "report"
input report_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  reportRequestMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xml_mtid: bigint
}

# input type for inserting data into table "report"
input report_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  centralAdminPublished: Boolean
  comment: String
  comment2: String
  contents: report_contents_arr_rel_insert_input
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filename: String
  folder: String
  folderpath: String
  hint: String
  hintEng: String
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  outputType: String
  ownerInstitute: bigint
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  recordType: String
  refreshed: Boolean
  reportFieldLinks: String
  reportRequest: report_request_obj_rel_insert_input
  reportRequestMtid: bigint
  seen: Boolean
  showInPublicationView: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  theOwnerInstitute: organization_obj_rel_insert_input
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  title: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  xml_mtid: bigint
}

# aggregate max on columns
type report_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  folder: String
  folderpath: String
  hint: String
  hintEng: String
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  outputType: String
  ownerInstitute: bigint
  prevValid: bigint
  progress: String
  recordType: String
  reportFieldLinks: String
  reportRequestMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  title: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  xml_mtid: bigint
}

# order by max() on columns of table "report"
input report_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  folder: order_by
  folderpath: order_by
  hint: order_by
  hintEng: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  outputType: order_by
  ownerInstitute: order_by
  prevValid: order_by
  progress: order_by
  recordType: order_by
  reportFieldLinks: order_by
  reportRequestMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  title: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# aggregate min on columns
type report_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  folder: String
  folderpath: String
  hint: String
  hintEng: String
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  outputType: String
  ownerInstitute: bigint
  prevValid: bigint
  progress: String
  recordType: String
  reportFieldLinks: String
  reportRequestMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  title: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  xml_mtid: bigint
}

# order by min() on columns of table "report"
input report_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  folder: order_by
  folderpath: order_by
  hint: order_by
  hintEng: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  outputType: order_by
  ownerInstitute: order_by
  prevValid: order_by
  progress: order_by
  recordType: order_by
  reportFieldLinks: order_by
  reportRequestMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  title: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# response of any mutation on the table "report"
type report_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report!]!
}

# input type for inserting object relation for remote table "report"
input report_obj_rel_insert_input {
  data: report_insert_input!
  on_conflict: report_on_conflict
}

# on conflict condition type for table "report"
input report_on_conflict {
  constraint: report_constraint!
  update_columns: [report_update_column!]!
  where: report_bool_exp
}

# ordering options when selecting data from "report"
input report_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  centralAdminPublished: order_by
  comment: order_by
  comment2: order_by
  contents_aggregate: report_contents_aggregate_order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  folder: order_by
  folderpath: order_by
  hint: order_by
  hintEng: order_by
  jobEndDate: order_by
  jobError: order_by
  jobException: order_by
  jobId: order_by
  jobParams: order_by
  jobStartDate: order_by
  jobStatus: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  needsNotification: order_by
  notified: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  outputType: order_by
  ownerInstitute: order_by
  prevValid: order_by
  progress: order_by
  published: order_by
  queued: order_by
  recordType: order_by
  refreshed: order_by
  reportFieldLinks: order_by
  reportRequest: report_request_order_by
  reportRequestMtid: order_by
  seen: order_by
  showInPublicationView: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  theOwnerInstitute: organization_order_by
  thread: order_by
  threadId: order_by
  threadName: order_by
  threadPriority: order_by
  title: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# columns and relationships of "report_parameter"
type report_parameter {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  booleanValue: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  dateValue: date
  deleted: Boolean!
  deletedDate: timestamp
  doubleValue: float8
  dtype: String!
  error: Int
  floatValue: Float
  hint: String
  hintEng: String
  integerArrayValue: bytea
  integerValue: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameterName: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  reportRequest: report_request
  reportRequestMtid: bigint
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  timeValue: timestamp
  timestampValue: timestamp
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "report_parameter"
type report_parameter_aggregate {
  aggregate: report_parameter_aggregate_fields
  nodes: [report_parameter!]!
}

# aggregate fields of "report_parameter"
type report_parameter_aggregate_fields {
  avg: report_parameter_avg_fields
  count(columns: [report_parameter_select_column!], distinct: Boolean): Int
  max: report_parameter_max_fields
  min: report_parameter_min_fields
  stddev: report_parameter_stddev_fields
  stddev_pop: report_parameter_stddev_pop_fields
  stddev_samp: report_parameter_stddev_samp_fields
  sum: report_parameter_sum_fields
  var_pop: report_parameter_var_pop_fields
  var_samp: report_parameter_var_samp_fields
  variance: report_parameter_variance_fields
}

# order by aggregate values of table "report_parameter"
input report_parameter_aggregate_order_by {
  avg: report_parameter_avg_order_by
  count: order_by
  max: report_parameter_max_order_by
  min: report_parameter_min_order_by
  stddev: report_parameter_stddev_order_by
  stddev_pop: report_parameter_stddev_pop_order_by
  stddev_samp: report_parameter_stddev_samp_order_by
  sum: report_parameter_sum_order_by
  var_pop: report_parameter_var_pop_order_by
  var_samp: report_parameter_var_samp_order_by
  variance: report_parameter_variance_order_by
}

# input type for inserting array relation for remote table "report_parameter"
input report_parameter_arr_rel_insert_input {
  data: [report_parameter_insert_input!]!
  on_conflict: report_parameter_on_conflict
}

# aggregate avg on columns
type report_parameter_avg_fields {
  approverMtid: Float
  creator: Float
  doubleValue: Float
  error: Float
  floatValue: Float
  integerValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "report_parameter"
input report_parameter_avg_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "report_parameter". All fields are combined with a logical 'AND'.
input report_parameter_bool_exp {
  _and: [report_parameter_bool_exp]
  _not: report_parameter_bool_exp
  _or: [report_parameter_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  booleanValue: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  dateValue: date_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  doubleValue: float8_comparison_exp
  dtype: String_comparison_exp
  error: Int_comparison_exp
  floatValue: Float_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  integerArrayValue: bytea_comparison_exp
  integerValue: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parameterName: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  reportRequest: report_request_bool_exp
  reportRequestMtid: bigint_comparison_exp
  status: Int_comparison_exp
  stringValue: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  timeValue: timestamp_comparison_exp
  timestampValue: timestamp_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "report_parameter"
enum report_parameter_constraint {
  # unique or primary key constraint
  report_parameter_pkey
}

# input type for incrementing integer column in table "report_parameter"
input report_parameter_inc_input {
  approverMtid: bigint
  creator: bigint
  doubleValue: float8
  error: Int
  floatValue: Float
  integerValue: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  reportRequestMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "report_parameter"
input report_parameter_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  booleanValue: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  dateValue: date
  deleted: Boolean
  deletedDate: timestamp
  doubleValue: float8
  dtype: String
  error: Int
  floatValue: Float
  hint: String
  hintEng: String
  integerArrayValue: bytea
  integerValue: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameterName: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  reportRequest: report_request_obj_rel_insert_input
  reportRequestMtid: bigint
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  timeValue: timestamp
  timestampValue: timestamp
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type report_parameter_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dateValue: date
  deletedDate: timestamp
  doubleValue: float8
  dtype: String
  error: Int
  floatValue: Float
  hint: String
  hintEng: String
  integerValue: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameterName: String
  prevValid: bigint
  reportRequestMtid: bigint
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  timeValue: timestamp
  timestampValue: timestamp
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "report_parameter"
input report_parameter_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dateValue: order_by
  deletedDate: order_by
  doubleValue: order_by
  dtype: order_by
  error: order_by
  floatValue: order_by
  hint: order_by
  hintEng: order_by
  integerValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parameterName: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  stringValue: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  timeValue: order_by
  timestampValue: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type report_parameter_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dateValue: date
  deletedDate: timestamp
  doubleValue: float8
  dtype: String
  error: Int
  floatValue: Float
  hint: String
  hintEng: String
  integerValue: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameterName: String
  prevValid: bigint
  reportRequestMtid: bigint
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  timeValue: timestamp
  timestampValue: timestamp
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "report_parameter"
input report_parameter_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dateValue: order_by
  deletedDate: order_by
  doubleValue: order_by
  dtype: order_by
  error: order_by
  floatValue: order_by
  hint: order_by
  hintEng: order_by
  integerValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parameterName: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  stringValue: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  timeValue: order_by
  timestampValue: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "report_parameter"
type report_parameter_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_parameter!]!
}

# input type for inserting object relation for remote table "report_parameter"
input report_parameter_obj_rel_insert_input {
  data: report_parameter_insert_input!
  on_conflict: report_parameter_on_conflict
}

# on conflict condition type for table "report_parameter"
input report_parameter_on_conflict {
  constraint: report_parameter_constraint!
  update_columns: [report_parameter_update_column!]!
  where: report_parameter_bool_exp
}

# ordering options when selecting data from "report_parameter"
input report_parameter_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  booleanValue: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  dateValue: order_by
  deleted: order_by
  deletedDate: order_by
  doubleValue: order_by
  dtype: order_by
  error: order_by
  floatValue: order_by
  hint: order_by
  hintEng: order_by
  integerArrayValue: order_by
  integerValue: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parameterName: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  reportRequest: report_request_order_by
  reportRequestMtid: order_by
  status: order_by
  stringValue: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  timeValue: order_by
  timestampValue: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "report_parameter"
input report_parameter_pk_columns_input {
  mtid: bigint!
}

# select columns of table "report_parameter"
enum report_parameter_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  booleanValue

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dateValue

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doubleValue

  # column name
  dtype

  # column name
  error

  # column name
  floatValue

  # column name
  hint

  # column name
  hintEng

  # column name
  integerArrayValue

  # column name
  integerValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parameterName

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  reportRequestMtid

  # column name
  status

  # column name
  stringValue

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  timeValue

  # column name
  timestampValue

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "report_parameter"
input report_parameter_set_input {
  approved: timestamp
  approverMtid: bigint
  booleanValue: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dateValue: date
  deleted: Boolean
  deletedDate: timestamp
  doubleValue: float8
  dtype: String
  error: Int
  floatValue: Float
  hint: String
  hintEng: String
  integerArrayValue: bytea
  integerValue: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parameterName: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  reportRequestMtid: bigint
  status: Int
  stringValue: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  timeValue: timestamp
  timestampValue: timestamp
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type report_parameter_stddev_fields {
  approverMtid: Float
  creator: Float
  doubleValue: Float
  error: Float
  floatValue: Float
  integerValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "report_parameter"
input report_parameter_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type report_parameter_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  doubleValue: Float
  error: Float
  floatValue: Float
  integerValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "report_parameter"
input report_parameter_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type report_parameter_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  doubleValue: Float
  error: Float
  floatValue: Float
  integerValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "report_parameter"
input report_parameter_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type report_parameter_sum_fields {
  approverMtid: bigint
  creator: bigint
  doubleValue: float8
  error: Int
  floatValue: Float
  integerValue: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  reportRequestMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "report_parameter"
input report_parameter_sum_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "report_parameter"
enum report_parameter_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  booleanValue

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dateValue

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doubleValue

  # column name
  dtype

  # column name
  error

  # column name
  floatValue

  # column name
  hint

  # column name
  hintEng

  # column name
  integerArrayValue

  # column name
  integerValue

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parameterName

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  reportRequestMtid

  # column name
  status

  # column name
  stringValue

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  timeValue

  # column name
  timestampValue

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type report_parameter_var_pop_fields {
  approverMtid: Float
  creator: Float
  doubleValue: Float
  error: Float
  floatValue: Float
  integerValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "report_parameter"
input report_parameter_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type report_parameter_var_samp_fields {
  approverMtid: Float
  creator: Float
  doubleValue: Float
  error: Float
  floatValue: Float
  integerValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "report_parameter"
input report_parameter_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type report_parameter_variance_fields {
  approverMtid: Float
  creator: Float
  doubleValue: Float
  error: Float
  floatValue: Float
  integerValue: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "report_parameter"
input report_parameter_variance_order_by {
  approverMtid: order_by
  creator: order_by
  doubleValue: order_by
  error: order_by
  floatValue: order_by
  integerValue: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "report"
input report_pk_columns_input {
  mtid: bigint!
}

# columns and relationships of "report_request"
type report_request {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  doRefresh: Boolean!
  error: Int
  expectedType: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String

  # An array relationship
  params(
    # distinct select on columns
    distinct_on: [report_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_parameter_order_by!]

    # filter the rows returned
    where: report_parameter_bool_exp
  ): [report_parameter!]!

  # An aggregated array relationship
  params_aggregate(
    # distinct select on columns
    distinct_on: [report_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_parameter_order_by!]

    # filter the rows returned
    where: report_parameter_bool_exp
  ): report_parameter_aggregate!
  prevValid: bigint
  published: Boolean!

  # An array relationship
  queries(
    # distinct select on columns
    distinct_on: [report_request_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_queries_order_by!]

    # filter the rows returned
    where: report_request_queries_bool_exp
  ): [report_request_queries!]!

  # An aggregated array relationship
  queries_aggregate(
    # distinct select on columns
    distinct_on: [report_request_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_queries_order_by!]

    # filter the rows returned
    where: report_request_queries_bool_exp
  ): report_request_queries_aggregate!
  refreshed: Boolean!

  # An object relationship
  reportTemplate: report_template
  reportTemplateMtid: bigint

  # An object relationship
  result: report
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  xmlId: bigint
}

# aggregated selection of "report_request"
type report_request_aggregate {
  aggregate: report_request_aggregate_fields
  nodes: [report_request!]!
}

# aggregate fields of "report_request"
type report_request_aggregate_fields {
  avg: report_request_avg_fields
  count(columns: [report_request_select_column!], distinct: Boolean): Int
  max: report_request_max_fields
  min: report_request_min_fields
  stddev: report_request_stddev_fields
  stddev_pop: report_request_stddev_pop_fields
  stddev_samp: report_request_stddev_samp_fields
  sum: report_request_sum_fields
  var_pop: report_request_var_pop_fields
  var_samp: report_request_var_samp_fields
  variance: report_request_variance_fields
}

# order by aggregate values of table "report_request"
input report_request_aggregate_order_by {
  avg: report_request_avg_order_by
  count: order_by
  max: report_request_max_order_by
  min: report_request_min_order_by
  stddev: report_request_stddev_order_by
  stddev_pop: report_request_stddev_pop_order_by
  stddev_samp: report_request_stddev_samp_order_by
  sum: report_request_sum_order_by
  var_pop: report_request_var_pop_order_by
  var_samp: report_request_var_samp_order_by
  variance: report_request_variance_order_by
}

# input type for inserting array relation for remote table "report_request"
input report_request_arr_rel_insert_input {
  data: [report_request_insert_input!]!
  on_conflict: report_request_on_conflict
}

# aggregate avg on columns
type report_request_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportTemplateMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xmlId: Float
}

# order by avg() on columns of table "report_request"
input report_request_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# Boolean expression to filter rows from the table "report_request". All fields are combined with a logical 'AND'.
input report_request_bool_exp {
  _and: [report_request_bool_exp]
  _not: report_request_bool_exp
  _or: [report_request_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  doRefresh: Boolean_comparison_exp
  error: Int_comparison_exp
  expectedType: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  params: report_parameter_bool_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  queries: report_request_queries_bool_exp
  refreshed: Boolean_comparison_exp
  reportTemplate: report_template_bool_exp
  reportTemplateMtid: bigint_comparison_exp
  result: report_bool_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  title: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  xmlId: bigint_comparison_exp
}

# unique or primary key constraints on table "report_request"
enum report_request_constraint {
  # unique or primary key constraint
  report_request_pkey
}

# input type for incrementing integer column in table "report_request"
input report_request_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  reportTemplateMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xmlId: bigint
}

# input type for inserting data into table "report_request"
input report_request_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  doRefresh: Boolean
  error: Int
  expectedType: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  params: report_parameter_arr_rel_insert_input
  prevValid: bigint
  published: Boolean
  queries: report_request_queries_arr_rel_insert_input
  refreshed: Boolean
  reportTemplate: report_template_obj_rel_insert_input
  reportTemplateMtid: bigint
  result: report_obj_rel_insert_input
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xmlId: bigint
}

# aggregate max on columns
type report_request_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  expectedType: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  reportTemplateMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xmlId: bigint
}

# order by max() on columns of table "report_request"
input report_request_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  expectedType: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  title: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# aggregate min on columns
type report_request_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  expectedType: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  reportTemplateMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xmlId: bigint
}

# order by min() on columns of table "report_request"
input report_request_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  expectedType: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  title: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# response of any mutation on the table "report_request"
type report_request_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_request!]!
}

# input type for inserting object relation for remote table "report_request"
input report_request_obj_rel_insert_input {
  data: report_request_insert_input!
  on_conflict: report_request_on_conflict
}

# on conflict condition type for table "report_request"
input report_request_on_conflict {
  constraint: report_request_constraint!
  update_columns: [report_request_update_column!]!
  where: report_request_bool_exp
}

# ordering options when selecting data from "report_request"
input report_request_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  doRefresh: order_by
  error: order_by
  expectedType: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  params_aggregate: report_parameter_aggregate_order_by
  prevValid: order_by
  published: order_by
  queries_aggregate: report_request_queries_aggregate_order_by
  refreshed: order_by
  reportTemplate: report_template_order_by
  reportTemplateMtid: order_by
  result: report_order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  title: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# primary key columns input for table: "report_request"
input report_request_pk_columns_input {
  mtid: bigint!
}

# columns and relationships of "report_request_queries"
type report_request_queries {
  queriesMtid: bigint!
  reportRequestMtid: bigint!

  # An object relationship
  smartQuery: smart_query!
}

# aggregated selection of "report_request_queries"
type report_request_queries_aggregate {
  aggregate: report_request_queries_aggregate_fields
  nodes: [report_request_queries!]!
}

# aggregate fields of "report_request_queries"
type report_request_queries_aggregate_fields {
  avg: report_request_queries_avg_fields
  count(columns: [report_request_queries_select_column!], distinct: Boolean): Int
  max: report_request_queries_max_fields
  min: report_request_queries_min_fields
  stddev: report_request_queries_stddev_fields
  stddev_pop: report_request_queries_stddev_pop_fields
  stddev_samp: report_request_queries_stddev_samp_fields
  sum: report_request_queries_sum_fields
  var_pop: report_request_queries_var_pop_fields
  var_samp: report_request_queries_var_samp_fields
  variance: report_request_queries_variance_fields
}

# order by aggregate values of table "report_request_queries"
input report_request_queries_aggregate_order_by {
  avg: report_request_queries_avg_order_by
  count: order_by
  max: report_request_queries_max_order_by
  min: report_request_queries_min_order_by
  stddev: report_request_queries_stddev_order_by
  stddev_pop: report_request_queries_stddev_pop_order_by
  stddev_samp: report_request_queries_stddev_samp_order_by
  sum: report_request_queries_sum_order_by
  var_pop: report_request_queries_var_pop_order_by
  var_samp: report_request_queries_var_samp_order_by
  variance: report_request_queries_variance_order_by
}

# input type for inserting array relation for remote table "report_request_queries"
input report_request_queries_arr_rel_insert_input {
  data: [report_request_queries_insert_input!]!
}

# aggregate avg on columns
type report_request_queries_avg_fields {
  queriesMtid: Float
  reportRequestMtid: Float
}

# order by avg() on columns of table "report_request_queries"
input report_request_queries_avg_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# Boolean expression to filter rows from the table "report_request_queries". All fields are combined with a logical 'AND'.
input report_request_queries_bool_exp {
  _and: [report_request_queries_bool_exp]
  _not: report_request_queries_bool_exp
  _or: [report_request_queries_bool_exp]
  queriesMtid: bigint_comparison_exp
  reportRequestMtid: bigint_comparison_exp
  smartQuery: smart_query_bool_exp
}

# input type for incrementing integer column in table "report_request_queries"
input report_request_queries_inc_input {
  queriesMtid: bigint
  reportRequestMtid: bigint
}

# input type for inserting data into table "report_request_queries"
input report_request_queries_insert_input {
  queriesMtid: bigint
  reportRequestMtid: bigint
  smartQuery: smart_query_obj_rel_insert_input
}

# aggregate max on columns
type report_request_queries_max_fields {
  queriesMtid: bigint
  reportRequestMtid: bigint
}

# order by max() on columns of table "report_request_queries"
input report_request_queries_max_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# aggregate min on columns
type report_request_queries_min_fields {
  queriesMtid: bigint
  reportRequestMtid: bigint
}

# order by min() on columns of table "report_request_queries"
input report_request_queries_min_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# response of any mutation on the table "report_request_queries"
type report_request_queries_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_request_queries!]!
}

# input type for inserting object relation for remote table "report_request_queries"
input report_request_queries_obj_rel_insert_input {
  data: report_request_queries_insert_input!
}

# ordering options when selecting data from "report_request_queries"
input report_request_queries_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
  smartQuery: smart_query_order_by
}

# select columns of table "report_request_queries"
enum report_request_queries_select_column {
  # column name
  queriesMtid

  # column name
  reportRequestMtid
}

# input type for updating data in table "report_request_queries"
input report_request_queries_set_input {
  queriesMtid: bigint
  reportRequestMtid: bigint
}

# aggregate stddev on columns
type report_request_queries_stddev_fields {
  queriesMtid: Float
  reportRequestMtid: Float
}

# order by stddev() on columns of table "report_request_queries"
input report_request_queries_stddev_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# aggregate stddev_pop on columns
type report_request_queries_stddev_pop_fields {
  queriesMtid: Float
  reportRequestMtid: Float
}

# order by stddev_pop() on columns of table "report_request_queries"
input report_request_queries_stddev_pop_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# aggregate stddev_samp on columns
type report_request_queries_stddev_samp_fields {
  queriesMtid: Float
  reportRequestMtid: Float
}

# order by stddev_samp() on columns of table "report_request_queries"
input report_request_queries_stddev_samp_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# aggregate sum on columns
type report_request_queries_sum_fields {
  queriesMtid: bigint
  reportRequestMtid: bigint
}

# order by sum() on columns of table "report_request_queries"
input report_request_queries_sum_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# aggregate var_pop on columns
type report_request_queries_var_pop_fields {
  queriesMtid: Float
  reportRequestMtid: Float
}

# order by var_pop() on columns of table "report_request_queries"
input report_request_queries_var_pop_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# aggregate var_samp on columns
type report_request_queries_var_samp_fields {
  queriesMtid: Float
  reportRequestMtid: Float
}

# order by var_samp() on columns of table "report_request_queries"
input report_request_queries_var_samp_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# aggregate variance on columns
type report_request_queries_variance_fields {
  queriesMtid: Float
  reportRequestMtid: Float
}

# order by variance() on columns of table "report_request_queries"
input report_request_queries_variance_order_by {
  queriesMtid: order_by
  reportRequestMtid: order_by
}

# select columns of table "report_request"
enum report_request_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doRefresh

  # column name
  error

  # column name
  expectedType

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  reportTemplateMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  title

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xmlId
}

# input type for updating data in table "report_request"
input report_request_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  doRefresh: Boolean
  error: Int
  expectedType: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  reportTemplateMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  title: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xmlId: bigint
}

# aggregate stddev on columns
type report_request_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportTemplateMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xmlId: Float
}

# order by stddev() on columns of table "report_request"
input report_request_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# aggregate stddev_pop on columns
type report_request_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportTemplateMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xmlId: Float
}

# order by stddev_pop() on columns of table "report_request"
input report_request_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# aggregate stddev_samp on columns
type report_request_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportTemplateMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xmlId: Float
}

# order by stddev_samp() on columns of table "report_request"
input report_request_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# aggregate sum on columns
type report_request_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  reportTemplateMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xmlId: bigint
}

# order by sum() on columns of table "report_request"
input report_request_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# update columns of table "report_request"
enum report_request_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  doRefresh

  # column name
  error

  # column name
  expectedType

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  reportTemplateMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  title

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xmlId
}

# aggregate var_pop on columns
type report_request_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportTemplateMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xmlId: Float
}

# order by var_pop() on columns of table "report_request"
input report_request_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# aggregate var_samp on columns
type report_request_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportTemplateMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xmlId: Float
}

# order by var_samp() on columns of table "report_request"
input report_request_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# aggregate variance on columns
type report_request_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  reportTemplateMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xmlId: Float
}

# order by variance() on columns of table "report_request"
input report_request_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  reportTemplateMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xmlId: order_by
}

# select columns of table "report"
enum report_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  centralAdminPublished

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  folder

  # column name
  folderpath

  # column name
  hint

  # column name
  hintEng

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  outputType

  # column name
  ownerInstitute

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  recordType

  # column name
  refreshed

  # column name
  reportFieldLinks

  # column name
  reportRequestMtid

  # column name
  seen

  # column name
  showInPublicationView

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  title

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xml_mtid
}

# input type for updating data in table "report"
input report_set_input {
  approved: timestamp
  approverMtid: bigint
  centralAdminPublished: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filename: String
  folder: String
  folderpath: String
  hint: String
  hintEng: String
  jobEndDate: timestamp
  jobError: String
  jobException: String
  jobId: bigint
  jobParams: String
  jobStartDate: timestamp
  jobStatus: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  needsNotification: Boolean
  notified: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  outputType: String
  ownerInstitute: bigint
  prevValid: bigint
  progress: String
  published: Boolean
  queued: Boolean
  recordType: String
  refreshed: Boolean
  reportFieldLinks: String
  reportRequestMtid: bigint
  seen: Boolean
  showInPublicationView: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  thread: String
  threadId: bigint
  threadName: String
  threadPriority: Int
  title: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
  xml_mtid: bigint
}

# aggregate stddev on columns
type report_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xml_mtid: Float
}

# order by stddev() on columns of table "report"
input report_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# aggregate stddev_pop on columns
type report_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xml_mtid: Float
}

# order by stddev_pop() on columns of table "report"
input report_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# aggregate stddev_samp on columns
type report_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xml_mtid: Float
}

# order by stddev_samp() on columns of table "report"
input report_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# aggregate sum on columns
type report_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  jobId: bigint
  jobStatus: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  reportRequestMtid: bigint
  status: Int
  threadId: bigint
  threadPriority: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  xml_mtid: bigint
}

# order by sum() on columns of table "report"
input report_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# columns and relationships of "report_template"
type report_template {
  acceptsMultipleQueries: Boolean!
  acceptsQueries: Boolean!
  admin_published: Boolean!
  anonymousViewable: Boolean!
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  author_published: Boolean!
  builtin: Boolean!
  central_admin_published: Boolean!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  csvEnabled: Boolean!
  dataJson: String

  # An array relationship
  defaultQueries(
    # distinct select on columns
    distinct_on: [report_template_default_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_default_queries_order_by!]

    # filter the rows returned
    where: report_template_default_queries_bool_exp
  ): [report_template_default_queries!]!

  # An aggregated array relationship
  defaultQueries_aggregate(
    # distinct select on columns
    distinct_on: [report_template_default_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_default_queries_order_by!]

    # filter the rows returned
    where: report_template_default_queries_bool_exp
  ): report_template_default_queries_aggregate!
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  filePath: String
  filename: String
  global: Boolean!
  instituteList: String
  instituteTypeList: String
  labelEng: String
  labelHun: String

  # An array relationship
  languageFiles(
    # distinct select on columns
    distinct_on: [report_template_language_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_language_files_order_by!]

    # filter the rows returned
    where: report_template_language_files_bool_exp
  ): [report_template_language_files!]!

  # An aggregated array relationship
  languageFiles_aggregate(
    # distinct select on columns
    distinct_on: [report_template_language_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_language_files_order_by!]

    # filter the rows returned
    where: report_template_language_files_bool_exp
  ): report_template_language_files_aggregate!
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtaTemplateId: String
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  published: Boolean!
  recordType: String
  refreshed: Boolean!
  requiresXml: Boolean!
  showInPublicationView: Boolean!
  statsJson: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String

  # An object relationship
  templateFile: uploaded_file
  templateFileMtid: bigint
  templateHun: String

  # An object relationship
  theOwnerInstitute: organization
  title: String
  titleEng: String
  unhandledTickets: Int!
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "report_template"
type report_template_aggregate {
  aggregate: report_template_aggregate_fields
  nodes: [report_template!]!
}

# aggregate fields of "report_template"
type report_template_aggregate_fields {
  avg: report_template_avg_fields
  count(columns: [report_template_select_column!], distinct: Boolean): Int
  max: report_template_max_fields
  min: report_template_min_fields
  stddev: report_template_stddev_fields
  stddev_pop: report_template_stddev_pop_fields
  stddev_samp: report_template_stddev_samp_fields
  sum: report_template_sum_fields
  var_pop: report_template_var_pop_fields
  var_samp: report_template_var_samp_fields
  variance: report_template_variance_fields
}

# order by aggregate values of table "report_template"
input report_template_aggregate_order_by {
  avg: report_template_avg_order_by
  count: order_by
  max: report_template_max_order_by
  min: report_template_min_order_by
  stddev: report_template_stddev_order_by
  stddev_pop: report_template_stddev_pop_order_by
  stddev_samp: report_template_stddev_samp_order_by
  sum: report_template_sum_order_by
  var_pop: report_template_var_pop_order_by
  var_samp: report_template_var_samp_order_by
  variance: report_template_variance_order_by
}

# input type for inserting array relation for remote table "report_template"
input report_template_arr_rel_insert_input {
  data: [report_template_insert_input!]!
  on_conflict: report_template_on_conflict
}

# aggregate avg on columns
type report_template_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  templateFileMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "report_template"
input report_template_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "report_template". All fields are combined with a logical 'AND'.
input report_template_bool_exp {
  _and: [report_template_bool_exp]
  _not: report_template_bool_exp
  _or: [report_template_bool_exp]
  acceptsMultipleQueries: Boolean_comparison_exp
  acceptsQueries: Boolean_comparison_exp
  admin_published: Boolean_comparison_exp
  anonymousViewable: Boolean_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  author_published: Boolean_comparison_exp
  builtin: Boolean_comparison_exp
  central_admin_published: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  csvEnabled: Boolean_comparison_exp
  dataJson: String_comparison_exp
  defaultQueries: report_template_default_queries_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  filePath: String_comparison_exp
  filename: String_comparison_exp
  global: Boolean_comparison_exp
  instituteList: String_comparison_exp
  instituteTypeList: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  languageFiles: report_template_language_files_bool_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  maxDedicatedRole: Int_comparison_exp
  minDedicatedRole: Int_comparison_exp
  mtaTemplateId: String_comparison_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  ownerInstitute: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  recordType: String_comparison_exp
  refreshed: Boolean_comparison_exp
  requiresXml: Boolean_comparison_exp
  showInPublicationView: Boolean_comparison_exp
  statsJson: String_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateFile: uploaded_file_bool_exp
  templateFileMtid: bigint_comparison_exp
  templateHun: String_comparison_exp
  theOwnerInstitute: organization_bool_exp
  title: String_comparison_exp
  titleEng: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  url: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "report_template"
enum report_template_constraint {
  # unique or primary key constraint
  report_template_pkey
}

# columns and relationships of "report_template_default_queries"
type report_template_default_queries {
  defaultQueriesMtid: bigint!
  reportTemplateMtid: bigint!

  # An object relationship
  smartQuery: smart_query!
}

# aggregated selection of "report_template_default_queries"
type report_template_default_queries_aggregate {
  aggregate: report_template_default_queries_aggregate_fields
  nodes: [report_template_default_queries!]!
}

# aggregate fields of "report_template_default_queries"
type report_template_default_queries_aggregate_fields {
  avg: report_template_default_queries_avg_fields
  count(columns: [report_template_default_queries_select_column!], distinct: Boolean): Int
  max: report_template_default_queries_max_fields
  min: report_template_default_queries_min_fields
  stddev: report_template_default_queries_stddev_fields
  stddev_pop: report_template_default_queries_stddev_pop_fields
  stddev_samp: report_template_default_queries_stddev_samp_fields
  sum: report_template_default_queries_sum_fields
  var_pop: report_template_default_queries_var_pop_fields
  var_samp: report_template_default_queries_var_samp_fields
  variance: report_template_default_queries_variance_fields
}

# order by aggregate values of table "report_template_default_queries"
input report_template_default_queries_aggregate_order_by {
  avg: report_template_default_queries_avg_order_by
  count: order_by
  max: report_template_default_queries_max_order_by
  min: report_template_default_queries_min_order_by
  stddev: report_template_default_queries_stddev_order_by
  stddev_pop: report_template_default_queries_stddev_pop_order_by
  stddev_samp: report_template_default_queries_stddev_samp_order_by
  sum: report_template_default_queries_sum_order_by
  var_pop: report_template_default_queries_var_pop_order_by
  var_samp: report_template_default_queries_var_samp_order_by
  variance: report_template_default_queries_variance_order_by
}

# input type for inserting array relation for remote table "report_template_default_queries"
input report_template_default_queries_arr_rel_insert_input {
  data: [report_template_default_queries_insert_input!]!
}

# aggregate avg on columns
type report_template_default_queries_avg_fields {
  defaultQueriesMtid: Float
  reportTemplateMtid: Float
}

# order by avg() on columns of table "report_template_default_queries"
input report_template_default_queries_avg_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# Boolean expression to filter rows from the table
# "report_template_default_queries". All fields are combined with a logical 'AND'.
input report_template_default_queries_bool_exp {
  _and: [report_template_default_queries_bool_exp]
  _not: report_template_default_queries_bool_exp
  _or: [report_template_default_queries_bool_exp]
  defaultQueriesMtid: bigint_comparison_exp
  reportTemplateMtid: bigint_comparison_exp
  smartQuery: smart_query_bool_exp
}

# input type for incrementing integer column in table "report_template_default_queries"
input report_template_default_queries_inc_input {
  defaultQueriesMtid: bigint
  reportTemplateMtid: bigint
}

# input type for inserting data into table "report_template_default_queries"
input report_template_default_queries_insert_input {
  defaultQueriesMtid: bigint
  reportTemplateMtid: bigint
  smartQuery: smart_query_obj_rel_insert_input
}

# aggregate max on columns
type report_template_default_queries_max_fields {
  defaultQueriesMtid: bigint
  reportTemplateMtid: bigint
}

# order by max() on columns of table "report_template_default_queries"
input report_template_default_queries_max_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate min on columns
type report_template_default_queries_min_fields {
  defaultQueriesMtid: bigint
  reportTemplateMtid: bigint
}

# order by min() on columns of table "report_template_default_queries"
input report_template_default_queries_min_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# response of any mutation on the table "report_template_default_queries"
type report_template_default_queries_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_template_default_queries!]!
}

# input type for inserting object relation for remote table "report_template_default_queries"
input report_template_default_queries_obj_rel_insert_input {
  data: report_template_default_queries_insert_input!
}

# ordering options when selecting data from "report_template_default_queries"
input report_template_default_queries_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
  smartQuery: smart_query_order_by
}

# select columns of table "report_template_default_queries"
enum report_template_default_queries_select_column {
  # column name
  defaultQueriesMtid

  # column name
  reportTemplateMtid
}

# input type for updating data in table "report_template_default_queries"
input report_template_default_queries_set_input {
  defaultQueriesMtid: bigint
  reportTemplateMtid: bigint
}

# aggregate stddev on columns
type report_template_default_queries_stddev_fields {
  defaultQueriesMtid: Float
  reportTemplateMtid: Float
}

# order by stddev() on columns of table "report_template_default_queries"
input report_template_default_queries_stddev_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate stddev_pop on columns
type report_template_default_queries_stddev_pop_fields {
  defaultQueriesMtid: Float
  reportTemplateMtid: Float
}

# order by stddev_pop() on columns of table "report_template_default_queries"
input report_template_default_queries_stddev_pop_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate stddev_samp on columns
type report_template_default_queries_stddev_samp_fields {
  defaultQueriesMtid: Float
  reportTemplateMtid: Float
}

# order by stddev_samp() on columns of table "report_template_default_queries"
input report_template_default_queries_stddev_samp_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate sum on columns
type report_template_default_queries_sum_fields {
  defaultQueriesMtid: bigint
  reportTemplateMtid: bigint
}

# order by sum() on columns of table "report_template_default_queries"
input report_template_default_queries_sum_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate var_pop on columns
type report_template_default_queries_var_pop_fields {
  defaultQueriesMtid: Float
  reportTemplateMtid: Float
}

# order by var_pop() on columns of table "report_template_default_queries"
input report_template_default_queries_var_pop_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate var_samp on columns
type report_template_default_queries_var_samp_fields {
  defaultQueriesMtid: Float
  reportTemplateMtid: Float
}

# order by var_samp() on columns of table "report_template_default_queries"
input report_template_default_queries_var_samp_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate variance on columns
type report_template_default_queries_variance_fields {
  defaultQueriesMtid: Float
  reportTemplateMtid: Float
}

# order by variance() on columns of table "report_template_default_queries"
input report_template_default_queries_variance_order_by {
  defaultQueriesMtid: order_by
  reportTemplateMtid: order_by
}

# input type for incrementing integer column in table "report_template"
input report_template_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  status: Int
  templateFileMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "report_template"
input report_template_insert_input {
  acceptsMultipleQueries: Boolean
  acceptsQueries: Boolean
  admin_published: Boolean
  anonymousViewable: Boolean
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  author_published: Boolean
  builtin: Boolean
  central_admin_published: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  csvEnabled: Boolean
  dataJson: String
  defaultQueries: report_template_default_queries_arr_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filePath: String
  filename: String
  global: Boolean
  instituteList: String
  instituteTypeList: String
  labelEng: String
  labelHun: String
  languageFiles: report_template_language_files_arr_rel_insert_input
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtaTemplateId: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  published: Boolean
  recordType: String
  refreshed: Boolean
  requiresXml: Boolean
  showInPublicationView: Boolean
  statsJson: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateFile: uploaded_file_obj_rel_insert_input
  templateFileMtid: bigint
  templateHun: String
  theOwnerInstitute: organization_obj_rel_insert_input
  title: String
  titleEng: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# columns and relationships of "report_template_language_files"
type report_template_language_files {
  languageFilesMtid: bigint!
  reportTemplateMtid: bigint!

  # An object relationship
  uploadedFile: uploaded_file!
}

# aggregated selection of "report_template_language_files"
type report_template_language_files_aggregate {
  aggregate: report_template_language_files_aggregate_fields
  nodes: [report_template_language_files!]!
}

# aggregate fields of "report_template_language_files"
type report_template_language_files_aggregate_fields {
  avg: report_template_language_files_avg_fields
  count(columns: [report_template_language_files_select_column!], distinct: Boolean): Int
  max: report_template_language_files_max_fields
  min: report_template_language_files_min_fields
  stddev: report_template_language_files_stddev_fields
  stddev_pop: report_template_language_files_stddev_pop_fields
  stddev_samp: report_template_language_files_stddev_samp_fields
  sum: report_template_language_files_sum_fields
  var_pop: report_template_language_files_var_pop_fields
  var_samp: report_template_language_files_var_samp_fields
  variance: report_template_language_files_variance_fields
}

# order by aggregate values of table "report_template_language_files"
input report_template_language_files_aggregate_order_by {
  avg: report_template_language_files_avg_order_by
  count: order_by
  max: report_template_language_files_max_order_by
  min: report_template_language_files_min_order_by
  stddev: report_template_language_files_stddev_order_by
  stddev_pop: report_template_language_files_stddev_pop_order_by
  stddev_samp: report_template_language_files_stddev_samp_order_by
  sum: report_template_language_files_sum_order_by
  var_pop: report_template_language_files_var_pop_order_by
  var_samp: report_template_language_files_var_samp_order_by
  variance: report_template_language_files_variance_order_by
}

# input type for inserting array relation for remote table "report_template_language_files"
input report_template_language_files_arr_rel_insert_input {
  data: [report_template_language_files_insert_input!]!
  on_conflict: report_template_language_files_on_conflict
}

# aggregate avg on columns
type report_template_language_files_avg_fields {
  languageFilesMtid: Float
  reportTemplateMtid: Float
}

# order by avg() on columns of table "report_template_language_files"
input report_template_language_files_avg_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# Boolean expression to filter rows from the table
# "report_template_language_files". All fields are combined with a logical 'AND'.
input report_template_language_files_bool_exp {
  _and: [report_template_language_files_bool_exp]
  _not: report_template_language_files_bool_exp
  _or: [report_template_language_files_bool_exp]
  languageFilesMtid: bigint_comparison_exp
  reportTemplateMtid: bigint_comparison_exp
  uploadedFile: uploaded_file_bool_exp
}

# unique or primary key constraints on table "report_template_language_files"
enum report_template_language_files_constraint {
  # unique or primary key constraint
  uk_l37qkh24rpowup96p0ihhffnc
}

# input type for incrementing integer column in table "report_template_language_files"
input report_template_language_files_inc_input {
  languageFilesMtid: bigint
  reportTemplateMtid: bigint
}

# input type for inserting data into table "report_template_language_files"
input report_template_language_files_insert_input {
  languageFilesMtid: bigint
  reportTemplateMtid: bigint
  uploadedFile: uploaded_file_obj_rel_insert_input
}

# aggregate max on columns
type report_template_language_files_max_fields {
  languageFilesMtid: bigint
  reportTemplateMtid: bigint
}

# order by max() on columns of table "report_template_language_files"
input report_template_language_files_max_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate min on columns
type report_template_language_files_min_fields {
  languageFilesMtid: bigint
  reportTemplateMtid: bigint
}

# order by min() on columns of table "report_template_language_files"
input report_template_language_files_min_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# response of any mutation on the table "report_template_language_files"
type report_template_language_files_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_template_language_files!]!
}

# input type for inserting object relation for remote table "report_template_language_files"
input report_template_language_files_obj_rel_insert_input {
  data: report_template_language_files_insert_input!
  on_conflict: report_template_language_files_on_conflict
}

# on conflict condition type for table "report_template_language_files"
input report_template_language_files_on_conflict {
  constraint: report_template_language_files_constraint!
  update_columns: [report_template_language_files_update_column!]!
  where: report_template_language_files_bool_exp
}

# ordering options when selecting data from "report_template_language_files"
input report_template_language_files_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
  uploadedFile: uploaded_file_order_by
}

# select columns of table "report_template_language_files"
enum report_template_language_files_select_column {
  # column name
  languageFilesMtid

  # column name
  reportTemplateMtid
}

# input type for updating data in table "report_template_language_files"
input report_template_language_files_set_input {
  languageFilesMtid: bigint
  reportTemplateMtid: bigint
}

# aggregate stddev on columns
type report_template_language_files_stddev_fields {
  languageFilesMtid: Float
  reportTemplateMtid: Float
}

# order by stddev() on columns of table "report_template_language_files"
input report_template_language_files_stddev_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate stddev_pop on columns
type report_template_language_files_stddev_pop_fields {
  languageFilesMtid: Float
  reportTemplateMtid: Float
}

# order by stddev_pop() on columns of table "report_template_language_files"
input report_template_language_files_stddev_pop_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate stddev_samp on columns
type report_template_language_files_stddev_samp_fields {
  languageFilesMtid: Float
  reportTemplateMtid: Float
}

# order by stddev_samp() on columns of table "report_template_language_files"
input report_template_language_files_stddev_samp_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate sum on columns
type report_template_language_files_sum_fields {
  languageFilesMtid: bigint
  reportTemplateMtid: bigint
}

# order by sum() on columns of table "report_template_language_files"
input report_template_language_files_sum_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# update columns of table "report_template_language_files"
enum report_template_language_files_update_column {
  # column name
  languageFilesMtid

  # column name
  reportTemplateMtid
}

# aggregate var_pop on columns
type report_template_language_files_var_pop_fields {
  languageFilesMtid: Float
  reportTemplateMtid: Float
}

# order by var_pop() on columns of table "report_template_language_files"
input report_template_language_files_var_pop_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate var_samp on columns
type report_template_language_files_var_samp_fields {
  languageFilesMtid: Float
  reportTemplateMtid: Float
}

# order by var_samp() on columns of table "report_template_language_files"
input report_template_language_files_var_samp_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate variance on columns
type report_template_language_files_variance_fields {
  languageFilesMtid: Float
  reportTemplateMtid: Float
}

# order by variance() on columns of table "report_template_language_files"
input report_template_language_files_variance_order_by {
  languageFilesMtid: order_by
  reportTemplateMtid: order_by
}

# aggregate max on columns
type report_template_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dataJson: String
  deletedDate: timestamp
  error: Int
  filePath: String
  filename: String
  instituteList: String
  instituteTypeList: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtaTemplateId: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  recordType: String
  statsJson: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateFileMtid: bigint
  templateHun: String
  title: String
  titleEng: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "report_template"
input report_template_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dataJson: order_by
  deletedDate: order_by
  error: order_by
  filePath: order_by
  filename: order_by
  instituteList: order_by
  instituteTypeList: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtaTemplateId: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  prevValid: order_by
  recordType: order_by
  statsJson: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateFileMtid: order_by
  templateHun: order_by
  title: order_by
  titleEng: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type report_template_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dataJson: String
  deletedDate: timestamp
  error: Int
  filePath: String
  filename: String
  instituteList: String
  instituteTypeList: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtaTemplateId: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  recordType: String
  statsJson: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateFileMtid: bigint
  templateHun: String
  title: String
  titleEng: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "report_template"
input report_template_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  dataJson: order_by
  deletedDate: order_by
  error: order_by
  filePath: order_by
  filename: order_by
  instituteList: order_by
  instituteTypeList: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtaTemplateId: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  prevValid: order_by
  recordType: order_by
  statsJson: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateFileMtid: order_by
  templateHun: order_by
  title: order_by
  titleEng: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "report_template"
type report_template_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_template!]!
}

# input type for inserting object relation for remote table "report_template"
input report_template_obj_rel_insert_input {
  data: report_template_insert_input!
  on_conflict: report_template_on_conflict
}

# on conflict condition type for table "report_template"
input report_template_on_conflict {
  constraint: report_template_constraint!
  update_columns: [report_template_update_column!]!
  where: report_template_bool_exp
}

# ordering options when selecting data from "report_template"
input report_template_order_by {
  acceptsMultipleQueries: order_by
  acceptsQueries: order_by
  admin_published: order_by
  anonymousViewable: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  author_published: order_by
  builtin: order_by
  central_admin_published: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  csvEnabled: order_by
  dataJson: order_by
  defaultQueries_aggregate: report_template_default_queries_aggregate_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  filePath: order_by
  filename: order_by
  global: order_by
  instituteList: order_by
  instituteTypeList: order_by
  labelEng: order_by
  labelHun: order_by
  languageFiles_aggregate: report_template_language_files_aggregate_order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtaTemplateId: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  prevValid: order_by
  published: order_by
  recordType: order_by
  refreshed: order_by
  requiresXml: order_by
  showInPublicationView: order_by
  statsJson: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateFile: uploaded_file_order_by
  templateFileMtid: order_by
  templateHun: order_by
  theOwnerInstitute: organization_order_by
  title: order_by
  titleEng: order_by
  unhandledTickets: order_by
  url: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "report_template_parameter_select"
type report_template_parameter_select {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  langId: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregated selection of "report_template_parameter_select"
type report_template_parameter_select_aggregate {
  aggregate: report_template_parameter_select_aggregate_fields
  nodes: [report_template_parameter_select!]!
}

# aggregate fields of "report_template_parameter_select"
type report_template_parameter_select_aggregate_fields {
  avg: report_template_parameter_select_avg_fields
  count(columns: [report_template_parameter_select_select_column!], distinct: Boolean): Int
  max: report_template_parameter_select_max_fields
  min: report_template_parameter_select_min_fields
  stddev: report_template_parameter_select_stddev_fields
  stddev_pop: report_template_parameter_select_stddev_pop_fields
  stddev_samp: report_template_parameter_select_stddev_samp_fields
  sum: report_template_parameter_select_sum_fields
  var_pop: report_template_parameter_select_var_pop_fields
  var_samp: report_template_parameter_select_var_samp_fields
  variance: report_template_parameter_select_variance_fields
}

# order by aggregate values of table "report_template_parameter_select"
input report_template_parameter_select_aggregate_order_by {
  avg: report_template_parameter_select_avg_order_by
  count: order_by
  max: report_template_parameter_select_max_order_by
  min: report_template_parameter_select_min_order_by
  stddev: report_template_parameter_select_stddev_order_by
  stddev_pop: report_template_parameter_select_stddev_pop_order_by
  stddev_samp: report_template_parameter_select_stddev_samp_order_by
  sum: report_template_parameter_select_sum_order_by
  var_pop: report_template_parameter_select_var_pop_order_by
  var_samp: report_template_parameter_select_var_samp_order_by
  variance: report_template_parameter_select_variance_order_by
}

# input type for inserting array relation for remote table "report_template_parameter_select"
input report_template_parameter_select_arr_rel_insert_input {
  data: [report_template_parameter_select_insert_input!]!
  on_conflict: report_template_parameter_select_on_conflict
}

# aggregate avg on columns
type report_template_parameter_select_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "report_template_parameter_select"
input report_template_parameter_select_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table
# "report_template_parameter_select". All fields are combined with a logical 'AND'.
input report_template_parameter_select_bool_exp {
  _and: [report_template_parameter_select_bool_exp]
  _not: report_template_parameter_select_bool_exp
  _or: [report_template_parameter_select_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  langId: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  value: String_comparison_exp
}

# unique or primary key constraints on table "report_template_parameter_select"
enum report_template_parameter_select_constraint {
  # unique or primary key constraint
  report_template_parameter_select_pkey
}

# input type for incrementing integer column in table "report_template_parameter_select"
input report_template_parameter_select_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "report_template_parameter_select"
input report_template_parameter_select_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  langId: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregate max on columns
type report_template_parameter_select_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  langId: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# order by max() on columns of table "report_template_parameter_select"
input report_template_parameter_select_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  langId: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# aggregate min on columns
type report_template_parameter_select_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  langId: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# order by min() on columns of table "report_template_parameter_select"
input report_template_parameter_select_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  langId: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# response of any mutation on the table "report_template_parameter_select"
type report_template_parameter_select_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_template_parameter_select!]!
}

# input type for inserting object relation for remote table "report_template_parameter_select"
input report_template_parameter_select_obj_rel_insert_input {
  data: report_template_parameter_select_insert_input!
  on_conflict: report_template_parameter_select_on_conflict
}

# on conflict condition type for table "report_template_parameter_select"
input report_template_parameter_select_on_conflict {
  constraint: report_template_parameter_select_constraint!
  update_columns: [report_template_parameter_select_update_column!]!
  where: report_template_parameter_select_bool_exp
}

# ordering options when selecting data from "report_template_parameter_select"
input report_template_parameter_select_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  langId: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# primary key columns input for table: "report_template_parameter_select"
input report_template_parameter_select_pk_columns_input {
  mtid: bigint!
}

# select columns of table "report_template_parameter_select"
enum report_template_parameter_select_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  langId

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  value
}

# input type for updating data in table "report_template_parameter_select"
input report_template_parameter_select_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  langId: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregate stddev on columns
type report_template_parameter_select_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "report_template_parameter_select"
input report_template_parameter_select_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type report_template_parameter_select_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "report_template_parameter_select"
input report_template_parameter_select_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type report_template_parameter_select_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "report_template_parameter_select"
input report_template_parameter_select_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type report_template_parameter_select_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "report_template_parameter_select"
input report_template_parameter_select_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "report_template_parameter_select"
enum report_template_parameter_select_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  langId

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  value
}

# aggregate var_pop on columns
type report_template_parameter_select_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "report_template_parameter_select"
input report_template_parameter_select_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type report_template_parameter_select_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "report_template_parameter_select"
input report_template_parameter_select_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type report_template_parameter_select_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "report_template_parameter_select"
input report_template_parameter_select_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "report_template"
input report_template_pk_columns_input {
  mtid: bigint!
}

# select columns of table "report_template"
enum report_template_select_column {
  # column name
  acceptsMultipleQueries

  # column name
  acceptsQueries

  # column name
  admin_published

  # column name
  anonymousViewable

  # column name
  approved

  # column name
  approverMtid

  # column name
  author_published

  # column name
  builtin

  # column name
  central_admin_published

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  csvEnabled

  # column name
  dataJson

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filePath

  # column name
  filename

  # column name
  global

  # column name
  instituteList

  # column name
  instituteTypeList

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxDedicatedRole

  # column name
  minDedicatedRole

  # column name
  mtaTemplateId

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerInstitute

  # column name
  prevValid

  # column name
  published

  # column name
  recordType

  # column name
  refreshed

  # column name
  requiresXml

  # column name
  showInPublicationView

  # column name
  statsJson

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateFileMtid

  # column name
  templateHun

  # column name
  title

  # column name
  titleEng

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "report_template"
input report_template_set_input {
  acceptsMultipleQueries: Boolean
  acceptsQueries: Boolean
  admin_published: Boolean
  anonymousViewable: Boolean
  approved: timestamp
  approverMtid: bigint
  author_published: Boolean
  builtin: Boolean
  central_admin_published: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  csvEnabled: Boolean
  dataJson: String
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filePath: String
  filename: String
  global: Boolean
  instituteList: String
  instituteTypeList: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtaTemplateId: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  published: Boolean
  recordType: String
  refreshed: Boolean
  requiresXml: Boolean
  showInPublicationView: Boolean
  statsJson: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateFileMtid: bigint
  templateHun: String
  title: String
  titleEng: String
  unhandledTickets: Int
  url: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type report_template_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  templateFileMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "report_template"
input report_template_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type report_template_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  templateFileMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "report_template"
input report_template_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type report_template_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  templateFileMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "report_template"
input report_template_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type report_template_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  status: Int
  templateFileMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "report_template"
input report_template_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "report_template"
enum report_template_update_column {
  # column name
  acceptsMultipleQueries

  # column name
  acceptsQueries

  # column name
  admin_published

  # column name
  anonymousViewable

  # column name
  approved

  # column name
  approverMtid

  # column name
  author_published

  # column name
  builtin

  # column name
  central_admin_published

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  csvEnabled

  # column name
  dataJson

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filePath

  # column name
  filename

  # column name
  global

  # column name
  instituteList

  # column name
  instituteTypeList

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxDedicatedRole

  # column name
  minDedicatedRole

  # column name
  mtaTemplateId

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerInstitute

  # column name
  prevValid

  # column name
  published

  # column name
  recordType

  # column name
  refreshed

  # column name
  requiresXml

  # column name
  showInPublicationView

  # column name
  statsJson

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateFileMtid

  # column name
  templateHun

  # column name
  title

  # column name
  titleEng

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type report_template_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  templateFileMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "report_template"
input report_template_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type report_template_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  templateFileMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "report_template"
input report_template_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type report_template_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  templateFileMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "report_template"
input report_template_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  templateFileMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "report"
enum report_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  centralAdminPublished

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  folder

  # column name
  folderpath

  # column name
  hint

  # column name
  hintEng

  # column name
  jobEndDate

  # column name
  jobError

  # column name
  jobException

  # column name
  jobId

  # column name
  jobParams

  # column name
  jobStartDate

  # column name
  jobStatus

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  needsNotification

  # column name
  notified

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  outputType

  # column name
  ownerInstitute

  # column name
  prevValid

  # column name
  progress

  # column name
  published

  # column name
  queued

  # column name
  recordType

  # column name
  refreshed

  # column name
  reportFieldLinks

  # column name
  reportRequestMtid

  # column name
  seen

  # column name
  showInPublicationView

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  thread

  # column name
  threadId

  # column name
  threadName

  # column name
  threadPriority

  # column name
  title

  # column name
  unhandledTickets

  # column name
  url

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  xml_mtid
}

# aggregate var_pop on columns
type report_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xml_mtid: Float
}

# order by var_pop() on columns of table "report"
input report_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# aggregate var_samp on columns
type report_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xml_mtid: Float
}

# order by var_samp() on columns of table "report"
input report_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# aggregate variance on columns
type report_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  jobId: Float
  jobStatus: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  reportRequestMtid: Float
  status: Float
  threadId: Float
  threadPriority: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  xml_mtid: Float
}

# order by variance() on columns of table "report"
input report_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  jobId: order_by
  jobStatus: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  reportRequestMtid: order_by
  status: order_by
  threadId: order_by
  threadPriority: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  xml_mtid: order_by
}

# columns and relationships of "report_xml"
type report_xml {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "report_xml"
type report_xml_aggregate {
  aggregate: report_xml_aggregate_fields
  nodes: [report_xml!]!
}

# aggregate fields of "report_xml"
type report_xml_aggregate_fields {
  avg: report_xml_avg_fields
  count(columns: [report_xml_select_column!], distinct: Boolean): Int
  max: report_xml_max_fields
  min: report_xml_min_fields
  stddev: report_xml_stddev_fields
  stddev_pop: report_xml_stddev_pop_fields
  stddev_samp: report_xml_stddev_samp_fields
  sum: report_xml_sum_fields
  var_pop: report_xml_var_pop_fields
  var_samp: report_xml_var_samp_fields
  variance: report_xml_variance_fields
}

# order by aggregate values of table "report_xml"
input report_xml_aggregate_order_by {
  avg: report_xml_avg_order_by
  count: order_by
  max: report_xml_max_order_by
  min: report_xml_min_order_by
  stddev: report_xml_stddev_order_by
  stddev_pop: report_xml_stddev_pop_order_by
  stddev_samp: report_xml_stddev_samp_order_by
  sum: report_xml_sum_order_by
  var_pop: report_xml_var_pop_order_by
  var_samp: report_xml_var_samp_order_by
  variance: report_xml_variance_order_by
}

# input type for inserting array relation for remote table "report_xml"
input report_xml_arr_rel_insert_input {
  data: [report_xml_insert_input!]!
  on_conflict: report_xml_on_conflict
}

# aggregate avg on columns
type report_xml_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "report_xml"
input report_xml_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "report_xml". All fields are combined with a logical 'AND'.
input report_xml_bool_exp {
  _and: [report_xml_bool_exp]
  _not: report_xml_bool_exp
  _or: [report_xml_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  filename: String_comparison_exp
  filepath: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "report_xml"
enum report_xml_constraint {
  # unique or primary key constraint
  report_xml_pkey
}

# input type for incrementing integer column in table "report_xml"
input report_xml_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "report_xml"
input report_xml_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type report_xml_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "report_xml"
input report_xml_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  filepath: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type report_xml_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "report_xml"
input report_xml_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  filepath: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "report_xml"
type report_xml_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [report_xml!]!
}

# input type for inserting object relation for remote table "report_xml"
input report_xml_obj_rel_insert_input {
  data: report_xml_insert_input!
  on_conflict: report_xml_on_conflict
}

# on conflict condition type for table "report_xml"
input report_xml_on_conflict {
  constraint: report_xml_constraint!
  update_columns: [report_xml_update_column!]!
  where: report_xml_bool_exp
}

# ordering options when selecting data from "report_xml"
input report_xml_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  filepath: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "report_xml"
input report_xml_pk_columns_input {
  mtid: bigint!
}

# select columns of table "report_xml"
enum report_xml_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  filepath

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "report_xml"
input report_xml_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type report_xml_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "report_xml"
input report_xml_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type report_xml_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "report_xml"
input report_xml_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type report_xml_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "report_xml"
input report_xml_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type report_xml_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "report_xml"
input report_xml_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "report_xml"
enum report_xml_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  filepath

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type report_xml_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "report_xml"
input report_xml_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type report_xml_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "report_xml"
input report_xml_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type report_xml_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "report_xml"
input report_xml_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "ris_import_error_detail"
type ris_import_error_detail {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  errorType: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  numberOfAppearance: Int!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  unknownValue: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "ris_import_error_detail"
type ris_import_error_detail_aggregate {
  aggregate: ris_import_error_detail_aggregate_fields
  nodes: [ris_import_error_detail!]!
}

# aggregate fields of "ris_import_error_detail"
type ris_import_error_detail_aggregate_fields {
  avg: ris_import_error_detail_avg_fields
  count(columns: [ris_import_error_detail_select_column!], distinct: Boolean): Int
  max: ris_import_error_detail_max_fields
  min: ris_import_error_detail_min_fields
  stddev: ris_import_error_detail_stddev_fields
  stddev_pop: ris_import_error_detail_stddev_pop_fields
  stddev_samp: ris_import_error_detail_stddev_samp_fields
  sum: ris_import_error_detail_sum_fields
  var_pop: ris_import_error_detail_var_pop_fields
  var_samp: ris_import_error_detail_var_samp_fields
  variance: ris_import_error_detail_variance_fields
}

# order by aggregate values of table "ris_import_error_detail"
input ris_import_error_detail_aggregate_order_by {
  avg: ris_import_error_detail_avg_order_by
  count: order_by
  max: ris_import_error_detail_max_order_by
  min: ris_import_error_detail_min_order_by
  stddev: ris_import_error_detail_stddev_order_by
  stddev_pop: ris_import_error_detail_stddev_pop_order_by
  stddev_samp: ris_import_error_detail_stddev_samp_order_by
  sum: ris_import_error_detail_sum_order_by
  var_pop: ris_import_error_detail_var_pop_order_by
  var_samp: ris_import_error_detail_var_samp_order_by
  variance: ris_import_error_detail_variance_order_by
}

# input type for inserting array relation for remote table "ris_import_error_detail"
input ris_import_error_detail_arr_rel_insert_input {
  data: [ris_import_error_detail_insert_input!]!
  on_conflict: ris_import_error_detail_on_conflict
}

# aggregate avg on columns
type ris_import_error_detail_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  errorType: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfAppearance: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "ris_import_error_detail"
input ris_import_error_detail_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "ris_import_error_detail". All fields are combined with a logical 'AND'.
input ris_import_error_detail_bool_exp {
  _and: [ris_import_error_detail_bool_exp]
  _not: ris_import_error_detail_bool_exp
  _or: [ris_import_error_detail_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  errorType: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  numberOfAppearance: Int_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  unknownValue: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "ris_import_error_detail"
enum ris_import_error_detail_constraint {
  # unique or primary key constraint
  ris_import_error_detail_pkey
}

# input type for incrementing integer column in table "ris_import_error_detail"
input ris_import_error_detail_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  errorType: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  numberOfAppearance: Int
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "ris_import_error_detail"
input ris_import_error_detail_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  errorType: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  numberOfAppearance: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unknownValue: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type ris_import_error_detail_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  errorType: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  numberOfAppearance: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unknownValue: String
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "ris_import_error_detail"
input ris_import_error_detail_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  errorType: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  unknownValue: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type ris_import_error_detail_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  errorType: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  numberOfAppearance: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unknownValue: String
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "ris_import_error_detail"
input ris_import_error_detail_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  errorType: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  unknownValue: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "ris_import_error_detail"
type ris_import_error_detail_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [ris_import_error_detail!]!
}

# input type for inserting object relation for remote table "ris_import_error_detail"
input ris_import_error_detail_obj_rel_insert_input {
  data: ris_import_error_detail_insert_input!
  on_conflict: ris_import_error_detail_on_conflict
}

# on conflict condition type for table "ris_import_error_detail"
input ris_import_error_detail_on_conflict {
  constraint: ris_import_error_detail_constraint!
  update_columns: [ris_import_error_detail_update_column!]!
  where: ris_import_error_detail_bool_exp
}

# ordering options when selecting data from "ris_import_error_detail"
input ris_import_error_detail_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  errorType: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  unknownValue: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "ris_import_error_detail"
input ris_import_error_detail_pk_columns_input {
  mtid: bigint!
}

# select columns of table "ris_import_error_detail"
enum ris_import_error_detail_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  errorType

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  numberOfAppearance

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  unknownValue

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "ris_import_error_detail"
input ris_import_error_detail_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  errorType: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  numberOfAppearance: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  unknownValue: String
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type ris_import_error_detail_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  errorType: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfAppearance: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "ris_import_error_detail"
input ris_import_error_detail_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type ris_import_error_detail_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  errorType: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfAppearance: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "ris_import_error_detail"
input ris_import_error_detail_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type ris_import_error_detail_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  errorType: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfAppearance: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "ris_import_error_detail"
input ris_import_error_detail_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type ris_import_error_detail_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  errorType: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  numberOfAppearance: Int
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "ris_import_error_detail"
input ris_import_error_detail_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "ris_import_error_detail"
enum ris_import_error_detail_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  errorType

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  numberOfAppearance

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  unknownValue

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type ris_import_error_detail_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  errorType: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfAppearance: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "ris_import_error_detail"
input ris_import_error_detail_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type ris_import_error_detail_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  errorType: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfAppearance: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "ris_import_error_detail"
input ris_import_error_detail_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type ris_import_error_detail_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  errorType: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  numberOfAppearance: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "ris_import_error_detail"
input ris_import_error_detail_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  errorType: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  numberOfAppearance: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "series_volume"
type series_volume {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint

  # An object relationship
  publication: publication
  publicationMtid: bigint
  published: Boolean!
  refreshed: Boolean!

  # An object relationship
  series: periodical
  seriesMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  volume: String
}

# aggregated selection of "series_volume"
type series_volume_aggregate {
  aggregate: series_volume_aggregate_fields
  nodes: [series_volume!]!
}

# aggregate fields of "series_volume"
type series_volume_aggregate_fields {
  avg: series_volume_avg_fields
  count(columns: [series_volume_select_column!], distinct: Boolean): Int
  max: series_volume_max_fields
  min: series_volume_min_fields
  stddev: series_volume_stddev_fields
  stddev_pop: series_volume_stddev_pop_fields
  stddev_samp: series_volume_stddev_samp_fields
  sum: series_volume_sum_fields
  var_pop: series_volume_var_pop_fields
  var_samp: series_volume_var_samp_fields
  variance: series_volume_variance_fields
}

# order by aggregate values of table "series_volume"
input series_volume_aggregate_order_by {
  avg: series_volume_avg_order_by
  count: order_by
  max: series_volume_max_order_by
  min: series_volume_min_order_by
  stddev: series_volume_stddev_order_by
  stddev_pop: series_volume_stddev_pop_order_by
  stddev_samp: series_volume_stddev_samp_order_by
  sum: series_volume_sum_order_by
  var_pop: series_volume_var_pop_order_by
  var_samp: series_volume_var_samp_order_by
  variance: series_volume_variance_order_by
}

# input type for inserting array relation for remote table "series_volume"
input series_volume_arr_rel_insert_input {
  data: [series_volume_insert_input!]!
  on_conflict: series_volume_on_conflict
}

# aggregate avg on columns
type series_volume_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  seriesMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "series_volume"
input series_volume_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "series_volume". All fields are combined with a logical 'AND'.
input series_volume_bool_exp {
  _and: [series_volume_bool_exp]
  _not: series_volume_bool_exp
  _or: [series_volume_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  publication: publication_bool_exp
  publicationMtid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  series: periodical_bool_exp
  seriesMtid: bigint_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  volume: String_comparison_exp
}

# unique or primary key constraints on table "series_volume"
enum series_volume_constraint {
  # unique or primary key constraint
  series_volume_pkey
}

# input type for incrementing integer column in table "series_volume"
input series_volume_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  seriesMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "series_volume"
input series_volume_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publication: publication_obj_rel_insert_input
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  series: periodical_obj_rel_insert_input
  seriesMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  volume: String
}

# aggregate max on columns
type series_volume_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  seriesMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  volume: String
}

# order by max() on columns of table "series_volume"
input series_volume_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  volume: order_by
}

# aggregate min on columns
type series_volume_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  seriesMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  volume: String
}

# order by min() on columns of table "series_volume"
input series_volume_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  volume: order_by
}

# response of any mutation on the table "series_volume"
type series_volume_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [series_volume!]!
}

# input type for inserting object relation for remote table "series_volume"
input series_volume_obj_rel_insert_input {
  data: series_volume_insert_input!
  on_conflict: series_volume_on_conflict
}

# on conflict condition type for table "series_volume"
input series_volume_on_conflict {
  constraint: series_volume_constraint!
  update_columns: [series_volume_update_column!]!
  where: series_volume_bool_exp
}

# ordering options when selecting data from "series_volume"
input series_volume_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  publication: publication_order_by
  publicationMtid: order_by
  published: order_by
  refreshed: order_by
  series: periodical_order_by
  seriesMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  volume: order_by
}

# primary key columns input for table: "series_volume"
input series_volume_pk_columns_input {
  mtid: bigint!
}

# select columns of table "series_volume"
enum series_volume_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  seriesMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  volume
}

# input type for updating data in table "series_volume"
input series_volume_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  publicationMtid: bigint
  published: Boolean
  refreshed: Boolean
  seriesMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  volume: String
}

# aggregate stddev on columns
type series_volume_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  seriesMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "series_volume"
input series_volume_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type series_volume_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  seriesMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "series_volume"
input series_volume_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type series_volume_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  seriesMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "series_volume"
input series_volume_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type series_volume_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  publicationMtid: bigint
  seriesMtid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "series_volume"
input series_volume_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "series_volume"
enum series_volume_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  publicationMtid

  # column name
  published

  # column name
  refreshed

  # column name
  seriesMtid

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  volume
}

# aggregate var_pop on columns
type series_volume_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  seriesMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "series_volume"
input series_volume_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type series_volume_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  seriesMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "series_volume"
input series_volume_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type series_volume_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  publicationMtid: Float
  seriesMtid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "series_volume"
input series_volume_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  publicationMtid: order_by
  seriesMtid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "shib_id_provider"
type shib_id_provider {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  idpId: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "shib_id_provider"
type shib_id_provider_aggregate {
  aggregate: shib_id_provider_aggregate_fields
  nodes: [shib_id_provider!]!
}

# aggregate fields of "shib_id_provider"
type shib_id_provider_aggregate_fields {
  avg: shib_id_provider_avg_fields
  count(columns: [shib_id_provider_select_column!], distinct: Boolean): Int
  max: shib_id_provider_max_fields
  min: shib_id_provider_min_fields
  stddev: shib_id_provider_stddev_fields
  stddev_pop: shib_id_provider_stddev_pop_fields
  stddev_samp: shib_id_provider_stddev_samp_fields
  sum: shib_id_provider_sum_fields
  var_pop: shib_id_provider_var_pop_fields
  var_samp: shib_id_provider_var_samp_fields
  variance: shib_id_provider_variance_fields
}

# order by aggregate values of table "shib_id_provider"
input shib_id_provider_aggregate_order_by {
  avg: shib_id_provider_avg_order_by
  count: order_by
  max: shib_id_provider_max_order_by
  min: shib_id_provider_min_order_by
  stddev: shib_id_provider_stddev_order_by
  stddev_pop: shib_id_provider_stddev_pop_order_by
  stddev_samp: shib_id_provider_stddev_samp_order_by
  sum: shib_id_provider_sum_order_by
  var_pop: shib_id_provider_var_pop_order_by
  var_samp: shib_id_provider_var_samp_order_by
  variance: shib_id_provider_variance_order_by
}

# input type for inserting array relation for remote table "shib_id_provider"
input shib_id_provider_arr_rel_insert_input {
  data: [shib_id_provider_insert_input!]!
  on_conflict: shib_id_provider_on_conflict
}

# aggregate avg on columns
type shib_id_provider_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "shib_id_provider"
input shib_id_provider_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "shib_id_provider". All fields are combined with a logical 'AND'.
input shib_id_provider_bool_exp {
  _and: [shib_id_provider_bool_exp]
  _not: shib_id_provider_bool_exp
  _or: [shib_id_provider_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  idpId: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "shib_id_provider"
enum shib_id_provider_constraint {
  # unique or primary key constraint
  shib_id_provider_pkey
}

# input type for incrementing integer column in table "shib_id_provider"
input shib_id_provider_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "shib_id_provider"
input shib_id_provider_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idpId: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type shib_id_provider_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idpId: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "shib_id_provider"
input shib_id_provider_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idpId: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type shib_id_provider_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  idpId: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "shib_id_provider"
input shib_id_provider_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  idpId: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "shib_id_provider"
type shib_id_provider_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [shib_id_provider!]!
}

# input type for inserting object relation for remote table "shib_id_provider"
input shib_id_provider_obj_rel_insert_input {
  data: shib_id_provider_insert_input!
  on_conflict: shib_id_provider_on_conflict
}

# on conflict condition type for table "shib_id_provider"
input shib_id_provider_on_conflict {
  constraint: shib_id_provider_constraint!
  update_columns: [shib_id_provider_update_column!]!
  where: shib_id_provider_bool_exp
}

# ordering options when selecting data from "shib_id_provider"
input shib_id_provider_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  idpId: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "shib_id_provider"
input shib_id_provider_pk_columns_input {
  mtid: bigint!
}

# select columns of table "shib_id_provider"
enum shib_id_provider_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idpId

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "shib_id_provider"
input shib_id_provider_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  idpId: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type shib_id_provider_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "shib_id_provider"
input shib_id_provider_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type shib_id_provider_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "shib_id_provider"
input shib_id_provider_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type shib_id_provider_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "shib_id_provider"
input shib_id_provider_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type shib_id_provider_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "shib_id_provider"
input shib_id_provider_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "shib_id_provider"
enum shib_id_provider_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  idpId

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type shib_id_provider_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "shib_id_provider"
input shib_id_provider_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type shib_id_provider_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "shib_id_provider"
input shib_id_provider_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type shib_id_provider_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "shib_id_provider"
input shib_id_provider_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

scalar smallint

# expression to compare columns of type smallint. All fields are combined with logical 'AND'.
input smallint_comparison_exp {
  _eq: smallint
  _gt: smallint
  _gte: smallint
  _in: [smallint!]
  _is_null: Boolean
  _lt: smallint
  _lte: smallint
  _neq: smallint
  _nin: [smallint!]
}

# columns and relationships of "smart_query"
type smart_query {
  adhocQuery: Boolean!
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  builtin: Boolean!
  comment: String
  comment2: String
  condGroupBasedJoin: Boolean!

  # An array relationship
  conditions(
    # distinct select on columns
    distinct_on: [smart_query_cond_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_cond_order_by!]

    # filter the rows returned
    where: smart_query_cond_bool_exp
  ): [smart_query_cond!]!

  # An aggregated array relationship
  conditions_aggregate(
    # distinct select on columns
    distinct_on: [smart_query_cond_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_cond_order_by!]

    # filter the rows returned
    where: smart_query_cond_bool_exp
  ): smart_query_cond_aggregate!
  conjunctional: Boolean!
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  defaultMaxCount: Int
  defaultOrder: Int
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  global: Boolean!
  hint: String
  hintEng: String
  indexed: Boolean!
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint!
  name: String
  nameEng: String
  negated: Boolean!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  published: Boolean!
  queryString: String
  queryTemplate: Boolean!
  refreshed: Boolean!
  resultType: String

  # An array relationship
  sorter(
    # distinct select on columns
    distinct_on: [smart_query_sort_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_sort_order_by!]

    # filter the rows returned
    where: smart_query_sort_bool_exp
  ): [smart_query_sort!]!

  # An aggregated array relationship
  sorter_aggregate(
    # distinct select on columns
    distinct_on: [smart_query_sort_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_sort_order_by!]

    # filter the rows returned
    where: smart_query_sort_bool_exp
  ): smart_query_sort_aggregate!
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An object relationship
  theOwnerInstitute: organization
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  view: Int
}

# aggregated selection of "smart_query"
type smart_query_aggregate {
  aggregate: smart_query_aggregate_fields
  nodes: [smart_query!]!
}

# aggregate fields of "smart_query"
type smart_query_aggregate_fields {
  avg: smart_query_avg_fields
  count(columns: [smart_query_select_column!], distinct: Boolean): Int
  max: smart_query_max_fields
  min: smart_query_min_fields
  stddev: smart_query_stddev_fields
  stddev_pop: smart_query_stddev_pop_fields
  stddev_samp: smart_query_stddev_samp_fields
  sum: smart_query_sum_fields
  var_pop: smart_query_var_pop_fields
  var_samp: smart_query_var_samp_fields
  variance: smart_query_variance_fields
}

# order by aggregate values of table "smart_query"
input smart_query_aggregate_order_by {
  avg: smart_query_avg_order_by
  count: order_by
  max: smart_query_max_order_by
  min: smart_query_min_order_by
  stddev: smart_query_stddev_order_by
  stddev_pop: smart_query_stddev_pop_order_by
  stddev_samp: smart_query_stddev_samp_order_by
  sum: smart_query_sum_order_by
  var_pop: smart_query_var_pop_order_by
  var_samp: smart_query_var_samp_order_by
  variance: smart_query_variance_order_by
}

# input type for inserting array relation for remote table "smart_query"
input smart_query_arr_rel_insert_input {
  data: [smart_query_insert_input!]!
  on_conflict: smart_query_on_conflict
}

# aggregate avg on columns
type smart_query_avg_fields {
  approverMtid: Float
  creator: Float
  defaultMaxCount: Float
  defaultOrder: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  view: Float
}

# order by avg() on columns of table "smart_query"
input smart_query_avg_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# Boolean expression to filter rows from the table "smart_query". All fields are combined with a logical 'AND'.
input smart_query_bool_exp {
  _and: [smart_query_bool_exp]
  _not: smart_query_bool_exp
  _or: [smart_query_bool_exp]
  adhocQuery: Boolean_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  builtin: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  condGroupBasedJoin: Boolean_comparison_exp
  conditions: smart_query_cond_bool_exp
  conjunctional: Boolean_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  defaultMaxCount: Int_comparison_exp
  defaultOrder: Int_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  global: Boolean_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  indexed: Boolean_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  maxDedicatedRole: Int_comparison_exp
  minDedicatedRole: Int_comparison_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  negated: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  ownerInstitute: bigint_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  queryString: String_comparison_exp
  queryTemplate: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  resultType: String_comparison_exp
  sorter: smart_query_sort_bool_exp
  status: Int_comparison_exp
  tag: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  theOwnerInstitute: organization_bool_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  view: Int_comparison_exp
}

# columns and relationships of "smart_query_cond"
type smart_query_cond {
  applicable: Boolean!
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  condGroup: String
  cond_pos: Int
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  operator: String
  otype: String
  pathGroup: String
  prevValid: bigint
  published: Boolean!

  # An object relationship
  query: smart_query
  queryMtid: bigint
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregated selection of "smart_query_cond"
type smart_query_cond_aggregate {
  aggregate: smart_query_cond_aggregate_fields
  nodes: [smart_query_cond!]!
}

# aggregate fields of "smart_query_cond"
type smart_query_cond_aggregate_fields {
  avg: smart_query_cond_avg_fields
  count(columns: [smart_query_cond_select_column!], distinct: Boolean): Int
  max: smart_query_cond_max_fields
  min: smart_query_cond_min_fields
  stddev: smart_query_cond_stddev_fields
  stddev_pop: smart_query_cond_stddev_pop_fields
  stddev_samp: smart_query_cond_stddev_samp_fields
  sum: smart_query_cond_sum_fields
  var_pop: smart_query_cond_var_pop_fields
  var_samp: smart_query_cond_var_samp_fields
  variance: smart_query_cond_variance_fields
}

# order by aggregate values of table "smart_query_cond"
input smart_query_cond_aggregate_order_by {
  avg: smart_query_cond_avg_order_by
  count: order_by
  max: smart_query_cond_max_order_by
  min: smart_query_cond_min_order_by
  stddev: smart_query_cond_stddev_order_by
  stddev_pop: smart_query_cond_stddev_pop_order_by
  stddev_samp: smart_query_cond_stddev_samp_order_by
  sum: smart_query_cond_sum_order_by
  var_pop: smart_query_cond_var_pop_order_by
  var_samp: smart_query_cond_var_samp_order_by
  variance: smart_query_cond_variance_order_by
}

# input type for inserting array relation for remote table "smart_query_cond"
input smart_query_cond_arr_rel_insert_input {
  data: [smart_query_cond_insert_input!]!
  on_conflict: smart_query_cond_on_conflict
}

# aggregate avg on columns
type smart_query_cond_avg_fields {
  approverMtid: Float
  cond_pos: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "smart_query_cond"
input smart_query_cond_avg_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "smart_query_cond". All fields are combined with a logical 'AND'.
input smart_query_cond_bool_exp {
  _and: [smart_query_cond_bool_exp]
  _not: smart_query_cond_bool_exp
  _or: [smart_query_cond_bool_exp]
  applicable: Boolean_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  condGroup: String_comparison_exp
  cond_pos: Int_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  fieldDefinition: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  operator: String_comparison_exp
  otype: String_comparison_exp
  pathGroup: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  query: smart_query_bool_exp
  queryMtid: bigint_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  value: String_comparison_exp
}

# unique or primary key constraints on table "smart_query_cond"
enum smart_query_cond_constraint {
  # unique or primary key constraint
  smart_query_cond_pkey
}

# input type for incrementing integer column in table "smart_query_cond"
input smart_query_cond_inc_input {
  approverMtid: bigint
  cond_pos: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  status: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "smart_query_cond"
input smart_query_cond_insert_input {
  applicable: Boolean
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  condGroup: String
  cond_pos: Int
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  operator: String
  otype: String
  pathGroup: String
  prevValid: bigint
  published: Boolean
  query: smart_query_obj_rel_insert_input
  queryMtid: bigint
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregate max on columns
type smart_query_cond_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  condGroup: String
  cond_pos: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  operator: String
  otype: String
  pathGroup: String
  prevValid: bigint
  queryMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# order by max() on columns of table "smart_query_cond"
input smart_query_cond_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  condGroup: order_by
  cond_pos: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  fieldDefinition: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  operator: order_by
  otype: order_by
  pathGroup: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# aggregate min on columns
type smart_query_cond_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  condGroup: String
  cond_pos: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  operator: String
  otype: String
  pathGroup: String
  prevValid: bigint
  queryMtid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# order by min() on columns of table "smart_query_cond"
input smart_query_cond_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  condGroup: order_by
  cond_pos: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  fieldDefinition: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  operator: order_by
  otype: order_by
  pathGroup: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# response of any mutation on the table "smart_query_cond"
type smart_query_cond_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [smart_query_cond!]!
}

# input type for inserting object relation for remote table "smart_query_cond"
input smart_query_cond_obj_rel_insert_input {
  data: smart_query_cond_insert_input!
  on_conflict: smart_query_cond_on_conflict
}

# on conflict condition type for table "smart_query_cond"
input smart_query_cond_on_conflict {
  constraint: smart_query_cond_constraint!
  update_columns: [smart_query_cond_update_column!]!
  where: smart_query_cond_bool_exp
}

# ordering options when selecting data from "smart_query_cond"
input smart_query_cond_order_by {
  applicable: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  condGroup: order_by
  cond_pos: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  fieldDefinition: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  operator: order_by
  otype: order_by
  pathGroup: order_by
  prevValid: order_by
  published: order_by
  query: smart_query_order_by
  queryMtid: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# primary key columns input for table: "smart_query_cond"
input smart_query_cond_pk_columns_input {
  mtid: bigint!
}

# select columns of table "smart_query_cond"
enum smart_query_cond_select_column {
  # column name
  applicable

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  condGroup

  # column name
  cond_pos

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  fieldDefinition

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  operator

  # column name
  otype

  # column name
  pathGroup

  # column name
  prevValid

  # column name
  published

  # column name
  queryMtid

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  value
}

# input type for updating data in table "smart_query_cond"
input smart_query_cond_set_input {
  applicable: Boolean
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  condGroup: String
  cond_pos: Int
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  operator: String
  otype: String
  pathGroup: String
  prevValid: bigint
  published: Boolean
  queryMtid: bigint
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregate stddev on columns
type smart_query_cond_stddev_fields {
  approverMtid: Float
  cond_pos: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "smart_query_cond"
input smart_query_cond_stddev_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type smart_query_cond_stddev_pop_fields {
  approverMtid: Float
  cond_pos: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "smart_query_cond"
input smart_query_cond_stddev_pop_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type smart_query_cond_stddev_samp_fields {
  approverMtid: Float
  cond_pos: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "smart_query_cond"
input smart_query_cond_stddev_samp_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type smart_query_cond_sum_fields {
  approverMtid: bigint
  cond_pos: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  status: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "smart_query_cond"
input smart_query_cond_sum_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "smart_query_cond"
enum smart_query_cond_update_column {
  # column name
  applicable

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  condGroup

  # column name
  cond_pos

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  fieldDefinition

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  operator

  # column name
  otype

  # column name
  pathGroup

  # column name
  prevValid

  # column name
  published

  # column name
  queryMtid

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  value
}

# aggregate var_pop on columns
type smart_query_cond_var_pop_fields {
  approverMtid: Float
  cond_pos: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "smart_query_cond"
input smart_query_cond_var_pop_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type smart_query_cond_var_samp_fields {
  approverMtid: Float
  cond_pos: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "smart_query_cond"
input smart_query_cond_var_samp_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type smart_query_cond_variance_fields {
  approverMtid: Float
  cond_pos: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  status: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "smart_query_cond"
input smart_query_cond_variance_order_by {
  approverMtid: order_by
  cond_pos: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  status: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# unique or primary key constraints on table "smart_query"
enum smart_query_constraint {
  # unique or primary key constraint
  smart_query_pkey
}

# columns and relationships of "smart_query_group"
type smart_query_group {
  defaultQuery: bigint
  id: bigint!
  listOrder: String

  # An object relationship
  owner: users
  ownerMtid: bigint
  resultType: String
}

# aggregated selection of "smart_query_group"
type smart_query_group_aggregate {
  aggregate: smart_query_group_aggregate_fields
  nodes: [smart_query_group!]!
}

# aggregate fields of "smart_query_group"
type smart_query_group_aggregate_fields {
  avg: smart_query_group_avg_fields
  count(columns: [smart_query_group_select_column!], distinct: Boolean): Int
  max: smart_query_group_max_fields
  min: smart_query_group_min_fields
  stddev: smart_query_group_stddev_fields
  stddev_pop: smart_query_group_stddev_pop_fields
  stddev_samp: smart_query_group_stddev_samp_fields
  sum: smart_query_group_sum_fields
  var_pop: smart_query_group_var_pop_fields
  var_samp: smart_query_group_var_samp_fields
  variance: smart_query_group_variance_fields
}

# order by aggregate values of table "smart_query_group"
input smart_query_group_aggregate_order_by {
  avg: smart_query_group_avg_order_by
  count: order_by
  max: smart_query_group_max_order_by
  min: smart_query_group_min_order_by
  stddev: smart_query_group_stddev_order_by
  stddev_pop: smart_query_group_stddev_pop_order_by
  stddev_samp: smart_query_group_stddev_samp_order_by
  sum: smart_query_group_sum_order_by
  var_pop: smart_query_group_var_pop_order_by
  var_samp: smart_query_group_var_samp_order_by
  variance: smart_query_group_variance_order_by
}

# input type for inserting array relation for remote table "smart_query_group"
input smart_query_group_arr_rel_insert_input {
  data: [smart_query_group_insert_input!]!
  on_conflict: smart_query_group_on_conflict
}

# aggregate avg on columns
type smart_query_group_avg_fields {
  defaultQuery: Float
  id: Float
  ownerMtid: Float
}

# order by avg() on columns of table "smart_query_group"
input smart_query_group_avg_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# Boolean expression to filter rows from the table "smart_query_group". All fields are combined with a logical 'AND'.
input smart_query_group_bool_exp {
  _and: [smart_query_group_bool_exp]
  _not: smart_query_group_bool_exp
  _or: [smart_query_group_bool_exp]
  defaultQuery: bigint_comparison_exp
  id: bigint_comparison_exp
  listOrder: String_comparison_exp
  owner: users_bool_exp
  ownerMtid: bigint_comparison_exp
  resultType: String_comparison_exp
}

# unique or primary key constraints on table "smart_query_group"
enum smart_query_group_constraint {
  # unique or primary key constraint
  smart_query_group_pkey
}

# input type for incrementing integer column in table "smart_query_group"
input smart_query_group_inc_input {
  defaultQuery: bigint
  id: bigint
  ownerMtid: bigint
}

# input type for inserting data into table "smart_query_group"
input smart_query_group_insert_input {
  defaultQuery: bigint
  id: bigint
  listOrder: String
  owner: users_obj_rel_insert_input
  ownerMtid: bigint
  resultType: String
}

# aggregate max on columns
type smart_query_group_max_fields {
  defaultQuery: bigint
  id: bigint
  listOrder: String
  ownerMtid: bigint
  resultType: String
}

# order by max() on columns of table "smart_query_group"
input smart_query_group_max_order_by {
  defaultQuery: order_by
  id: order_by
  listOrder: order_by
  ownerMtid: order_by
  resultType: order_by
}

# aggregate min on columns
type smart_query_group_min_fields {
  defaultQuery: bigint
  id: bigint
  listOrder: String
  ownerMtid: bigint
  resultType: String
}

# order by min() on columns of table "smart_query_group"
input smart_query_group_min_order_by {
  defaultQuery: order_by
  id: order_by
  listOrder: order_by
  ownerMtid: order_by
  resultType: order_by
}

# response of any mutation on the table "smart_query_group"
type smart_query_group_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [smart_query_group!]!
}

# input type for inserting object relation for remote table "smart_query_group"
input smart_query_group_obj_rel_insert_input {
  data: smart_query_group_insert_input!
  on_conflict: smart_query_group_on_conflict
}

# on conflict condition type for table "smart_query_group"
input smart_query_group_on_conflict {
  constraint: smart_query_group_constraint!
  update_columns: [smart_query_group_update_column!]!
  where: smart_query_group_bool_exp
}

# ordering options when selecting data from "smart_query_group"
input smart_query_group_order_by {
  defaultQuery: order_by
  id: order_by
  listOrder: order_by
  owner: users_order_by
  ownerMtid: order_by
  resultType: order_by
}

# primary key columns input for table: "smart_query_group"
input smart_query_group_pk_columns_input {
  id: bigint!
}

# select columns of table "smart_query_group"
enum smart_query_group_select_column {
  # column name
  defaultQuery

  # column name
  id

  # column name
  listOrder

  # column name
  ownerMtid

  # column name
  resultType
}

# input type for updating data in table "smart_query_group"
input smart_query_group_set_input {
  defaultQuery: bigint
  id: bigint
  listOrder: String
  ownerMtid: bigint
  resultType: String
}

# aggregate stddev on columns
type smart_query_group_stddev_fields {
  defaultQuery: Float
  id: Float
  ownerMtid: Float
}

# order by stddev() on columns of table "smart_query_group"
input smart_query_group_stddev_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# aggregate stddev_pop on columns
type smart_query_group_stddev_pop_fields {
  defaultQuery: Float
  id: Float
  ownerMtid: Float
}

# order by stddev_pop() on columns of table "smart_query_group"
input smart_query_group_stddev_pop_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# aggregate stddev_samp on columns
type smart_query_group_stddev_samp_fields {
  defaultQuery: Float
  id: Float
  ownerMtid: Float
}

# order by stddev_samp() on columns of table "smart_query_group"
input smart_query_group_stddev_samp_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# aggregate sum on columns
type smart_query_group_sum_fields {
  defaultQuery: bigint
  id: bigint
  ownerMtid: bigint
}

# order by sum() on columns of table "smart_query_group"
input smart_query_group_sum_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# update columns of table "smart_query_group"
enum smart_query_group_update_column {
  # column name
  defaultQuery

  # column name
  id

  # column name
  listOrder

  # column name
  ownerMtid

  # column name
  resultType
}

# aggregate var_pop on columns
type smart_query_group_var_pop_fields {
  defaultQuery: Float
  id: Float
  ownerMtid: Float
}

# order by var_pop() on columns of table "smart_query_group"
input smart_query_group_var_pop_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# aggregate var_samp on columns
type smart_query_group_var_samp_fields {
  defaultQuery: Float
  id: Float
  ownerMtid: Float
}

# order by var_samp() on columns of table "smart_query_group"
input smart_query_group_var_samp_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# aggregate variance on columns
type smart_query_group_variance_fields {
  defaultQuery: Float
  id: Float
  ownerMtid: Float
}

# order by variance() on columns of table "smart_query_group"
input smart_query_group_variance_order_by {
  defaultQuery: order_by
  id: order_by
  ownerMtid: order_by
}

# input type for incrementing integer column in table "smart_query"
input smart_query_inc_input {
  approverMtid: bigint
  creator: bigint
  defaultMaxCount: Int
  defaultOrder: Int
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  view: Int
}

# input type for inserting data into table "smart_query"
input smart_query_insert_input {
  adhocQuery: Boolean
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  builtin: Boolean
  comment: String
  comment2: String
  condGroupBasedJoin: Boolean
  conditions: smart_query_cond_arr_rel_insert_input
  conjunctional: Boolean
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  defaultMaxCount: Int
  defaultOrder: Int
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  global: Boolean
  hint: String
  hintEng: String
  indexed: Boolean
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  negated: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  published: Boolean
  queryString: String
  queryTemplate: Boolean
  refreshed: Boolean
  resultType: String
  sorter: smart_query_sort_arr_rel_insert_input
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  theOwnerInstitute: organization_obj_rel_insert_input
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  view: Int
}

# aggregate max on columns
type smart_query_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  defaultMaxCount: Int
  defaultOrder: Int
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  queryString: String
  resultType: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  view: Int
}

# order by max() on columns of table "smart_query"
input smart_query_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  prevValid: order_by
  queryString: order_by
  resultType: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# aggregate min on columns
type smart_query_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  defaultMaxCount: Int
  defaultOrder: Int
  deletedDate: timestamp
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  queryString: String
  resultType: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  view: Int
}

# order by min() on columns of table "smart_query"
input smart_query_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  deletedDate: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  prevValid: order_by
  queryString: order_by
  resultType: order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# response of any mutation on the table "smart_query"
type smart_query_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [smart_query!]!
}

# input type for inserting object relation for remote table "smart_query"
input smart_query_obj_rel_insert_input {
  data: smart_query_insert_input!
  on_conflict: smart_query_on_conflict
}

# on conflict condition type for table "smart_query"
input smart_query_on_conflict {
  constraint: smart_query_constraint!
  update_columns: [smart_query_update_column!]!
  where: smart_query_bool_exp
}

# ordering options when selecting data from "smart_query"
input smart_query_order_by {
  adhocQuery: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  builtin: order_by
  comment: order_by
  comment2: order_by
  condGroupBasedJoin: order_by
  conditions_aggregate: smart_query_cond_aggregate_order_by
  conjunctional: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  global: order_by
  hint: order_by
  hintEng: order_by
  indexed: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  negated: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  ownerInstitute: order_by
  prevValid: order_by
  published: order_by
  queryString: order_by
  queryTemplate: order_by
  refreshed: order_by
  resultType: order_by
  sorter_aggregate: smart_query_sort_aggregate_order_by
  status: order_by
  tag: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  theOwnerInstitute: organization_order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# primary key columns input for table: "smart_query"
input smart_query_pk_columns_input {
  mtid: bigint!
}

# select columns of table "smart_query"
enum smart_query_select_column {
  # column name
  adhocQuery

  # column name
  approved

  # column name
  approverMtid

  # column name
  builtin

  # column name
  comment

  # column name
  comment2

  # column name
  condGroupBasedJoin

  # column name
  conjunctional

  # column name
  created

  # column name
  creator

  # column name
  defaultMaxCount

  # column name
  defaultOrder

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  global

  # column name
  hint

  # column name
  hintEng

  # column name
  indexed

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxDedicatedRole

  # column name
  minDedicatedRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  negated

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerInstitute

  # column name
  prevValid

  # column name
  published

  # column name
  queryString

  # column name
  queryTemplate

  # column name
  refreshed

  # column name
  resultType

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  view
}

# input type for updating data in table "smart_query"
input smart_query_set_input {
  adhocQuery: Boolean
  approved: timestamp
  approverMtid: bigint
  builtin: Boolean
  comment: String
  comment2: String
  condGroupBasedJoin: Boolean
  conjunctional: Boolean
  created: timestamp
  creator: bigint
  defaultMaxCount: Int
  defaultOrder: Int
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  global: Boolean
  hint: String
  hintEng: String
  indexed: Boolean
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  name: String
  nameEng: String
  negated: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  ownerInstitute: bigint
  prevValid: bigint
  published: Boolean
  queryString: String
  queryTemplate: Boolean
  refreshed: Boolean
  resultType: String
  status: Int
  tag: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  view: Int
}

# columns and relationships of "smart_query_sort"
type smart_query_sort {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  ascending: Boolean!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!

  # An object relationship
  query: smart_query
  queryMtid: bigint
  refreshed: Boolean!
  sorter_pos: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "smart_query_sort"
type smart_query_sort_aggregate {
  aggregate: smart_query_sort_aggregate_fields
  nodes: [smart_query_sort!]!
}

# aggregate fields of "smart_query_sort"
type smart_query_sort_aggregate_fields {
  avg: smart_query_sort_avg_fields
  count(columns: [smart_query_sort_select_column!], distinct: Boolean): Int
  max: smart_query_sort_max_fields
  min: smart_query_sort_min_fields
  stddev: smart_query_sort_stddev_fields
  stddev_pop: smart_query_sort_stddev_pop_fields
  stddev_samp: smart_query_sort_stddev_samp_fields
  sum: smart_query_sort_sum_fields
  var_pop: smart_query_sort_var_pop_fields
  var_samp: smart_query_sort_var_samp_fields
  variance: smart_query_sort_variance_fields
}

# order by aggregate values of table "smart_query_sort"
input smart_query_sort_aggregate_order_by {
  avg: smart_query_sort_avg_order_by
  count: order_by
  max: smart_query_sort_max_order_by
  min: smart_query_sort_min_order_by
  stddev: smart_query_sort_stddev_order_by
  stddev_pop: smart_query_sort_stddev_pop_order_by
  stddev_samp: smart_query_sort_stddev_samp_order_by
  sum: smart_query_sort_sum_order_by
  var_pop: smart_query_sort_var_pop_order_by
  var_samp: smart_query_sort_var_samp_order_by
  variance: smart_query_sort_variance_order_by
}

# input type for inserting array relation for remote table "smart_query_sort"
input smart_query_sort_arr_rel_insert_input {
  data: [smart_query_sort_insert_input!]!
  on_conflict: smart_query_sort_on_conflict
}

# aggregate avg on columns
type smart_query_sort_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  sorter_pos: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "smart_query_sort"
input smart_query_sort_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "smart_query_sort". All fields are combined with a logical 'AND'.
input smart_query_sort_bool_exp {
  _and: [smart_query_sort_bool_exp]
  _not: smart_query_sort_bool_exp
  _or: [smart_query_sort_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  ascending: Boolean_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  fieldDefinition: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  query: smart_query_bool_exp
  queryMtid: bigint_comparison_exp
  refreshed: Boolean_comparison_exp
  sorter_pos: Int_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "smart_query_sort"
enum smart_query_sort_constraint {
  # unique or primary key constraint
  smart_query_sort_pkey
}

# input type for incrementing integer column in table "smart_query_sort"
input smart_query_sort_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  sorter_pos: Int
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "smart_query_sort"
input smart_query_sort_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  ascending: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  query: smart_query_obj_rel_insert_input
  queryMtid: bigint
  refreshed: Boolean
  sorter_pos: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type smart_query_sort_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  queryMtid: bigint
  sorter_pos: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "smart_query_sort"
input smart_query_sort_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  fieldDefinition: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type smart_query_sort_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  queryMtid: bigint
  sorter_pos: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "smart_query_sort"
input smart_query_sort_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  fieldDefinition: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "smart_query_sort"
type smart_query_sort_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [smart_query_sort!]!
}

# input type for inserting object relation for remote table "smart_query_sort"
input smart_query_sort_obj_rel_insert_input {
  data: smart_query_sort_insert_input!
  on_conflict: smart_query_sort_on_conflict
}

# on conflict condition type for table "smart_query_sort"
input smart_query_sort_on_conflict {
  constraint: smart_query_sort_constraint!
  update_columns: [smart_query_sort_update_column!]!
  where: smart_query_sort_bool_exp
}

# ordering options when selecting data from "smart_query_sort"
input smart_query_sort_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  ascending: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  fieldDefinition: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  query: smart_query_order_by
  queryMtid: order_by
  refreshed: order_by
  sorter_pos: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "smart_query_sort"
input smart_query_sort_pk_columns_input {
  mtid: bigint!
}

# select columns of table "smart_query_sort"
enum smart_query_sort_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  ascending

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  fieldDefinition

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  queryMtid

  # column name
  refreshed

  # column name
  sorter_pos

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "smart_query_sort"
input smart_query_sort_set_input {
  approved: timestamp
  approverMtid: bigint
  ascending: Boolean
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  fieldDefinition: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  queryMtid: bigint
  refreshed: Boolean
  sorter_pos: Int
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type smart_query_sort_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  sorter_pos: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "smart_query_sort"
input smart_query_sort_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type smart_query_sort_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  sorter_pos: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "smart_query_sort"
input smart_query_sort_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type smart_query_sort_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  sorter_pos: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "smart_query_sort"
input smart_query_sort_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type smart_query_sort_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  queryMtid: bigint
  sorter_pos: Int
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "smart_query_sort"
input smart_query_sort_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "smart_query_sort"
enum smart_query_sort_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  ascending

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  fieldDefinition

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  queryMtid

  # column name
  refreshed

  # column name
  sorter_pos

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type smart_query_sort_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  sorter_pos: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "smart_query_sort"
input smart_query_sort_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type smart_query_sort_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  sorter_pos: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "smart_query_sort"
input smart_query_sort_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type smart_query_sort_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  queryMtid: Float
  sorter_pos: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "smart_query_sort"
input smart_query_sort_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  queryMtid: order_by
  sorter_pos: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev on columns
type smart_query_stddev_fields {
  approverMtid: Float
  creator: Float
  defaultMaxCount: Float
  defaultOrder: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  view: Float
}

# order by stddev() on columns of table "smart_query"
input smart_query_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# aggregate stddev_pop on columns
type smart_query_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  defaultMaxCount: Float
  defaultOrder: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  view: Float
}

# order by stddev_pop() on columns of table "smart_query"
input smart_query_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# aggregate stddev_samp on columns
type smart_query_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  defaultMaxCount: Float
  defaultOrder: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  view: Float
}

# order by stddev_samp() on columns of table "smart_query"
input smart_query_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# aggregate sum on columns
type smart_query_sum_fields {
  approverMtid: bigint
  creator: bigint
  defaultMaxCount: Int
  defaultOrder: Int
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  maxDedicatedRole: Int
  minDedicatedRole: Int
  mtid: bigint
  oldId: Int
  ownerInstitute: bigint
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  view: Int
}

# order by sum() on columns of table "smart_query"
input smart_query_sum_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# update columns of table "smart_query"
enum smart_query_update_column {
  # column name
  adhocQuery

  # column name
  approved

  # column name
  approverMtid

  # column name
  builtin

  # column name
  comment

  # column name
  comment2

  # column name
  condGroupBasedJoin

  # column name
  conjunctional

  # column name
  created

  # column name
  creator

  # column name
  defaultMaxCount

  # column name
  defaultOrder

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  global

  # column name
  hint

  # column name
  hintEng

  # column name
  indexed

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  maxDedicatedRole

  # column name
  minDedicatedRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  negated

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  ownerInstitute

  # column name
  prevValid

  # column name
  published

  # column name
  queryString

  # column name
  queryTemplate

  # column name
  refreshed

  # column name
  resultType

  # column name
  status

  # column name
  tag

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  view
}

# aggregate var_pop on columns
type smart_query_var_pop_fields {
  approverMtid: Float
  creator: Float
  defaultMaxCount: Float
  defaultOrder: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  view: Float
}

# order by var_pop() on columns of table "smart_query"
input smart_query_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# aggregate var_samp on columns
type smart_query_var_samp_fields {
  approverMtid: Float
  creator: Float
  defaultMaxCount: Float
  defaultOrder: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  view: Float
}

# order by var_samp() on columns of table "smart_query"
input smart_query_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# aggregate variance on columns
type smart_query_variance_fields {
  approverMtid: Float
  creator: Float
  defaultMaxCount: Float
  defaultOrder: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  maxDedicatedRole: Float
  minDedicatedRole: Float
  mtid: Float
  oldId: Float
  ownerInstitute: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  view: Float
}

# order by variance() on columns of table "smart_query"
input smart_query_variance_order_by {
  approverMtid: order_by
  creator: order_by
  defaultMaxCount: order_by
  defaultOrder: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  maxDedicatedRole: order_by
  minDedicatedRole: order_by
  mtid: order_by
  oldId: order_by
  ownerInstitute: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  view: order_by
}

# columns and relationships of "snippet_cache"
type snippet_cache {
  binCachedValue: bytea
  cachedValue: String
  mtid: bigint!
  otype: String!
}

# aggregated selection of "snippet_cache"
type snippet_cache_aggregate {
  aggregate: snippet_cache_aggregate_fields
  nodes: [snippet_cache!]!
}

# aggregate fields of "snippet_cache"
type snippet_cache_aggregate_fields {
  avg: snippet_cache_avg_fields
  count(columns: [snippet_cache_select_column!], distinct: Boolean): Int
  max: snippet_cache_max_fields
  min: snippet_cache_min_fields
  stddev: snippet_cache_stddev_fields
  stddev_pop: snippet_cache_stddev_pop_fields
  stddev_samp: snippet_cache_stddev_samp_fields
  sum: snippet_cache_sum_fields
  var_pop: snippet_cache_var_pop_fields
  var_samp: snippet_cache_var_samp_fields
  variance: snippet_cache_variance_fields
}

# order by aggregate values of table "snippet_cache"
input snippet_cache_aggregate_order_by {
  avg: snippet_cache_avg_order_by
  count: order_by
  max: snippet_cache_max_order_by
  min: snippet_cache_min_order_by
  stddev: snippet_cache_stddev_order_by
  stddev_pop: snippet_cache_stddev_pop_order_by
  stddev_samp: snippet_cache_stddev_samp_order_by
  sum: snippet_cache_sum_order_by
  var_pop: snippet_cache_var_pop_order_by
  var_samp: snippet_cache_var_samp_order_by
  variance: snippet_cache_variance_order_by
}

# input type for inserting array relation for remote table "snippet_cache"
input snippet_cache_arr_rel_insert_input {
  data: [snippet_cache_insert_input!]!
  on_conflict: snippet_cache_on_conflict
}

# aggregate avg on columns
type snippet_cache_avg_fields {
  mtid: Float
}

# order by avg() on columns of table "snippet_cache"
input snippet_cache_avg_order_by {
  mtid: order_by
}

# Boolean expression to filter rows from the table "snippet_cache". All fields are combined with a logical 'AND'.
input snippet_cache_bool_exp {
  _and: [snippet_cache_bool_exp]
  _not: snippet_cache_bool_exp
  _or: [snippet_cache_bool_exp]
  binCachedValue: bytea_comparison_exp
  cachedValue: String_comparison_exp
  mtid: bigint_comparison_exp
  otype: String_comparison_exp
}

# unique or primary key constraints on table "snippet_cache"
enum snippet_cache_constraint {
  # unique or primary key constraint
  snippet_cache_pkey
}

# input type for incrementing integer column in table "snippet_cache"
input snippet_cache_inc_input {
  mtid: bigint
}

# input type for inserting data into table "snippet_cache"
input snippet_cache_insert_input {
  binCachedValue: bytea
  cachedValue: String
  mtid: bigint
  otype: String
}

# aggregate max on columns
type snippet_cache_max_fields {
  cachedValue: String
  mtid: bigint
  otype: String
}

# order by max() on columns of table "snippet_cache"
input snippet_cache_max_order_by {
  cachedValue: order_by
  mtid: order_by
  otype: order_by
}

# aggregate min on columns
type snippet_cache_min_fields {
  cachedValue: String
  mtid: bigint
  otype: String
}

# order by min() on columns of table "snippet_cache"
input snippet_cache_min_order_by {
  cachedValue: order_by
  mtid: order_by
  otype: order_by
}

# response of any mutation on the table "snippet_cache"
type snippet_cache_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [snippet_cache!]!
}

# input type for inserting object relation for remote table "snippet_cache"
input snippet_cache_obj_rel_insert_input {
  data: snippet_cache_insert_input!
  on_conflict: snippet_cache_on_conflict
}

# on conflict condition type for table "snippet_cache"
input snippet_cache_on_conflict {
  constraint: snippet_cache_constraint!
  update_columns: [snippet_cache_update_column!]!
  where: snippet_cache_bool_exp
}

# ordering options when selecting data from "snippet_cache"
input snippet_cache_order_by {
  binCachedValue: order_by
  cachedValue: order_by
  mtid: order_by
  otype: order_by
}

# primary key columns input for table: "snippet_cache"
input snippet_cache_pk_columns_input {
  mtid: bigint!
  otype: String!
}

# select columns of table "snippet_cache"
enum snippet_cache_select_column {
  # column name
  binCachedValue

  # column name
  cachedValue

  # column name
  mtid

  # column name
  otype
}

# input type for updating data in table "snippet_cache"
input snippet_cache_set_input {
  binCachedValue: bytea
  cachedValue: String
  mtid: bigint
  otype: String
}

# columns and relationships of "snippet_cache_status"
type snippet_cache_status {
  mtid: bigint!
  needsSnippetInvalidationWhereReferenced: Boolean!
  otype: String!
  snippetsInvalidated: Boolean!
  updatedDate: timestamp
}

# aggregated selection of "snippet_cache_status"
type snippet_cache_status_aggregate {
  aggregate: snippet_cache_status_aggregate_fields
  nodes: [snippet_cache_status!]!
}

# aggregate fields of "snippet_cache_status"
type snippet_cache_status_aggregate_fields {
  avg: snippet_cache_status_avg_fields
  count(columns: [snippet_cache_status_select_column!], distinct: Boolean): Int
  max: snippet_cache_status_max_fields
  min: snippet_cache_status_min_fields
  stddev: snippet_cache_status_stddev_fields
  stddev_pop: snippet_cache_status_stddev_pop_fields
  stddev_samp: snippet_cache_status_stddev_samp_fields
  sum: snippet_cache_status_sum_fields
  var_pop: snippet_cache_status_var_pop_fields
  var_samp: snippet_cache_status_var_samp_fields
  variance: snippet_cache_status_variance_fields
}

# order by aggregate values of table "snippet_cache_status"
input snippet_cache_status_aggregate_order_by {
  avg: snippet_cache_status_avg_order_by
  count: order_by
  max: snippet_cache_status_max_order_by
  min: snippet_cache_status_min_order_by
  stddev: snippet_cache_status_stddev_order_by
  stddev_pop: snippet_cache_status_stddev_pop_order_by
  stddev_samp: snippet_cache_status_stddev_samp_order_by
  sum: snippet_cache_status_sum_order_by
  var_pop: snippet_cache_status_var_pop_order_by
  var_samp: snippet_cache_status_var_samp_order_by
  variance: snippet_cache_status_variance_order_by
}

# input type for inserting array relation for remote table "snippet_cache_status"
input snippet_cache_status_arr_rel_insert_input {
  data: [snippet_cache_status_insert_input!]!
  on_conflict: snippet_cache_status_on_conflict
}

# aggregate avg on columns
type snippet_cache_status_avg_fields {
  mtid: Float
}

# order by avg() on columns of table "snippet_cache_status"
input snippet_cache_status_avg_order_by {
  mtid: order_by
}

# Boolean expression to filter rows from the table "snippet_cache_status". All fields are combined with a logical 'AND'.
input snippet_cache_status_bool_exp {
  _and: [snippet_cache_status_bool_exp]
  _not: snippet_cache_status_bool_exp
  _or: [snippet_cache_status_bool_exp]
  mtid: bigint_comparison_exp
  needsSnippetInvalidationWhereReferenced: Boolean_comparison_exp
  otype: String_comparison_exp
  snippetsInvalidated: Boolean_comparison_exp
  updatedDate: timestamp_comparison_exp
}

# unique or primary key constraints on table "snippet_cache_status"
enum snippet_cache_status_constraint {
  # unique or primary key constraint
  snippet_cache_status_pkey
}

# input type for incrementing integer column in table "snippet_cache_status"
input snippet_cache_status_inc_input {
  mtid: bigint
}

# input type for inserting data into table "snippet_cache_status"
input snippet_cache_status_insert_input {
  mtid: bigint
  needsSnippetInvalidationWhereReferenced: Boolean
  otype: String
  snippetsInvalidated: Boolean
  updatedDate: timestamp
}

# aggregate max on columns
type snippet_cache_status_max_fields {
  mtid: bigint
  otype: String
  updatedDate: timestamp
}

# order by max() on columns of table "snippet_cache_status"
input snippet_cache_status_max_order_by {
  mtid: order_by
  otype: order_by
  updatedDate: order_by
}

# aggregate min on columns
type snippet_cache_status_min_fields {
  mtid: bigint
  otype: String
  updatedDate: timestamp
}

# order by min() on columns of table "snippet_cache_status"
input snippet_cache_status_min_order_by {
  mtid: order_by
  otype: order_by
  updatedDate: order_by
}

# response of any mutation on the table "snippet_cache_status"
type snippet_cache_status_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [snippet_cache_status!]!
}

# input type for inserting object relation for remote table "snippet_cache_status"
input snippet_cache_status_obj_rel_insert_input {
  data: snippet_cache_status_insert_input!
  on_conflict: snippet_cache_status_on_conflict
}

# on conflict condition type for table "snippet_cache_status"
input snippet_cache_status_on_conflict {
  constraint: snippet_cache_status_constraint!
  update_columns: [snippet_cache_status_update_column!]!
  where: snippet_cache_status_bool_exp
}

# ordering options when selecting data from "snippet_cache_status"
input snippet_cache_status_order_by {
  mtid: order_by
  needsSnippetInvalidationWhereReferenced: order_by
  otype: order_by
  snippetsInvalidated: order_by
  updatedDate: order_by
}

# primary key columns input for table: "snippet_cache_status"
input snippet_cache_status_pk_columns_input {
  mtid: bigint!
  otype: String!
}

# select columns of table "snippet_cache_status"
enum snippet_cache_status_select_column {
  # column name
  mtid

  # column name
  needsSnippetInvalidationWhereReferenced

  # column name
  otype

  # column name
  snippetsInvalidated

  # column name
  updatedDate
}

# input type for updating data in table "snippet_cache_status"
input snippet_cache_status_set_input {
  mtid: bigint
  needsSnippetInvalidationWhereReferenced: Boolean
  otype: String
  snippetsInvalidated: Boolean
  updatedDate: timestamp
}

# aggregate stddev on columns
type snippet_cache_status_stddev_fields {
  mtid: Float
}

# order by stddev() on columns of table "snippet_cache_status"
input snippet_cache_status_stddev_order_by {
  mtid: order_by
}

# aggregate stddev_pop on columns
type snippet_cache_status_stddev_pop_fields {
  mtid: Float
}

# order by stddev_pop() on columns of table "snippet_cache_status"
input snippet_cache_status_stddev_pop_order_by {
  mtid: order_by
}

# aggregate stddev_samp on columns
type snippet_cache_status_stddev_samp_fields {
  mtid: Float
}

# order by stddev_samp() on columns of table "snippet_cache_status"
input snippet_cache_status_stddev_samp_order_by {
  mtid: order_by
}

# aggregate sum on columns
type snippet_cache_status_sum_fields {
  mtid: bigint
}

# order by sum() on columns of table "snippet_cache_status"
input snippet_cache_status_sum_order_by {
  mtid: order_by
}

# update columns of table "snippet_cache_status"
enum snippet_cache_status_update_column {
  # column name
  mtid

  # column name
  needsSnippetInvalidationWhereReferenced

  # column name
  otype

  # column name
  snippetsInvalidated

  # column name
  updatedDate
}

# aggregate var_pop on columns
type snippet_cache_status_var_pop_fields {
  mtid: Float
}

# order by var_pop() on columns of table "snippet_cache_status"
input snippet_cache_status_var_pop_order_by {
  mtid: order_by
}

# aggregate var_samp on columns
type snippet_cache_status_var_samp_fields {
  mtid: Float
}

# order by var_samp() on columns of table "snippet_cache_status"
input snippet_cache_status_var_samp_order_by {
  mtid: order_by
}

# aggregate variance on columns
type snippet_cache_status_variance_fields {
  mtid: Float
}

# order by variance() on columns of table "snippet_cache_status"
input snippet_cache_status_variance_order_by {
  mtid: order_by
}

# aggregate stddev on columns
type snippet_cache_stddev_fields {
  mtid: Float
}

# order by stddev() on columns of table "snippet_cache"
input snippet_cache_stddev_order_by {
  mtid: order_by
}

# aggregate stddev_pop on columns
type snippet_cache_stddev_pop_fields {
  mtid: Float
}

# order by stddev_pop() on columns of table "snippet_cache"
input snippet_cache_stddev_pop_order_by {
  mtid: order_by
}

# aggregate stddev_samp on columns
type snippet_cache_stddev_samp_fields {
  mtid: Float
}

# order by stddev_samp() on columns of table "snippet_cache"
input snippet_cache_stddev_samp_order_by {
  mtid: order_by
}

# aggregate sum on columns
type snippet_cache_sum_fields {
  mtid: bigint
}

# order by sum() on columns of table "snippet_cache"
input snippet_cache_sum_order_by {
  mtid: order_by
}

# update columns of table "snippet_cache"
enum snippet_cache_update_column {
  # column name
  binCachedValue

  # column name
  cachedValue

  # column name
  mtid

  # column name
  otype
}

# aggregate var_pop on columns
type snippet_cache_var_pop_fields {
  mtid: Float
}

# order by var_pop() on columns of table "snippet_cache"
input snippet_cache_var_pop_order_by {
  mtid: order_by
}

# aggregate var_samp on columns
type snippet_cache_var_samp_fields {
  mtid: Float
}

# order by var_samp() on columns of table "snippet_cache"
input snippet_cache_var_samp_order_by {
  mtid: order_by
}

# aggregate variance on columns
type snippet_cache_variance_fields {
  mtid: Float
}

# order by variance() on columns of table "snippet_cache"
input snippet_cache_variance_order_by {
  mtid: order_by
}

# columns and relationships of "source"
type source {
  active: Boolean!

  # An array relationship
  allowedInstitutes(
    # distinct select on columns
    distinct_on: [source_allowed_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_allowed_institutes_order_by!]

    # filter the rows returned
    where: source_allowed_institutes_bool_exp
  ): [source_allowed_institutes!]!

  # An aggregated array relationship
  allowedInstitutes_aggregate(
    # distinct select on columns
    distinct_on: [source_allowed_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_allowed_institutes_order_by!]

    # filter the rows returned
    where: source_allowed_institutes_bool_exp
  ): source_allowed_institutes_aggregate!
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  docInstUpload: Boolean
  dtype: String!
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  errorMsg: String
  hint: String
  hintEng: String
  hungarian: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  linkPattern: String
  linkSample: String
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oaOrder: Int
  oaType: Int
  oaType2: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phdUpload: Int
  prevValid: bigint
  publiclyVisible: Boolean
  published: Boolean!
  refreshed: Boolean!
  regexp: String
  regexpHint: String
  repoType: String
  status: Int
  swordMaxPieces: Int
  swordMaxSize: Int
  swordPassword: String
  swordTypes: String
  swordUrl: String
  swordUser: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String

  # An object relationship
  type: publication_source_type
  typeMtid: bigint
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "source"
type source_aggregate {
  aggregate: source_aggregate_fields
  nodes: [source!]!
}

# aggregate fields of "source"
type source_aggregate_fields {
  avg: source_avg_fields
  count(columns: [source_select_column!], distinct: Boolean): Int
  max: source_max_fields
  min: source_min_fields
  stddev: source_stddev_fields
  stddev_pop: source_stddev_pop_fields
  stddev_samp: source_stddev_samp_fields
  sum: source_sum_fields
  var_pop: source_var_pop_fields
  var_samp: source_var_samp_fields
  variance: source_variance_fields
}

# order by aggregate values of table "source"
input source_aggregate_order_by {
  avg: source_avg_order_by
  count: order_by
  max: source_max_order_by
  min: source_min_order_by
  stddev: source_stddev_order_by
  stddev_pop: source_stddev_pop_order_by
  stddev_samp: source_stddev_samp_order_by
  sum: source_sum_order_by
  var_pop: source_var_pop_order_by
  var_samp: source_var_samp_order_by
  variance: source_variance_order_by
}

# columns and relationships of "source_allowed_institutes"
type source_allowed_institutes {
  allowedInstitutesMtid: bigint!

  # An object relationship
  organization: organization!
  sourceMtid: bigint!
}

# aggregated selection of "source_allowed_institutes"
type source_allowed_institutes_aggregate {
  aggregate: source_allowed_institutes_aggregate_fields
  nodes: [source_allowed_institutes!]!
}

# aggregate fields of "source_allowed_institutes"
type source_allowed_institutes_aggregate_fields {
  avg: source_allowed_institutes_avg_fields
  count(columns: [source_allowed_institutes_select_column!], distinct: Boolean): Int
  max: source_allowed_institutes_max_fields
  min: source_allowed_institutes_min_fields
  stddev: source_allowed_institutes_stddev_fields
  stddev_pop: source_allowed_institutes_stddev_pop_fields
  stddev_samp: source_allowed_institutes_stddev_samp_fields
  sum: source_allowed_institutes_sum_fields
  var_pop: source_allowed_institutes_var_pop_fields
  var_samp: source_allowed_institutes_var_samp_fields
  variance: source_allowed_institutes_variance_fields
}

# order by aggregate values of table "source_allowed_institutes"
input source_allowed_institutes_aggregate_order_by {
  avg: source_allowed_institutes_avg_order_by
  count: order_by
  max: source_allowed_institutes_max_order_by
  min: source_allowed_institutes_min_order_by
  stddev: source_allowed_institutes_stddev_order_by
  stddev_pop: source_allowed_institutes_stddev_pop_order_by
  stddev_samp: source_allowed_institutes_stddev_samp_order_by
  sum: source_allowed_institutes_sum_order_by
  var_pop: source_allowed_institutes_var_pop_order_by
  var_samp: source_allowed_institutes_var_samp_order_by
  variance: source_allowed_institutes_variance_order_by
}

# input type for inserting array relation for remote table "source_allowed_institutes"
input source_allowed_institutes_arr_rel_insert_input {
  data: [source_allowed_institutes_insert_input!]!
}

# aggregate avg on columns
type source_allowed_institutes_avg_fields {
  allowedInstitutesMtid: Float
  sourceMtid: Float
}

# order by avg() on columns of table "source_allowed_institutes"
input source_allowed_institutes_avg_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# Boolean expression to filter rows from the table "source_allowed_institutes". All fields are combined with a logical 'AND'.
input source_allowed_institutes_bool_exp {
  _and: [source_allowed_institutes_bool_exp]
  _not: source_allowed_institutes_bool_exp
  _or: [source_allowed_institutes_bool_exp]
  allowedInstitutesMtid: bigint_comparison_exp
  organization: organization_bool_exp
  sourceMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "source_allowed_institutes"
input source_allowed_institutes_inc_input {
  allowedInstitutesMtid: bigint
  sourceMtid: bigint
}

# input type for inserting data into table "source_allowed_institutes"
input source_allowed_institutes_insert_input {
  allowedInstitutesMtid: bigint
  organization: organization_obj_rel_insert_input
  sourceMtid: bigint
}

# aggregate max on columns
type source_allowed_institutes_max_fields {
  allowedInstitutesMtid: bigint
  sourceMtid: bigint
}

# order by max() on columns of table "source_allowed_institutes"
input source_allowed_institutes_max_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# aggregate min on columns
type source_allowed_institutes_min_fields {
  allowedInstitutesMtid: bigint
  sourceMtid: bigint
}

# order by min() on columns of table "source_allowed_institutes"
input source_allowed_institutes_min_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# response of any mutation on the table "source_allowed_institutes"
type source_allowed_institutes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [source_allowed_institutes!]!
}

# input type for inserting object relation for remote table "source_allowed_institutes"
input source_allowed_institutes_obj_rel_insert_input {
  data: source_allowed_institutes_insert_input!
}

# ordering options when selecting data from "source_allowed_institutes"
input source_allowed_institutes_order_by {
  allowedInstitutesMtid: order_by
  organization: organization_order_by
  sourceMtid: order_by
}

# select columns of table "source_allowed_institutes"
enum source_allowed_institutes_select_column {
  # column name
  allowedInstitutesMtid

  # column name
  sourceMtid
}

# input type for updating data in table "source_allowed_institutes"
input source_allowed_institutes_set_input {
  allowedInstitutesMtid: bigint
  sourceMtid: bigint
}

# aggregate stddev on columns
type source_allowed_institutes_stddev_fields {
  allowedInstitutesMtid: Float
  sourceMtid: Float
}

# order by stddev() on columns of table "source_allowed_institutes"
input source_allowed_institutes_stddev_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# aggregate stddev_pop on columns
type source_allowed_institutes_stddev_pop_fields {
  allowedInstitutesMtid: Float
  sourceMtid: Float
}

# order by stddev_pop() on columns of table "source_allowed_institutes"
input source_allowed_institutes_stddev_pop_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# aggregate stddev_samp on columns
type source_allowed_institutes_stddev_samp_fields {
  allowedInstitutesMtid: Float
  sourceMtid: Float
}

# order by stddev_samp() on columns of table "source_allowed_institutes"
input source_allowed_institutes_stddev_samp_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# aggregate sum on columns
type source_allowed_institutes_sum_fields {
  allowedInstitutesMtid: bigint
  sourceMtid: bigint
}

# order by sum() on columns of table "source_allowed_institutes"
input source_allowed_institutes_sum_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# aggregate var_pop on columns
type source_allowed_institutes_var_pop_fields {
  allowedInstitutesMtid: Float
  sourceMtid: Float
}

# order by var_pop() on columns of table "source_allowed_institutes"
input source_allowed_institutes_var_pop_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# aggregate var_samp on columns
type source_allowed_institutes_var_samp_fields {
  allowedInstitutesMtid: Float
  sourceMtid: Float
}

# order by var_samp() on columns of table "source_allowed_institutes"
input source_allowed_institutes_var_samp_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# aggregate variance on columns
type source_allowed_institutes_variance_fields {
  allowedInstitutesMtid: Float
  sourceMtid: Float
}

# order by variance() on columns of table "source_allowed_institutes"
input source_allowed_institutes_variance_order_by {
  allowedInstitutesMtid: order_by
  sourceMtid: order_by
}

# input type for inserting array relation for remote table "source"
input source_arr_rel_insert_input {
  data: [source_insert_input!]!
  on_conflict: source_on_conflict
}

# aggregate avg on columns
type source_avg_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaOrder: Float
  oaType: Float
  oaType2: Float
  oldId: Float
  phdUpload: Float
  prevValid: Float
  status: Float
  swordMaxPieces: Float
  swordMaxSize: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "source"
input source_avg_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "source". All fields are combined with a logical 'AND'.
input source_bool_exp {
  _and: [source_bool_exp]
  _not: source_bool_exp
  _or: [source_bool_exp]
  active: Boolean_comparison_exp
  allowedInstitutes: source_allowed_institutes_bool_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  docInstUpload: Boolean_comparison_exp
  dtype: String_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  errorMsg: String_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  hungarian: Boolean_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  linkPattern: String_comparison_exp
  linkSample: String_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oaOrder: Int_comparison_exp
  oaType: Int_comparison_exp
  oaType2: Int_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  phdUpload: Int_comparison_exp
  prevValid: bigint_comparison_exp
  publiclyVisible: Boolean_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  regexp: String_comparison_exp
  regexpHint: String_comparison_exp
  repoType: String_comparison_exp
  status: Int_comparison_exp
  swordMaxPieces: Int_comparison_exp
  swordMaxSize: Int_comparison_exp
  swordPassword: String_comparison_exp
  swordTypes: String_comparison_exp
  swordUrl: String_comparison_exp
  swordUser: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  type: publication_source_type_bool_exp
  typeMtid: bigint_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "source"
enum source_constraint {
  # unique or primary key constraint
  source_pkey
}

# input type for incrementing integer column in table "source"
input source_inc_input {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oaOrder: Int
  oaType: Int
  oaType2: Int
  oldId: Int
  phdUpload: Int
  prevValid: bigint
  status: Int
  swordMaxPieces: Int
  swordMaxSize: Int
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "source"
input source_insert_input {
  active: Boolean
  allowedInstitutes: source_allowed_institutes_arr_rel_insert_input
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  docInstUpload: Boolean
  dtype: String
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  errorMsg: String
  hint: String
  hintEng: String
  hungarian: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  linkPattern: String
  linkSample: String
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oaOrder: Int
  oaType: Int
  oaType2: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phdUpload: Int
  prevValid: bigint
  publiclyVisible: Boolean
  published: Boolean
  refreshed: Boolean
  regexp: String
  regexpHint: String
  repoType: String
  status: Int
  swordMaxPieces: Int
  swordMaxSize: Int
  swordPassword: String
  swordTypes: String
  swordUrl: String
  swordUser: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  type: publication_source_type_obj_rel_insert_input
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type source_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  errorMsg: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  linkPattern: String
  linkSample: String
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oaOrder: Int
  oaType: Int
  oaType2: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phdUpload: Int
  prevValid: bigint
  regexp: String
  regexpHint: String
  repoType: String
  status: Int
  swordMaxPieces: Int
  swordMaxSize: Int
  swordPassword: String
  swordTypes: String
  swordUrl: String
  swordUser: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "source"
input source_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  errorMsg: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  linkPattern: order_by
  linkSample: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  phdUpload: order_by
  prevValid: order_by
  regexp: order_by
  regexpHint: order_by
  repoType: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  swordPassword: order_by
  swordTypes: order_by
  swordUrl: order_by
  swordUser: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type source_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  errorMsg: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  linkPattern: String
  linkSample: String
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oaOrder: Int
  oaType: Int
  oaType2: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phdUpload: Int
  prevValid: bigint
  regexp: String
  regexpHint: String
  repoType: String
  status: Int
  swordMaxPieces: Int
  swordMaxSize: Int
  swordPassword: String
  swordTypes: String
  swordUrl: String
  swordUser: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "source"
input source_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  errorMsg: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  linkPattern: order_by
  linkSample: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  phdUpload: order_by
  prevValid: order_by
  regexp: order_by
  regexpHint: order_by
  repoType: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  swordPassword: order_by
  swordTypes: order_by
  swordUrl: order_by
  swordUser: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "source"
type source_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [source!]!
}

# input type for inserting object relation for remote table "source"
input source_obj_rel_insert_input {
  data: source_insert_input!
  on_conflict: source_on_conflict
}

# on conflict condition type for table "source"
input source_on_conflict {
  constraint: source_constraint!
  update_columns: [source_update_column!]!
  where: source_bool_exp
}

# ordering options when selecting data from "source"
input source_order_by {
  active: order_by
  allowedInstitutes_aggregate: source_allowed_institutes_aggregate_order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  docInstUpload: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  errorMsg: order_by
  hint: order_by
  hintEng: order_by
  hungarian: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  linkPattern: order_by
  linkSample: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  phdUpload: order_by
  prevValid: order_by
  publiclyVisible: order_by
  published: order_by
  refreshed: order_by
  regexp: order_by
  regexpHint: order_by
  repoType: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  swordPassword: order_by
  swordTypes: order_by
  swordUrl: order_by
  swordUser: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  type: publication_source_type_order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "source"
input source_pk_columns_input {
  mtid: bigint!
}

# select columns of table "source"
enum source_select_column {
  # column name
  active

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  docInstUpload

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  errorMsg

  # column name
  hint

  # column name
  hintEng

  # column name
  hungarian

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  linkPattern

  # column name
  linkSample

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oaOrder

  # column name
  oaType

  # column name
  oaType2

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  phdUpload

  # column name
  prevValid

  # column name
  publiclyVisible

  # column name
  published

  # column name
  refreshed

  # column name
  regexp

  # column name
  regexpHint

  # column name
  repoType

  # column name
  status

  # column name
  swordMaxPieces

  # column name
  swordMaxSize

  # column name
  swordPassword

  # column name
  swordTypes

  # column name
  swordUrl

  # column name
  swordUser

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  typeMtid

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "source"
input source_set_input {
  active: Boolean
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  docInstUpload: Boolean
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  errorMsg: String
  hint: String
  hintEng: String
  hungarian: Boolean
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  linkPattern: String
  linkSample: String
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oaOrder: Int
  oaType: Int
  oaType2: Int
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  phdUpload: Int
  prevValid: bigint
  publiclyVisible: Boolean
  published: Boolean
  refreshed: Boolean
  regexp: String
  regexpHint: String
  repoType: String
  status: Int
  swordMaxPieces: Int
  swordMaxSize: Int
  swordPassword: String
  swordTypes: String
  swordUrl: String
  swordUser: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type source_stddev_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaOrder: Float
  oaType: Float
  oaType2: Float
  oldId: Float
  phdUpload: Float
  prevValid: Float
  status: Float
  swordMaxPieces: Float
  swordMaxSize: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "source"
input source_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type source_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaOrder: Float
  oaType: Float
  oaType2: Float
  oldId: Float
  phdUpload: Float
  prevValid: Float
  status: Float
  swordMaxPieces: Float
  swordMaxSize: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "source"
input source_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type source_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaOrder: Float
  oaType: Float
  oaType2: Float
  oldId: Float
  phdUpload: Float
  prevValid: Float
  status: Float
  swordMaxPieces: Float
  swordMaxSize: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "source"
input source_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type source_sum_fields {
  approverMtid: bigint
  creator: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oaOrder: Int
  oaType: Int
  oaType2: Int
  oldId: Int
  phdUpload: Int
  prevValid: bigint
  status: Int
  swordMaxPieces: Int
  swordMaxSize: Int
  typeMtid: bigint
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "source"
input source_sum_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "source"
enum source_update_column {
  # column name
  active

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  docInstUpload

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  errorMsg

  # column name
  hint

  # column name
  hintEng

  # column name
  hungarian

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  linkPattern

  # column name
  linkSample

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oaOrder

  # column name
  oaType

  # column name
  oaType2

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  phdUpload

  # column name
  prevValid

  # column name
  publiclyVisible

  # column name
  published

  # column name
  refreshed

  # column name
  regexp

  # column name
  regexpHint

  # column name
  repoType

  # column name
  status

  # column name
  swordMaxPieces

  # column name
  swordMaxSize

  # column name
  swordPassword

  # column name
  swordTypes

  # column name
  swordUrl

  # column name
  swordUser

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  typeMtid

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type source_var_pop_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaOrder: Float
  oaType: Float
  oaType2: Float
  oldId: Float
  phdUpload: Float
  prevValid: Float
  status: Float
  swordMaxPieces: Float
  swordMaxSize: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "source"
input source_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type source_var_samp_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaOrder: Float
  oaType: Float
  oaType2: Float
  oldId: Float
  phdUpload: Float
  prevValid: Float
  status: Float
  swordMaxPieces: Float
  swordMaxSize: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "source"
input source_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type source_variance_fields {
  approverMtid: Float
  creator: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oaOrder: Float
  oaType: Float
  oaType2: Float
  oldId: Float
  phdUpload: Float
  prevValid: Float
  status: Float
  swordMaxPieces: Float
  swordMaxSize: Float
  typeMtid: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "source"
input source_variance_order_by {
  approverMtid: order_by
  creator: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oaOrder: order_by
  oaType: order_by
  oaType2: order_by
  oldId: order_by
  phdUpload: order_by
  prevValid: order_by
  status: order_by
  swordMaxPieces: order_by
  swordMaxSize: order_by
  typeMtid: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# expression to compare columns of type String. All fields are combined with logical 'AND'.
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String
  _ilike: String
  _in: [String!]
  _is_null: Boolean
  _like: String
  _lt: String
  _lte: String
  _neq: String
  _nilike: String
  _nin: [String!]
  _nlike: String
  _nsimilar: String
  _similar: String
}

# columns and relationships of "sub_type"
type sub_type {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An object relationship
  bookSubType: sub_type
  bookSubTypeMtid: bigint

  # An array relationship
  categories(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): [category_sub_types_allowed!]!

  # An aggregated array relationship
  categories_aggregate(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): category_sub_types_allowed_aggregate!

  # An object relationship
  category: category
  categoryMtid: bigint
  code: Int!
  comment: String
  comment2: String
  completePublication: Boolean!
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp

  # An object relationship
  docType: publication_type
  docTypeMtid: bigint
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean!
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int!
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mayHaveImpactFactor: Boolean!
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint

  # An array relationship
  properties(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): [achievement_property_listing!]!

  # An aggregated array relationship
  properties_aggregate(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): achievement_property_listing_aggregate!
  published: Boolean!
  qualificationInHAS: String
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "sub_type"
type sub_type_aggregate {
  aggregate: sub_type_aggregate_fields
  nodes: [sub_type!]!
}

# aggregate fields of "sub_type"
type sub_type_aggregate_fields {
  avg: sub_type_avg_fields
  count(columns: [sub_type_select_column!], distinct: Boolean): Int
  max: sub_type_max_fields
  min: sub_type_min_fields
  stddev: sub_type_stddev_fields
  stddev_pop: sub_type_stddev_pop_fields
  stddev_samp: sub_type_stddev_samp_fields
  sum: sub_type_sum_fields
  var_pop: sub_type_var_pop_fields
  var_samp: sub_type_var_samp_fields
  variance: sub_type_variance_fields
}

# order by aggregate values of table "sub_type"
input sub_type_aggregate_order_by {
  avg: sub_type_avg_order_by
  count: order_by
  max: sub_type_max_order_by
  min: sub_type_min_order_by
  stddev: sub_type_stddev_order_by
  stddev_pop: sub_type_stddev_pop_order_by
  stddev_samp: sub_type_stddev_samp_order_by
  sum: sub_type_sum_order_by
  var_pop: sub_type_var_pop_order_by
  var_samp: sub_type_var_samp_order_by
  variance: sub_type_variance_order_by
}

# input type for inserting array relation for remote table "sub_type"
input sub_type_arr_rel_insert_input {
  data: [sub_type_insert_input!]!
  on_conflict: sub_type_on_conflict
}

# aggregate avg on columns
type sub_type_avg_fields {
  approverMtid: Float
  bookSubTypeMtid: Float
  categoryMtid: Float
  code: Float
  creator: Float
  docTypeMtid: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "sub_type"
input sub_type_avg_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "sub_type". All fields are combined with a logical 'AND'.
input sub_type_bool_exp {
  _and: [sub_type_bool_exp]
  _not: sub_type_bool_exp
  _or: [sub_type_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  bookSubType: sub_type_bool_exp
  bookSubTypeMtid: bigint_comparison_exp
  categories: category_sub_types_allowed_bool_exp
  category: category_bool_exp
  categoryMtid: bigint_comparison_exp
  code: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  completePublication: Boolean_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  docType: publication_type_bool_exp
  docTypeMtid: bigint_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  error: Int_comparison_exp
  excludeFromOaStats: Boolean_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mayHaveImpactFactor: Boolean_comparison_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  properties: achievement_property_listing_bool_exp
  published: Boolean_comparison_exp
  qualificationInHAS: String_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "sub_type"
enum sub_type_constraint {
  # unique or primary key constraint
  sub_type_pkey
}

# input type for incrementing integer column in table "sub_type"
input sub_type_inc_input {
  approverMtid: bigint
  bookSubTypeMtid: bigint
  categoryMtid: bigint
  code: Int
  creator: bigint
  docTypeMtid: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "sub_type"
input sub_type_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  bookSubType: sub_type_obj_rel_insert_input
  bookSubTypeMtid: bigint
  categories: category_sub_types_allowed_arr_rel_insert_input
  category: category_obj_rel_insert_input
  categoryMtid: bigint
  code: Int
  comment: String
  comment2: String
  completePublication: Boolean
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  docType: publication_type_obj_rel_insert_input
  docTypeMtid: bigint
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mayHaveImpactFactor: Boolean
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  properties: achievement_property_listing_arr_rel_insert_input
  published: Boolean
  qualificationInHAS: String
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type sub_type_max_fields {
  approved: timestamp
  approverMtid: bigint
  bookSubTypeMtid: bigint
  categoryMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  docTypeMtid: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  qualificationInHAS: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "sub_type"
input sub_type_max_order_by {
  approved: order_by
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  qualificationInHAS: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type sub_type_min_fields {
  approved: timestamp
  approverMtid: bigint
  bookSubTypeMtid: bigint
  categoryMtid: bigint
  code: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  docTypeMtid: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  qualificationInHAS: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "sub_type"
input sub_type_min_order_by {
  approved: order_by
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  qualificationInHAS: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "sub_type"
type sub_type_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [sub_type!]!
}

# input type for inserting object relation for remote table "sub_type"
input sub_type_obj_rel_insert_input {
  data: sub_type_insert_input!
  on_conflict: sub_type_on_conflict
}

# on conflict condition type for table "sub_type"
input sub_type_on_conflict {
  constraint: sub_type_constraint!
  update_columns: [sub_type_update_column!]!
  where: sub_type_bool_exp
}

# ordering options when selecting data from "sub_type"
input sub_type_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  bookSubType: sub_type_order_by
  bookSubTypeMtid: order_by
  categories_aggregate: category_sub_types_allowed_aggregate_order_by
  category: category_order_by
  categoryMtid: order_by
  code: order_by
  comment: order_by
  comment2: order_by
  completePublication: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  docType: publication_type_order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  error: order_by
  excludeFromOaStats: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mayHaveImpactFactor: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  properties_aggregate: achievement_property_listing_aggregate_order_by
  published: order_by
  qualificationInHAS: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "sub_type"
input sub_type_pk_columns_input {
  mtid: bigint!
}

# select columns of table "sub_type"
enum sub_type_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  bookSubTypeMtid

  # column name
  categoryMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  completePublication

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  docTypeMtid

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  excludeFromOaStats

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mayHaveImpactFactor

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  qualificationInHAS

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "sub_type"
input sub_type_set_input {
  approved: timestamp
  approverMtid: bigint
  bookSubTypeMtid: bigint
  categoryMtid: bigint
  code: Int
  comment: String
  comment2: String
  completePublication: Boolean
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  docTypeMtid: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  excludeFromOaStats: Boolean
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mayHaveImpactFactor: Boolean
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  qualificationInHAS: String
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type sub_type_stddev_fields {
  approverMtid: Float
  bookSubTypeMtid: Float
  categoryMtid: Float
  code: Float
  creator: Float
  docTypeMtid: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "sub_type"
input sub_type_stddev_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type sub_type_stddev_pop_fields {
  approverMtid: Float
  bookSubTypeMtid: Float
  categoryMtid: Float
  code: Float
  creator: Float
  docTypeMtid: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "sub_type"
input sub_type_stddev_pop_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type sub_type_stddev_samp_fields {
  approverMtid: Float
  bookSubTypeMtid: Float
  categoryMtid: Float
  code: Float
  creator: Float
  docTypeMtid: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "sub_type"
input sub_type_stddev_samp_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type sub_type_sum_fields {
  approverMtid: bigint
  bookSubTypeMtid: bigint
  categoryMtid: bigint
  code: Int
  creator: bigint
  docTypeMtid: bigint
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "sub_type"
input sub_type_sum_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "sub_type"
enum sub_type_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  bookSubTypeMtid

  # column name
  categoryMtid

  # column name
  code

  # column name
  comment

  # column name
  comment2

  # column name
  completePublication

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  docTypeMtid

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  error

  # column name
  excludeFromOaStats

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mayHaveImpactFactor

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  qualificationInHAS

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type sub_type_var_pop_fields {
  approverMtid: Float
  bookSubTypeMtid: Float
  categoryMtid: Float
  code: Float
  creator: Float
  docTypeMtid: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "sub_type"
input sub_type_var_pop_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type sub_type_var_samp_fields {
  approverMtid: Float
  bookSubTypeMtid: Float
  categoryMtid: Float
  code: Float
  creator: Float
  docTypeMtid: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "sub_type"
input sub_type_var_samp_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type sub_type_variance_fields {
  approverMtid: Float
  bookSubTypeMtid: Float
  categoryMtid: Float
  code: Float
  creator: Float
  docTypeMtid: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "sub_type"
input sub_type_variance_order_by {
  approverMtid: order_by
  bookSubTypeMtid: order_by
  categoryMtid: order_by
  code: order_by
  creator: order_by
  docTypeMtid: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# subscription root
type subscription_root {
  # fetch data from the table: "achievement_property"
  achievementProperties(
    # distinct select on columns
    distinct_on: [achievement_property_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_order_by!]

    # filter the rows returned
    where: achievement_property_bool_exp
  ): [achievement_property!]!

  # fetch data from the table: "achievement_property" using primary key columns
  achievementProperty(mtid: bigint!): achievement_property

  # fetch aggregated fields from the table: "achievement_property"
  achievementPropertyAggregate(
    # distinct select on columns
    distinct_on: [achievement_property_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_order_by!]

    # filter the rows returned
    where: achievement_property_bool_exp
  ): achievement_property_aggregate!

  # fetch data from the table: "achievement_property_listing" using primary key columns
  achievementPropertyListing(mtid: bigint!): achievement_property_listing

  # fetch aggregated fields from the table: "achievement_property_listing"
  achievementPropertyListingAggregate(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): achievement_property_listing_aggregate!

  # fetch data from the table: "achievement_property_listing"
  achievementPropertyListings(
    # distinct select on columns
    distinct_on: [achievement_property_listing_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_listing_order_by!]

    # filter the rows returned
    where: achievement_property_listing_bool_exp
  ): [achievement_property_listing!]!

  # fetch data from the table: "achievement_property_value" using primary key columns
  achievementPropertyValue(mtid: bigint!): achievement_property_value

  # fetch aggregated fields from the table: "achievement_property_value"
  achievementPropertyValueAggregate(
    # distinct select on columns
    distinct_on: [achievement_property_value_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_value_order_by!]

    # filter the rows returned
    where: achievement_property_value_bool_exp
  ): achievement_property_value_aggregate!

  # fetch data from the table: "achievement_property_value"
  achievementPropertyValues(
    # distinct select on columns
    distinct_on: [achievement_property_value_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [achievement_property_value_order_by!]

    # filter the rows returned
    where: achievement_property_value_bool_exp
  ): [achievement_property_value!]!

  # fetch data from the table: "activity_log" using primary key columns
  activityLog(id: bigint!): activity_log

  # fetch aggregated fields from the table: "activity_log"
  activityLogAggregate(
    # distinct select on columns
    distinct_on: [activity_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [activity_log_order_by!]

    # filter the rows returned
    where: activity_log_bool_exp
  ): activity_log_aggregate!

  # fetch data from the table: "activity_log"
  activityLogs(
    # distinct select on columns
    distinct_on: [activity_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [activity_log_order_by!]

    # filter the rows returned
    where: activity_log_bool_exp
  ): [activity_log!]!

  # fetch data from the table: "address" using primary key columns
  address(mtid: bigint!): address

  # fetch aggregated fields from the table: "address"
  addressAggregate(
    # distinct select on columns
    distinct_on: [address_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [address_order_by!]

    # filter the rows returned
    where: address_bool_exp
  ): address_aggregate!

  # fetch data from the table: "address"
  addresses(
    # distinct select on columns
    distinct_on: [address_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [address_order_by!]

    # filter the rows returned
    where: address_bool_exp
  ): [address!]!

  # fetch data from the table: "admin_role" using primary key columns
  adminRole(mtid: bigint!): admin_role

  # fetch aggregated fields from the table: "admin_role"
  adminRoleAggregate(
    # distinct select on columns
    distinct_on: [admin_role_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [admin_role_order_by!]

    # filter the rows returned
    where: admin_role_bool_exp
  ): admin_role_aggregate!

  # fetch data from the table: "admin_role"
  adminRoles(
    # distinct select on columns
    distinct_on: [admin_role_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [admin_role_order_by!]

    # filter the rows returned
    where: admin_role_bool_exp
  ): [admin_role!]!

  # fetch data from the table: "affiliation" using primary key columns
  affiliation(mtid: bigint!): affiliation

  # fetch aggregated fields from the table: "affiliation"
  affiliationAggregate(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): affiliation_aggregate!

  # fetch data from the table: "affiliation"
  affiliations(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): [affiliation!]!

  # fetch data from the table: "appearance" using primary key columns
  appearance(mtid: bigint!): appearance

  # fetch aggregated fields from the table: "appearance"
  appearanceAggregate(
    # distinct select on columns
    distinct_on: [appearance_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [appearance_order_by!]

    # filter the rows returned
    where: appearance_bool_exp
  ): appearance_aggregate!

  # fetch data from the table: "appearance"
  appearances(
    # distinct select on columns
    distinct_on: [appearance_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [appearance_order_by!]

    # filter the rows returned
    where: appearance_bool_exp
  ): [appearance!]!

  # fetch data from the table: "authentication_failure" using primary key columns
  authenticationFailure(id: bigint!): authentication_failure

  # fetch aggregated fields from the table: "authentication_failure"
  authenticationFailureAggregate(
    # distinct select on columns
    distinct_on: [authentication_failure_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authentication_failure_order_by!]

    # filter the rows returned
    where: authentication_failure_bool_exp
  ): authentication_failure_aggregate!

  # fetch data from the table: "authentication_failure"
  authenticationFailures(
    # distinct select on columns
    distinct_on: [authentication_failure_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authentication_failure_order_by!]

    # filter the rows returned
    where: authentication_failure_bool_exp
  ): [authentication_failure!]!

  # fetch data from the table: "author_identifier" using primary key columns
  authorIdentifier(mtid: bigint!): author_identifier

  # fetch aggregated fields from the table: "author_identifier"
  authorIdentifierAggregate(
    # distinct select on columns
    distinct_on: [author_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_identifier_order_by!]

    # filter the rows returned
    where: author_identifier_bool_exp
  ): author_identifier_aggregate!

  # fetch data from the table: "author_identifier"
  authorIdentifiers(
    # distinct select on columns
    distinct_on: [author_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_identifier_order_by!]

    # filter the rows returned
    where: author_identifier_bool_exp
  ): [author_identifier!]!

  # fetch data from the table: "author_name" using primary key columns
  authorName(mtid: bigint!): author_name

  # fetch aggregated fields from the table: "author_name"
  authorNameAggregate(
    # distinct select on columns
    distinct_on: [author_name_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_name_order_by!]

    # filter the rows returned
    where: author_name_bool_exp
  ): author_name_aggregate!

  # fetch data from the table: "author_name"
  authorNames(
    # distinct select on columns
    distinct_on: [author_name_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_name_order_by!]

    # filter the rows returned
    where: author_name_bool_exp
  ): [author_name!]!

  # fetch data from the table: "authorship" using primary key columns
  authorship(mtid: bigint!): authorship

  # fetch aggregated fields from the table: "authorship"
  authorshipAggregate(
    # distinct select on columns
    distinct_on: [authorship_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_order_by!]

    # filter the rows returned
    where: authorship_bool_exp
  ): authorship_aggregate!

  # fetch aggregated fields from the table: "authorship_organizations"
  authorshipOrganizationsAggregate(
    # distinct select on columns
    distinct_on: [authorship_organizations_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_organizations_order_by!]

    # filter the rows returned
    where: authorship_organizations_bool_exp
  ): authorship_organizations_aggregate!

  # fetch data from the table: "authorship_organizations"
  authorshipOrganizationses(
    # distinct select on columns
    distinct_on: [authorship_organizations_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_organizations_order_by!]

    # filter the rows returned
    where: authorship_organizations_bool_exp
  ): [authorship_organizations!]!

  # fetch data from the table: "authorship_type" using primary key columns
  authorshipType(mtid: bigint!): authorship_type

  # fetch aggregated fields from the table: "authorship_type"
  authorshipTypeAggregate(
    # distinct select on columns
    distinct_on: [authorship_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_order_by!]

    # filter the rows returned
    where: authorship_type_bool_exp
  ): authorship_type_aggregate!

  # fetch aggregated fields from the table: "authorship_type_sub_types_allowed"
  authorshipTypeSubTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [authorship_type_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_sub_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_sub_types_allowed_bool_exp
  ): authorship_type_sub_types_allowed_aggregate!

  # fetch data from the table: "authorship_type_sub_types_allowed"
  authorshipTypeSubTypesAlloweds(
    # distinct select on columns
    distinct_on: [authorship_type_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_sub_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_sub_types_allowed_bool_exp
  ): [authorship_type_sub_types_allowed!]!

  # fetch aggregated fields from the table: "authorship_type_types_allowed"
  authorshipTypeTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [authorship_type_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_types_allowed_bool_exp
  ): authorship_type_types_allowed_aggregate!

  # fetch data from the table: "authorship_type_types_allowed"
  authorshipTypeTypesAlloweds(
    # distinct select on columns
    distinct_on: [authorship_type_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_types_allowed_order_by!]

    # filter the rows returned
    where: authorship_type_types_allowed_bool_exp
  ): [authorship_type_types_allowed!]!

  # fetch data from the table: "authorship_type"
  authorshipTypes(
    # distinct select on columns
    distinct_on: [authorship_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_type_order_by!]

    # filter the rows returned
    where: authorship_type_bool_exp
  ): [authorship_type!]!

  # fetch data from the table: "authorship"
  authorships(
    # distinct select on columns
    distinct_on: [authorship_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [authorship_order_by!]

    # filter the rows returned
    where: authorship_bool_exp
  ): [authorship!]!

  # fetch data from the table: "binary_content" using primary key columns
  binaryContent(id: bigint!): binary_content

  # fetch aggregated fields from the table: "binary_content"
  binaryContentAggregate(
    # distinct select on columns
    distinct_on: [binary_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [binary_content_order_by!]

    # filter the rows returned
    where: binary_content_bool_exp
  ): binary_content_aggregate!

  # fetch data from the table: "binary_content"
  binaryContents(
    # distinct select on columns
    distinct_on: [binary_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [binary_content_order_by!]

    # filter the rows returned
    where: binary_content_bool_exp
  ): [binary_content!]!

  # fetch data from the table: "bulk_duplum_merge_request" using primary key columns
  bulkDuplumMergeRequest(mtid: bigint!): bulk_duplum_merge_request

  # fetch aggregated fields from the table: "bulk_duplum_merge_request"
  bulkDuplumMergeRequestAggregate(
    # distinct select on columns
    distinct_on: [bulk_duplum_merge_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [bulk_duplum_merge_request_order_by!]

    # filter the rows returned
    where: bulk_duplum_merge_request_bool_exp
  ): bulk_duplum_merge_request_aggregate!

  # fetch data from the table: "bulk_duplum_merge_request"
  bulkDuplumMergeRequests(
    # distinct select on columns
    distinct_on: [bulk_duplum_merge_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [bulk_duplum_merge_request_order_by!]

    # filter the rows returned
    where: bulk_duplum_merge_request_bool_exp
  ): [bulk_duplum_merge_request!]!

  # fetch data from the table: "category"
  categories(
    # distinct select on columns
    distinct_on: [category_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_order_by!]

    # filter the rows returned
    where: category_bool_exp
  ): [category!]!

  # fetch data from the table: "category" using primary key columns
  category(mtid: bigint!): category

  # fetch aggregated fields from the table: "category"
  categoryAggregate(
    # distinct select on columns
    distinct_on: [category_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_order_by!]

    # filter the rows returned
    where: category_bool_exp
  ): category_aggregate!

  # fetch aggregated fields from the table: "category_sub_types_allowed"
  categorySubTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): category_sub_types_allowed_aggregate!

  # fetch data from the table: "category_sub_types_allowed"
  categorySubTypesAlloweds(
    # distinct select on columns
    distinct_on: [category_sub_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_sub_types_allowed_order_by!]

    # filter the rows returned
    where: category_sub_types_allowed_bool_exp
  ): [category_sub_types_allowed!]!

  # fetch aggregated fields from the table: "category_types_allowed"
  categoryTypesAllowedAggregate(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): category_types_allowed_aggregate!

  # fetch data from the table: "category_types_allowed"
  categoryTypesAlloweds(
    # distinct select on columns
    distinct_on: [category_types_allowed_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [category_types_allowed_order_by!]

    # filter the rows returned
    where: category_types_allowed_bool_exp
  ): [category_types_allowed!]!

  # fetch data from the table: "citation" using primary key columns
  citation(mtid: bigint!): citation

  # fetch aggregated fields from the table: "citation"
  citationAggregate(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): citation_aggregate!

  # fetch data from the table: "citation"
  citations(
    # distinct select on columns
    distinct_on: [citation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [citation_order_by!]

    # filter the rows returned
    where: citation_bool_exp
  ): [citation!]!

  # fetch data from the table: "classification" using primary key columns
  classification(mtid: bigint!): classification

  # fetch aggregated fields from the table: "classification"
  classificationAggregate(
    # distinct select on columns
    distinct_on: [classification_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_order_by!]

    # filter the rows returned
    where: classification_bool_exp
  ): classification_aggregate!

  # fetch data from the table: "classification_external" using primary key columns
  classificationExternal(mtid: bigint!): classification_external

  # fetch aggregated fields from the table: "classification_external"
  classificationExternalAggregate(
    # distinct select on columns
    distinct_on: [classification_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_order_by!]

    # filter the rows returned
    where: classification_external_bool_exp
  ): classification_external_aggregate!

  # fetch aggregated fields from the table: "classification_external_mapped_to"
  classificationExternalMappedToAggregate(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): classification_external_mapped_to_aggregate!

  # fetch data from the table: "classification_external_mapped_to"
  classificationExternalMappedToes(
    # distinct select on columns
    distinct_on: [classification_external_mapped_to_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_mapped_to_order_by!]

    # filter the rows returned
    where: classification_external_mapped_to_bool_exp
  ): [classification_external_mapped_to!]!

  # fetch data from the table: "classification_external"
  classificationExternals(
    # distinct select on columns
    distinct_on: [classification_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_external_order_by!]

    # filter the rows returned
    where: classification_external_bool_exp
  ): [classification_external!]!

  # fetch aggregated fields from the table: "classification_parents"
  classificationParentsAggregate(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): classification_parents_aggregate!

  # fetch data from the table: "classification_parents"
  classificationParentses(
    # distinct select on columns
    distinct_on: [classification_parents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_parents_order_by!]

    # filter the rows returned
    where: classification_parents_bool_exp
  ): [classification_parents!]!

  # fetch data from the table: "classification_tree" using primary key columns
  classificationTree(mtid: bigint!): classification_tree

  # fetch aggregated fields from the table: "classification_tree"
  classificationTreeAggregate(
    # distinct select on columns
    distinct_on: [classification_tree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_tree_order_by!]

    # filter the rows returned
    where: classification_tree_bool_exp
  ): classification_tree_aggregate!

  # fetch data from the table: "classification_tree"
  classificationTrees(
    # distinct select on columns
    distinct_on: [classification_tree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_tree_order_by!]

    # filter the rows returned
    where: classification_tree_bool_exp
  ): [classification_tree!]!

  # fetch data from the table: "classification"
  classifications(
    # distinct select on columns
    distinct_on: [classification_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [classification_order_by!]

    # filter the rows returned
    where: classification_bool_exp
  ): [classification!]!

  # fetch data from the table: "conference" using primary key columns
  conference(mtid: bigint!): conference

  # fetch aggregated fields from the table: "conference"
  conferenceAggregate(
    # distinct select on columns
    distinct_on: [conference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_order_by!]

    # filter the rows returned
    where: conference_bool_exp
  ): conference_aggregate!

  # fetch aggregated fields from the table: "conference_location"
  conferenceLocationAggregate(
    # distinct select on columns
    distinct_on: [conference_location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_location_order_by!]

    # filter the rows returned
    where: conference_location_bool_exp
  ): conference_location_aggregate!

  # fetch data from the table: "conference_location"
  conferenceLocations(
    # distinct select on columns
    distinct_on: [conference_location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_location_order_by!]

    # filter the rows returned
    where: conference_location_bool_exp
  ): [conference_location!]!

  # fetch aggregated fields from the table: "conference_organizers"
  conferenceOrganizersAggregate(
    # distinct select on columns
    distinct_on: [conference_organizers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_organizers_order_by!]

    # filter the rows returned
    where: conference_organizers_bool_exp
  ): conference_organizers_aggregate!

  # fetch data from the table: "conference_organizers"
  conferenceOrganizerses(
    # distinct select on columns
    distinct_on: [conference_organizers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_organizers_order_by!]

    # filter the rows returned
    where: conference_organizers_bool_exp
  ): [conference_organizers!]!

  # fetch data from the table: "conference"
  conferences(
    # distinct select on columns
    distinct_on: [conference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [conference_order_by!]

    # filter the rows returned
    where: conference_bool_exp
  ): [conference!]!

  # fetch data from the table: "cron_job" using primary key columns
  cronJob(mtid: bigint!): cron_job

  # fetch aggregated fields from the table: "cron_job"
  cronJobAggregate(
    # distinct select on columns
    distinct_on: [cron_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_order_by!]

    # filter the rows returned
    where: cron_job_bool_exp
  ): cron_job_aggregate!

  # fetch data from the table: "cron_job_run_request" using primary key columns
  cronJobRunRequest(mtid: bigint!): cron_job_run_request

  # fetch aggregated fields from the table: "cron_job_run_request"
  cronJobRunRequestAggregate(
    # distinct select on columns
    distinct_on: [cron_job_run_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_run_request_order_by!]

    # filter the rows returned
    where: cron_job_run_request_bool_exp
  ): cron_job_run_request_aggregate!

  # fetch data from the table: "cron_job_run_request"
  cronJobRunRequests(
    # distinct select on columns
    distinct_on: [cron_job_run_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_run_request_order_by!]

    # filter the rows returned
    where: cron_job_run_request_bool_exp
  ): [cron_job_run_request!]!

  # fetch data from the table: "cron_job"
  cronJobs(
    # distinct select on columns
    distinct_on: [cron_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [cron_job_order_by!]

    # filter the rows returned
    where: cron_job_bool_exp
  ): [cron_job!]!

  # fetch data from the table: "degree" using primary key columns
  degree(mtid: bigint!): degree

  # fetch aggregated fields from the table: "degree"
  degreeAggregate(
    # distinct select on columns
    distinct_on: [degree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_order_by!]

    # filter the rows returned
    where: degree_bool_exp
  ): degree_aggregate!

  # fetch data from the table: "degree_holder" using primary key columns
  degreeHolder(mtid: bigint!): degree_holder

  # fetch aggregated fields from the table: "degree_holder"
  degreeHolderAggregate(
    # distinct select on columns
    distinct_on: [degree_holder_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_holder_order_by!]

    # filter the rows returned
    where: degree_holder_bool_exp
  ): degree_holder_aggregate!

  # fetch data from the table: "degree_holder"
  degreeHolders(
    # distinct select on columns
    distinct_on: [degree_holder_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_holder_order_by!]

    # filter the rows returned
    where: degree_holder_bool_exp
  ): [degree_holder!]!

  # fetch data from the table: "degree"
  degrees(
    # distinct select on columns
    distinct_on: [degree_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_order_by!]

    # filter the rows returned
    where: degree_bool_exp
  ): [degree!]!

  # fetch data from the table: "discipline" using primary key columns
  discipline(mtid: bigint!): discipline

  # fetch aggregated fields from the table: "discipline"
  disciplineAggregate(
    # distinct select on columns
    distinct_on: [discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [discipline_order_by!]

    # filter the rows returned
    where: discipline_bool_exp
  ): discipline_aggregate!

  # fetch data from the table: "discipline"
  disciplines(
    # distinct select on columns
    distinct_on: [discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [discipline_order_by!]

    # filter the rows returned
    where: discipline_bool_exp
  ): [discipline!]!

  # fetch data from the table: "division_containment" using primary key columns
  divisionContainment(mtid: bigint!): division_containment

  # fetch aggregated fields from the table: "division_containment"
  divisionContainmentAggregate(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): division_containment_aggregate!

  # fetch data from the table: "division_containment"
  divisionContainments(
    # distinct select on columns
    distinct_on: [division_containment_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [division_containment_order_by!]

    # filter the rows returned
    where: division_containment_bool_exp
  ): [division_containment!]!

  # fetch data from the table: "duplum_desc" using primary key columns
  duplumDesc(id: bigint!): duplum_desc

  # fetch aggregated fields from the table: "duplum_desc"
  duplumDescAggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_order_by!]

    # filter the rows returned
    where: duplum_desc_bool_exp
  ): duplum_desc_aggregate!

  # fetch aggregated fields from the table: "duplum_desc_book_chapters_merged"
  duplumDescBookChaptersMergedAggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_book_chapters_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_book_chapters_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_book_chapters_merged_bool_exp
  ): duplum_desc_book_chapters_merged_aggregate!

  # fetch data from the table: "duplum_desc_book_chapters_merged"
  duplumDescBookChaptersMergeds(
    # distinct select on columns
    distinct_on: [duplum_desc_book_chapters_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_book_chapters_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_book_chapters_merged_bool_exp
  ): [duplum_desc_book_chapters_merged!]!

  # fetch aggregated fields from the table: "duplum_desc_citations_merged"
  duplumDescCitationsMergedAggregate(
    # distinct select on columns
    distinct_on: [duplum_desc_citations_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_citations_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_citations_merged_bool_exp
  ): duplum_desc_citations_merged_aggregate!

  # fetch data from the table: "duplum_desc_citations_merged"
  duplumDescCitationsMergeds(
    # distinct select on columns
    distinct_on: [duplum_desc_citations_merged_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_citations_merged_order_by!]

    # filter the rows returned
    where: duplum_desc_citations_merged_bool_exp
  ): [duplum_desc_citations_merged!]!

  # fetch data from the table: "duplum_desc"
  duplumDescs(
    # distinct select on columns
    distinct_on: [duplum_desc_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_desc_order_by!]

    # filter the rows returned
    where: duplum_desc_bool_exp
  ): [duplum_desc!]!

  # fetch data from the table: "duplum_search_request" using primary key columns
  duplumSearchRequest(mtid: bigint!): duplum_search_request

  # fetch aggregated fields from the table: "duplum_search_request"
  duplumSearchRequestAggregate(
    # distinct select on columns
    distinct_on: [duplum_search_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_request_order_by!]

    # filter the rows returned
    where: duplum_search_request_bool_exp
  ): duplum_search_request_aggregate!

  # fetch data from the table: "duplum_search_request"
  duplumSearchRequests(
    # distinct select on columns
    distinct_on: [duplum_search_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_request_order_by!]

    # filter the rows returned
    where: duplum_search_request_bool_exp
  ): [duplum_search_request!]!

  # fetch data from the table: "duplum_search_result" using primary key columns
  duplumSearchResult(id: bigint!): duplum_search_result

  # fetch aggregated fields from the table: "duplum_search_result"
  duplumSearchResultAggregate(
    # distinct select on columns
    distinct_on: [duplum_search_result_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_result_order_by!]

    # filter the rows returned
    where: duplum_search_result_bool_exp
  ): duplum_search_result_aggregate!

  # fetch data from the table: "duplum_search_result"
  duplumSearchResults(
    # distinct select on columns
    distinct_on: [duplum_search_result_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [duplum_search_result_order_by!]

    # filter the rows returned
    where: duplum_search_result_bool_exp
  ): [duplum_search_result!]!

  # fetch data from the table: "error_log" using primary key columns
  errorLog(id: bigint!): error_log

  # fetch aggregated fields from the table: "error_log"
  errorLogAggregate(
    # distinct select on columns
    distinct_on: [error_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [error_log_order_by!]

    # filter the rows returned
    where: error_log_bool_exp
  ): error_log_aggregate!

  # fetch data from the table: "error_log"
  errorLogs(
    # distinct select on columns
    distinct_on: [error_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [error_log_order_by!]

    # filter the rows returned
    where: error_log_bool_exp
  ): [error_log!]!

  # fetch data from the table: "export_format" using primary key columns
  exportFormat(mtid: bigint!): export_format

  # fetch aggregated fields from the table: "export_format"
  exportFormatAggregate(
    # distinct select on columns
    distinct_on: [export_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_format_order_by!]

    # filter the rows returned
    where: export_format_bool_exp
  ): export_format_aggregate!

  # fetch data from the table: "export_format"
  exportFormats(
    # distinct select on columns
    distinct_on: [export_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_format_order_by!]

    # filter the rows returned
    where: export_format_bool_exp
  ): [export_format!]!

  # fetch data from the table: "export_request" using primary key columns
  exportRequest(mtid: bigint!): export_request

  # fetch aggregated fields from the table: "export_request"
  exportRequestAggregate(
    # distinct select on columns
    distinct_on: [export_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_request_order_by!]

    # filter the rows returned
    where: export_request_bool_exp
  ): export_request_aggregate!

  # fetch data from the table: "export_request"
  exportRequests(
    # distinct select on columns
    distinct_on: [export_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [export_request_order_by!]

    # filter the rows returned
    where: export_request_bool_exp
  ): [export_request!]!

  # fetch data from the table: "forum" using primary key columns
  forum(mtid: bigint!): forum

  # fetch aggregated fields from the table: "forum"
  forumAggregate(
    # distinct select on columns
    distinct_on: [forum_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [forum_order_by!]

    # filter the rows returned
    where: forum_bool_exp
  ): forum_aggregate!

  # fetch data from the table: "forum"
  forums(
    # distinct select on columns
    distinct_on: [forum_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [forum_order_by!]

    # filter the rows returned
    where: forum_bool_exp
  ): [forum!]!

  # fetch data from the table: "funding" using primary key columns
  funding(mtid: bigint!): funding

  # fetch aggregated fields from the table: "funding"
  fundingAggregate(
    # distinct select on columns
    distinct_on: [funding_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [funding_order_by!]

    # filter the rows returned
    where: funding_bool_exp
  ): funding_aggregate!

  # fetch data from the table: "funding"
  fundings(
    # distinct select on columns
    distinct_on: [funding_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [funding_order_by!]

    # filter the rows returned
    where: funding_bool_exp
  ): [funding!]!

  # fetch data from the table: "import_alias" using primary key columns
  importAlias(mtid: bigint!): import_alias

  # fetch aggregated fields from the table: "import_alias"
  importAliasAggregate(
    # distinct select on columns
    distinct_on: [import_alias_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_alias_order_by!]

    # filter the rows returned
    where: import_alias_bool_exp
  ): import_alias_aggregate!

  # fetch data from the table: "import_alias"
  importAliases(
    # distinct select on columns
    distinct_on: [import_alias_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_alias_order_by!]

    # filter the rows returned
    where: import_alias_bool_exp
  ): [import_alias!]!

  # fetch data from the table: "import_format" using primary key columns
  importFormat(mtid: bigint!): import_format

  # fetch aggregated fields from the table: "import_format"
  importFormatAggregate(
    # distinct select on columns
    distinct_on: [import_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_format_order_by!]

    # filter the rows returned
    where: import_format_bool_exp
  ): import_format_aggregate!

  # fetch data from the table: "import_format"
  importFormats(
    # distinct select on columns
    distinct_on: [import_format_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_format_order_by!]

    # filter the rows returned
    where: import_format_bool_exp
  ): [import_format!]!

  # fetch data from the table: "import_log" using primary key columns
  importLog(id: bigint!): import_log

  # fetch aggregated fields from the table: "import_log"
  importLogAggregate(
    # distinct select on columns
    distinct_on: [import_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_log_order_by!]

    # filter the rows returned
    where: import_log_bool_exp
  ): import_log_aggregate!

  # fetch data from the table: "import_log"
  importLogs(
    # distinct select on columns
    distinct_on: [import_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_log_order_by!]

    # filter the rows returned
    where: import_log_bool_exp
  ): [import_log!]!

  # fetch data from the table: "import_request" using primary key columns
  importRequest(mtid: bigint!): import_request

  # fetch aggregated fields from the table: "import_request"
  importRequestAggregate(
    # distinct select on columns
    distinct_on: [import_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_request_order_by!]

    # filter the rows returned
    where: import_request_bool_exp
  ): import_request_aggregate!

  # fetch data from the table: "import_request"
  importRequests(
    # distinct select on columns
    distinct_on: [import_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_request_order_by!]

    # filter the rows returned
    where: import_request_bool_exp
  ): [import_request!]!

  # fetch data from the table: "import_stat" using primary key columns
  importStat(mtid: bigint!): import_stat

  # fetch aggregated fields from the table: "import_stat"
  importStatAggregate(
    # distinct select on columns
    distinct_on: [import_stat_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_order_by!]

    # filter the rows returned
    where: import_stat_bool_exp
  ): import_stat_aggregate!

  # fetch aggregated fields from the table: "import_stat_import_error_details"
  importStatImportErrorDetailsAggregate(
    # distinct select on columns
    distinct_on: [import_stat_import_error_details_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_import_error_details_order_by!]

    # filter the rows returned
    where: import_stat_import_error_details_bool_exp
  ): import_stat_import_error_details_aggregate!

  # fetch data from the table: "import_stat_import_error_details"
  importStatImportErrorDetailses(
    # distinct select on columns
    distinct_on: [import_stat_import_error_details_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_import_error_details_order_by!]

    # filter the rows returned
    where: import_stat_import_error_details_bool_exp
  ): [import_stat_import_error_details!]!

  # fetch data from the table: "import_stat"
  importStats(
    # distinct select on columns
    distinct_on: [import_stat_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_order_by!]

    # filter the rows returned
    where: import_stat_bool_exp
  ): [import_stat!]!

  # fetch data from the table: "import_stat_wos_ids"
  import_stat_wos_ids(
    # distinct select on columns
    distinct_on: [import_stat_wos_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_wos_ids_order_by!]

    # filter the rows returned
    where: import_stat_wos_ids_bool_exp
  ): [import_stat_wos_ids!]!

  # fetch aggregated fields from the table: "import_stat_wos_ids"
  import_stat_wos_ids_aggregate(
    # distinct select on columns
    distinct_on: [import_stat_wos_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [import_stat_wos_ids_order_by!]

    # filter the rows returned
    where: import_stat_wos_ids_bool_exp
  ): import_stat_wos_ids_aggregate!

  # fetch data from the table: "institute_type" using primary key columns
  instituteType(mtid: bigint!): institute_type

  # fetch aggregated fields from the table: "institute_type"
  instituteTypeAggregate(
    # distinct select on columns
    distinct_on: [institute_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [institute_type_order_by!]

    # filter the rows returned
    where: institute_type_bool_exp
  ): institute_type_aggregate!

  # fetch data from the table: "institute_type"
  instituteTypes(
    # distinct select on columns
    distinct_on: [institute_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [institute_type_order_by!]

    # filter the rows returned
    where: institute_type_bool_exp
  ): [institute_type!]!

  # fetch aggregated fields from the table: "journal_successors"
  journalSuccessorsAggregate(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): journal_successors_aggregate!

  # fetch data from the table: "journal_successors"
  journalSuccessorses(
    # distinct select on columns
    distinct_on: [journal_successors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [journal_successors_order_by!]

    # filter the rows returned
    where: journal_successors_bool_exp
  ): [journal_successors!]!

  # fetch data from the table: "keyword" using primary key columns
  keyword(mtid: bigint!): keyword

  # fetch aggregated fields from the table: "keyword"
  keywordAggregate(
    # distinct select on columns
    distinct_on: [keyword_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [keyword_order_by!]

    # filter the rows returned
    where: keyword_bool_exp
  ): keyword_aggregate!

  # fetch data from the table: "keyword"
  keywords(
    # distinct select on columns
    distinct_on: [keyword_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [keyword_order_by!]

    # filter the rows returned
    where: keyword_bool_exp
  ): [keyword!]!

  # fetch data from the table: "language" using primary key columns
  language(mtid: bigint!): language

  # fetch aggregated fields from the table: "language"
  languageAggregate(
    # distinct select on columns
    distinct_on: [language_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [language_order_by!]

    # filter the rows returned
    where: language_bool_exp
  ): language_aggregate!

  # fetch data from the table: "language"
  languages(
    # distinct select on columns
    distinct_on: [language_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [language_order_by!]

    # filter the rows returned
    where: language_bool_exp
  ): [language!]!

  # fetch data from the table: "localized_message" using primary key columns
  localizedMessage(mtid: bigint!): localized_message

  # fetch aggregated fields from the table: "localized_message"
  localizedMessageAggregate(
    # distinct select on columns
    distinct_on: [localized_message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [localized_message_order_by!]

    # filter the rows returned
    where: localized_message_bool_exp
  ): localized_message_aggregate!

  # fetch data from the table: "localized_message"
  localizedMessages(
    # distinct select on columns
    distinct_on: [localized_message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [localized_message_order_by!]

    # filter the rows returned
    where: localized_message_bool_exp
  ): [localized_message!]!

  # fetch data from the table: "location" using primary key columns
  location(mtid: bigint!): location

  # fetch aggregated fields from the table: "location"
  locationAggregate(
    # distinct select on columns
    distinct_on: [location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [location_order_by!]

    # filter the rows returned
    where: location_bool_exp
  ): location_aggregate!

  # fetch data from the table: "location"
  locations(
    # distinct select on columns
    distinct_on: [location_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [location_order_by!]

    # filter the rows returned
    where: location_bool_exp
  ): [location!]!

  # fetch data from the table: "lock_list" using primary key columns
  lockList(mtid: bigint!): lock_list

  # fetch aggregated fields from the table: "lock_list"
  lockListAggregate(
    # distinct select on columns
    distinct_on: [lock_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_order_by!]

    # filter the rows returned
    where: lock_list_bool_exp
  ): lock_list_aggregate!

  # fetch aggregated fields from the table: "lock_list_delegated_admins"
  lockListDelegatedAdminsAggregate(
    # distinct select on columns
    distinct_on: [lock_list_delegated_admins_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_delegated_admins_order_by!]

    # filter the rows returned
    where: lock_list_delegated_admins_bool_exp
  ): lock_list_delegated_admins_aggregate!

  # fetch data from the table: "lock_list_delegated_admins"
  lockListDelegatedAdminses(
    # distinct select on columns
    distinct_on: [lock_list_delegated_admins_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_delegated_admins_order_by!]

    # filter the rows returned
    where: lock_list_delegated_admins_bool_exp
  ): [lock_list_delegated_admins!]!

  # fetch data from the table: "lock_list"
  lockLists(
    # distinct select on columns
    distinct_on: [lock_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [lock_list_order_by!]

    # filter the rows returned
    where: lock_list_bool_exp
  ): [lock_list!]!

  # fetch data from the table: "mab_discipline" using primary key columns
  mabDiscipline(mtid: bigint!): mab_discipline

  # fetch aggregated fields from the table: "mab_discipline"
  mabDisciplineAggregate(
    # distinct select on columns
    distinct_on: [mab_discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mab_discipline_order_by!]

    # filter the rows returned
    where: mab_discipline_bool_exp
  ): mab_discipline_aggregate!

  # fetch data from the table: "mab_discipline"
  mabDisciplines(
    # distinct select on columns
    distinct_on: [mab_discipline_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mab_discipline_order_by!]

    # filter the rows returned
    where: mab_discipline_bool_exp
  ): [mab_discipline!]!

  # fetch data from the table: "mention" using primary key columns
  mention(mtid: bigint!): mention

  # fetch aggregated fields from the table: "mention"
  mentionAggregate(
    # distinct select on columns
    distinct_on: [mention_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mention_order_by!]

    # filter the rows returned
    where: mention_bool_exp
  ): mention_aggregate!

  # fetch data from the table: "mention"
  mentions(
    # distinct select on columns
    distinct_on: [mention_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mention_order_by!]

    # filter the rows returned
    where: mention_bool_exp
  ): [mention!]!

  # fetch data from the table: "message" using primary key columns
  message(mtid: bigint!): message

  # fetch aggregated fields from the table: "message"
  messageAggregate(
    # distinct select on columns
    distinct_on: [message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_order_by!]

    # filter the rows returned
    where: message_bool_exp
  ): message_aggregate!

  # fetch aggregated fields from the table: "message_files"
  messageFilesAggregate(
    # distinct select on columns
    distinct_on: [message_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_files_order_by!]

    # filter the rows returned
    where: message_files_bool_exp
  ): message_files_aggregate!

  # fetch data from the table: "message_files"
  messageFileses(
    # distinct select on columns
    distinct_on: [message_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_files_order_by!]

    # filter the rows returned
    where: message_files_bool_exp
  ): [message_files!]!

  # fetch data from the table: "message_institutes" using primary key columns
  messageInstitutes(forumMessageMtid: bigint!, institutesMtid: bigint!): message_institutes

  # fetch aggregated fields from the table: "message_institutes"
  messageInstitutesAggregate(
    # distinct select on columns
    distinct_on: [message_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_institutes_order_by!]

    # filter the rows returned
    where: message_institutes_bool_exp
  ): message_institutes_aggregate!

  # fetch data from the table: "message_institutes"
  messageInstituteses(
    # distinct select on columns
    distinct_on: [message_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_institutes_order_by!]

    # filter the rows returned
    where: message_institutes_bool_exp
  ): [message_institutes!]!

  # fetch aggregated fields from the table: "message_mailboxes"
  messageMailboxesAggregate(
    # distinct select on columns
    distinct_on: [message_mailboxes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_mailboxes_order_by!]

    # filter the rows returned
    where: message_mailboxes_bool_exp
  ): message_mailboxes_aggregate!

  # fetch data from the table: "message_mailboxes"
  messageMailboxeses(
    # distinct select on columns
    distinct_on: [message_mailboxes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_mailboxes_order_by!]

    # filter the rows returned
    where: message_mailboxes_bool_exp
  ): [message_mailboxes!]!

  # fetch data from the table: "message_parameter" using primary key columns
  messageParameter(mtid: bigint!): message_parameter

  # fetch aggregated fields from the table: "message_parameter"
  messageParameterAggregate(
    # distinct select on columns
    distinct_on: [message_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_parameter_order_by!]

    # filter the rows returned
    where: message_parameter_bool_exp
  ): message_parameter_aggregate!

  # fetch data from the table: "message_parameter"
  messageParameters(
    # distinct select on columns
    distinct_on: [message_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_parameter_order_by!]

    # filter the rows returned
    where: message_parameter_bool_exp
  ): [message_parameter!]!

  # fetch aggregated fields from the table: "message_recipients"
  messageRecipientsAggregate(
    # distinct select on columns
    distinct_on: [message_recipients_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_recipients_order_by!]

    # filter the rows returned
    where: message_recipients_bool_exp
  ): message_recipients_aggregate!

  # fetch data from the table: "message_recipients"
  messageRecipientses(
    # distinct select on columns
    distinct_on: [message_recipients_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_recipients_order_by!]

    # filter the rows returned
    where: message_recipients_bool_exp
  ): [message_recipients!]!

  # fetch data from the table: "message_sent" using primary key columns
  messageSent(id: bigint!): message_sent

  # fetch aggregated fields from the table: "message_sent"
  messageSentAggregate(
    # distinct select on columns
    distinct_on: [message_sent_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_sent_order_by!]

    # filter the rows returned
    where: message_sent_bool_exp
  ): message_sent_aggregate!

  # fetch data from the table: "message_sent"
  messageSents(
    # distinct select on columns
    distinct_on: [message_sent_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_sent_order_by!]

    # filter the rows returned
    where: message_sent_bool_exp
  ): [message_sent!]!

  # fetch data from the table: "message_template" using primary key columns
  messageTemplate(mtid: bigint!): message_template

  # fetch aggregated fields from the table: "message_template"
  messageTemplateAggregate(
    # distinct select on columns
    distinct_on: [message_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_order_by!]

    # filter the rows returned
    where: message_template_bool_exp
  ): message_template_aggregate!

  # fetch aggregated fields from the table: "message_template_parameters"
  messageTemplateParametersAggregate(
    # distinct select on columns
    distinct_on: [message_template_parameters_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_parameters_order_by!]

    # filter the rows returned
    where: message_template_parameters_bool_exp
  ): message_template_parameters_aggregate!

  # fetch data from the table: "message_template_parameters"
  messageTemplateParameterses(
    # distinct select on columns
    distinct_on: [message_template_parameters_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_parameters_order_by!]

    # filter the rows returned
    where: message_template_parameters_bool_exp
  ): [message_template_parameters!]!

  # fetch data from the table: "message_template"
  messageTemplates(
    # distinct select on columns
    distinct_on: [message_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_template_order_by!]

    # filter the rows returned
    where: message_template_bool_exp
  ): [message_template!]!

  # fetch data from the table: "message"
  messages(
    # distinct select on columns
    distinct_on: [message_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [message_order_by!]

    # filter the rows returned
    where: message_bool_exp
  ): [message!]!

  # fetch data from the table: "mycite_revision_entity"
  myciteRevisionEntities(
    # distinct select on columns
    distinct_on: [mycite_revision_entity_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mycite_revision_entity_order_by!]

    # filter the rows returned
    where: mycite_revision_entity_bool_exp
  ): [mycite_revision_entity!]!

  # fetch data from the table: "mycite_revision_entity" using primary key columns
  myciteRevisionEntity(id: Int!): mycite_revision_entity

  # fetch aggregated fields from the table: "mycite_revision_entity"
  myciteRevisionEntityAggregate(
    # distinct select on columns
    distinct_on: [mycite_revision_entity_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [mycite_revision_entity_order_by!]

    # filter the rows returned
    where: mycite_revision_entity_bool_exp
  ): mycite_revision_entity_aggregate!

  # fetch data from the table: "named_list" using primary key columns
  namedList(mtid: bigint!): named_list

  # fetch aggregated fields from the table: "named_list"
  namedListAggregate(
    # distinct select on columns
    distinct_on: [named_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [named_list_order_by!]

    # filter the rows returned
    where: named_list_bool_exp
  ): named_list_aggregate!

  # fetch data from the table: "named_list"
  namedLists(
    # distinct select on columns
    distinct_on: [named_list_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [named_list_order_by!]

    # filter the rows returned
    where: named_list_bool_exp
  ): [named_list!]!

  # fetch data from the table: "not_duplums" using primary key columns
  notDuplums(id: bigint!): not_duplums

  # fetch aggregated fields from the table: "not_duplums"
  notDuplumsAggregate(
    # distinct select on columns
    distinct_on: [not_duplums_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_order_by!]

    # filter the rows returned
    where: not_duplums_bool_exp
  ): not_duplums_aggregate!

  # fetch data from the table: "not_duplums"
  notDuplumses(
    # distinct select on columns
    distinct_on: [not_duplums_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_order_by!]

    # filter the rows returned
    where: not_duplums_bool_exp
  ): [not_duplums!]!

  # fetch data from the table: "not_duplums_not_duplum_ids"
  not_duplums_not_duplum_ids(
    # distinct select on columns
    distinct_on: [not_duplums_not_duplum_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_not_duplum_ids_order_by!]

    # filter the rows returned
    where: not_duplums_not_duplum_ids_bool_exp
  ): [not_duplums_not_duplum_ids!]!

  # fetch aggregated fields from the table: "not_duplums_not_duplum_ids"
  not_duplums_not_duplum_ids_aggregate(
    # distinct select on columns
    distinct_on: [not_duplums_not_duplum_ids_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [not_duplums_not_duplum_ids_order_by!]

    # filter the rows returned
    where: not_duplums_not_duplum_ids_bool_exp
  ): not_duplums_not_duplum_ids_aggregate!

  # fetch data from the table: "organization" using primary key columns
  organization(mtid: bigint!): organization

  # fetch aggregated fields from the table: "organization"
  organizationAggregate(
    # distinct select on columns
    distinct_on: [organization_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_order_by!]

    # filter the rows returned
    where: organization_bool_exp
  ): organization_aggregate!

  # fetch data from the table: "organization_identifier" using primary key columns
  organizationIdentifier(mtid: bigint!): organization_identifier

  # fetch aggregated fields from the table: "organization_identifier"
  organizationIdentifierAggregate(
    # distinct select on columns
    distinct_on: [organization_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_identifier_order_by!]

    # filter the rows returned
    where: organization_identifier_bool_exp
  ): organization_identifier_aggregate!

  # fetch data from the table: "organization_identifier"
  organizationIdentifiers(
    # distinct select on columns
    distinct_on: [organization_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_identifier_order_by!]

    # filter the rows returned
    where: organization_identifier_bool_exp
  ): [organization_identifier!]!

  # fetch aggregated fields from the table: "organization_mab_disciplines"
  organizationMabDisciplinesAggregate(
    # distinct select on columns
    distinct_on: [organization_mab_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_mab_disciplines_order_by!]

    # filter the rows returned
    where: organization_mab_disciplines_bool_exp
  ): organization_mab_disciplines_aggregate!

  # fetch data from the table: "organization_mab_disciplines"
  organizationMabDisciplineses(
    # distinct select on columns
    distinct_on: [organization_mab_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_mab_disciplines_order_by!]

    # filter the rows returned
    where: organization_mab_disciplines_bool_exp
  ): [organization_mab_disciplines!]!

  # fetch data from the table: "organization"
  organizations(
    # distinct select on columns
    distinct_on: [organization_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [organization_order_by!]

    # filter the rows returned
    where: organization_bool_exp
  ): [organization!]!

  # fetch data from the table: "periodical" using primary key columns
  periodical(mtid: bigint!): periodical

  # fetch aggregated fields from the table: "periodical"
  periodicalAggregate(
    # distinct select on columns
    distinct_on: [periodical_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_order_by!]

    # filter the rows returned
    where: periodical_bool_exp
  ): periodical_aggregate!

  # fetch data from the table: "periodical_issn" using primary key columns
  periodicalIssn(mtid: bigint!): periodical_issn

  # fetch aggregated fields from the table: "periodical_issn"
  periodicalIssnAggregate(
    # distinct select on columns
    distinct_on: [periodical_issn_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_issn_order_by!]

    # filter the rows returned
    where: periodical_issn_bool_exp
  ): periodical_issn_aggregate!

  # fetch data from the table: "periodical_issn"
  periodicalIssns(
    # distinct select on columns
    distinct_on: [periodical_issn_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_issn_order_by!]

    # filter the rows returned
    where: periodical_issn_bool_exp
  ): [periodical_issn!]!

  # fetch aggregated fields from the table: "periodical_publishers"
  periodicalPublishersAggregate(
    # distinct select on columns
    distinct_on: [periodical_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_publishers_order_by!]

    # filter the rows returned
    where: periodical_publishers_bool_exp
  ): periodical_publishers_aggregate!

  # fetch data from the table: "periodical_publishers"
  periodicalPublisherses(
    # distinct select on columns
    distinct_on: [periodical_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_publishers_order_by!]

    # filter the rows returned
    where: periodical_publishers_bool_exp
  ): [periodical_publishers!]!

  # fetch aggregated fields from the table: "periodical_subjects_external"
  periodicalSubjectsExternalAggregate(
    # distinct select on columns
    distinct_on: [periodical_subjects_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_subjects_external_order_by!]

    # filter the rows returned
    where: periodical_subjects_external_bool_exp
  ): periodical_subjects_external_aggregate!

  # fetch data from the table: "periodical_subjects_external"
  periodicalSubjectsExternals(
    # distinct select on columns
    distinct_on: [periodical_subjects_external_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_subjects_external_order_by!]

    # filter the rows returned
    where: periodical_subjects_external_bool_exp
  ): [periodical_subjects_external!]!

  # fetch data from the table: "periodical"
  periodicals(
    # distinct select on columns
    distinct_on: [periodical_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [periodical_order_by!]

    # filter the rows returned
    where: periodical_bool_exp
  ): [periodical!]!

  # fetch data from the table: "project" using primary key columns
  project(mtid: bigint!): project

  # fetch aggregated fields from the table: "project"
  projectAggregate(
    # distinct select on columns
    distinct_on: [project_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [project_order_by!]

    # filter the rows returned
    where: project_bool_exp
  ): project_aggregate!

  # fetch data from the table: "project"
  projects(
    # distinct select on columns
    distinct_on: [project_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [project_order_by!]

    # filter the rows returned
    where: project_bool_exp
  ): [project!]!

  # fetch data from the table: "pub_fixer_log" using primary key columns
  pubFixerLog(id: bigint!): pub_fixer_log

  # fetch aggregated fields from the table: "pub_fixer_log"
  pubFixerLogAggregate(
    # distinct select on columns
    distinct_on: [pub_fixer_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [pub_fixer_log_order_by!]

    # filter the rows returned
    where: pub_fixer_log_bool_exp
  ): pub_fixer_log_aggregate!

  # fetch data from the table: "pub_fixer_log"
  pubFixerLogs(
    # distinct select on columns
    distinct_on: [pub_fixer_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [pub_fixer_log_order_by!]

    # filter the rows returned
    where: pub_fixer_log_bool_exp
  ): [pub_fixer_log!]!

  # fetch data from the table: "publication" using primary key columns
  publication(mtid: bigint!): publication

  # fetch aggregated fields from the table: "publication"
  publicationAggregate(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): publication_aggregate!

  # fetch data from the table: "publication_authors" using primary key columns
  publicationAuthors(authorsMtid: bigint!, publicationMtid: bigint!): publication_authors

  # fetch aggregated fields from the table: "publication_authors"
  publicationAuthorsAggregate(
    # distinct select on columns
    distinct_on: [publication_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_authors_order_by!]

    # filter the rows returned
    where: publication_authors_bool_exp
  ): publication_authors_aggregate!

  # fetch data from the table: "publication_authors"
  publicationAuthorses(
    # distinct select on columns
    distinct_on: [publication_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_authors_order_by!]

    # filter the rows returned
    where: publication_authors_bool_exp
  ): [publication_authors!]!

  # fetch data from the table: "publication_direct_institutes" using primary key columns
  publicationDirectInstitutes(directInstitutesMtid: bigint!, publicationMtid: bigint!): publication_direct_institutes

  # fetch aggregated fields from the table: "publication_direct_institutes"
  publicationDirectInstitutesAggregate(
    # distinct select on columns
    distinct_on: [publication_direct_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_direct_institutes_order_by!]

    # filter the rows returned
    where: publication_direct_institutes_bool_exp
  ): publication_direct_institutes_aggregate!

  # fetch data from the table: "publication_direct_institutes"
  publicationDirectInstituteses(
    # distinct select on columns
    distinct_on: [publication_direct_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_direct_institutes_order_by!]

    # filter the rows returned
    where: publication_direct_institutes_bool_exp
  ): [publication_direct_institutes!]!

  # fetch aggregated fields from the table: "publication_files"
  publicationFilesAggregate(
    # distinct select on columns
    distinct_on: [publication_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_files_order_by!]

    # filter the rows returned
    where: publication_files_bool_exp
  ): publication_files_aggregate!

  # fetch data from the table: "publication_files"
  publicationFileses(
    # distinct select on columns
    distinct_on: [publication_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_files_order_by!]

    # filter the rows returned
    where: publication_files_bool_exp
  ): [publication_files!]!

  # fetch data from the table: "publication_identifier" using primary key columns
  publicationIdentifier(mtid: bigint!): publication_identifier

  # fetch aggregated fields from the table: "publication_identifier"
  publicationIdentifierAggregate(
    # distinct select on columns
    distinct_on: [publication_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_identifier_order_by!]

    # filter the rows returned
    where: publication_identifier_bool_exp
  ): publication_identifier_aggregate!

  # fetch data from the table: "publication_identifier"
  publicationIdentifiers(
    # distinct select on columns
    distinct_on: [publication_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_identifier_order_by!]

    # filter the rows returned
    where: publication_identifier_bool_exp
  ): [publication_identifier!]!

  # fetch data from the table: "publication_institutes" using primary key columns
  publicationInstitutes(institutesMtid: bigint!, publicationMtid: bigint!): publication_institutes

  # fetch aggregated fields from the table: "publication_institutes"
  publicationInstitutesAggregate(
    # distinct select on columns
    distinct_on: [publication_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_institutes_order_by!]

    # filter the rows returned
    where: publication_institutes_bool_exp
  ): publication_institutes_aggregate!

  # fetch data from the table: "publication_institutes"
  publicationInstituteses(
    # distinct select on columns
    distinct_on: [publication_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_institutes_order_by!]

    # filter the rows returned
    where: publication_institutes_bool_exp
  ): [publication_institutes!]!

  # fetch aggregated fields from the table: "publication_keywords"
  publicationKeywordsAggregate(
    # distinct select on columns
    distinct_on: [publication_keywords_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_keywords_order_by!]

    # filter the rows returned
    where: publication_keywords_bool_exp
  ): publication_keywords_aggregate!

  # fetch data from the table: "publication_keywords"
  publicationKeywordses(
    # distinct select on columns
    distinct_on: [publication_keywords_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_keywords_order_by!]

    # filter the rows returned
    where: publication_keywords_bool_exp
  ): [publication_keywords!]!

  # fetch aggregated fields from the table: "publication_languages"
  publicationLanguagesAggregate(
    # distinct select on columns
    distinct_on: [publication_languages_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_languages_order_by!]

    # filter the rows returned
    where: publication_languages_bool_exp
  ): publication_languages_aggregate!

  # fetch data from the table: "publication_languages"
  publicationLanguageses(
    # distinct select on columns
    distinct_on: [publication_languages_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_languages_order_by!]

    # filter the rows returned
    where: publication_languages_bool_exp
  ): [publication_languages!]!

  # fetch aggregated fields from the table: "publication_old_org_authors"
  publicationOldOrgAuthorsAggregate(
    # distinct select on columns
    distinct_on: [publication_old_org_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_old_org_authors_order_by!]

    # filter the rows returned
    where: publication_old_org_authors_bool_exp
  ): publication_old_org_authors_aggregate!

  # fetch data from the table: "publication_old_org_authors"
  publicationOldOrgAuthorses(
    # distinct select on columns
    distinct_on: [publication_old_org_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_old_org_authors_order_by!]

    # filter the rows returned
    where: publication_old_org_authors_bool_exp
  ): [publication_old_org_authors!]!

  # fetch data from the table: "publication_owner_authors" using primary key columns
  publicationOwnerAuthors(ownerAuthorsMtid: bigint!, publicationMtid: bigint!): publication_owner_authors

  # fetch aggregated fields from the table: "publication_owner_authors"
  publicationOwnerAuthorsAggregate(
    # distinct select on columns
    distinct_on: [publication_owner_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_authors_order_by!]

    # filter the rows returned
    where: publication_owner_authors_bool_exp
  ): publication_owner_authors_aggregate!

  # fetch data from the table: "publication_owner_authors"
  publicationOwnerAuthorses(
    # distinct select on columns
    distinct_on: [publication_owner_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_authors_order_by!]

    # filter the rows returned
    where: publication_owner_authors_bool_exp
  ): [publication_owner_authors!]!

  # fetch data from the table: "publication_owner_institutes" using primary key columns
  publicationOwnerInstitutes(ownerInstitutesMtid: bigint!, publicationMtid: bigint!): publication_owner_institutes

  # fetch aggregated fields from the table: "publication_owner_institutes"
  publicationOwnerInstitutesAggregate(
    # distinct select on columns
    distinct_on: [publication_owner_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_institutes_order_by!]

    # filter the rows returned
    where: publication_owner_institutes_bool_exp
  ): publication_owner_institutes_aggregate!

  # fetch data from the table: "publication_owner_institutes"
  publicationOwnerInstituteses(
    # distinct select on columns
    distinct_on: [publication_owner_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owner_institutes_order_by!]

    # filter the rows returned
    where: publication_owner_institutes_bool_exp
  ): [publication_owner_institutes!]!

  # fetch aggregated fields from the table: "publication_published_at"
  publicationPublishedAtAggregate(
    # distinct select on columns
    distinct_on: [publication_published_at_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_published_at_order_by!]

    # filter the rows returned
    where: publication_published_at_bool_exp
  ): publication_published_at_aggregate!

  # fetch data from the table: "publication_published_at"
  publicationPublishedAts(
    # distinct select on columns
    distinct_on: [publication_published_at_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_published_at_order_by!]

    # filter the rows returned
    where: publication_published_at_bool_exp
  ): [publication_published_at!]!

  # fetch aggregated fields from the table: "publication_publishers"
  publicationPublishersAggregate(
    # distinct select on columns
    distinct_on: [publication_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_publishers_order_by!]

    # filter the rows returned
    where: publication_publishers_bool_exp
  ): publication_publishers_aggregate!

  # fetch data from the table: "publication_publishers"
  publicationPublisherses(
    # distinct select on columns
    distinct_on: [publication_publishers_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_publishers_order_by!]

    # filter the rows returned
    where: publication_publishers_bool_exp
  ): [publication_publishers!]!

  # fetch aggregated fields from the table: "publication_ratings"
  publicationRatingsAggregate(
    # distinct select on columns
    distinct_on: [publication_ratings_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_ratings_order_by!]

    # filter the rows returned
    where: publication_ratings_bool_exp
  ): publication_ratings_aggregate!

  # fetch data from the table: "publication_ratings"
  publicationRatingses(
    # distinct select on columns
    distinct_on: [publication_ratings_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_ratings_order_by!]

    # filter the rows returned
    where: publication_ratings_bool_exp
  ): [publication_ratings!]!

  # fetch data from the table: "publication_source_type" using primary key columns
  publicationSourceType(mtid: bigint!): publication_source_type

  # fetch aggregated fields from the table: "publication_source_type"
  publicationSourceTypeAggregate(
    # distinct select on columns
    distinct_on: [publication_source_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_source_type_order_by!]

    # filter the rows returned
    where: publication_source_type_bool_exp
  ): publication_source_type_aggregate!

  # fetch data from the table: "publication_source_type"
  publicationSourceTypes(
    # distinct select on columns
    distinct_on: [publication_source_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_source_type_order_by!]

    # filter the rows returned
    where: publication_source_type_bool_exp
  ): [publication_source_type!]!

  # fetch aggregated fields from the table: "publication_subjects"
  publicationSubjectsAggregate(
    # distinct select on columns
    distinct_on: [publication_subjects_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_subjects_order_by!]

    # filter the rows returned
    where: publication_subjects_bool_exp
  ): publication_subjects_aggregate!

  # fetch data from the table: "publication_subjects"
  publicationSubjectses(
    # distinct select on columns
    distinct_on: [publication_subjects_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_subjects_order_by!]

    # filter the rows returned
    where: publication_subjects_bool_exp
  ): [publication_subjects!]!

  # fetch data from the table: "publication_type" using primary key columns
  publicationType(mtid: bigint!): publication_type

  # fetch aggregated fields from the table: "publication_type"
  publicationTypeAggregate(
    # distinct select on columns
    distinct_on: [publication_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_type_order_by!]

    # filter the rows returned
    where: publication_type_bool_exp
  ): publication_type_aggregate!

  # fetch data from the table: "publication_type"
  publicationTypes(
    # distinct select on columns
    distinct_on: [publication_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_type_order_by!]

    # filter the rows returned
    where: publication_type_bool_exp
  ): [publication_type!]!

  # fetch data from the table: "publication_owners"
  publication_owners(
    # distinct select on columns
    distinct_on: [publication_owners_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owners_order_by!]

    # filter the rows returned
    where: publication_owners_bool_exp
  ): [publication_owners!]!

  # fetch aggregated fields from the table: "publication_owners"
  publication_owners_aggregate(
    # distinct select on columns
    distinct_on: [publication_owners_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_owners_order_by!]

    # filter the rows returned
    where: publication_owners_bool_exp
  ): publication_owners_aggregate!

  # fetch data from the table: "publication"
  publications(
    # distinct select on columns
    distinct_on: [publication_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publication_order_by!]

    # filter the rows returned
    where: publication_bool_exp
  ): [publication!]!

  # fetch data from the table: "publisher" using primary key columns
  publisher(mtid: bigint!): publisher

  # fetch aggregated fields from the table: "publisher"
  publisherAggregate(
    # distinct select on columns
    distinct_on: [publisher_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_order_by!]

    # filter the rows returned
    where: publisher_bool_exp
  ): publisher_aggregate!

  # fetch aggregated fields from the table: "publisher_cities"
  publisherCitiesAggregate(
    # distinct select on columns
    distinct_on: [publisher_cities_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_cities_order_by!]

    # filter the rows returned
    where: publisher_cities_bool_exp
  ): publisher_cities_aggregate!

  # fetch data from the table: "publisher_cities"
  publisherCitieses(
    # distinct select on columns
    distinct_on: [publisher_cities_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_cities_order_by!]

    # filter the rows returned
    where: publisher_cities_bool_exp
  ): [publisher_cities!]!

  # fetch data from the table: "publisher"
  publishers(
    # distinct select on columns
    distinct_on: [publisher_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [publisher_order_by!]

    # filter the rows returned
    where: publisher_bool_exp
  ): [publisher!]!

  # fetch data from the table: "query_info" using primary key columns
  queryInfo(mtid: bigint!): query_info

  # fetch aggregated fields from the table: "query_info"
  queryInfoAggregate(
    # distinct select on columns
    distinct_on: [query_info_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [query_info_order_by!]

    # filter the rows returned
    where: query_info_bool_exp
  ): query_info_aggregate!

  # fetch data from the table: "query_info"
  queryInfoes(
    # distinct select on columns
    distinct_on: [query_info_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [query_info_order_by!]

    # filter the rows returned
    where: query_info_bool_exp
  ): [query_info!]!

  # fetch data from the table: "queued_background_job" using primary key columns
  queuedBackgroundJob(id: bigint!): queued_background_job

  # fetch aggregated fields from the table: "queued_background_job"
  queuedBackgroundJobAggregate(
    # distinct select on columns
    distinct_on: [queued_background_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [queued_background_job_order_by!]

    # filter the rows returned
    where: queued_background_job_bool_exp
  ): queued_background_job_aggregate!

  # fetch data from the table: "queued_background_job"
  queuedBackgroundJobs(
    # distinct select on columns
    distinct_on: [queued_background_job_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [queued_background_job_order_by!]

    # filter the rows returned
    where: queued_background_job_bool_exp
  ): [queued_background_job!]!

  # fetch data from the table: "rating" using primary key columns
  rating(mtid: bigint!): rating

  # fetch aggregated fields from the table: "rating"
  ratingAggregate(
    # distinct select on columns
    distinct_on: [rating_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_order_by!]

    # filter the rows returned
    where: rating_bool_exp
  ): rating_aggregate!

  # fetch data from the table: "rating_type" using primary key columns
  ratingType(mtid: bigint!): rating_type

  # fetch aggregated fields from the table: "rating_type"
  ratingTypeAggregate(
    # distinct select on columns
    distinct_on: [rating_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_type_order_by!]

    # filter the rows returned
    where: rating_type_bool_exp
  ): rating_type_aggregate!

  # fetch data from the table: "rating_type"
  ratingTypes(
    # distinct select on columns
    distinct_on: [rating_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_type_order_by!]

    # filter the rows returned
    where: rating_type_bool_exp
  ): [rating_type!]!

  # fetch data from the table: "rating"
  ratings(
    # distinct select on columns
    distinct_on: [rating_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [rating_order_by!]

    # filter the rows returned
    where: rating_bool_exp
  ): [rating!]!

  # fetch data from the table: "recalculate_institute_ownerships_request" using primary key columns
  recalculateInstituteOwnershipsRequest(mtid: bigint!): recalculate_institute_ownerships_request

  # fetch data from the table: "recalculate_institute_ownerships_request_affected_institutes" using primary key columns
  recalculateInstituteOwnershipsRequestAffectedInstitutes(affectedInstitutesMtid: bigint!, recalculateInstituteOwnershipsRequestMtid: bigint!): recalculate_institute_ownerships_request_affected_institutes

  # fetch aggregated fields from the table: "recalculate_institute_ownerships_request_affected_institutes"
  recalculateInstituteOwnershipsRequestAffectedInstitutesAggregate(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_affected_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_affected_institutes_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  ): recalculate_institute_ownerships_request_affected_institutes_aggregate!

  # fetch data from the table: "recalculate_institute_ownerships_request_affected_institutes"
  recalculateInstituteOwnershipsRequestAffectedInstituteses(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_affected_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_affected_institutes_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_affected_institutes_bool_exp
  ): [recalculate_institute_ownerships_request_affected_institutes!]!

  # fetch aggregated fields from the table: "recalculate_institute_ownerships_request"
  recalculateInstituteOwnershipsRequestAggregate(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_bool_exp
  ): recalculate_institute_ownerships_request_aggregate!

  # fetch data from the table: "recalculate_institute_ownerships_request"
  recalculateInstituteOwnershipsRequests(
    # distinct select on columns
    distinct_on: [recalculate_institute_ownerships_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [recalculate_institute_ownerships_request_order_by!]

    # filter the rows returned
    where: recalculate_institute_ownerships_request_bool_exp
  ): [recalculate_institute_ownerships_request!]!

  # fetch data from the table: "reference" using primary key columns
  reference(mtid: bigint!): reference

  # fetch aggregated fields from the table: "reference"
  referenceAggregate(
    # distinct select on columns
    distinct_on: [reference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reference_order_by!]

    # filter the rows returned
    where: reference_bool_exp
  ): reference_aggregate!

  # fetch data from the table: "reference"
  references(
    # distinct select on columns
    distinct_on: [reference_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reference_order_by!]

    # filter the rows returned
    where: reference_bool_exp
  ): [reference!]!

  # fetch data from the table: "refresh_item" using primary key columns
  refreshItem(id: String!): refresh_item

  # fetch aggregated fields from the table: "refresh_item"
  refreshItemAggregate(
    # distinct select on columns
    distinct_on: [refresh_item_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_item_order_by!]

    # filter the rows returned
    where: refresh_item_bool_exp
  ): refresh_item_aggregate!

  # fetch data from the table: "refresh_item"
  refreshItems(
    # distinct select on columns
    distinct_on: [refresh_item_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_item_order_by!]

    # filter the rows returned
    where: refresh_item_bool_exp
  ): [refresh_item!]!

  # fetch data from the table: "refresh_log" using primary key columns
  refreshLog(id: bigint!): refresh_log

  # fetch aggregated fields from the table: "refresh_log"
  refreshLogAggregate(
    # distinct select on columns
    distinct_on: [refresh_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_log_order_by!]

    # filter the rows returned
    where: refresh_log_bool_exp
  ): refresh_log_aggregate!

  # fetch data from the table: "refresh_log"
  refreshLogs(
    # distinct select on columns
    distinct_on: [refresh_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [refresh_log_order_by!]

    # filter the rows returned
    where: refresh_log_bool_exp
  ): [refresh_log!]!

  # fetch data from the table: "reorg" using primary key columns
  reorg(mtid: bigint!): reorg

  # fetch aggregated fields from the table: "reorg"
  reorgAggregate(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): reorg_aggregate!

  # fetch data from the table: "reorg_type" using primary key columns
  reorgType(mtid: bigint!): reorg_type

  # fetch aggregated fields from the table: "reorg_type"
  reorgTypeAggregate(
    # distinct select on columns
    distinct_on: [reorg_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_type_order_by!]

    # filter the rows returned
    where: reorg_type_bool_exp
  ): reorg_type_aggregate!

  # fetch data from the table: "reorg_type"
  reorgTypes(
    # distinct select on columns
    distinct_on: [reorg_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_type_order_by!]

    # filter the rows returned
    where: reorg_type_bool_exp
  ): [reorg_type!]!

  # fetch data from the table: "reorg"
  reorgs(
    # distinct select on columns
    distinct_on: [reorg_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [reorg_order_by!]

    # filter the rows returned
    where: reorg_bool_exp
  ): [reorg!]!

  # fetch data from the table: "report" using primary key columns
  report(mtid: bigint!): report

  # fetch aggregated fields from the table: "report"
  reportAggregate(
    # distinct select on columns
    distinct_on: [report_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_order_by!]

    # filter the rows returned
    where: report_bool_exp
  ): report_aggregate!

  # fetch data from the table: "report_content" using primary key columns
  reportContent(mtid: bigint!): report_content

  # fetch aggregated fields from the table: "report_content"
  reportContentAggregate(
    # distinct select on columns
    distinct_on: [report_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_order_by!]

    # filter the rows returned
    where: report_content_bool_exp
  ): report_content_aggregate!

  # fetch aggregated fields from the table: "report_content_file_content"
  reportContentFileContentAggregate(
    # distinct select on columns
    distinct_on: [report_content_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_file_content_order_by!]

    # filter the rows returned
    where: report_content_file_content_bool_exp
  ): report_content_file_content_aggregate!

  # fetch data from the table: "report_content_file_content"
  reportContentFileContents(
    # distinct select on columns
    distinct_on: [report_content_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_file_content_order_by!]

    # filter the rows returned
    where: report_content_file_content_bool_exp
  ): [report_content_file_content!]!

  # fetch aggregated fields from the table: "report_contents"
  reportContentJoinAggregate(
    # distinct select on columns
    distinct_on: [report_contents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_contents_order_by!]

    # filter the rows returned
    where: report_contents_bool_exp
  ): report_contents_aggregate!

  # fetch data from the table: "report_contents"
  reportContentJoins(
    # distinct select on columns
    distinct_on: [report_contents_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_contents_order_by!]

    # filter the rows returned
    where: report_contents_bool_exp
  ): [report_contents!]!

  # fetch data from the table: "report_content"
  reportContents(
    # distinct select on columns
    distinct_on: [report_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_content_order_by!]

    # filter the rows returned
    where: report_content_bool_exp
  ): [report_content!]!

  # fetch data from the table: "report_parameter" using primary key columns
  reportParameter(mtid: bigint!): report_parameter

  # fetch aggregated fields from the table: "report_parameter"
  reportParameterAggregate(
    # distinct select on columns
    distinct_on: [report_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_parameter_order_by!]

    # filter the rows returned
    where: report_parameter_bool_exp
  ): report_parameter_aggregate!

  # fetch data from the table: "report_parameter"
  reportParameters(
    # distinct select on columns
    distinct_on: [report_parameter_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_parameter_order_by!]

    # filter the rows returned
    where: report_parameter_bool_exp
  ): [report_parameter!]!

  # fetch data from the table: "report_request" using primary key columns
  reportRequest(mtid: bigint!): report_request

  # fetch aggregated fields from the table: "report_request"
  reportRequestAggregate(
    # distinct select on columns
    distinct_on: [report_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_order_by!]

    # filter the rows returned
    where: report_request_bool_exp
  ): report_request_aggregate!

  # fetch aggregated fields from the table: "report_request_queries"
  reportRequestQueriesAggregate(
    # distinct select on columns
    distinct_on: [report_request_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_queries_order_by!]

    # filter the rows returned
    where: report_request_queries_bool_exp
  ): report_request_queries_aggregate!

  # fetch data from the table: "report_request_queries"
  reportRequestQuerieses(
    # distinct select on columns
    distinct_on: [report_request_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_queries_order_by!]

    # filter the rows returned
    where: report_request_queries_bool_exp
  ): [report_request_queries!]!

  # fetch data from the table: "report_request"
  reportRequests(
    # distinct select on columns
    distinct_on: [report_request_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_request_order_by!]

    # filter the rows returned
    where: report_request_bool_exp
  ): [report_request!]!

  # fetch data from the table: "report_template" using primary key columns
  reportTemplate(mtid: bigint!): report_template

  # fetch aggregated fields from the table: "report_template"
  reportTemplateAggregate(
    # distinct select on columns
    distinct_on: [report_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_order_by!]

    # filter the rows returned
    where: report_template_bool_exp
  ): report_template_aggregate!

  # fetch aggregated fields from the table: "report_template_default_queries"
  reportTemplateDefaultQueriesAggregate(
    # distinct select on columns
    distinct_on: [report_template_default_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_default_queries_order_by!]

    # filter the rows returned
    where: report_template_default_queries_bool_exp
  ): report_template_default_queries_aggregate!

  # fetch data from the table: "report_template_default_queries"
  reportTemplateDefaultQuerieses(
    # distinct select on columns
    distinct_on: [report_template_default_queries_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_default_queries_order_by!]

    # filter the rows returned
    where: report_template_default_queries_bool_exp
  ): [report_template_default_queries!]!

  # fetch aggregated fields from the table: "report_template_language_files"
  reportTemplateLanguageFilesAggregate(
    # distinct select on columns
    distinct_on: [report_template_language_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_language_files_order_by!]

    # filter the rows returned
    where: report_template_language_files_bool_exp
  ): report_template_language_files_aggregate!

  # fetch data from the table: "report_template_language_files"
  reportTemplateLanguageFileses(
    # distinct select on columns
    distinct_on: [report_template_language_files_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_language_files_order_by!]

    # filter the rows returned
    where: report_template_language_files_bool_exp
  ): [report_template_language_files!]!

  # fetch data from the table: "report_template_parameter_select" using primary key columns
  reportTemplateParameterSelect(mtid: bigint!): report_template_parameter_select

  # fetch aggregated fields from the table: "report_template_parameter_select"
  reportTemplateParameterSelectAggregate(
    # distinct select on columns
    distinct_on: [report_template_parameter_select_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_parameter_select_order_by!]

    # filter the rows returned
    where: report_template_parameter_select_bool_exp
  ): report_template_parameter_select_aggregate!

  # fetch data from the table: "report_template_parameter_select"
  reportTemplateParameterSelects(
    # distinct select on columns
    distinct_on: [report_template_parameter_select_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_parameter_select_order_by!]

    # filter the rows returned
    where: report_template_parameter_select_bool_exp
  ): [report_template_parameter_select!]!

  # fetch data from the table: "report_template"
  reportTemplates(
    # distinct select on columns
    distinct_on: [report_template_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_template_order_by!]

    # filter the rows returned
    where: report_template_bool_exp
  ): [report_template!]!

  # fetch data from the table: "report_xml" using primary key columns
  reportXml(mtid: bigint!): report_xml

  # fetch aggregated fields from the table: "report_xml"
  reportXmlAggregate(
    # distinct select on columns
    distinct_on: [report_xml_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_xml_order_by!]

    # filter the rows returned
    where: report_xml_bool_exp
  ): report_xml_aggregate!

  # fetch data from the table: "report_xml"
  reportXmls(
    # distinct select on columns
    distinct_on: [report_xml_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_xml_order_by!]

    # filter the rows returned
    where: report_xml_bool_exp
  ): [report_xml!]!

  # fetch data from the table: "report"
  reports(
    # distinct select on columns
    distinct_on: [report_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [report_order_by!]

    # filter the rows returned
    where: report_bool_exp
  ): [report!]!

  # fetch data from the table: "ris_import_error_detail" using primary key columns
  risImportErrorDetail(mtid: bigint!): ris_import_error_detail

  # fetch aggregated fields from the table: "ris_import_error_detail"
  risImportErrorDetailAggregate(
    # distinct select on columns
    distinct_on: [ris_import_error_detail_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ris_import_error_detail_order_by!]

    # filter the rows returned
    where: ris_import_error_detail_bool_exp
  ): ris_import_error_detail_aggregate!

  # fetch data from the table: "ris_import_error_detail"
  risImportErrorDetails(
    # distinct select on columns
    distinct_on: [ris_import_error_detail_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ris_import_error_detail_order_by!]

    # filter the rows returned
    where: ris_import_error_detail_bool_exp
  ): [ris_import_error_detail!]!

  # fetch data from the table: "series_volume" using primary key columns
  seriesVolume(mtid: bigint!): series_volume

  # fetch aggregated fields from the table: "series_volume"
  seriesVolumeAggregate(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): series_volume_aggregate!

  # fetch data from the table: "series_volume"
  seriesVolumes(
    # distinct select on columns
    distinct_on: [series_volume_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [series_volume_order_by!]

    # filter the rows returned
    where: series_volume_bool_exp
  ): [series_volume!]!

  # fetch data from the table: "shib_id_provider" using primary key columns
  shibIdProvider(mtid: bigint!): shib_id_provider

  # fetch aggregated fields from the table: "shib_id_provider"
  shibIdProviderAggregate(
    # distinct select on columns
    distinct_on: [shib_id_provider_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [shib_id_provider_order_by!]

    # filter the rows returned
    where: shib_id_provider_bool_exp
  ): shib_id_provider_aggregate!

  # fetch data from the table: "shib_id_provider"
  shibIdProviders(
    # distinct select on columns
    distinct_on: [shib_id_provider_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [shib_id_provider_order_by!]

    # filter the rows returned
    where: shib_id_provider_bool_exp
  ): [shib_id_provider!]!

  # fetch data from the table: "smart_query"
  smartQueries(
    # distinct select on columns
    distinct_on: [smart_query_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_order_by!]

    # filter the rows returned
    where: smart_query_bool_exp
  ): [smart_query!]!

  # fetch data from the table: "smart_query" using primary key columns
  smartQuery(mtid: bigint!): smart_query

  # fetch aggregated fields from the table: "smart_query"
  smartQueryAggregate(
    # distinct select on columns
    distinct_on: [smart_query_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_order_by!]

    # filter the rows returned
    where: smart_query_bool_exp
  ): smart_query_aggregate!

  # fetch data from the table: "smart_query_cond" using primary key columns
  smartQueryCond(mtid: bigint!): smart_query_cond

  # fetch aggregated fields from the table: "smart_query_cond"
  smartQueryCondAggregate(
    # distinct select on columns
    distinct_on: [smart_query_cond_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_cond_order_by!]

    # filter the rows returned
    where: smart_query_cond_bool_exp
  ): smart_query_cond_aggregate!

  # fetch data from the table: "smart_query_cond"
  smartQueryConds(
    # distinct select on columns
    distinct_on: [smart_query_cond_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_cond_order_by!]

    # filter the rows returned
    where: smart_query_cond_bool_exp
  ): [smart_query_cond!]!

  # fetch data from the table: "smart_query_group" using primary key columns
  smartQueryGroup(id: bigint!): smart_query_group

  # fetch aggregated fields from the table: "smart_query_group"
  smartQueryGroupAggregate(
    # distinct select on columns
    distinct_on: [smart_query_group_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_group_order_by!]

    # filter the rows returned
    where: smart_query_group_bool_exp
  ): smart_query_group_aggregate!

  # fetch data from the table: "smart_query_group"
  smartQueryGroups(
    # distinct select on columns
    distinct_on: [smart_query_group_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_group_order_by!]

    # filter the rows returned
    where: smart_query_group_bool_exp
  ): [smart_query_group!]!

  # fetch data from the table: "smart_query_sort" using primary key columns
  smartQuerySort(mtid: bigint!): smart_query_sort

  # fetch aggregated fields from the table: "smart_query_sort"
  smartQuerySortAggregate(
    # distinct select on columns
    distinct_on: [smart_query_sort_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_sort_order_by!]

    # filter the rows returned
    where: smart_query_sort_bool_exp
  ): smart_query_sort_aggregate!

  # fetch data from the table: "smart_query_sort"
  smartQuerySorts(
    # distinct select on columns
    distinct_on: [smart_query_sort_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [smart_query_sort_order_by!]

    # filter the rows returned
    where: smart_query_sort_bool_exp
  ): [smart_query_sort!]!

  # fetch data from the table: "snippet_cache" using primary key columns
  snippetCache(mtid: bigint!, otype: String!): snippet_cache

  # fetch aggregated fields from the table: "snippet_cache"
  snippetCacheAggregate(
    # distinct select on columns
    distinct_on: [snippet_cache_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_order_by!]

    # filter the rows returned
    where: snippet_cache_bool_exp
  ): snippet_cache_aggregate!

  # fetch data from the table: "snippet_cache_status" using primary key columns
  snippetCacheStatus(mtid: bigint!, otype: String!): snippet_cache_status

  # fetch aggregated fields from the table: "snippet_cache_status"
  snippetCacheStatusAggregate(
    # distinct select on columns
    distinct_on: [snippet_cache_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_status_order_by!]

    # filter the rows returned
    where: snippet_cache_status_bool_exp
  ): snippet_cache_status_aggregate!

  # fetch data from the table: "snippet_cache_status"
  snippetCacheStatuses(
    # distinct select on columns
    distinct_on: [snippet_cache_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_status_order_by!]

    # filter the rows returned
    where: snippet_cache_status_bool_exp
  ): [snippet_cache_status!]!

  # fetch data from the table: "snippet_cache"
  snippetCaches(
    # distinct select on columns
    distinct_on: [snippet_cache_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [snippet_cache_order_by!]

    # filter the rows returned
    where: snippet_cache_bool_exp
  ): [snippet_cache!]!

  # fetch data from the table: "source" using primary key columns
  source(mtid: bigint!): source

  # fetch aggregated fields from the table: "source"
  sourceAggregate(
    # distinct select on columns
    distinct_on: [source_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_order_by!]

    # filter the rows returned
    where: source_bool_exp
  ): source_aggregate!

  # fetch aggregated fields from the table: "source_allowed_institutes"
  sourceAllowedInstitutesAggregate(
    # distinct select on columns
    distinct_on: [source_allowed_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_allowed_institutes_order_by!]

    # filter the rows returned
    where: source_allowed_institutes_bool_exp
  ): source_allowed_institutes_aggregate!

  # fetch data from the table: "source_allowed_institutes"
  sourceAllowedInstituteses(
    # distinct select on columns
    distinct_on: [source_allowed_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_allowed_institutes_order_by!]

    # filter the rows returned
    where: source_allowed_institutes_bool_exp
  ): [source_allowed_institutes!]!

  # fetch data from the table: "source"
  sources(
    # distinct select on columns
    distinct_on: [source_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [source_order_by!]

    # filter the rows returned
    where: source_bool_exp
  ): [source!]!

  # fetch data from the table: "sub_type" using primary key columns
  subType(mtid: bigint!): sub_type

  # fetch aggregated fields from the table: "sub_type"
  subTypeAggregate(
    # distinct select on columns
    distinct_on: [sub_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [sub_type_order_by!]

    # filter the rows returned
    where: sub_type_bool_exp
  ): sub_type_aggregate!

  # fetch data from the table: "sub_type"
  subTypes(
    # distinct select on columns
    distinct_on: [sub_type_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [sub_type_order_by!]

    # filter the rows returned
    where: sub_type_bool_exp
  ): [sub_type!]!

  # fetch data from the table: "ticket" using primary key columns
  ticket(mtid: bigint!): ticket

  # fetch aggregated fields from the table: "ticket"
  ticketAggregate(
    # distinct select on columns
    distinct_on: [ticket_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_order_by!]

    # filter the rows returned
    where: ticket_bool_exp
  ): ticket_aggregate!

  # fetch data from the table: "ticket_authors" using primary key columns
  ticketAuthors(authorsMtid: bigint!, ticketMtid: bigint!): ticket_authors

  # fetch aggregated fields from the table: "ticket_authors"
  ticketAuthorsAggregate(
    # distinct select on columns
    distinct_on: [ticket_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_authors_order_by!]

    # filter the rows returned
    where: ticket_authors_bool_exp
  ): ticket_authors_aggregate!

  # fetch data from the table: "ticket_authors"
  ticketAuthorses(
    # distinct select on columns
    distinct_on: [ticket_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_authors_order_by!]

    # filter the rows returned
    where: ticket_authors_bool_exp
  ): [ticket_authors!]!

  # fetch data from the table: "ticket_institutes" using primary key columns
  ticketInstitutes(institutesMtid: bigint!, ticketMtid: bigint!): ticket_institutes

  # fetch aggregated fields from the table: "ticket_institutes"
  ticketInstitutesAggregate(
    # distinct select on columns
    distinct_on: [ticket_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_institutes_order_by!]

    # filter the rows returned
    where: ticket_institutes_bool_exp
  ): ticket_institutes_aggregate!

  # fetch data from the table: "ticket_institutes"
  ticketInstituteses(
    # distinct select on columns
    distinct_on: [ticket_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_institutes_order_by!]

    # filter the rows returned
    where: ticket_institutes_bool_exp
  ): [ticket_institutes!]!

  # fetch data from the table: "ticket"
  tickets(
    # distinct select on columns
    distinct_on: [ticket_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_order_by!]

    # filter the rows returned
    where: ticket_bool_exp
  ): [ticket!]!

  # fetch data from the table: "uploaded_file" using primary key columns
  uploadedFile(mtid: bigint!): uploaded_file

  # fetch aggregated fields from the table: "uploaded_file"
  uploadedFileAggregate(
    # distinct select on columns
    distinct_on: [uploaded_file_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_order_by!]

    # filter the rows returned
    where: uploaded_file_bool_exp
  ): uploaded_file_aggregate!

  # fetch aggregated fields from the table: "uploaded_file_file_content"
  uploadedFileFileContentAggregate(
    # distinct select on columns
    distinct_on: [uploaded_file_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_file_content_order_by!]

    # filter the rows returned
    where: uploaded_file_file_content_bool_exp
  ): uploaded_file_file_content_aggregate!

  # fetch data from the table: "uploaded_file_file_content"
  uploadedFileFileContents(
    # distinct select on columns
    distinct_on: [uploaded_file_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_file_content_order_by!]

    # filter the rows returned
    where: uploaded_file_file_content_bool_exp
  ): [uploaded_file_file_content!]!

  # fetch data from the table: "uploaded_file"
  uploadedFiles(
    # distinct select on columns
    distinct_on: [uploaded_file_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_order_by!]

    # filter the rows returned
    where: uploaded_file_bool_exp
  ): [uploaded_file!]!

  # fetch data from the table: "usage_log" using primary key columns
  usageLog(id: bigint!): usage_log

  # fetch aggregated fields from the table: "usage_log"
  usageLogAggregate(
    # distinct select on columns
    distinct_on: [usage_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [usage_log_order_by!]

    # filter the rows returned
    where: usage_log_bool_exp
  ): usage_log_aggregate!

  # fetch data from the table: "usage_log"
  usageLogs(
    # distinct select on columns
    distinct_on: [usage_log_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [usage_log_order_by!]

    # filter the rows returned
    where: usage_log_bool_exp
  ): [usage_log!]!

  # fetch data from the table: "users" using primary key columns
  user(mtid: bigint!): users

  # fetch aggregated fields from the table: "users"
  userAggregate(
    # distinct select on columns
    distinct_on: [users_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_order_by!]

    # filter the rows returned
    where: users_bool_exp
  ): users_aggregate!

  # fetch data from the table: "user_notification_time" using primary key columns
  userNotificationTime(mtid: bigint!): user_notification_time

  # fetch aggregated fields from the table: "user_notification_time"
  userNotificationTimeAggregate(
    # distinct select on columns
    distinct_on: [user_notification_time_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_notification_time_order_by!]

    # filter the rows returned
    where: user_notification_time_bool_exp
  ): user_notification_time_aggregate!

  # fetch data from the table: "user_notification_time"
  userNotificationTimes(
    # distinct select on columns
    distinct_on: [user_notification_time_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_notification_time_order_by!]

    # filter the rows returned
    where: user_notification_time_bool_exp
  ): [user_notification_time!]!

  # fetch data from the table: "user_preferences" using primary key columns
  userPreferences(mtid: bigint!): user_preferences

  # fetch aggregated fields from the table: "user_preferences"
  userPreferencesAggregate(
    # distinct select on columns
    distinct_on: [user_preferences_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_preferences_order_by!]

    # filter the rows returned
    where: user_preferences_bool_exp
  ): user_preferences_aggregate!

  # fetch data from the table: "user_preferences"
  userPreferenceses(
    # distinct select on columns
    distinct_on: [user_preferences_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [user_preferences_order_by!]

    # filter the rows returned
    where: user_preferences_bool_exp
  ): [user_preferences!]!

  # fetch data from the table: "users"
  users(
    # distinct select on columns
    distinct_on: [users_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_order_by!]

    # filter the rows returned
    where: users_bool_exp
  ): [users!]!

  # fetch aggregated fields from the table: "users_assistants"
  usersAssistantsAggregate(
    # distinct select on columns
    distinct_on: [users_assistants_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_assistants_order_by!]

    # filter the rows returned
    where: users_assistants_bool_exp
  ): users_assistants_aggregate!

  # fetch data from the table: "users_assistants"
  usersAssistantses(
    # distinct select on columns
    distinct_on: [users_assistants_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_assistants_order_by!]

    # filter the rows returned
    where: users_assistants_bool_exp
  ): [users_assistants!]!

  # fetch aggregated fields from the table: "users_disciplines"
  usersDisciplinesAggregate(
    # distinct select on columns
    distinct_on: [users_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_disciplines_order_by!]

    # filter the rows returned
    where: users_disciplines_bool_exp
  ): users_disciplines_aggregate!

  # fetch data from the table: "users_disciplines"
  usersDisciplineses(
    # distinct select on columns
    distinct_on: [users_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_disciplines_order_by!]

    # filter the rows returned
    where: users_disciplines_bool_exp
  ): [users_disciplines!]!

  # fetch data from the table: "variable" using primary key columns
  variable(mtid: bigint!): variable

  # fetch aggregated fields from the table: "variable"
  variableAggregate(
    # distinct select on columns
    distinct_on: [variable_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [variable_order_by!]

    # filter the rows returned
    where: variable_bool_exp
  ): variable_aggregate!

  # fetch data from the table: "variable"
  variables(
    # distinct select on columns
    distinct_on: [variable_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [variable_order_by!]

    # filter the rows returned
    where: variable_bool_exp
  ): [variable!]!

  # fetch data from the table: "workflow" using primary key columns
  workflow(mtid: bigint!): workflow

  # fetch aggregated fields from the table: "workflow"
  workflowAggregate(
    # distinct select on columns
    distinct_on: [workflow_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_order_by!]

    # filter the rows returned
    where: workflow_bool_exp
  ): workflow_aggregate!

  # fetch data from the table: "workflow_status" using primary key columns
  workflowStatus(mtid: bigint!): workflow_status

  # fetch aggregated fields from the table: "workflow_status"
  workflowStatusAggregate(
    # distinct select on columns
    distinct_on: [workflow_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_status_order_by!]

    # filter the rows returned
    where: workflow_status_bool_exp
  ): workflow_status_aggregate!

  # fetch data from the table: "workflow_status"
  workflowStatuses(
    # distinct select on columns
    distinct_on: [workflow_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_status_order_by!]

    # filter the rows returned
    where: workflow_status_bool_exp
  ): [workflow_status!]!

  # fetch data from the table: "workflow_step" using primary key columns
  workflowStep(mtid: bigint!): workflow_step

  # fetch aggregated fields from the table: "workflow_step"
  workflowStepAggregate(
    # distinct select on columns
    distinct_on: [workflow_step_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_order_by!]

    # filter the rows returned
    where: workflow_step_bool_exp
  ): workflow_step_aggregate!

  # fetch data from the table: "workflow_step_status" using primary key columns
  workflowStepStatus(mtid: bigint!): workflow_step_status

  # fetch aggregated fields from the table: "workflow_step_status"
  workflowStepStatusAggregate(
    # distinct select on columns
    distinct_on: [workflow_step_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_status_order_by!]

    # filter the rows returned
    where: workflow_step_status_bool_exp
  ): workflow_step_status_aggregate!

  # fetch data from the table: "workflow_step_status"
  workflowStepStatuses(
    # distinct select on columns
    distinct_on: [workflow_step_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_status_order_by!]

    # filter the rows returned
    where: workflow_step_status_bool_exp
  ): [workflow_step_status!]!

  # fetch data from the table: "workflow_step"
  workflowSteps(
    # distinct select on columns
    distinct_on: [workflow_step_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_order_by!]

    # filter the rows returned
    where: workflow_step_bool_exp
  ): [workflow_step!]!

  # fetch data from the table: "workflow"
  workflows(
    # distinct select on columns
    distinct_on: [workflow_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_order_by!]

    # filter the rows returned
    where: workflow_bool_exp
  ): [workflow!]!
}

# columns and relationships of "ticket"
type ticket {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  assignee: Int

  # An array relationship
  authors(
    # distinct select on columns
    distinct_on: [ticket_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_authors_order_by!]

    # filter the rows returned
    where: ticket_authors_bool_exp
  ): [ticket_authors!]!

  # An aggregated array relationship
  authors_aggregate(
    # distinct select on columns
    distinct_on: [ticket_authors_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_authors_order_by!]

    # filter the rows returned
    where: ticket_authors_bool_exp
  ): ticket_authors_aggregate!
  body: String
  closeDate: timestamp
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int

  # An array relationship
  institutes(
    # distinct select on columns
    distinct_on: [ticket_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_institutes_order_by!]

    # filter the rows returned
    where: ticket_institutes_bool_exp
  ): [ticket_institutes!]!

  # An aggregated array relationship
  institutes_aggregate(
    # distinct select on columns
    distinct_on: [ticket_institutes_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [ticket_institutes_order_by!]

    # filter the rows returned
    where: ticket_institutes_bool_exp
  ): ticket_institutes_aggregate!
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  reply: String
  sendDate: timestamp

  # An object relationship
  sender: users
  senderEmail: String
  senderMtid: bigint
  startDate: timestamp

  # An object relationship
  startedBy: users
  startedByMtid: bigint
  status: Int
  subject: String
  targetId: bigint
  targetStatus: Int
  targetType: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  ticketStatus: Int
  type: Int
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "ticket"
type ticket_aggregate {
  aggregate: ticket_aggregate_fields
  nodes: [ticket!]!
}

# aggregate fields of "ticket"
type ticket_aggregate_fields {
  avg: ticket_avg_fields
  count(columns: [ticket_select_column!], distinct: Boolean): Int
  max: ticket_max_fields
  min: ticket_min_fields
  stddev: ticket_stddev_fields
  stddev_pop: ticket_stddev_pop_fields
  stddev_samp: ticket_stddev_samp_fields
  sum: ticket_sum_fields
  var_pop: ticket_var_pop_fields
  var_samp: ticket_var_samp_fields
  variance: ticket_variance_fields
}

# order by aggregate values of table "ticket"
input ticket_aggregate_order_by {
  avg: ticket_avg_order_by
  count: order_by
  max: ticket_max_order_by
  min: ticket_min_order_by
  stddev: ticket_stddev_order_by
  stddev_pop: ticket_stddev_pop_order_by
  stddev_samp: ticket_stddev_samp_order_by
  sum: ticket_sum_order_by
  var_pop: ticket_var_pop_order_by
  var_samp: ticket_var_samp_order_by
  variance: ticket_variance_order_by
}

# input type for inserting array relation for remote table "ticket"
input ticket_arr_rel_insert_input {
  data: [ticket_insert_input!]!
  on_conflict: ticket_on_conflict
}

# columns and relationships of "ticket_authors"
type ticket_authors {
  authorsMtid: bigint!
  ticketMtid: bigint!

  # An object relationship
  users: users!
}

# aggregated selection of "ticket_authors"
type ticket_authors_aggregate {
  aggregate: ticket_authors_aggregate_fields
  nodes: [ticket_authors!]!
}

# aggregate fields of "ticket_authors"
type ticket_authors_aggregate_fields {
  avg: ticket_authors_avg_fields
  count(columns: [ticket_authors_select_column!], distinct: Boolean): Int
  max: ticket_authors_max_fields
  min: ticket_authors_min_fields
  stddev: ticket_authors_stddev_fields
  stddev_pop: ticket_authors_stddev_pop_fields
  stddev_samp: ticket_authors_stddev_samp_fields
  sum: ticket_authors_sum_fields
  var_pop: ticket_authors_var_pop_fields
  var_samp: ticket_authors_var_samp_fields
  variance: ticket_authors_variance_fields
}

# order by aggregate values of table "ticket_authors"
input ticket_authors_aggregate_order_by {
  avg: ticket_authors_avg_order_by
  count: order_by
  max: ticket_authors_max_order_by
  min: ticket_authors_min_order_by
  stddev: ticket_authors_stddev_order_by
  stddev_pop: ticket_authors_stddev_pop_order_by
  stddev_samp: ticket_authors_stddev_samp_order_by
  sum: ticket_authors_sum_order_by
  var_pop: ticket_authors_var_pop_order_by
  var_samp: ticket_authors_var_samp_order_by
  variance: ticket_authors_variance_order_by
}

# input type for inserting array relation for remote table "ticket_authors"
input ticket_authors_arr_rel_insert_input {
  data: [ticket_authors_insert_input!]!
  on_conflict: ticket_authors_on_conflict
}

# aggregate avg on columns
type ticket_authors_avg_fields {
  authorsMtid: Float
  ticketMtid: Float
}

# order by avg() on columns of table "ticket_authors"
input ticket_authors_avg_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# Boolean expression to filter rows from the table "ticket_authors". All fields are combined with a logical 'AND'.
input ticket_authors_bool_exp {
  _and: [ticket_authors_bool_exp]
  _not: ticket_authors_bool_exp
  _or: [ticket_authors_bool_exp]
  authorsMtid: bigint_comparison_exp
  ticketMtid: bigint_comparison_exp
  users: users_bool_exp
}

# unique or primary key constraints on table "ticket_authors"
enum ticket_authors_constraint {
  # unique or primary key constraint
  ticket_authors_pkey
}

# input type for incrementing integer column in table "ticket_authors"
input ticket_authors_inc_input {
  authorsMtid: bigint
  ticketMtid: bigint
}

# input type for inserting data into table "ticket_authors"
input ticket_authors_insert_input {
  authorsMtid: bigint
  ticketMtid: bigint
  users: users_obj_rel_insert_input
}

# aggregate max on columns
type ticket_authors_max_fields {
  authorsMtid: bigint
  ticketMtid: bigint
}

# order by max() on columns of table "ticket_authors"
input ticket_authors_max_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# aggregate min on columns
type ticket_authors_min_fields {
  authorsMtid: bigint
  ticketMtid: bigint
}

# order by min() on columns of table "ticket_authors"
input ticket_authors_min_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# response of any mutation on the table "ticket_authors"
type ticket_authors_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [ticket_authors!]!
}

# input type for inserting object relation for remote table "ticket_authors"
input ticket_authors_obj_rel_insert_input {
  data: ticket_authors_insert_input!
  on_conflict: ticket_authors_on_conflict
}

# on conflict condition type for table "ticket_authors"
input ticket_authors_on_conflict {
  constraint: ticket_authors_constraint!
  update_columns: [ticket_authors_update_column!]!
  where: ticket_authors_bool_exp
}

# ordering options when selecting data from "ticket_authors"
input ticket_authors_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
  users: users_order_by
}

# primary key columns input for table: "ticket_authors"
input ticket_authors_pk_columns_input {
  authorsMtid: bigint!
  ticketMtid: bigint!
}

# select columns of table "ticket_authors"
enum ticket_authors_select_column {
  # column name
  authorsMtid

  # column name
  ticketMtid
}

# input type for updating data in table "ticket_authors"
input ticket_authors_set_input {
  authorsMtid: bigint
  ticketMtid: bigint
}

# aggregate stddev on columns
type ticket_authors_stddev_fields {
  authorsMtid: Float
  ticketMtid: Float
}

# order by stddev() on columns of table "ticket_authors"
input ticket_authors_stddev_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# aggregate stddev_pop on columns
type ticket_authors_stddev_pop_fields {
  authorsMtid: Float
  ticketMtid: Float
}

# order by stddev_pop() on columns of table "ticket_authors"
input ticket_authors_stddev_pop_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# aggregate stddev_samp on columns
type ticket_authors_stddev_samp_fields {
  authorsMtid: Float
  ticketMtid: Float
}

# order by stddev_samp() on columns of table "ticket_authors"
input ticket_authors_stddev_samp_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# aggregate sum on columns
type ticket_authors_sum_fields {
  authorsMtid: bigint
  ticketMtid: bigint
}

# order by sum() on columns of table "ticket_authors"
input ticket_authors_sum_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# update columns of table "ticket_authors"
enum ticket_authors_update_column {
  # column name
  authorsMtid

  # column name
  ticketMtid
}

# aggregate var_pop on columns
type ticket_authors_var_pop_fields {
  authorsMtid: Float
  ticketMtid: Float
}

# order by var_pop() on columns of table "ticket_authors"
input ticket_authors_var_pop_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# aggregate var_samp on columns
type ticket_authors_var_samp_fields {
  authorsMtid: Float
  ticketMtid: Float
}

# order by var_samp() on columns of table "ticket_authors"
input ticket_authors_var_samp_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# aggregate variance on columns
type ticket_authors_variance_fields {
  authorsMtid: Float
  ticketMtid: Float
}

# order by variance() on columns of table "ticket_authors"
input ticket_authors_variance_order_by {
  authorsMtid: order_by
  ticketMtid: order_by
}

# aggregate avg on columns
type ticket_avg_fields {
  approverMtid: Float
  assignee: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  senderMtid: Float
  startedByMtid: Float
  status: Float
  targetId: Float
  targetStatus: Float
  ticketStatus: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "ticket"
input ticket_avg_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "ticket". All fields are combined with a logical 'AND'.
input ticket_bool_exp {
  _and: [ticket_bool_exp]
  _not: ticket_bool_exp
  _or: [ticket_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  assignee: Int_comparison_exp
  authors: ticket_authors_bool_exp
  body: String_comparison_exp
  closeDate: timestamp_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  institutes: ticket_institutes_bool_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  reply: String_comparison_exp
  sendDate: timestamp_comparison_exp
  sender: users_bool_exp
  senderEmail: String_comparison_exp
  senderMtid: bigint_comparison_exp
  startDate: timestamp_comparison_exp
  startedBy: users_bool_exp
  startedByMtid: bigint_comparison_exp
  status: Int_comparison_exp
  subject: String_comparison_exp
  targetId: bigint_comparison_exp
  targetStatus: Int_comparison_exp
  targetType: String_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  ticketStatus: Int_comparison_exp
  type: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "ticket"
enum ticket_constraint {
  # unique or primary key constraint
  ticket_pkey
}

# input type for incrementing integer column in table "ticket"
input ticket_inc_input {
  approverMtid: bigint
  assignee: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  senderMtid: bigint
  startedByMtid: bigint
  status: Int
  targetId: bigint
  targetStatus: Int
  ticketStatus: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "ticket"
input ticket_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  assignee: Int
  authors: ticket_authors_arr_rel_insert_input
  body: String
  closeDate: timestamp
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  institutes: ticket_institutes_arr_rel_insert_input
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  reply: String
  sendDate: timestamp
  sender: users_obj_rel_insert_input
  senderEmail: String
  senderMtid: bigint
  startDate: timestamp
  startedBy: users_obj_rel_insert_input
  startedByMtid: bigint
  status: Int
  subject: String
  targetId: bigint
  targetStatus: Int
  targetType: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  ticketStatus: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# columns and relationships of "ticket_institutes"
type ticket_institutes {
  institutesMtid: bigint!

  # An object relationship
  organization: organization!
  ticketMtid: bigint!
}

# aggregated selection of "ticket_institutes"
type ticket_institutes_aggregate {
  aggregate: ticket_institutes_aggregate_fields
  nodes: [ticket_institutes!]!
}

# aggregate fields of "ticket_institutes"
type ticket_institutes_aggregate_fields {
  avg: ticket_institutes_avg_fields
  count(columns: [ticket_institutes_select_column!], distinct: Boolean): Int
  max: ticket_institutes_max_fields
  min: ticket_institutes_min_fields
  stddev: ticket_institutes_stddev_fields
  stddev_pop: ticket_institutes_stddev_pop_fields
  stddev_samp: ticket_institutes_stddev_samp_fields
  sum: ticket_institutes_sum_fields
  var_pop: ticket_institutes_var_pop_fields
  var_samp: ticket_institutes_var_samp_fields
  variance: ticket_institutes_variance_fields
}

# order by aggregate values of table "ticket_institutes"
input ticket_institutes_aggregate_order_by {
  avg: ticket_institutes_avg_order_by
  count: order_by
  max: ticket_institutes_max_order_by
  min: ticket_institutes_min_order_by
  stddev: ticket_institutes_stddev_order_by
  stddev_pop: ticket_institutes_stddev_pop_order_by
  stddev_samp: ticket_institutes_stddev_samp_order_by
  sum: ticket_institutes_sum_order_by
  var_pop: ticket_institutes_var_pop_order_by
  var_samp: ticket_institutes_var_samp_order_by
  variance: ticket_institutes_variance_order_by
}

# input type for inserting array relation for remote table "ticket_institutes"
input ticket_institutes_arr_rel_insert_input {
  data: [ticket_institutes_insert_input!]!
  on_conflict: ticket_institutes_on_conflict
}

# aggregate avg on columns
type ticket_institutes_avg_fields {
  institutesMtid: Float
  ticketMtid: Float
}

# order by avg() on columns of table "ticket_institutes"
input ticket_institutes_avg_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# Boolean expression to filter rows from the table "ticket_institutes". All fields are combined with a logical 'AND'.
input ticket_institutes_bool_exp {
  _and: [ticket_institutes_bool_exp]
  _not: ticket_institutes_bool_exp
  _or: [ticket_institutes_bool_exp]
  institutesMtid: bigint_comparison_exp
  organization: organization_bool_exp
  ticketMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "ticket_institutes"
enum ticket_institutes_constraint {
  # unique or primary key constraint
  ticket_institutes_pkey
}

# input type for incrementing integer column in table "ticket_institutes"
input ticket_institutes_inc_input {
  institutesMtid: bigint
  ticketMtid: bigint
}

# input type for inserting data into table "ticket_institutes"
input ticket_institutes_insert_input {
  institutesMtid: bigint
  organization: organization_obj_rel_insert_input
  ticketMtid: bigint
}

# aggregate max on columns
type ticket_institutes_max_fields {
  institutesMtid: bigint
  ticketMtid: bigint
}

# order by max() on columns of table "ticket_institutes"
input ticket_institutes_max_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# aggregate min on columns
type ticket_institutes_min_fields {
  institutesMtid: bigint
  ticketMtid: bigint
}

# order by min() on columns of table "ticket_institutes"
input ticket_institutes_min_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# response of any mutation on the table "ticket_institutes"
type ticket_institutes_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [ticket_institutes!]!
}

# input type for inserting object relation for remote table "ticket_institutes"
input ticket_institutes_obj_rel_insert_input {
  data: ticket_institutes_insert_input!
  on_conflict: ticket_institutes_on_conflict
}

# on conflict condition type for table "ticket_institutes"
input ticket_institutes_on_conflict {
  constraint: ticket_institutes_constraint!
  update_columns: [ticket_institutes_update_column!]!
  where: ticket_institutes_bool_exp
}

# ordering options when selecting data from "ticket_institutes"
input ticket_institutes_order_by {
  institutesMtid: order_by
  organization: organization_order_by
  ticketMtid: order_by
}

# primary key columns input for table: "ticket_institutes"
input ticket_institutes_pk_columns_input {
  institutesMtid: bigint!
  ticketMtid: bigint!
}

# select columns of table "ticket_institutes"
enum ticket_institutes_select_column {
  # column name
  institutesMtid

  # column name
  ticketMtid
}

# input type for updating data in table "ticket_institutes"
input ticket_institutes_set_input {
  institutesMtid: bigint
  ticketMtid: bigint
}

# aggregate stddev on columns
type ticket_institutes_stddev_fields {
  institutesMtid: Float
  ticketMtid: Float
}

# order by stddev() on columns of table "ticket_institutes"
input ticket_institutes_stddev_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# aggregate stddev_pop on columns
type ticket_institutes_stddev_pop_fields {
  institutesMtid: Float
  ticketMtid: Float
}

# order by stddev_pop() on columns of table "ticket_institutes"
input ticket_institutes_stddev_pop_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# aggregate stddev_samp on columns
type ticket_institutes_stddev_samp_fields {
  institutesMtid: Float
  ticketMtid: Float
}

# order by stddev_samp() on columns of table "ticket_institutes"
input ticket_institutes_stddev_samp_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# aggregate sum on columns
type ticket_institutes_sum_fields {
  institutesMtid: bigint
  ticketMtid: bigint
}

# order by sum() on columns of table "ticket_institutes"
input ticket_institutes_sum_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# update columns of table "ticket_institutes"
enum ticket_institutes_update_column {
  # column name
  institutesMtid

  # column name
  ticketMtid
}

# aggregate var_pop on columns
type ticket_institutes_var_pop_fields {
  institutesMtid: Float
  ticketMtid: Float
}

# order by var_pop() on columns of table "ticket_institutes"
input ticket_institutes_var_pop_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# aggregate var_samp on columns
type ticket_institutes_var_samp_fields {
  institutesMtid: Float
  ticketMtid: Float
}

# order by var_samp() on columns of table "ticket_institutes"
input ticket_institutes_var_samp_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# aggregate variance on columns
type ticket_institutes_variance_fields {
  institutesMtid: Float
  ticketMtid: Float
}

# order by variance() on columns of table "ticket_institutes"
input ticket_institutes_variance_order_by {
  institutesMtid: order_by
  ticketMtid: order_by
}

# aggregate max on columns
type ticket_max_fields {
  approved: timestamp
  approverMtid: bigint
  assignee: Int
  body: String
  closeDate: timestamp
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  reply: String
  sendDate: timestamp
  senderEmail: String
  senderMtid: bigint
  startDate: timestamp
  startedByMtid: bigint
  status: Int
  subject: String
  targetId: bigint
  targetStatus: Int
  targetType: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  ticketStatus: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "ticket"
input ticket_max_order_by {
  approved: order_by
  approverMtid: order_by
  assignee: order_by
  body: order_by
  closeDate: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  reply: order_by
  sendDate: order_by
  senderEmail: order_by
  senderMtid: order_by
  startDate: order_by
  startedByMtid: order_by
  status: order_by
  subject: order_by
  targetId: order_by
  targetStatus: order_by
  targetType: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type ticket_min_fields {
  approved: timestamp
  approverMtid: bigint
  assignee: Int
  body: String
  closeDate: timestamp
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  reply: String
  sendDate: timestamp
  senderEmail: String
  senderMtid: bigint
  startDate: timestamp
  startedByMtid: bigint
  status: Int
  subject: String
  targetId: bigint
  targetStatus: Int
  targetType: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  ticketStatus: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "ticket"
input ticket_min_order_by {
  approved: order_by
  approverMtid: order_by
  assignee: order_by
  body: order_by
  closeDate: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  reply: order_by
  sendDate: order_by
  senderEmail: order_by
  senderMtid: order_by
  startDate: order_by
  startedByMtid: order_by
  status: order_by
  subject: order_by
  targetId: order_by
  targetStatus: order_by
  targetType: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "ticket"
type ticket_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [ticket!]!
}

# input type for inserting object relation for remote table "ticket"
input ticket_obj_rel_insert_input {
  data: ticket_insert_input!
  on_conflict: ticket_on_conflict
}

# on conflict condition type for table "ticket"
input ticket_on_conflict {
  constraint: ticket_constraint!
  update_columns: [ticket_update_column!]!
  where: ticket_bool_exp
}

# ordering options when selecting data from "ticket"
input ticket_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  assignee: order_by
  authors_aggregate: ticket_authors_aggregate_order_by
  body: order_by
  closeDate: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  institutes_aggregate: ticket_institutes_aggregate_order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  reply: order_by
  sendDate: order_by
  sender: users_order_by
  senderEmail: order_by
  senderMtid: order_by
  startDate: order_by
  startedBy: users_order_by
  startedByMtid: order_by
  status: order_by
  subject: order_by
  targetId: order_by
  targetStatus: order_by
  targetType: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "ticket"
input ticket_pk_columns_input {
  mtid: bigint!
}

# select columns of table "ticket"
enum ticket_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  assignee

  # column name
  body

  # column name
  closeDate

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  reply

  # column name
  sendDate

  # column name
  senderEmail

  # column name
  senderMtid

  # column name
  startDate

  # column name
  startedByMtid

  # column name
  status

  # column name
  subject

  # column name
  targetId

  # column name
  targetStatus

  # column name
  targetType

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  ticketStatus

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "ticket"
input ticket_set_input {
  approved: timestamp
  approverMtid: bigint
  assignee: Int
  body: String
  closeDate: timestamp
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  reply: String
  sendDate: timestamp
  senderEmail: String
  senderMtid: bigint
  startDate: timestamp
  startedByMtid: bigint
  status: Int
  subject: String
  targetId: bigint
  targetStatus: Int
  targetType: String
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  ticketStatus: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type ticket_stddev_fields {
  approverMtid: Float
  assignee: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  senderMtid: Float
  startedByMtid: Float
  status: Float
  targetId: Float
  targetStatus: Float
  ticketStatus: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "ticket"
input ticket_stddev_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type ticket_stddev_pop_fields {
  approverMtid: Float
  assignee: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  senderMtid: Float
  startedByMtid: Float
  status: Float
  targetId: Float
  targetStatus: Float
  ticketStatus: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "ticket"
input ticket_stddev_pop_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type ticket_stddev_samp_fields {
  approverMtid: Float
  assignee: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  senderMtid: Float
  startedByMtid: Float
  status: Float
  targetId: Float
  targetStatus: Float
  ticketStatus: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "ticket"
input ticket_stddev_samp_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type ticket_sum_fields {
  approverMtid: bigint
  assignee: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  senderMtid: bigint
  startedByMtid: bigint
  status: Int
  targetId: bigint
  targetStatus: Int
  ticketStatus: Int
  type: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "ticket"
input ticket_sum_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "ticket"
enum ticket_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  assignee

  # column name
  body

  # column name
  closeDate

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  reply

  # column name
  sendDate

  # column name
  senderEmail

  # column name
  senderMtid

  # column name
  startDate

  # column name
  startedByMtid

  # column name
  status

  # column name
  subject

  # column name
  targetId

  # column name
  targetStatus

  # column name
  targetType

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  ticketStatus

  # column name
  type

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type ticket_var_pop_fields {
  approverMtid: Float
  assignee: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  senderMtid: Float
  startedByMtid: Float
  status: Float
  targetId: Float
  targetStatus: Float
  ticketStatus: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "ticket"
input ticket_var_pop_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type ticket_var_samp_fields {
  approverMtid: Float
  assignee: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  senderMtid: Float
  startedByMtid: Float
  status: Float
  targetId: Float
  targetStatus: Float
  ticketStatus: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "ticket"
input ticket_var_samp_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type ticket_variance_fields {
  approverMtid: Float
  assignee: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  senderMtid: Float
  startedByMtid: Float
  status: Float
  targetId: Float
  targetStatus: Float
  ticketStatus: Float
  type: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "ticket"
input ticket_variance_order_by {
  approverMtid: order_by
  assignee: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  senderMtid: order_by
  startedByMtid: order_by
  status: order_by
  targetId: order_by
  targetStatus: order_by
  ticketStatus: order_by
  type: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

scalar timestamp

# expression to compare columns of type timestamp. All fields are combined with logical 'AND'.
input timestamp_comparison_exp {
  _eq: timestamp
  _gt: timestamp
  _gte: timestamp
  _in: [timestamp!]
  _is_null: Boolean
  _lt: timestamp
  _lte: timestamp
  _neq: timestamp
  _nin: [timestamp!]
}

# columns and relationships of "uploaded_file"
type uploaded_file {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int

  # An array relationship
  fileContent(
    # distinct select on columns
    distinct_on: [uploaded_file_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_file_content_order_by!]

    # filter the rows returned
    where: uploaded_file_file_content_bool_exp
  ): [uploaded_file_file_content!]!

  # An aggregated array relationship
  fileContent_aggregate(
    # distinct select on columns
    distinct_on: [uploaded_file_file_content_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [uploaded_file_file_content_order_by!]

    # filter the rows returned
    where: uploaded_file_file_content_bool_exp
  ): uploaded_file_file_content_aggregate!
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mimeType: String
  mtid: bigint!
  multipleOwners: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "uploaded_file"
type uploaded_file_aggregate {
  aggregate: uploaded_file_aggregate_fields
  nodes: [uploaded_file!]!
}

# aggregate fields of "uploaded_file"
type uploaded_file_aggregate_fields {
  avg: uploaded_file_avg_fields
  count(columns: [uploaded_file_select_column!], distinct: Boolean): Int
  max: uploaded_file_max_fields
  min: uploaded_file_min_fields
  stddev: uploaded_file_stddev_fields
  stddev_pop: uploaded_file_stddev_pop_fields
  stddev_samp: uploaded_file_stddev_samp_fields
  sum: uploaded_file_sum_fields
  var_pop: uploaded_file_var_pop_fields
  var_samp: uploaded_file_var_samp_fields
  variance: uploaded_file_variance_fields
}

# order by aggregate values of table "uploaded_file"
input uploaded_file_aggregate_order_by {
  avg: uploaded_file_avg_order_by
  count: order_by
  max: uploaded_file_max_order_by
  min: uploaded_file_min_order_by
  stddev: uploaded_file_stddev_order_by
  stddev_pop: uploaded_file_stddev_pop_order_by
  stddev_samp: uploaded_file_stddev_samp_order_by
  sum: uploaded_file_sum_order_by
  var_pop: uploaded_file_var_pop_order_by
  var_samp: uploaded_file_var_samp_order_by
  variance: uploaded_file_variance_order_by
}

# input type for inserting array relation for remote table "uploaded_file"
input uploaded_file_arr_rel_insert_input {
  data: [uploaded_file_insert_input!]!
  on_conflict: uploaded_file_on_conflict
}

# aggregate avg on columns
type uploaded_file_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "uploaded_file"
input uploaded_file_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "uploaded_file". All fields are combined with a logical 'AND'.
input uploaded_file_bool_exp {
  _and: [uploaded_file_bool_exp]
  _not: uploaded_file_bool_exp
  _or: [uploaded_file_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  fileContent: uploaded_file_file_content_bool_exp
  filename: String_comparison_exp
  filepath: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mimeType: String_comparison_exp
  mtid: bigint_comparison_exp
  multipleOwners: Boolean_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  parentId: bigint_comparison_exp
  parentType: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  size: bigint_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "uploaded_file"
enum uploaded_file_constraint {
  # unique or primary key constraint
  uploaded_file_pkey
}

# columns and relationships of "uploaded_file_file_content"
type uploaded_file_file_content {
  # An object relationship
  binaryContent: binary_content!
  fileContentId: bigint!
  uploadedFileMtid: bigint!
}

# aggregated selection of "uploaded_file_file_content"
type uploaded_file_file_content_aggregate {
  aggregate: uploaded_file_file_content_aggregate_fields
  nodes: [uploaded_file_file_content!]!
}

# aggregate fields of "uploaded_file_file_content"
type uploaded_file_file_content_aggregate_fields {
  avg: uploaded_file_file_content_avg_fields
  count(columns: [uploaded_file_file_content_select_column!], distinct: Boolean): Int
  max: uploaded_file_file_content_max_fields
  min: uploaded_file_file_content_min_fields
  stddev: uploaded_file_file_content_stddev_fields
  stddev_pop: uploaded_file_file_content_stddev_pop_fields
  stddev_samp: uploaded_file_file_content_stddev_samp_fields
  sum: uploaded_file_file_content_sum_fields
  var_pop: uploaded_file_file_content_var_pop_fields
  var_samp: uploaded_file_file_content_var_samp_fields
  variance: uploaded_file_file_content_variance_fields
}

# order by aggregate values of table "uploaded_file_file_content"
input uploaded_file_file_content_aggregate_order_by {
  avg: uploaded_file_file_content_avg_order_by
  count: order_by
  max: uploaded_file_file_content_max_order_by
  min: uploaded_file_file_content_min_order_by
  stddev: uploaded_file_file_content_stddev_order_by
  stddev_pop: uploaded_file_file_content_stddev_pop_order_by
  stddev_samp: uploaded_file_file_content_stddev_samp_order_by
  sum: uploaded_file_file_content_sum_order_by
  var_pop: uploaded_file_file_content_var_pop_order_by
  var_samp: uploaded_file_file_content_var_samp_order_by
  variance: uploaded_file_file_content_variance_order_by
}

# input type for inserting array relation for remote table "uploaded_file_file_content"
input uploaded_file_file_content_arr_rel_insert_input {
  data: [uploaded_file_file_content_insert_input!]!
}

# aggregate avg on columns
type uploaded_file_file_content_avg_fields {
  fileContentId: Float
  uploadedFileMtid: Float
}

# order by avg() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_avg_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# Boolean expression to filter rows from the table "uploaded_file_file_content". All fields are combined with a logical 'AND'.
input uploaded_file_file_content_bool_exp {
  _and: [uploaded_file_file_content_bool_exp]
  _not: uploaded_file_file_content_bool_exp
  _or: [uploaded_file_file_content_bool_exp]
  binaryContent: binary_content_bool_exp
  fileContentId: bigint_comparison_exp
  uploadedFileMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "uploaded_file_file_content"
input uploaded_file_file_content_inc_input {
  fileContentId: bigint
  uploadedFileMtid: bigint
}

# input type for inserting data into table "uploaded_file_file_content"
input uploaded_file_file_content_insert_input {
  binaryContent: binary_content_obj_rel_insert_input
  fileContentId: bigint
  uploadedFileMtid: bigint
}

# aggregate max on columns
type uploaded_file_file_content_max_fields {
  fileContentId: bigint
  uploadedFileMtid: bigint
}

# order by max() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_max_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# aggregate min on columns
type uploaded_file_file_content_min_fields {
  fileContentId: bigint
  uploadedFileMtid: bigint
}

# order by min() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_min_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# response of any mutation on the table "uploaded_file_file_content"
type uploaded_file_file_content_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [uploaded_file_file_content!]!
}

# input type for inserting object relation for remote table "uploaded_file_file_content"
input uploaded_file_file_content_obj_rel_insert_input {
  data: uploaded_file_file_content_insert_input!
}

# ordering options when selecting data from "uploaded_file_file_content"
input uploaded_file_file_content_order_by {
  binaryContent: binary_content_order_by
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# select columns of table "uploaded_file_file_content"
enum uploaded_file_file_content_select_column {
  # column name
  fileContentId

  # column name
  uploadedFileMtid
}

# input type for updating data in table "uploaded_file_file_content"
input uploaded_file_file_content_set_input {
  fileContentId: bigint
  uploadedFileMtid: bigint
}

# aggregate stddev on columns
type uploaded_file_file_content_stddev_fields {
  fileContentId: Float
  uploadedFileMtid: Float
}

# order by stddev() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_stddev_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# aggregate stddev_pop on columns
type uploaded_file_file_content_stddev_pop_fields {
  fileContentId: Float
  uploadedFileMtid: Float
}

# order by stddev_pop() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_stddev_pop_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# aggregate stddev_samp on columns
type uploaded_file_file_content_stddev_samp_fields {
  fileContentId: Float
  uploadedFileMtid: Float
}

# order by stddev_samp() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_stddev_samp_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# aggregate sum on columns
type uploaded_file_file_content_sum_fields {
  fileContentId: bigint
  uploadedFileMtid: bigint
}

# order by sum() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_sum_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# aggregate var_pop on columns
type uploaded_file_file_content_var_pop_fields {
  fileContentId: Float
  uploadedFileMtid: Float
}

# order by var_pop() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_var_pop_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# aggregate var_samp on columns
type uploaded_file_file_content_var_samp_fields {
  fileContentId: Float
  uploadedFileMtid: Float
}

# order by var_samp() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_var_samp_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# aggregate variance on columns
type uploaded_file_file_content_variance_fields {
  fileContentId: Float
  uploadedFileMtid: Float
}

# order by variance() on columns of table "uploaded_file_file_content"
input uploaded_file_file_content_variance_order_by {
  fileContentId: order_by
  uploadedFileMtid: order_by
}

# input type for incrementing integer column in table "uploaded_file"
input uploaded_file_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentId: bigint
  prevValid: bigint
  size: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "uploaded_file"
input uploaded_file_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  fileContent: uploaded_file_file_content_arr_rel_insert_input
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mimeType: String
  mtid: bigint
  multipleOwners: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type uploaded_file_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mimeType: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "uploaded_file"
input uploaded_file_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  filepath: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mimeType: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentId: order_by
  parentType: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type uploaded_file_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mimeType: String
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "uploaded_file"
input uploaded_file_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  filename: order_by
  filepath: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mimeType: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentId: order_by
  parentType: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "uploaded_file"
type uploaded_file_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [uploaded_file!]!
}

# input type for inserting object relation for remote table "uploaded_file"
input uploaded_file_obj_rel_insert_input {
  data: uploaded_file_insert_input!
  on_conflict: uploaded_file_on_conflict
}

# on conflict condition type for table "uploaded_file"
input uploaded_file_on_conflict {
  constraint: uploaded_file_constraint!
  update_columns: [uploaded_file_update_column!]!
  where: uploaded_file_bool_exp
}

# ordering options when selecting data from "uploaded_file"
input uploaded_file_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  fileContent_aggregate: uploaded_file_file_content_aggregate_order_by
  filename: order_by
  filepath: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mimeType: order_by
  mtid: order_by
  multipleOwners: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  parentId: order_by
  parentType: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  size: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "uploaded_file"
input uploaded_file_pk_columns_input {
  mtid: bigint!
}

# select columns of table "uploaded_file"
enum uploaded_file_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  filepath

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mimeType

  # column name
  mtid

  # column name
  multipleOwners

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentId

  # column name
  parentType

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  size

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "uploaded_file"
input uploaded_file_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  filename: String
  filepath: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mimeType: String
  mtid: bigint
  multipleOwners: Boolean
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  parentId: bigint
  parentType: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  size: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type uploaded_file_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "uploaded_file"
input uploaded_file_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type uploaded_file_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "uploaded_file"
input uploaded_file_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type uploaded_file_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "uploaded_file"
input uploaded_file_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type uploaded_file_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  parentId: bigint
  prevValid: bigint
  size: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "uploaded_file"
input uploaded_file_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "uploaded_file"
enum uploaded_file_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  filename

  # column name
  filepath

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mimeType

  # column name
  mtid

  # column name
  multipleOwners

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  parentId

  # column name
  parentType

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  size

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type uploaded_file_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "uploaded_file"
input uploaded_file_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type uploaded_file_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "uploaded_file"
input uploaded_file_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type uploaded_file_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  parentId: Float
  prevValid: Float
  size: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "uploaded_file"
input uploaded_file_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  parentId: order_by
  prevValid: order_by
  size: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "usage_log"
type usage_log {
  bytes: bigint!
  id: bigint!
  objects: bigint!
  requests: bigint!
  timestamp: timestamp
  userId: bigint!
  username: String
}

# aggregated selection of "usage_log"
type usage_log_aggregate {
  aggregate: usage_log_aggregate_fields
  nodes: [usage_log!]!
}

# aggregate fields of "usage_log"
type usage_log_aggregate_fields {
  avg: usage_log_avg_fields
  count(columns: [usage_log_select_column!], distinct: Boolean): Int
  max: usage_log_max_fields
  min: usage_log_min_fields
  stddev: usage_log_stddev_fields
  stddev_pop: usage_log_stddev_pop_fields
  stddev_samp: usage_log_stddev_samp_fields
  sum: usage_log_sum_fields
  var_pop: usage_log_var_pop_fields
  var_samp: usage_log_var_samp_fields
  variance: usage_log_variance_fields
}

# order by aggregate values of table "usage_log"
input usage_log_aggregate_order_by {
  avg: usage_log_avg_order_by
  count: order_by
  max: usage_log_max_order_by
  min: usage_log_min_order_by
  stddev: usage_log_stddev_order_by
  stddev_pop: usage_log_stddev_pop_order_by
  stddev_samp: usage_log_stddev_samp_order_by
  sum: usage_log_sum_order_by
  var_pop: usage_log_var_pop_order_by
  var_samp: usage_log_var_samp_order_by
  variance: usage_log_variance_order_by
}

# input type for inserting array relation for remote table "usage_log"
input usage_log_arr_rel_insert_input {
  data: [usage_log_insert_input!]!
  on_conflict: usage_log_on_conflict
}

# aggregate avg on columns
type usage_log_avg_fields {
  bytes: Float
  id: Float
  objects: Float
  requests: Float
  userId: Float
}

# order by avg() on columns of table "usage_log"
input usage_log_avg_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# Boolean expression to filter rows from the table "usage_log". All fields are combined with a logical 'AND'.
input usage_log_bool_exp {
  _and: [usage_log_bool_exp]
  _not: usage_log_bool_exp
  _or: [usage_log_bool_exp]
  bytes: bigint_comparison_exp
  id: bigint_comparison_exp
  objects: bigint_comparison_exp
  requests: bigint_comparison_exp
  timestamp: timestamp_comparison_exp
  userId: bigint_comparison_exp
  username: String_comparison_exp
}

# unique or primary key constraints on table "usage_log"
enum usage_log_constraint {
  # unique or primary key constraint
  usage_log_pkey
}

# input type for incrementing integer column in table "usage_log"
input usage_log_inc_input {
  bytes: bigint
  id: bigint
  objects: bigint
  requests: bigint
  userId: bigint
}

# input type for inserting data into table "usage_log"
input usage_log_insert_input {
  bytes: bigint
  id: bigint
  objects: bigint
  requests: bigint
  timestamp: timestamp
  userId: bigint
  username: String
}

# aggregate max on columns
type usage_log_max_fields {
  bytes: bigint
  id: bigint
  objects: bigint
  requests: bigint
  timestamp: timestamp
  userId: bigint
  username: String
}

# order by max() on columns of table "usage_log"
input usage_log_max_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  timestamp: order_by
  userId: order_by
  username: order_by
}

# aggregate min on columns
type usage_log_min_fields {
  bytes: bigint
  id: bigint
  objects: bigint
  requests: bigint
  timestamp: timestamp
  userId: bigint
  username: String
}

# order by min() on columns of table "usage_log"
input usage_log_min_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  timestamp: order_by
  userId: order_by
  username: order_by
}

# response of any mutation on the table "usage_log"
type usage_log_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [usage_log!]!
}

# input type for inserting object relation for remote table "usage_log"
input usage_log_obj_rel_insert_input {
  data: usage_log_insert_input!
  on_conflict: usage_log_on_conflict
}

# on conflict condition type for table "usage_log"
input usage_log_on_conflict {
  constraint: usage_log_constraint!
  update_columns: [usage_log_update_column!]!
  where: usage_log_bool_exp
}

# ordering options when selecting data from "usage_log"
input usage_log_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  timestamp: order_by
  userId: order_by
  username: order_by
}

# primary key columns input for table: "usage_log"
input usage_log_pk_columns_input {
  id: bigint!
}

# select columns of table "usage_log"
enum usage_log_select_column {
  # column name
  bytes

  # column name
  id

  # column name
  objects

  # column name
  requests

  # column name
  timestamp

  # column name
  userId

  # column name
  username
}

# input type for updating data in table "usage_log"
input usage_log_set_input {
  bytes: bigint
  id: bigint
  objects: bigint
  requests: bigint
  timestamp: timestamp
  userId: bigint
  username: String
}

# aggregate stddev on columns
type usage_log_stddev_fields {
  bytes: Float
  id: Float
  objects: Float
  requests: Float
  userId: Float
}

# order by stddev() on columns of table "usage_log"
input usage_log_stddev_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# aggregate stddev_pop on columns
type usage_log_stddev_pop_fields {
  bytes: Float
  id: Float
  objects: Float
  requests: Float
  userId: Float
}

# order by stddev_pop() on columns of table "usage_log"
input usage_log_stddev_pop_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# aggregate stddev_samp on columns
type usage_log_stddev_samp_fields {
  bytes: Float
  id: Float
  objects: Float
  requests: Float
  userId: Float
}

# order by stddev_samp() on columns of table "usage_log"
input usage_log_stddev_samp_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# aggregate sum on columns
type usage_log_sum_fields {
  bytes: bigint
  id: bigint
  objects: bigint
  requests: bigint
  userId: bigint
}

# order by sum() on columns of table "usage_log"
input usage_log_sum_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# update columns of table "usage_log"
enum usage_log_update_column {
  # column name
  bytes

  # column name
  id

  # column name
  objects

  # column name
  requests

  # column name
  timestamp

  # column name
  userId

  # column name
  username
}

# aggregate var_pop on columns
type usage_log_var_pop_fields {
  bytes: Float
  id: Float
  objects: Float
  requests: Float
  userId: Float
}

# order by var_pop() on columns of table "usage_log"
input usage_log_var_pop_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# aggregate var_samp on columns
type usage_log_var_samp_fields {
  bytes: Float
  id: Float
  objects: Float
  requests: Float
  userId: Float
}

# order by var_samp() on columns of table "usage_log"
input usage_log_var_samp_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# aggregate variance on columns
type usage_log_variance_fields {
  bytes: Float
  id: Float
  objects: Float
  requests: Float
  userId: Float
}

# order by variance() on columns of table "usage_log"
input usage_log_variance_order_by {
  bytes: order_by
  id: order_by
  objects: order_by
  requests: order_by
  userId: order_by
}

# columns and relationships of "user_notification_time"
type user_notification_time {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  cronExpression: String
  def: Boolean!
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "user_notification_time"
type user_notification_time_aggregate {
  aggregate: user_notification_time_aggregate_fields
  nodes: [user_notification_time!]!
}

# aggregate fields of "user_notification_time"
type user_notification_time_aggregate_fields {
  avg: user_notification_time_avg_fields
  count(columns: [user_notification_time_select_column!], distinct: Boolean): Int
  max: user_notification_time_max_fields
  min: user_notification_time_min_fields
  stddev: user_notification_time_stddev_fields
  stddev_pop: user_notification_time_stddev_pop_fields
  stddev_samp: user_notification_time_stddev_samp_fields
  sum: user_notification_time_sum_fields
  var_pop: user_notification_time_var_pop_fields
  var_samp: user_notification_time_var_samp_fields
  variance: user_notification_time_variance_fields
}

# order by aggregate values of table "user_notification_time"
input user_notification_time_aggregate_order_by {
  avg: user_notification_time_avg_order_by
  count: order_by
  max: user_notification_time_max_order_by
  min: user_notification_time_min_order_by
  stddev: user_notification_time_stddev_order_by
  stddev_pop: user_notification_time_stddev_pop_order_by
  stddev_samp: user_notification_time_stddev_samp_order_by
  sum: user_notification_time_sum_order_by
  var_pop: user_notification_time_var_pop_order_by
  var_samp: user_notification_time_var_samp_order_by
  variance: user_notification_time_variance_order_by
}

# input type for inserting array relation for remote table "user_notification_time"
input user_notification_time_arr_rel_insert_input {
  data: [user_notification_time_insert_input!]!
  on_conflict: user_notification_time_on_conflict
}

# aggregate avg on columns
type user_notification_time_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "user_notification_time"
input user_notification_time_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "user_notification_time". All fields are combined with a logical 'AND'.
input user_notification_time_bool_exp {
  _and: [user_notification_time_bool_exp]
  _not: user_notification_time_bool_exp
  _or: [user_notification_time_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  cronExpression: String_comparison_exp
  def: Boolean_comparison_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "user_notification_time"
enum user_notification_time_constraint {
  # unique or primary key constraint
  user_notification_time_pkey
}

# input type for incrementing integer column in table "user_notification_time"
input user_notification_time_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "user_notification_time"
input user_notification_time_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  cronExpression: String
  def: Boolean
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type user_notification_time_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronExpression: String
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "user_notification_time"
input user_notification_time_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronExpression: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type user_notification_time_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronExpression: String
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "user_notification_time"
input user_notification_time_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  cronExpression: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "user_notification_time"
type user_notification_time_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [user_notification_time!]!
}

# input type for inserting object relation for remote table "user_notification_time"
input user_notification_time_obj_rel_insert_input {
  data: user_notification_time_insert_input!
  on_conflict: user_notification_time_on_conflict
}

# on conflict condition type for table "user_notification_time"
input user_notification_time_on_conflict {
  constraint: user_notification_time_constraint!
  update_columns: [user_notification_time_update_column!]!
  where: user_notification_time_bool_exp
}

# ordering options when selecting data from "user_notification_time"
input user_notification_time_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  cronExpression: order_by
  def: order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "user_notification_time"
input user_notification_time_pk_columns_input {
  mtid: bigint!
}

# select columns of table "user_notification_time"
enum user_notification_time_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronExpression

  # column name
  def

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "user_notification_time"
input user_notification_time_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  cronExpression: String
  def: Boolean
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type user_notification_time_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "user_notification_time"
input user_notification_time_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type user_notification_time_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "user_notification_time"
input user_notification_time_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type user_notification_time_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "user_notification_time"
input user_notification_time_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type user_notification_time_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "user_notification_time"
input user_notification_time_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "user_notification_time"
enum user_notification_time_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  cronExpression

  # column name
  def

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type user_notification_time_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "user_notification_time"
input user_notification_time_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type user_notification_time_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "user_notification_time"
input user_notification_time_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type user_notification_time_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "user_notification_time"
input user_notification_time_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "user_preferences"
type user_preferences {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  backendPrefs: String
  clientPrefsString: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  language: Int
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!

  # An object relationship
  user: users
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "user_preferences"
type user_preferences_aggregate {
  aggregate: user_preferences_aggregate_fields
  nodes: [user_preferences!]!
}

# aggregate fields of "user_preferences"
type user_preferences_aggregate_fields {
  avg: user_preferences_avg_fields
  count(columns: [user_preferences_select_column!], distinct: Boolean): Int
  max: user_preferences_max_fields
  min: user_preferences_min_fields
  stddev: user_preferences_stddev_fields
  stddev_pop: user_preferences_stddev_pop_fields
  stddev_samp: user_preferences_stddev_samp_fields
  sum: user_preferences_sum_fields
  var_pop: user_preferences_var_pop_fields
  var_samp: user_preferences_var_samp_fields
  variance: user_preferences_variance_fields
}

# order by aggregate values of table "user_preferences"
input user_preferences_aggregate_order_by {
  avg: user_preferences_avg_order_by
  count: order_by
  max: user_preferences_max_order_by
  min: user_preferences_min_order_by
  stddev: user_preferences_stddev_order_by
  stddev_pop: user_preferences_stddev_pop_order_by
  stddev_samp: user_preferences_stddev_samp_order_by
  sum: user_preferences_sum_order_by
  var_pop: user_preferences_var_pop_order_by
  var_samp: user_preferences_var_samp_order_by
  variance: user_preferences_variance_order_by
}

# input type for inserting array relation for remote table "user_preferences"
input user_preferences_arr_rel_insert_input {
  data: [user_preferences_insert_input!]!
  on_conflict: user_preferences_on_conflict
}

# aggregate avg on columns
type user_preferences_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  language: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "user_preferences"
input user_preferences_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "user_preferences". All fields are combined with a logical 'AND'.
input user_preferences_bool_exp {
  _and: [user_preferences_bool_exp]
  _not: user_preferences_bool_exp
  _or: [user_preferences_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  backendPrefs: String_comparison_exp
  clientPrefsString: String_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  language: Int_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  user: users_bool_exp
  userMtid: bigint_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "user_preferences"
enum user_preferences_constraint {
  # unique or primary key constraint
  user_preferences_pkey
}

# input type for incrementing integer column in table "user_preferences"
input user_preferences_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  language: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "user_preferences"
input user_preferences_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  backendPrefs: String
  clientPrefsString: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  language: Int
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  user: users_obj_rel_insert_input
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type user_preferences_max_fields {
  approved: timestamp
  approverMtid: bigint
  backendPrefs: String
  clientPrefsString: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  language: Int
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "user_preferences"
input user_preferences_max_order_by {
  approved: order_by
  approverMtid: order_by
  backendPrefs: order_by
  clientPrefsString: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type user_preferences_min_fields {
  approved: timestamp
  approverMtid: bigint
  backendPrefs: String
  clientPrefsString: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  language: Int
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "user_preferences"
input user_preferences_min_order_by {
  approved: order_by
  approverMtid: order_by
  backendPrefs: order_by
  clientPrefsString: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "user_preferences"
type user_preferences_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [user_preferences!]!
}

# input type for inserting object relation for remote table "user_preferences"
input user_preferences_obj_rel_insert_input {
  data: user_preferences_insert_input!
  on_conflict: user_preferences_on_conflict
}

# on conflict condition type for table "user_preferences"
input user_preferences_on_conflict {
  constraint: user_preferences_constraint!
  update_columns: [user_preferences_update_column!]!
  where: user_preferences_bool_exp
}

# ordering options when selecting data from "user_preferences"
input user_preferences_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  backendPrefs: order_by
  clientPrefsString: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  language: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  user: users_order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "user_preferences"
input user_preferences_pk_columns_input {
  mtid: bigint!
}

# select columns of table "user_preferences"
enum user_preferences_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  backendPrefs

  # column name
  clientPrefsString

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  userMtid

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "user_preferences"
input user_preferences_set_input {
  approved: timestamp
  approverMtid: bigint
  backendPrefs: String
  clientPrefsString: String
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  language: Int
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# aggregate stddev on columns
type user_preferences_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  language: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "user_preferences"
input user_preferences_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type user_preferences_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  language: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "user_preferences"
input user_preferences_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type user_preferences_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  language: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "user_preferences"
input user_preferences_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type user_preferences_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  language: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  userMtid: bigint
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "user_preferences"
input user_preferences_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "user_preferences"
enum user_preferences_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  backendPrefs

  # column name
  clientPrefsString

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  language

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  userMtid

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type user_preferences_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  language: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "user_preferences"
input user_preferences_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type user_preferences_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  language: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "user_preferences"
input user_preferences_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type user_preferences_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  language: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  userMtid: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "user_preferences"
input user_preferences_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  language: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  userMtid: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "users"
type users {
  # An array relationship
  adminRoles(
    # distinct select on columns
    distinct_on: [admin_role_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [admin_role_order_by!]

    # filter the rows returned
    where: admin_role_bool_exp
  ): [admin_role!]!

  # An aggregated array relationship
  adminRoles_aggregate(
    # distinct select on columns
    distinct_on: [admin_role_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [admin_role_order_by!]

    # filter the rows returned
    where: admin_role_bool_exp
  ): admin_role_aggregate!

  # An array relationship
  affiliations(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): [affiliation!]!
  affiliationsForSort: String

  # An aggregated array relationship
  affiliations_aggregate(
    # distinct select on columns
    distinct_on: [affiliation_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [affiliation_order_by!]

    # filter the rows returned
    where: affiliation_bool_exp
  ): affiliation_aggregate!
  allowedIps: String
  altTab: Boolean
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint

  # An array relationship
  assistants(
    # distinct select on columns
    distinct_on: [users_assistants_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_assistants_order_by!]

    # filter the rows returned
    where: users_assistants_bool_exp
  ): [users_assistants!]!

  # An aggregated array relationship
  assistants_aggregate(
    # distinct select on columns
    distinct_on: [users_assistants_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_assistants_order_by!]

    # filter the rows returned
    where: users_assistants_bool_exp
  ): users_assistants_aggregate!

  # An array relationship
  authorNames(
    # distinct select on columns
    distinct_on: [author_name_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_name_order_by!]

    # filter the rows returned
    where: author_name_bool_exp
  ): [author_name!]!

  # An aggregated array relationship
  authorNames_aggregate(
    # distinct select on columns
    distinct_on: [author_name_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_name_order_by!]

    # filter the rows returned
    where: author_name_bool_exp
  ): author_name_aggregate!
  auxName: String
  birthDate: timestamp
  birthPlace: String
  chosenUserName: String
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  dead: Boolean
  deathDate: timestamp

  # An array relationship
  degrees(
    # distinct select on columns
    distinct_on: [degree_holder_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_holder_order_by!]

    # filter the rows returned
    where: degree_holder_bool_exp
  ): [degree_holder!]!

  # An aggregated array relationship
  degrees_aggregate(
    # distinct select on columns
    distinct_on: [degree_holder_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [degree_holder_order_by!]

    # filter the rows returned
    where: degree_holder_bool_exp
  ): degree_holder_aggregate!
  deleted: Boolean!
  deletedDate: timestamp
  digestMode: String

  # An array relationship
  disciplines(
    # distinct select on columns
    distinct_on: [users_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_disciplines_order_by!]

    # filter the rows returned
    where: users_disciplines_bool_exp
  ): [users_disciplines!]!

  # An aggregated array relationship
  disciplines_aggregate(
    # distinct select on columns
    distinct_on: [users_disciplines_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_disciplines_order_by!]

    # filter the rows returned
    where: users_disciplines_bool_exp
  ): users_disciplines_aggregate!
  doiCitationCount: Int
  dtype: String!
  duplumRole: Int

  # An object relationship
  duplumSearchResult: duplum_search_result
  duplumSearchResultMtid: bigint
  email: String
  emailAddressConfirmed: Boolean
  enabled: Boolean!
  error: Int
  familyName: String
  foreignEditionCitationCount: Int
  gender: Int
  givenName: String

  # An array relationship
  identifiers(
    # distinct select on columns
    distinct_on: [author_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_identifier_order_by!]

    # filter the rows returned
    where: author_identifier_bool_exp
  ): [author_identifier!]!

  # An aggregated array relationship
  identifiers_aggregate(
    # distinct select on columns
    distinct_on: [author_identifier_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [author_identifier_order_by!]

    # filter the rows returned
    where: author_identifier_bool_exp
  ): author_identifier_aggregate!
  inactivatedAt: timestamp

  # An object relationship
  inactivatedBy: users
  inactivatedByMtid: bigint
  inactivationComment: String
  inactiveFrom: timestamp
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDataChange: timestamp
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastLogin: timestamp
  lastLogin2: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastOnlineAction: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  moreCitationsPerCitingDoc: Boolean!
  mtid: bigint!
  nationalOriginCitationCount: Int
  needsToChangePasswordUntil: timestamp
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passwordHash: String
  phone: String
  policyAcceptDate: timestamp

  # An object relationship
  preferences: user_preferences
  prevValid: bigint
  pubStats: String
  publicationCount: Int
  published: Boolean!
  pubsCompleteEnd: date
  pubsCompleteStart: date
  pwFormat: String
  receiveEmailAlertsForForumEvents: Boolean!
  receiveEmailAlertsForTicketEvents: Boolean!
  refreshed: Boolean!
  registrationComment: String
  registrationDate: timestamp
  rights: String
  robot: Boolean!

  # An object relationship
  robotSupervisor: users
  robotSupervisorMtid: bigint
  scopusCitationCount: Int

  # An object relationship
  selectedPubList: named_list
  selectedPubListIsEmpty: Boolean!
  selectedPubListIsOpen: Boolean
  selectedPubListMtid: bigint
  shibCreated: timestamp
  shibId: String
  shibIdProvider: String
  speciality: String
  status: Int

  # An object relationship
  summaryTable: report

  # An object relationship
  summaryTable2: report
  summaryTable2Code: String

  # An object relationship
  summaryTable2Csv: report

  # An object relationship
  summaryTable2Eng: report
  summaryTable2Mtid: bigint

  # An object relationship
  summaryTable2Template: report_template
  summaryTable2csvMtid: bigint
  summaryTable2engMtid: bigint
  summaryTable2templateMtid: bigint

  # An object relationship
  summaryTableCsv: report
  summaryTableCsvMtid: bigint

  # An object relationship
  summaryTableEng: report
  summaryTableEngMtid: bigint
  summaryTableMtid: bigint

  # An array relationship
  supervisedRobots(
    # distinct select on columns
    distinct_on: [users_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_order_by!]

    # filter the rows returned
    where: users_bool_exp
  ): [users!]!

  # An aggregated array relationship
  supervisedRobots_aggregate(
    # distinct select on columns
    distinct_on: [users_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [users_order_by!]

    # filter the rows returned
    where: users_bool_exp
  ): users_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporaryAccessToken: String
  temporaryAccessTokenValidBefore: timestamp
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int!

  # An object relationship
  userNotificationTime: user_notification_time
  userNotificationTimeMtid: bigint
  username: String
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# aggregated selection of "users"
type users_aggregate {
  aggregate: users_aggregate_fields
  nodes: [users!]!
}

# aggregate fields of "users"
type users_aggregate_fields {
  avg: users_avg_fields
  count(columns: [users_select_column!], distinct: Boolean): Int
  max: users_max_fields
  min: users_min_fields
  stddev: users_stddev_fields
  stddev_pop: users_stddev_pop_fields
  stddev_samp: users_stddev_samp_fields
  sum: users_sum_fields
  var_pop: users_var_pop_fields
  var_samp: users_var_samp_fields
  variance: users_variance_fields
}

# order by aggregate values of table "users"
input users_aggregate_order_by {
  avg: users_avg_order_by
  count: order_by
  max: users_max_order_by
  min: users_min_order_by
  stddev: users_stddev_order_by
  stddev_pop: users_stddev_pop_order_by
  stddev_samp: users_stddev_samp_order_by
  sum: users_sum_order_by
  var_pop: users_var_pop_order_by
  var_samp: users_var_samp_order_by
  variance: users_variance_order_by
}

# input type for inserting array relation for remote table "users"
input users_arr_rel_insert_input {
  data: [users_insert_input!]!
  on_conflict: users_on_conflict
}

# columns and relationships of "users_assistants"
type users_assistants {
  assistantsMtid: bigint!
  authorMtid: bigint!

  # An object relationship
  users: users!
}

# aggregated selection of "users_assistants"
type users_assistants_aggregate {
  aggregate: users_assistants_aggregate_fields
  nodes: [users_assistants!]!
}

# aggregate fields of "users_assistants"
type users_assistants_aggregate_fields {
  avg: users_assistants_avg_fields
  count(columns: [users_assistants_select_column!], distinct: Boolean): Int
  max: users_assistants_max_fields
  min: users_assistants_min_fields
  stddev: users_assistants_stddev_fields
  stddev_pop: users_assistants_stddev_pop_fields
  stddev_samp: users_assistants_stddev_samp_fields
  sum: users_assistants_sum_fields
  var_pop: users_assistants_var_pop_fields
  var_samp: users_assistants_var_samp_fields
  variance: users_assistants_variance_fields
}

# order by aggregate values of table "users_assistants"
input users_assistants_aggregate_order_by {
  avg: users_assistants_avg_order_by
  count: order_by
  max: users_assistants_max_order_by
  min: users_assistants_min_order_by
  stddev: users_assistants_stddev_order_by
  stddev_pop: users_assistants_stddev_pop_order_by
  stddev_samp: users_assistants_stddev_samp_order_by
  sum: users_assistants_sum_order_by
  var_pop: users_assistants_var_pop_order_by
  var_samp: users_assistants_var_samp_order_by
  variance: users_assistants_variance_order_by
}

# input type for inserting array relation for remote table "users_assistants"
input users_assistants_arr_rel_insert_input {
  data: [users_assistants_insert_input!]!
}

# aggregate avg on columns
type users_assistants_avg_fields {
  assistantsMtid: Float
  authorMtid: Float
}

# order by avg() on columns of table "users_assistants"
input users_assistants_avg_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# Boolean expression to filter rows from the table "users_assistants". All fields are combined with a logical 'AND'.
input users_assistants_bool_exp {
  _and: [users_assistants_bool_exp]
  _not: users_assistants_bool_exp
  _or: [users_assistants_bool_exp]
  assistantsMtid: bigint_comparison_exp
  authorMtid: bigint_comparison_exp
  users: users_bool_exp
}

# input type for incrementing integer column in table "users_assistants"
input users_assistants_inc_input {
  assistantsMtid: bigint
  authorMtid: bigint
}

# input type for inserting data into table "users_assistants"
input users_assistants_insert_input {
  assistantsMtid: bigint
  authorMtid: bigint
  users: users_obj_rel_insert_input
}

# aggregate max on columns
type users_assistants_max_fields {
  assistantsMtid: bigint
  authorMtid: bigint
}

# order by max() on columns of table "users_assistants"
input users_assistants_max_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate min on columns
type users_assistants_min_fields {
  assistantsMtid: bigint
  authorMtid: bigint
}

# order by min() on columns of table "users_assistants"
input users_assistants_min_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# response of any mutation on the table "users_assistants"
type users_assistants_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [users_assistants!]!
}

# input type for inserting object relation for remote table "users_assistants"
input users_assistants_obj_rel_insert_input {
  data: users_assistants_insert_input!
}

# ordering options when selecting data from "users_assistants"
input users_assistants_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
  users: users_order_by
}

# select columns of table "users_assistants"
enum users_assistants_select_column {
  # column name
  assistantsMtid

  # column name
  authorMtid
}

# input type for updating data in table "users_assistants"
input users_assistants_set_input {
  assistantsMtid: bigint
  authorMtid: bigint
}

# aggregate stddev on columns
type users_assistants_stddev_fields {
  assistantsMtid: Float
  authorMtid: Float
}

# order by stddev() on columns of table "users_assistants"
input users_assistants_stddev_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate stddev_pop on columns
type users_assistants_stddev_pop_fields {
  assistantsMtid: Float
  authorMtid: Float
}

# order by stddev_pop() on columns of table "users_assistants"
input users_assistants_stddev_pop_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate stddev_samp on columns
type users_assistants_stddev_samp_fields {
  assistantsMtid: Float
  authorMtid: Float
}

# order by stddev_samp() on columns of table "users_assistants"
input users_assistants_stddev_samp_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate sum on columns
type users_assistants_sum_fields {
  assistantsMtid: bigint
  authorMtid: bigint
}

# order by sum() on columns of table "users_assistants"
input users_assistants_sum_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate var_pop on columns
type users_assistants_var_pop_fields {
  assistantsMtid: Float
  authorMtid: Float
}

# order by var_pop() on columns of table "users_assistants"
input users_assistants_var_pop_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate var_samp on columns
type users_assistants_var_samp_fields {
  assistantsMtid: Float
  authorMtid: Float
}

# order by var_samp() on columns of table "users_assistants"
input users_assistants_var_samp_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate variance on columns
type users_assistants_variance_fields {
  assistantsMtid: Float
  authorMtid: Float
}

# order by variance() on columns of table "users_assistants"
input users_assistants_variance_order_by {
  assistantsMtid: order_by
  authorMtid: order_by
}

# aggregate avg on columns
type users_avg_fields {
  approverMtid: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  gender: Float
  inactivatedByMtid: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  robotSupervisorMtid: Float
  scopusCitationCount: Float
  selectedPubListMtid: Float
  status: Float
  summaryTable2Mtid: Float
  summaryTable2csvMtid: Float
  summaryTable2engMtid: Float
  summaryTable2templateMtid: Float
  summaryTableCsvMtid: Float
  summaryTableEngMtid: Float
  summaryTableMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  userNotificationTimeMtid: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by avg() on columns of table "users"
input users_avg_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# Boolean expression to filter rows from the table "users". All fields are combined with a logical 'AND'.
input users_bool_exp {
  _and: [users_bool_exp]
  _not: users_bool_exp
  _or: [users_bool_exp]
  adminRoles: admin_role_bool_exp
  affiliations: affiliation_bool_exp
  affiliationsForSort: String_comparison_exp
  allowedIps: String_comparison_exp
  altTab: Boolean_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  assistants: users_assistants_bool_exp
  authorNames: author_name_bool_exp
  auxName: String_comparison_exp
  birthDate: timestamp_comparison_exp
  birthPlace: String_comparison_exp
  chosenUserName: String_comparison_exp
  citationCount: Int_comparison_exp
  citingPubCount: Int_comparison_exp
  citsCompleteEnd: date_comparison_exp
  citsCompleteStart: date_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  dead: Boolean_comparison_exp
  deathDate: timestamp_comparison_exp
  degrees: degree_holder_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  digestMode: String_comparison_exp
  disciplines: users_disciplines_bool_exp
  doiCitationCount: Int_comparison_exp
  dtype: String_comparison_exp
  duplumRole: Int_comparison_exp
  duplumSearchResult: duplum_search_result_bool_exp
  duplumSearchResultMtid: bigint_comparison_exp
  email: String_comparison_exp
  emailAddressConfirmed: Boolean_comparison_exp
  enabled: Boolean_comparison_exp
  error: Int_comparison_exp
  familyName: String_comparison_exp
  foreignEditionCitationCount: Int_comparison_exp
  gender: Int_comparison_exp
  givenName: String_comparison_exp
  identifiers: author_identifier_bool_exp
  inactivatedAt: timestamp_comparison_exp
  inactivatedBy: users_bool_exp
  inactivatedByMtid: bigint_comparison_exp
  inactivationComment: String_comparison_exp
  inactiveFrom: timestamp_comparison_exp
  independentCitationCount: Int_comparison_exp
  independentCitingPubCount: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastDataChange: timestamp_comparison_exp
  lastDuplumOK: timestamp_comparison_exp
  lastDuplumSearch: timestamp_comparison_exp
  lastLogin: timestamp_comparison_exp
  lastLogin2: timestamp_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastOnlineAction: timestamp_comparison_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  moreCitationsPerCitingDoc: Boolean_comparison_exp
  mtid: bigint_comparison_exp
  nationalOriginCitationCount: Int_comparison_exp
  needsToChangePasswordUntil: timestamp_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  passwordHash: String_comparison_exp
  phone: String_comparison_exp
  policyAcceptDate: timestamp_comparison_exp
  preferences: user_preferences_bool_exp
  prevValid: bigint_comparison_exp
  pubStats: String_comparison_exp
  publicationCount: Int_comparison_exp
  published: Boolean_comparison_exp
  pubsCompleteEnd: date_comparison_exp
  pubsCompleteStart: date_comparison_exp
  pwFormat: String_comparison_exp
  receiveEmailAlertsForForumEvents: Boolean_comparison_exp
  receiveEmailAlertsForTicketEvents: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  registrationComment: String_comparison_exp
  registrationDate: timestamp_comparison_exp
  rights: String_comparison_exp
  robot: Boolean_comparison_exp
  robotSupervisor: users_bool_exp
  robotSupervisorMtid: bigint_comparison_exp
  scopusCitationCount: Int_comparison_exp
  selectedPubList: named_list_bool_exp
  selectedPubListIsEmpty: Boolean_comparison_exp
  selectedPubListIsOpen: Boolean_comparison_exp
  selectedPubListMtid: bigint_comparison_exp
  shibCreated: timestamp_comparison_exp
  shibId: String_comparison_exp
  shibIdProvider: String_comparison_exp
  speciality: String_comparison_exp
  status: Int_comparison_exp
  summaryTable: report_bool_exp
  summaryTable2: report_bool_exp
  summaryTable2Code: String_comparison_exp
  summaryTable2Csv: report_bool_exp
  summaryTable2Eng: report_bool_exp
  summaryTable2Mtid: bigint_comparison_exp
  summaryTable2Template: report_template_bool_exp
  summaryTable2csvMtid: bigint_comparison_exp
  summaryTable2engMtid: bigint_comparison_exp
  summaryTable2templateMtid: bigint_comparison_exp
  summaryTableCsv: report_bool_exp
  summaryTableCsvMtid: bigint_comparison_exp
  summaryTableEng: report_bool_exp
  summaryTableEngMtid: bigint_comparison_exp
  summaryTableMtid: bigint_comparison_exp
  supervisedRobots: users_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  temporaryAccessToken: String_comparison_exp
  temporaryAccessTokenValidBefore: timestamp_comparison_exp
  unhandledCitationCount: Int_comparison_exp
  unhandledCitingPubCount: Int_comparison_exp
  unhandledTickets: Int_comparison_exp
  userNotificationTime: user_notification_time_bool_exp
  userNotificationTimeMtid: bigint_comparison_exp
  username: String_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  wosCitationCount: Int_comparison_exp
}

# unique or primary key constraints on table "users"
enum users_constraint {
  # unique or primary key constraint
  users_pkey
}

# columns and relationships of "users_disciplines"
type users_disciplines {
  authorMtid: bigint!

  # An object relationship
  discipline: discipline!
  disciplinesMtid: bigint!
}

# aggregated selection of "users_disciplines"
type users_disciplines_aggregate {
  aggregate: users_disciplines_aggregate_fields
  nodes: [users_disciplines!]!
}

# aggregate fields of "users_disciplines"
type users_disciplines_aggregate_fields {
  avg: users_disciplines_avg_fields
  count(columns: [users_disciplines_select_column!], distinct: Boolean): Int
  max: users_disciplines_max_fields
  min: users_disciplines_min_fields
  stddev: users_disciplines_stddev_fields
  stddev_pop: users_disciplines_stddev_pop_fields
  stddev_samp: users_disciplines_stddev_samp_fields
  sum: users_disciplines_sum_fields
  var_pop: users_disciplines_var_pop_fields
  var_samp: users_disciplines_var_samp_fields
  variance: users_disciplines_variance_fields
}

# order by aggregate values of table "users_disciplines"
input users_disciplines_aggregate_order_by {
  avg: users_disciplines_avg_order_by
  count: order_by
  max: users_disciplines_max_order_by
  min: users_disciplines_min_order_by
  stddev: users_disciplines_stddev_order_by
  stddev_pop: users_disciplines_stddev_pop_order_by
  stddev_samp: users_disciplines_stddev_samp_order_by
  sum: users_disciplines_sum_order_by
  var_pop: users_disciplines_var_pop_order_by
  var_samp: users_disciplines_var_samp_order_by
  variance: users_disciplines_variance_order_by
}

# input type for inserting array relation for remote table "users_disciplines"
input users_disciplines_arr_rel_insert_input {
  data: [users_disciplines_insert_input!]!
}

# aggregate avg on columns
type users_disciplines_avg_fields {
  authorMtid: Float
  disciplinesMtid: Float
}

# order by avg() on columns of table "users_disciplines"
input users_disciplines_avg_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# Boolean expression to filter rows from the table "users_disciplines". All fields are combined with a logical 'AND'.
input users_disciplines_bool_exp {
  _and: [users_disciplines_bool_exp]
  _not: users_disciplines_bool_exp
  _or: [users_disciplines_bool_exp]
  authorMtid: bigint_comparison_exp
  discipline: discipline_bool_exp
  disciplinesMtid: bigint_comparison_exp
}

# input type for incrementing integer column in table "users_disciplines"
input users_disciplines_inc_input {
  authorMtid: bigint
  disciplinesMtid: bigint
}

# input type for inserting data into table "users_disciplines"
input users_disciplines_insert_input {
  authorMtid: bigint
  discipline: discipline_obj_rel_insert_input
  disciplinesMtid: bigint
}

# aggregate max on columns
type users_disciplines_max_fields {
  authorMtid: bigint
  disciplinesMtid: bigint
}

# order by max() on columns of table "users_disciplines"
input users_disciplines_max_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# aggregate min on columns
type users_disciplines_min_fields {
  authorMtid: bigint
  disciplinesMtid: bigint
}

# order by min() on columns of table "users_disciplines"
input users_disciplines_min_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# response of any mutation on the table "users_disciplines"
type users_disciplines_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [users_disciplines!]!
}

# input type for inserting object relation for remote table "users_disciplines"
input users_disciplines_obj_rel_insert_input {
  data: users_disciplines_insert_input!
}

# ordering options when selecting data from "users_disciplines"
input users_disciplines_order_by {
  authorMtid: order_by
  discipline: discipline_order_by
  disciplinesMtid: order_by
}

# select columns of table "users_disciplines"
enum users_disciplines_select_column {
  # column name
  authorMtid

  # column name
  disciplinesMtid
}

# input type for updating data in table "users_disciplines"
input users_disciplines_set_input {
  authorMtid: bigint
  disciplinesMtid: bigint
}

# aggregate stddev on columns
type users_disciplines_stddev_fields {
  authorMtid: Float
  disciplinesMtid: Float
}

# order by stddev() on columns of table "users_disciplines"
input users_disciplines_stddev_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# aggregate stddev_pop on columns
type users_disciplines_stddev_pop_fields {
  authorMtid: Float
  disciplinesMtid: Float
}

# order by stddev_pop() on columns of table "users_disciplines"
input users_disciplines_stddev_pop_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# aggregate stddev_samp on columns
type users_disciplines_stddev_samp_fields {
  authorMtid: Float
  disciplinesMtid: Float
}

# order by stddev_samp() on columns of table "users_disciplines"
input users_disciplines_stddev_samp_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# aggregate sum on columns
type users_disciplines_sum_fields {
  authorMtid: bigint
  disciplinesMtid: bigint
}

# order by sum() on columns of table "users_disciplines"
input users_disciplines_sum_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# aggregate var_pop on columns
type users_disciplines_var_pop_fields {
  authorMtid: Float
  disciplinesMtid: Float
}

# order by var_pop() on columns of table "users_disciplines"
input users_disciplines_var_pop_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# aggregate var_samp on columns
type users_disciplines_var_samp_fields {
  authorMtid: Float
  disciplinesMtid: Float
}

# order by var_samp() on columns of table "users_disciplines"
input users_disciplines_var_samp_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# aggregate variance on columns
type users_disciplines_variance_fields {
  authorMtid: Float
  disciplinesMtid: Float
}

# order by variance() on columns of table "users_disciplines"
input users_disciplines_variance_order_by {
  authorMtid: order_by
  disciplinesMtid: order_by
}

# input type for incrementing integer column in table "users"
input users_inc_input {
  approverMtid: bigint
  citationCount: Int
  citingPubCount: Int
  creator: bigint
  doiCitationCount: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  foreignEditionCitationCount: Int
  gender: Int
  inactivatedByMtid: bigint
  independentCitationCount: Int
  independentCitingPubCount: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  oldId: Int
  prevValid: bigint
  publicationCount: Int
  robotSupervisorMtid: bigint
  scopusCitationCount: Int
  selectedPubListMtid: bigint
  status: Int
  summaryTable2Mtid: bigint
  summaryTable2csvMtid: bigint
  summaryTable2engMtid: bigint
  summaryTable2templateMtid: bigint
  summaryTableCsvMtid: bigint
  summaryTableEngMtid: bigint
  summaryTableMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  userNotificationTimeMtid: bigint
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# input type for inserting data into table "users"
input users_insert_input {
  adminRoles: admin_role_arr_rel_insert_input
  affiliations: affiliation_arr_rel_insert_input
  affiliationsForSort: String
  allowedIps: String
  altTab: Boolean
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  assistants: users_assistants_arr_rel_insert_input
  authorNames: author_name_arr_rel_insert_input
  auxName: String
  birthDate: timestamp
  birthPlace: String
  chosenUserName: String
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  dead: Boolean
  deathDate: timestamp
  degrees: degree_holder_arr_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  digestMode: String
  disciplines: users_disciplines_arr_rel_insert_input
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResult: duplum_search_result_obj_rel_insert_input
  duplumSearchResultMtid: bigint
  email: String
  emailAddressConfirmed: Boolean
  enabled: Boolean
  error: Int
  familyName: String
  foreignEditionCitationCount: Int
  gender: Int
  givenName: String
  identifiers: author_identifier_arr_rel_insert_input
  inactivatedAt: timestamp
  inactivatedBy: users_obj_rel_insert_input
  inactivatedByMtid: bigint
  inactivationComment: String
  inactiveFrom: timestamp
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDataChange: timestamp
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastLogin: timestamp
  lastLogin2: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastOnlineAction: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  moreCitationsPerCitingDoc: Boolean
  mtid: bigint
  nationalOriginCitationCount: Int
  needsToChangePasswordUntil: timestamp
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passwordHash: String
  phone: String
  policyAcceptDate: timestamp
  preferences: user_preferences_obj_rel_insert_input
  prevValid: bigint
  pubStats: String
  publicationCount: Int
  published: Boolean
  pubsCompleteEnd: date
  pubsCompleteStart: date
  pwFormat: String
  receiveEmailAlertsForForumEvents: Boolean
  receiveEmailAlertsForTicketEvents: Boolean
  refreshed: Boolean
  registrationComment: String
  registrationDate: timestamp
  rights: String
  robot: Boolean
  robotSupervisor: users_obj_rel_insert_input
  robotSupervisorMtid: bigint
  scopusCitationCount: Int
  selectedPubList: named_list_obj_rel_insert_input
  selectedPubListIsEmpty: Boolean
  selectedPubListIsOpen: Boolean
  selectedPubListMtid: bigint
  shibCreated: timestamp
  shibId: String
  shibIdProvider: String
  speciality: String
  status: Int
  summaryTable: report_obj_rel_insert_input
  summaryTable2: report_obj_rel_insert_input
  summaryTable2Code: String
  summaryTable2Csv: report_obj_rel_insert_input
  summaryTable2Eng: report_obj_rel_insert_input
  summaryTable2Mtid: bigint
  summaryTable2Template: report_template_obj_rel_insert_input
  summaryTable2csvMtid: bigint
  summaryTable2engMtid: bigint
  summaryTable2templateMtid: bigint
  summaryTableCsv: report_obj_rel_insert_input
  summaryTableCsvMtid: bigint
  summaryTableEng: report_obj_rel_insert_input
  summaryTableEngMtid: bigint
  summaryTableMtid: bigint
  supervisedRobots: users_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporaryAccessToken: String
  temporaryAccessTokenValidBefore: timestamp
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  userNotificationTime: user_notification_time_obj_rel_insert_input
  userNotificationTimeMtid: bigint
  username: String
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# aggregate max on columns
type users_max_fields {
  affiliationsForSort: String
  allowedIps: String
  approved: timestamp
  approverMtid: bigint
  auxName: String
  birthDate: timestamp
  birthPlace: String
  chosenUserName: String
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deathDate: timestamp
  deletedDate: timestamp
  digestMode: String
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  email: String
  error: Int
  familyName: String
  foreignEditionCitationCount: Int
  gender: Int
  givenName: String
  inactivatedAt: timestamp
  inactivatedByMtid: bigint
  inactivationComment: String
  inactiveFrom: timestamp
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDataChange: timestamp
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastLogin: timestamp
  lastLogin2: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastOnlineAction: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  needsToChangePasswordUntil: timestamp
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passwordHash: String
  phone: String
  policyAcceptDate: timestamp
  prevValid: bigint
  pubStats: String
  publicationCount: Int
  pubsCompleteEnd: date
  pubsCompleteStart: date
  pwFormat: String
  registrationComment: String
  registrationDate: timestamp
  rights: String
  robotSupervisorMtid: bigint
  scopusCitationCount: Int
  selectedPubListMtid: bigint
  shibCreated: timestamp
  shibId: String
  shibIdProvider: String
  speciality: String
  status: Int
  summaryTable2Code: String
  summaryTable2Mtid: bigint
  summaryTable2csvMtid: bigint
  summaryTable2engMtid: bigint
  summaryTable2templateMtid: bigint
  summaryTableCsvMtid: bigint
  summaryTableEngMtid: bigint
  summaryTableMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporaryAccessToken: String
  temporaryAccessTokenValidBefore: timestamp
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  userNotificationTimeMtid: bigint
  username: String
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# order by max() on columns of table "users"
input users_max_order_by {
  affiliationsForSort: order_by
  allowedIps: order_by
  approved: order_by
  approverMtid: order_by
  auxName: order_by
  birthDate: order_by
  birthPlace: order_by
  chosenUserName: order_by
  citationCount: order_by
  citingPubCount: order_by
  citsCompleteEnd: order_by
  citsCompleteStart: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deathDate: order_by
  deletedDate: order_by
  digestMode: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  email: order_by
  error: order_by
  familyName: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  givenName: order_by
  inactivatedAt: order_by
  inactivatedByMtid: order_by
  inactivationComment: order_by
  inactiveFrom: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  labelEng: order_by
  labelHun: order_by
  lastDataChange: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastLogin: order_by
  lastLogin2: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastOnlineAction: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  needsToChangePasswordUntil: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  passwordHash: order_by
  phone: order_by
  policyAcceptDate: order_by
  prevValid: order_by
  pubStats: order_by
  publicationCount: order_by
  pubsCompleteEnd: order_by
  pubsCompleteStart: order_by
  pwFormat: order_by
  registrationComment: order_by
  registrationDate: order_by
  rights: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  shibCreated: order_by
  shibId: order_by
  shibIdProvider: order_by
  speciality: order_by
  status: order_by
  summaryTable2Code: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  temporaryAccessToken: order_by
  temporaryAccessTokenValidBefore: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  username: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate min on columns
type users_min_fields {
  affiliationsForSort: String
  allowedIps: String
  approved: timestamp
  approverMtid: bigint
  auxName: String
  birthDate: timestamp
  birthPlace: String
  chosenUserName: String
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deathDate: timestamp
  deletedDate: timestamp
  digestMode: String
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  email: String
  error: Int
  familyName: String
  foreignEditionCitationCount: Int
  gender: Int
  givenName: String
  inactivatedAt: timestamp
  inactivatedByMtid: bigint
  inactivationComment: String
  inactiveFrom: timestamp
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDataChange: timestamp
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastLogin: timestamp
  lastLogin2: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastOnlineAction: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  needsToChangePasswordUntil: timestamp
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passwordHash: String
  phone: String
  policyAcceptDate: timestamp
  prevValid: bigint
  pubStats: String
  publicationCount: Int
  pubsCompleteEnd: date
  pubsCompleteStart: date
  pwFormat: String
  registrationComment: String
  registrationDate: timestamp
  rights: String
  robotSupervisorMtid: bigint
  scopusCitationCount: Int
  selectedPubListMtid: bigint
  shibCreated: timestamp
  shibId: String
  shibIdProvider: String
  speciality: String
  status: Int
  summaryTable2Code: String
  summaryTable2Mtid: bigint
  summaryTable2csvMtid: bigint
  summaryTable2engMtid: bigint
  summaryTable2templateMtid: bigint
  summaryTableCsvMtid: bigint
  summaryTableEngMtid: bigint
  summaryTableMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporaryAccessToken: String
  temporaryAccessTokenValidBefore: timestamp
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  userNotificationTimeMtid: bigint
  username: String
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# order by min() on columns of table "users"
input users_min_order_by {
  affiliationsForSort: order_by
  allowedIps: order_by
  approved: order_by
  approverMtid: order_by
  auxName: order_by
  birthDate: order_by
  birthPlace: order_by
  chosenUserName: order_by
  citationCount: order_by
  citingPubCount: order_by
  citsCompleteEnd: order_by
  citsCompleteStart: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deathDate: order_by
  deletedDate: order_by
  digestMode: order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  email: order_by
  error: order_by
  familyName: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  givenName: order_by
  inactivatedAt: order_by
  inactivatedByMtid: order_by
  inactivationComment: order_by
  inactiveFrom: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  labelEng: order_by
  labelHun: order_by
  lastDataChange: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastLogin: order_by
  lastLogin2: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastOnlineAction: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  needsToChangePasswordUntil: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  passwordHash: order_by
  phone: order_by
  policyAcceptDate: order_by
  prevValid: order_by
  pubStats: order_by
  publicationCount: order_by
  pubsCompleteEnd: order_by
  pubsCompleteStart: order_by
  pwFormat: order_by
  registrationComment: order_by
  registrationDate: order_by
  rights: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  shibCreated: order_by
  shibId: order_by
  shibIdProvider: order_by
  speciality: order_by
  status: order_by
  summaryTable2Code: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  temporaryAccessToken: order_by
  temporaryAccessTokenValidBefore: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  username: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# response of any mutation on the table "users"
type users_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [users!]!
}

# input type for inserting object relation for remote table "users"
input users_obj_rel_insert_input {
  data: users_insert_input!
  on_conflict: users_on_conflict
}

# on conflict condition type for table "users"
input users_on_conflict {
  constraint: users_constraint!
  update_columns: [users_update_column!]!
  where: users_bool_exp
}

# ordering options when selecting data from "users"
input users_order_by {
  adminRoles_aggregate: admin_role_aggregate_order_by
  affiliationsForSort: order_by
  affiliations_aggregate: affiliation_aggregate_order_by
  allowedIps: order_by
  altTab: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  assistants_aggregate: users_assistants_aggregate_order_by
  authorNames_aggregate: author_name_aggregate_order_by
  auxName: order_by
  birthDate: order_by
  birthPlace: order_by
  chosenUserName: order_by
  citationCount: order_by
  citingPubCount: order_by
  citsCompleteEnd: order_by
  citsCompleteStart: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  dead: order_by
  deathDate: order_by
  degrees_aggregate: degree_holder_aggregate_order_by
  deleted: order_by
  deletedDate: order_by
  digestMode: order_by
  disciplines_aggregate: users_disciplines_aggregate_order_by
  doiCitationCount: order_by
  dtype: order_by
  duplumRole: order_by
  duplumSearchResult: duplum_search_result_order_by
  duplumSearchResultMtid: order_by
  email: order_by
  emailAddressConfirmed: order_by
  enabled: order_by
  error: order_by
  familyName: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  givenName: order_by
  identifiers_aggregate: author_identifier_aggregate_order_by
  inactivatedAt: order_by
  inactivatedBy: users_order_by
  inactivatedByMtid: order_by
  inactivationComment: order_by
  inactiveFrom: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  labelEng: order_by
  labelHun: order_by
  lastDataChange: order_by
  lastDuplumOK: order_by
  lastDuplumSearch: order_by
  lastLogin: order_by
  lastLogin2: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastOnlineAction: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  moreCitationsPerCitingDoc: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  needsToChangePasswordUntil: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  passwordHash: order_by
  phone: order_by
  policyAcceptDate: order_by
  preferences: user_preferences_order_by
  prevValid: order_by
  pubStats: order_by
  publicationCount: order_by
  published: order_by
  pubsCompleteEnd: order_by
  pubsCompleteStart: order_by
  pwFormat: order_by
  receiveEmailAlertsForForumEvents: order_by
  receiveEmailAlertsForTicketEvents: order_by
  refreshed: order_by
  registrationComment: order_by
  registrationDate: order_by
  rights: order_by
  robot: order_by
  robotSupervisor: users_order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubList: named_list_order_by
  selectedPubListIsEmpty: order_by
  selectedPubListIsOpen: order_by
  selectedPubListMtid: order_by
  shibCreated: order_by
  shibId: order_by
  shibIdProvider: order_by
  speciality: order_by
  status: order_by
  summaryTable: report_order_by
  summaryTable2: report_order_by
  summaryTable2Code: order_by
  summaryTable2Csv: report_order_by
  summaryTable2Eng: report_order_by
  summaryTable2Mtid: order_by
  summaryTable2Template: report_template_order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsv: report_order_by
  summaryTableCsvMtid: order_by
  summaryTableEng: report_order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  supervisedRobots_aggregate: users_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  temporaryAccessToken: order_by
  temporaryAccessTokenValidBefore: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTime: user_notification_time_order_by
  userNotificationTimeMtid: order_by
  username: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# primary key columns input for table: "users"
input users_pk_columns_input {
  mtid: bigint!
}

# select columns of table "users"
enum users_select_column {
  # column name
  affiliationsForSort

  # column name
  allowedIps

  # column name
  altTab

  # column name
  approved

  # column name
  approverMtid

  # column name
  auxName

  # column name
  birthDate

  # column name
  birthPlace

  # column name
  chosenUserName

  # column name
  citationCount

  # column name
  citingPubCount

  # column name
  citsCompleteEnd

  # column name
  citsCompleteStart

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dead

  # column name
  deathDate

  # column name
  deleted

  # column name
  deletedDate

  # column name
  digestMode

  # column name
  doiCitationCount

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  email

  # column name
  emailAddressConfirmed

  # column name
  enabled

  # column name
  error

  # column name
  familyName

  # column name
  foreignEditionCitationCount

  # column name
  gender

  # column name
  givenName

  # column name
  inactivatedAt

  # column name
  inactivatedByMtid

  # column name
  inactivationComment

  # column name
  inactiveFrom

  # column name
  independentCitationCount

  # column name
  independentCitingPubCount

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDataChange

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastLogin

  # column name
  lastLogin2

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastOnlineAction

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  moreCitationsPerCitingDoc

  # column name
  mtid

  # column name
  nationalOriginCitationCount

  # column name
  needsToChangePasswordUntil

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  passwordHash

  # column name
  phone

  # column name
  policyAcceptDate

  # column name
  prevValid

  # column name
  pubStats

  # column name
  publicationCount

  # column name
  published

  # column name
  pubsCompleteEnd

  # column name
  pubsCompleteStart

  # column name
  pwFormat

  # column name
  receiveEmailAlertsForForumEvents

  # column name
  receiveEmailAlertsForTicketEvents

  # column name
  refreshed

  # column name
  registrationComment

  # column name
  registrationDate

  # column name
  rights

  # column name
  robot

  # column name
  robotSupervisorMtid

  # column name
  scopusCitationCount

  # column name
  selectedPubListIsEmpty

  # column name
  selectedPubListIsOpen

  # column name
  selectedPubListMtid

  # column name
  shibCreated

  # column name
  shibId

  # column name
  shibIdProvider

  # column name
  speciality

  # column name
  status

  # column name
  summaryTable2Code

  # column name
  summaryTable2Mtid

  # column name
  summaryTable2csvMtid

  # column name
  summaryTable2engMtid

  # column name
  summaryTable2templateMtid

  # column name
  summaryTableCsvMtid

  # column name
  summaryTableEngMtid

  # column name
  summaryTableMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  temporaryAccessToken

  # column name
  temporaryAccessTokenValidBefore

  # column name
  unhandledCitationCount

  # column name
  unhandledCitingPubCount

  # column name
  unhandledTickets

  # column name
  userNotificationTimeMtid

  # column name
  username

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  wosCitationCount
}

# input type for updating data in table "users"
input users_set_input {
  affiliationsForSort: String
  allowedIps: String
  altTab: Boolean
  approved: timestamp
  approverMtid: bigint
  auxName: String
  birthDate: timestamp
  birthPlace: String
  chosenUserName: String
  citationCount: Int
  citingPubCount: Int
  citsCompleteEnd: date
  citsCompleteStart: date
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  dead: Boolean
  deathDate: timestamp
  deleted: Boolean
  deletedDate: timestamp
  digestMode: String
  doiCitationCount: Int
  dtype: String
  duplumRole: Int
  duplumSearchResultMtid: bigint
  email: String
  emailAddressConfirmed: Boolean
  enabled: Boolean
  error: Int
  familyName: String
  foreignEditionCitationCount: Int
  gender: Int
  givenName: String
  inactivatedAt: timestamp
  inactivatedByMtid: bigint
  inactivationComment: String
  inactiveFrom: timestamp
  independentCitationCount: Int
  independentCitingPubCount: Int
  labelEng: String
  labelHun: String
  lastDataChange: timestamp
  lastDuplumOK: timestamp
  lastDuplumSearch: timestamp
  lastLogin: timestamp
  lastLogin2: timestamp
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastOnlineAction: timestamp
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  moreCitationsPerCitingDoc: Boolean
  mtid: bigint
  nationalOriginCitationCount: Int
  needsToChangePasswordUntil: timestamp
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  passwordHash: String
  phone: String
  policyAcceptDate: timestamp
  prevValid: bigint
  pubStats: String
  publicationCount: Int
  published: Boolean
  pubsCompleteEnd: date
  pubsCompleteStart: date
  pwFormat: String
  receiveEmailAlertsForForumEvents: Boolean
  receiveEmailAlertsForTicketEvents: Boolean
  refreshed: Boolean
  registrationComment: String
  registrationDate: timestamp
  rights: String
  robot: Boolean
  robotSupervisorMtid: bigint
  scopusCitationCount: Int
  selectedPubListIsEmpty: Boolean
  selectedPubListIsOpen: Boolean
  selectedPubListMtid: bigint
  shibCreated: timestamp
  shibId: String
  shibIdProvider: String
  speciality: String
  status: Int
  summaryTable2Code: String
  summaryTable2Mtid: bigint
  summaryTable2csvMtid: bigint
  summaryTable2engMtid: bigint
  summaryTable2templateMtid: bigint
  summaryTableCsvMtid: bigint
  summaryTableEngMtid: bigint
  summaryTableMtid: bigint
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  temporaryAccessToken: String
  temporaryAccessTokenValidBefore: timestamp
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  userNotificationTimeMtid: bigint
  username: String
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# aggregate stddev on columns
type users_stddev_fields {
  approverMtid: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  gender: Float
  inactivatedByMtid: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  robotSupervisorMtid: Float
  scopusCitationCount: Float
  selectedPubListMtid: Float
  status: Float
  summaryTable2Mtid: Float
  summaryTable2csvMtid: Float
  summaryTable2engMtid: Float
  summaryTable2templateMtid: Float
  summaryTableCsvMtid: Float
  summaryTableEngMtid: Float
  summaryTableMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  userNotificationTimeMtid: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by stddev() on columns of table "users"
input users_stddev_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate stddev_pop on columns
type users_stddev_pop_fields {
  approverMtid: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  gender: Float
  inactivatedByMtid: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  robotSupervisorMtid: Float
  scopusCitationCount: Float
  selectedPubListMtid: Float
  status: Float
  summaryTable2Mtid: Float
  summaryTable2csvMtid: Float
  summaryTable2engMtid: Float
  summaryTable2templateMtid: Float
  summaryTableCsvMtid: Float
  summaryTableEngMtid: Float
  summaryTableMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  userNotificationTimeMtid: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by stddev_pop() on columns of table "users"
input users_stddev_pop_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate stddev_samp on columns
type users_stddev_samp_fields {
  approverMtid: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  gender: Float
  inactivatedByMtid: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  robotSupervisorMtid: Float
  scopusCitationCount: Float
  selectedPubListMtid: Float
  status: Float
  summaryTable2Mtid: Float
  summaryTable2csvMtid: Float
  summaryTable2engMtid: Float
  summaryTable2templateMtid: Float
  summaryTableCsvMtid: Float
  summaryTableEngMtid: Float
  summaryTableMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  userNotificationTimeMtid: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by stddev_samp() on columns of table "users"
input users_stddev_samp_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate sum on columns
type users_sum_fields {
  approverMtid: bigint
  citationCount: Int
  citingPubCount: Int
  creator: bigint
  doiCitationCount: Int
  duplumRole: Int
  duplumSearchResultMtid: bigint
  error: Int
  foreignEditionCitationCount: Int
  gender: Int
  inactivatedByMtid: bigint
  independentCitationCount: Int
  independentCitingPubCount: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  nationalOriginCitationCount: Int
  oldId: Int
  prevValid: bigint
  publicationCount: Int
  robotSupervisorMtid: bigint
  scopusCitationCount: Int
  selectedPubListMtid: bigint
  status: Int
  summaryTable2Mtid: bigint
  summaryTable2csvMtid: bigint
  summaryTable2engMtid: bigint
  summaryTable2templateMtid: bigint
  summaryTableCsvMtid: bigint
  summaryTableEngMtid: bigint
  summaryTableMtid: bigint
  unhandledCitationCount: Int
  unhandledCitingPubCount: Int
  unhandledTickets: Int
  userNotificationTimeMtid: bigint
  validFromYear: smallint
  validToYear: smallint
  wosCitationCount: Int
}

# order by sum() on columns of table "users"
input users_sum_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# update columns of table "users"
enum users_update_column {
  # column name
  affiliationsForSort

  # column name
  allowedIps

  # column name
  altTab

  # column name
  approved

  # column name
  approverMtid

  # column name
  auxName

  # column name
  birthDate

  # column name
  birthPlace

  # column name
  chosenUserName

  # column name
  citationCount

  # column name
  citingPubCount

  # column name
  citsCompleteEnd

  # column name
  citsCompleteStart

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  dead

  # column name
  deathDate

  # column name
  deleted

  # column name
  deletedDate

  # column name
  digestMode

  # column name
  doiCitationCount

  # column name
  dtype

  # column name
  duplumRole

  # column name
  duplumSearchResultMtid

  # column name
  email

  # column name
  emailAddressConfirmed

  # column name
  enabled

  # column name
  error

  # column name
  familyName

  # column name
  foreignEditionCitationCount

  # column name
  gender

  # column name
  givenName

  # column name
  inactivatedAt

  # column name
  inactivatedByMtid

  # column name
  inactivationComment

  # column name
  inactiveFrom

  # column name
  independentCitationCount

  # column name
  independentCitingPubCount

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastDataChange

  # column name
  lastDuplumOK

  # column name
  lastDuplumSearch

  # column name
  lastLogin

  # column name
  lastLogin2

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastOnlineAction

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  moreCitationsPerCitingDoc

  # column name
  mtid

  # column name
  nationalOriginCitationCount

  # column name
  needsToChangePasswordUntil

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  passwordHash

  # column name
  phone

  # column name
  policyAcceptDate

  # column name
  prevValid

  # column name
  pubStats

  # column name
  publicationCount

  # column name
  published

  # column name
  pubsCompleteEnd

  # column name
  pubsCompleteStart

  # column name
  pwFormat

  # column name
  receiveEmailAlertsForForumEvents

  # column name
  receiveEmailAlertsForTicketEvents

  # column name
  refreshed

  # column name
  registrationComment

  # column name
  registrationDate

  # column name
  rights

  # column name
  robot

  # column name
  robotSupervisorMtid

  # column name
  scopusCitationCount

  # column name
  selectedPubListIsEmpty

  # column name
  selectedPubListIsOpen

  # column name
  selectedPubListMtid

  # column name
  shibCreated

  # column name
  shibId

  # column name
  shibIdProvider

  # column name
  speciality

  # column name
  status

  # column name
  summaryTable2Code

  # column name
  summaryTable2Mtid

  # column name
  summaryTable2csvMtid

  # column name
  summaryTable2engMtid

  # column name
  summaryTable2templateMtid

  # column name
  summaryTableCsvMtid

  # column name
  summaryTableEngMtid

  # column name
  summaryTableMtid

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  temporaryAccessToken

  # column name
  temporaryAccessTokenValidBefore

  # column name
  unhandledCitationCount

  # column name
  unhandledCitingPubCount

  # column name
  unhandledTickets

  # column name
  userNotificationTimeMtid

  # column name
  username

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  wosCitationCount
}

# aggregate var_pop on columns
type users_var_pop_fields {
  approverMtid: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  gender: Float
  inactivatedByMtid: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  robotSupervisorMtid: Float
  scopusCitationCount: Float
  selectedPubListMtid: Float
  status: Float
  summaryTable2Mtid: Float
  summaryTable2csvMtid: Float
  summaryTable2engMtid: Float
  summaryTable2templateMtid: Float
  summaryTableCsvMtid: Float
  summaryTableEngMtid: Float
  summaryTableMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  userNotificationTimeMtid: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by var_pop() on columns of table "users"
input users_var_pop_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate var_samp on columns
type users_var_samp_fields {
  approverMtid: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  gender: Float
  inactivatedByMtid: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  robotSupervisorMtid: Float
  scopusCitationCount: Float
  selectedPubListMtid: Float
  status: Float
  summaryTable2Mtid: Float
  summaryTable2csvMtid: Float
  summaryTable2engMtid: Float
  summaryTable2templateMtid: Float
  summaryTableCsvMtid: Float
  summaryTableEngMtid: Float
  summaryTableMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  userNotificationTimeMtid: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by var_samp() on columns of table "users"
input users_var_samp_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# aggregate variance on columns
type users_variance_fields {
  approverMtid: Float
  citationCount: Float
  citingPubCount: Float
  creator: Float
  doiCitationCount: Float
  duplumRole: Float
  duplumSearchResultMtid: Float
  error: Float
  foreignEditionCitationCount: Float
  gender: Float
  inactivatedByMtid: Float
  independentCitationCount: Float
  independentCitingPubCount: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  nationalOriginCitationCount: Float
  oldId: Float
  prevValid: Float
  publicationCount: Float
  robotSupervisorMtid: Float
  scopusCitationCount: Float
  selectedPubListMtid: Float
  status: Float
  summaryTable2Mtid: Float
  summaryTable2csvMtid: Float
  summaryTable2engMtid: Float
  summaryTable2templateMtid: Float
  summaryTableCsvMtid: Float
  summaryTableEngMtid: Float
  summaryTableMtid: Float
  unhandledCitationCount: Float
  unhandledCitingPubCount: Float
  unhandledTickets: Float
  userNotificationTimeMtid: Float
  validFromYear: Float
  validToYear: Float
  wosCitationCount: Float
}

# order by variance() on columns of table "users"
input users_variance_order_by {
  approverMtid: order_by
  citationCount: order_by
  citingPubCount: order_by
  creator: order_by
  doiCitationCount: order_by
  duplumRole: order_by
  duplumSearchResultMtid: order_by
  error: order_by
  foreignEditionCitationCount: order_by
  gender: order_by
  inactivatedByMtid: order_by
  independentCitationCount: order_by
  independentCitingPubCount: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  nationalOriginCitationCount: order_by
  oldId: order_by
  prevValid: order_by
  publicationCount: order_by
  robotSupervisorMtid: order_by
  scopusCitationCount: order_by
  selectedPubListMtid: order_by
  status: order_by
  summaryTable2Mtid: order_by
  summaryTable2csvMtid: order_by
  summaryTable2engMtid: order_by
  summaryTable2templateMtid: order_by
  summaryTableCsvMtid: order_by
  summaryTableEngMtid: order_by
  summaryTableMtid: order_by
  unhandledCitationCount: order_by
  unhandledCitingPubCount: order_by
  unhandledTickets: order_by
  userNotificationTimeMtid: order_by
  validFromYear: order_by
  validToYear: order_by
  wosCitationCount: order_by
}

# columns and relationships of "variable"
type variable {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  cacheInterval: Int!
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  help: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregated selection of "variable"
type variable_aggregate {
  aggregate: variable_aggregate_fields
  nodes: [variable!]!
}

# aggregate fields of "variable"
type variable_aggregate_fields {
  avg: variable_avg_fields
  count(columns: [variable_select_column!], distinct: Boolean): Int
  max: variable_max_fields
  min: variable_min_fields
  stddev: variable_stddev_fields
  stddev_pop: variable_stddev_pop_fields
  stddev_samp: variable_stddev_samp_fields
  sum: variable_sum_fields
  var_pop: variable_var_pop_fields
  var_samp: variable_var_samp_fields
  variance: variable_variance_fields
}

# order by aggregate values of table "variable"
input variable_aggregate_order_by {
  avg: variable_avg_order_by
  count: order_by
  max: variable_max_order_by
  min: variable_min_order_by
  stddev: variable_stddev_order_by
  stddev_pop: variable_stddev_pop_order_by
  stddev_samp: variable_stddev_samp_order_by
  sum: variable_sum_order_by
  var_pop: variable_var_pop_order_by
  var_samp: variable_var_samp_order_by
  variance: variable_variance_order_by
}

# input type for inserting array relation for remote table "variable"
input variable_arr_rel_insert_input {
  data: [variable_insert_input!]!
  on_conflict: variable_on_conflict
}

# aggregate avg on columns
type variable_avg_fields {
  approverMtid: Float
  cacheInterval: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "variable"
input variable_avg_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "variable". All fields are combined with a logical 'AND'.
input variable_bool_exp {
  _and: [variable_bool_exp]
  _not: variable_bool_exp
  _or: [variable_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  cacheInterval: Int_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  help: String_comparison_exp
  hint: String_comparison_exp
  hintEng: String_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  value: String_comparison_exp
}

# unique or primary key constraints on table "variable"
enum variable_constraint {
  # unique or primary key constraint
  variable_pkey
}

# input type for incrementing integer column in table "variable"
input variable_inc_input {
  approverMtid: bigint
  cacheInterval: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "variable"
input variable_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  cacheInterval: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  help: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregate max on columns
type variable_max_fields {
  approved: timestamp
  approverMtid: bigint
  cacheInterval: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  help: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# order by max() on columns of table "variable"
input variable_max_order_by {
  approved: order_by
  approverMtid: order_by
  cacheInterval: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  help: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# aggregate min on columns
type variable_min_fields {
  approved: timestamp
  approverMtid: bigint
  cacheInterval: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  help: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# order by min() on columns of table "variable"
input variable_min_order_by {
  approved: order_by
  approverMtid: order_by
  cacheInterval: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  help: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# response of any mutation on the table "variable"
type variable_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [variable!]!
}

# input type for inserting object relation for remote table "variable"
input variable_obj_rel_insert_input {
  data: variable_insert_input!
  on_conflict: variable_on_conflict
}

# on conflict condition type for table "variable"
input variable_on_conflict {
  constraint: variable_constraint!
  update_columns: [variable_update_column!]!
  where: variable_bool_exp
}

# ordering options when selecting data from "variable"
input variable_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  cacheInterval: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  help: order_by
  hint: order_by
  hintEng: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  value: order_by
}

# primary key columns input for table: "variable"
input variable_pk_columns_input {
  mtid: bigint!
}

# select columns of table "variable"
enum variable_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  cacheInterval

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  help

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  value
}

# input type for updating data in table "variable"
input variable_set_input {
  approved: timestamp
  approverMtid: bigint
  cacheInterval: Int
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  help: String
  hint: String
  hintEng: String
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  value: String
}

# aggregate stddev on columns
type variable_stddev_fields {
  approverMtid: Float
  cacheInterval: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "variable"
input variable_stddev_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type variable_stddev_pop_fields {
  approverMtid: Float
  cacheInterval: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "variable"
input variable_stddev_pop_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type variable_stddev_samp_fields {
  approverMtid: Float
  cacheInterval: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "variable"
input variable_stddev_samp_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate sum on columns
type variable_sum_fields {
  approverMtid: bigint
  cacheInterval: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "variable"
input variable_sum_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "variable"
enum variable_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  cacheInterval

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  help

  # column name
  hint

  # column name
  hintEng

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  value
}

# aggregate var_pop on columns
type variable_var_pop_fields {
  approverMtid: Float
  cacheInterval: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "variable"
input variable_var_pop_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type variable_var_samp_fields {
  approverMtid: Float
  cacheInterval: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "variable"
input variable_var_samp_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type variable_variance_fields {
  approverMtid: Float
  cacheInterval: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "variable"
input variable_variance_order_by {
  approverMtid: order_by
  cacheInterval: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "workflow"
type workflow {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  minimumRole: Int
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  query: String
  recordType: String
  refreshed: Boolean!
  requiresList: Boolean!
  sorter: String
  status: Int

  # An array relationship
  steps(
    # distinct select on columns
    distinct_on: [workflow_step_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_order_by!]

    # filter the rows returned
    where: workflow_step_bool_exp
  ): [workflow_step!]!

  # An aggregated array relationship
  steps_aggregate(
    # distinct select on columns
    distinct_on: [workflow_step_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_order_by!]

    # filter the rows returned
    where: workflow_step_bool_exp
  ): workflow_step_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint
}

# aggregated selection of "workflow"
type workflow_aggregate {
  aggregate: workflow_aggregate_fields
  nodes: [workflow!]!
}

# aggregate fields of "workflow"
type workflow_aggregate_fields {
  avg: workflow_avg_fields
  count(columns: [workflow_select_column!], distinct: Boolean): Int
  max: workflow_max_fields
  min: workflow_min_fields
  stddev: workflow_stddev_fields
  stddev_pop: workflow_stddev_pop_fields
  stddev_samp: workflow_stddev_samp_fields
  sum: workflow_sum_fields
  var_pop: workflow_var_pop_fields
  var_samp: workflow_var_samp_fields
  variance: workflow_variance_fields
}

# order by aggregate values of table "workflow"
input workflow_aggregate_order_by {
  avg: workflow_avg_order_by
  count: order_by
  max: workflow_max_order_by
  min: workflow_min_order_by
  stddev: workflow_stddev_order_by
  stddev_pop: workflow_stddev_pop_order_by
  stddev_samp: workflow_stddev_samp_order_by
  sum: workflow_sum_order_by
  var_pop: workflow_var_pop_order_by
  var_samp: workflow_var_samp_order_by
  variance: workflow_variance_order_by
}

# input type for inserting array relation for remote table "workflow"
input workflow_arr_rel_insert_input {
  data: [workflow_insert_input!]!
  on_conflict: workflow_on_conflict
}

# aggregate avg on columns
type workflow_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by avg() on columns of table "workflow"
input workflow_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# Boolean expression to filter rows from the table "workflow". All fields are combined with a logical 'AND'.
input workflow_bool_exp {
  _and: [workflow_bool_exp]
  _not: workflow_bool_exp
  _or: [workflow_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  description: String_comparison_exp
  descriptionEng: String_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  minimumRole: Int_comparison_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  query: String_comparison_exp
  recordType: String_comparison_exp
  refreshed: Boolean_comparison_exp
  requiresList: Boolean_comparison_exp
  sorter: String_comparison_exp
  status: Int_comparison_exp
  steps: workflow_step_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
}

# unique or primary key constraints on table "workflow"
enum workflow_constraint {
  # unique or primary key constraint
  workflow_pkey
}

# input type for incrementing integer column in table "workflow"
input workflow_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# input type for inserting data into table "workflow"
input workflow_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  query: String
  recordType: String
  refreshed: Boolean
  requiresList: Boolean
  sorter: String
  status: Int
  steps: workflow_step_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# aggregate max on columns
type workflow_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  query: String
  recordType: String
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by max() on columns of table "workflow"
input workflow_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  description: order_by
  descriptionEng: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  query: order_by
  recordType: order_by
  sorter: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate min on columns
type workflow_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  query: String
  recordType: String
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by min() on columns of table "workflow"
input workflow_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  description: order_by
  descriptionEng: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  query: order_by
  recordType: order_by
  sorter: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# response of any mutation on the table "workflow"
type workflow_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [workflow!]!
}

# input type for inserting object relation for remote table "workflow"
input workflow_obj_rel_insert_input {
  data: workflow_insert_input!
  on_conflict: workflow_on_conflict
}

# on conflict condition type for table "workflow"
input workflow_on_conflict {
  constraint: workflow_constraint!
  update_columns: [workflow_update_column!]!
  where: workflow_bool_exp
}

# ordering options when selecting data from "workflow"
input workflow_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  description: order_by
  descriptionEng: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  minimumRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  query: order_by
  recordType: order_by
  refreshed: order_by
  requiresList: order_by
  sorter: order_by
  status: order_by
  steps_aggregate: workflow_step_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# primary key columns input for table: "workflow"
input workflow_pk_columns_input {
  mtid: bigint!
}

# select columns of table "workflow"
enum workflow_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  description

  # column name
  descriptionEng

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  minimumRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  query

  # column name
  recordType

  # column name
  refreshed

  # column name
  requiresList

  # column name
  sorter

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# input type for updating data in table "workflow"
input workflow_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  locked: timestamp
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  query: String
  recordType: String
  refreshed: Boolean
  requiresList: Boolean
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# columns and relationships of "workflow_status"
type workflow_status {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  completed: Boolean!
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list_mtid: bigint
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int

  # An array relationship
  stepStatuses(
    # distinct select on columns
    distinct_on: [workflow_step_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_status_order_by!]

    # filter the rows returned
    where: workflow_step_status_bool_exp
  ): [workflow_step_status!]!

  # An aggregated array relationship
  stepStatuses_aggregate(
    # distinct select on columns
    distinct_on: [workflow_step_status_select_column!]

    # limit the number of rows returned
    limit: Int

    # skip the first n rows. Use only with order_by
    offset: Int

    # sort the rows by one or more columns
    order_by: [workflow_step_status_order_by!]

    # filter the rows returned
    where: workflow_step_status_bool_exp
  ): workflow_step_status_aggregate!
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint

  # An object relationship
  workflow: workflow
  workflowMtid: bigint
}

# aggregated selection of "workflow_status"
type workflow_status_aggregate {
  aggregate: workflow_status_aggregate_fields
  nodes: [workflow_status!]!
}

# aggregate fields of "workflow_status"
type workflow_status_aggregate_fields {
  avg: workflow_status_avg_fields
  count(columns: [workflow_status_select_column!], distinct: Boolean): Int
  max: workflow_status_max_fields
  min: workflow_status_min_fields
  stddev: workflow_status_stddev_fields
  stddev_pop: workflow_status_stddev_pop_fields
  stddev_samp: workflow_status_stddev_samp_fields
  sum: workflow_status_sum_fields
  var_pop: workflow_status_var_pop_fields
  var_samp: workflow_status_var_samp_fields
  variance: workflow_status_variance_fields
}

# order by aggregate values of table "workflow_status"
input workflow_status_aggregate_order_by {
  avg: workflow_status_avg_order_by
  count: order_by
  max: workflow_status_max_order_by
  min: workflow_status_min_order_by
  stddev: workflow_status_stddev_order_by
  stddev_pop: workflow_status_stddev_pop_order_by
  stddev_samp: workflow_status_stddev_samp_order_by
  sum: workflow_status_sum_order_by
  var_pop: workflow_status_var_pop_order_by
  var_samp: workflow_status_var_samp_order_by
  variance: workflow_status_variance_order_by
}

# input type for inserting array relation for remote table "workflow_status"
input workflow_status_arr_rel_insert_input {
  data: [workflow_status_insert_input!]!
  on_conflict: workflow_status_on_conflict
}

# aggregate avg on columns
type workflow_status_avg_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  list_mtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by avg() on columns of table "workflow_status"
input workflow_status_avg_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# Boolean expression to filter rows from the table "workflow_status". All fields are combined with a logical 'AND'.
input workflow_status_bool_exp {
  _and: [workflow_status_bool_exp]
  _not: workflow_status_bool_exp
  _or: [workflow_status_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  completed: Boolean_comparison_exp
  count: Int_comparison_exp
  countUncut: Int_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  list_mtid: bigint_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  stepStatuses: workflow_step_status_bool_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  workflow: workflow_bool_exp
  workflowMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "workflow_status"
enum workflow_status_constraint {
  # unique or primary key constraint
  workflow_status_pkey
}

# input type for incrementing integer column in table "workflow_status"
input workflow_status_inc_input {
  approverMtid: bigint
  count: Int
  countUncut: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  list_mtid: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# input type for inserting data into table "workflow_status"
input workflow_status_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  completed: Boolean
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list_mtid: bigint
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  stepStatuses: workflow_step_status_arr_rel_insert_input
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflow: workflow_obj_rel_insert_input
  workflowMtid: bigint
}

# aggregate max on columns
type workflow_status_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list_mtid: bigint
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# order by max() on columns of table "workflow_status"
input workflow_status_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  countUncut: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list_mtid: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate min on columns
type workflow_status_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list_mtid: bigint
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# order by min() on columns of table "workflow_status"
input workflow_status_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  countUncut: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list_mtid: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# response of any mutation on the table "workflow_status"
type workflow_status_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [workflow_status!]!
}

# input type for inserting object relation for remote table "workflow_status"
input workflow_status_obj_rel_insert_input {
  data: workflow_status_insert_input!
  on_conflict: workflow_status_on_conflict
}

# on conflict condition type for table "workflow_status"
input workflow_status_on_conflict {
  constraint: workflow_status_constraint!
  update_columns: [workflow_status_update_column!]!
  where: workflow_status_bool_exp
}

# ordering options when selecting data from "workflow_status"
input workflow_status_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  completed: order_by
  count: order_by
  countUncut: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  list_mtid: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  name: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  stepStatuses_aggregate: workflow_step_status_aggregate_order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflow: workflow_order_by
  workflowMtid: order_by
}

# primary key columns input for table: "workflow_status"
input workflow_status_pk_columns_input {
  mtid: bigint!
}

# select columns of table "workflow_status"
enum workflow_status_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  completed

  # column name
  count

  # column name
  countUncut

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list_mtid

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  workflowMtid
}

# input type for updating data in table "workflow_status"
input workflow_status_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  completed: Boolean
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  list_mtid: bigint
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  name: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# aggregate stddev on columns
type workflow_status_stddev_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  list_mtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by stddev() on columns of table "workflow_status"
input workflow_status_stddev_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate stddev_pop on columns
type workflow_status_stddev_pop_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  list_mtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by stddev_pop() on columns of table "workflow_status"
input workflow_status_stddev_pop_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate stddev_samp on columns
type workflow_status_stddev_samp_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  list_mtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by stddev_samp() on columns of table "workflow_status"
input workflow_status_stddev_samp_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate sum on columns
type workflow_status_sum_fields {
  approverMtid: bigint
  count: Int
  countUncut: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  list_mtid: bigint
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# order by sum() on columns of table "workflow_status"
input workflow_status_sum_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# update columns of table "workflow_status"
enum workflow_status_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  completed

  # column name
  count

  # column name
  countUncut

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  list_mtid

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  name

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  workflowMtid
}

# aggregate var_pop on columns
type workflow_status_var_pop_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  list_mtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by var_pop() on columns of table "workflow_status"
input workflow_status_var_pop_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate var_samp on columns
type workflow_status_var_samp_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  list_mtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by var_samp() on columns of table "workflow_status"
input workflow_status_var_samp_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate variance on columns
type workflow_status_variance_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  list_mtid: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by variance() on columns of table "workflow_status"
input workflow_status_variance_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  list_mtid: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate stddev on columns
type workflow_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev() on columns of table "workflow"
input workflow_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_pop on columns
type workflow_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_pop() on columns of table "workflow"
input workflow_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate stddev_samp on columns
type workflow_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by stddev_samp() on columns of table "workflow"
input workflow_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# columns and relationships of "workflow_step"
type workflow_step {
  action: String
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  minimumRole: Int
  mtid: bigint!
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  query: String
  refreshed: Boolean!
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint

  # An object relationship
  workflow: workflow
  workflowMtid: bigint
}

# aggregated selection of "workflow_step"
type workflow_step_aggregate {
  aggregate: workflow_step_aggregate_fields
  nodes: [workflow_step!]!
}

# aggregate fields of "workflow_step"
type workflow_step_aggregate_fields {
  avg: workflow_step_avg_fields
  count(columns: [workflow_step_select_column!], distinct: Boolean): Int
  max: workflow_step_max_fields
  min: workflow_step_min_fields
  stddev: workflow_step_stddev_fields
  stddev_pop: workflow_step_stddev_pop_fields
  stddev_samp: workflow_step_stddev_samp_fields
  sum: workflow_step_sum_fields
  var_pop: workflow_step_var_pop_fields
  var_samp: workflow_step_var_samp_fields
  variance: workflow_step_variance_fields
}

# order by aggregate values of table "workflow_step"
input workflow_step_aggregate_order_by {
  avg: workflow_step_avg_order_by
  count: order_by
  max: workflow_step_max_order_by
  min: workflow_step_min_order_by
  stddev: workflow_step_stddev_order_by
  stddev_pop: workflow_step_stddev_pop_order_by
  stddev_samp: workflow_step_stddev_samp_order_by
  sum: workflow_step_sum_order_by
  var_pop: workflow_step_var_pop_order_by
  var_samp: workflow_step_var_samp_order_by
  variance: workflow_step_variance_order_by
}

# input type for inserting array relation for remote table "workflow_step"
input workflow_step_arr_rel_insert_input {
  data: [workflow_step_insert_input!]!
  on_conflict: workflow_step_on_conflict
}

# aggregate avg on columns
type workflow_step_avg_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by avg() on columns of table "workflow_step"
input workflow_step_avg_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# Boolean expression to filter rows from the table "workflow_step". All fields are combined with a logical 'AND'.
input workflow_step_bool_exp {
  _and: [workflow_step_bool_exp]
  _not: workflow_step_bool_exp
  _or: [workflow_step_bool_exp]
  action: String_comparison_exp
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  description: String_comparison_exp
  descriptionEng: String_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  minimumRole: Int_comparison_exp
  mtid: bigint_comparison_exp
  name: String_comparison_exp
  nameEng: String_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  query: String_comparison_exp
  refreshed: Boolean_comparison_exp
  sorter: String_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  workflow: workflow_bool_exp
  workflowMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "workflow_step"
enum workflow_step_constraint {
  # unique or primary key constraint
  workflow_step_pkey
}

# input type for incrementing integer column in table "workflow_step"
input workflow_step_inc_input {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# input type for inserting data into table "workflow_step"
input workflow_step_insert_input {
  action: String
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  query: String
  refreshed: Boolean
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflow: workflow_obj_rel_insert_input
  workflowMtid: bigint
}

# aggregate max on columns
type workflow_step_max_fields {
  action: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  query: String
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# order by max() on columns of table "workflow_step"
input workflow_step_max_order_by {
  action: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  description: order_by
  descriptionEng: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  query: order_by
  sorter: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate min on columns
type workflow_step_min_fields {
  action: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  query: String
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# order by min() on columns of table "workflow_step"
input workflow_step_min_order_by {
  action: order_by
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  description: order_by
  descriptionEng: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  query: order_by
  sorter: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# response of any mutation on the table "workflow_step"
type workflow_step_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [workflow_step!]!
}

# input type for inserting object relation for remote table "workflow_step"
input workflow_step_obj_rel_insert_input {
  data: workflow_step_insert_input!
  on_conflict: workflow_step_on_conflict
}

# on conflict condition type for table "workflow_step"
input workflow_step_on_conflict {
  constraint: workflow_step_constraint!
  update_columns: [workflow_step_update_column!]!
  where: workflow_step_bool_exp
}

# ordering options when selecting data from "workflow_step"
input workflow_step_order_by {
  action: order_by
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  description: order_by
  descriptionEng: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  minimumRole: order_by
  mtid: order_by
  name: order_by
  nameEng: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  query: order_by
  refreshed: order_by
  sorter: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflow: workflow_order_by
  workflowMtid: order_by
}

# primary key columns input for table: "workflow_step"
input workflow_step_pk_columns_input {
  mtid: bigint!
}

# select columns of table "workflow_step"
enum workflow_step_select_column {
  # column name
  action

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  description

  # column name
  descriptionEng

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  minimumRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  query

  # column name
  refreshed

  # column name
  sorter

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  workflowMtid
}

# input type for updating data in table "workflow_step"
input workflow_step_set_input {
  action: String
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  description: String
  descriptionEng: String
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  name: String
  nameEng: String
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  query: String
  refreshed: Boolean
  sorter: String
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# columns and relationships of "workflow_step_status"
type workflow_step_status {
  approved: timestamp

  # An object relationship
  approver: users
  approverMtid: bigint
  comment: String
  comment2: String
  completed: Boolean!
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint

  # An object relationship
  creatorUser: users
  deleted: Boolean!
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint

  # An object relationship
  lastModifierSwitched: users

  # An object relationship
  lastModifierUser: users
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint

  # An object relationship
  lockerUser: users
  mtid: bigint!
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean!
  refreshed: Boolean!
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int!
  validFromYear: smallint
  validToYear: smallint

  # An object relationship
  workflowStatus: workflow_status
  workflowStatusMtid: bigint

  # An object relationship
  workflowStep: workflow_step
  workflowStepMtid: bigint
}

# aggregated selection of "workflow_step_status"
type workflow_step_status_aggregate {
  aggregate: workflow_step_status_aggregate_fields
  nodes: [workflow_step_status!]!
}

# aggregate fields of "workflow_step_status"
type workflow_step_status_aggregate_fields {
  avg: workflow_step_status_avg_fields
  count(columns: [workflow_step_status_select_column!], distinct: Boolean): Int
  max: workflow_step_status_max_fields
  min: workflow_step_status_min_fields
  stddev: workflow_step_status_stddev_fields
  stddev_pop: workflow_step_status_stddev_pop_fields
  stddev_samp: workflow_step_status_stddev_samp_fields
  sum: workflow_step_status_sum_fields
  var_pop: workflow_step_status_var_pop_fields
  var_samp: workflow_step_status_var_samp_fields
  variance: workflow_step_status_variance_fields
}

# order by aggregate values of table "workflow_step_status"
input workflow_step_status_aggregate_order_by {
  avg: workflow_step_status_avg_order_by
  count: order_by
  max: workflow_step_status_max_order_by
  min: workflow_step_status_min_order_by
  stddev: workflow_step_status_stddev_order_by
  stddev_pop: workflow_step_status_stddev_pop_order_by
  stddev_samp: workflow_step_status_stddev_samp_order_by
  sum: workflow_step_status_sum_order_by
  var_pop: workflow_step_status_var_pop_order_by
  var_samp: workflow_step_status_var_samp_order_by
  variance: workflow_step_status_variance_order_by
}

# input type for inserting array relation for remote table "workflow_step_status"
input workflow_step_status_arr_rel_insert_input {
  data: [workflow_step_status_insert_input!]!
  on_conflict: workflow_step_status_on_conflict
}

# aggregate avg on columns
type workflow_step_status_avg_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowStatusMtid: Float
  workflowStepMtid: Float
}

# order by avg() on columns of table "workflow_step_status"
input workflow_step_status_avg_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# Boolean expression to filter rows from the table "workflow_step_status". All fields are combined with a logical 'AND'.
input workflow_step_status_bool_exp {
  _and: [workflow_step_status_bool_exp]
  _not: workflow_step_status_bool_exp
  _or: [workflow_step_status_bool_exp]
  approved: timestamp_comparison_exp
  approver: users_bool_exp
  approverMtid: bigint_comparison_exp
  comment: String_comparison_exp
  comment2: String_comparison_exp
  completed: Boolean_comparison_exp
  count: Int_comparison_exp
  countUncut: Int_comparison_exp
  created: timestamp_comparison_exp
  creator: bigint_comparison_exp
  creatorUser: users_bool_exp
  deleted: Boolean_comparison_exp
  deletedDate: timestamp_comparison_exp
  error: Int_comparison_exp
  labelEng: String_comparison_exp
  labelHun: String_comparison_exp
  lastModified: timestamp_comparison_exp
  lastModifier: bigint_comparison_exp
  lastModifierAdmin: bigint_comparison_exp
  lastModifierSwitched: users_bool_exp
  lastModifierUser: users_bool_exp
  lastRefresh: timestamp_comparison_exp
  lastTemplateMake: timestamp_comparison_exp
  lastTouched: timestamp_comparison_exp
  listPosition: Int_comparison_exp
  locked: timestamp_comparison_exp
  lockerMtid: bigint_comparison_exp
  lockerUser: users_bool_exp
  mtid: bigint_comparison_exp
  oldId: Int_comparison_exp
  oldTimestamp: timestamp_comparison_exp
  otype: String_comparison_exp
  prevValid: bigint_comparison_exp
  published: Boolean_comparison_exp
  refreshed: Boolean_comparison_exp
  status: Int_comparison_exp
  template2Eng: String_comparison_exp
  template2Hun: String_comparison_exp
  templateEng: String_comparison_exp
  templateHun: String_comparison_exp
  unhandledTickets: Int_comparison_exp
  validFromYear: smallint_comparison_exp
  validToYear: smallint_comparison_exp
  workflowStatus: workflow_status_bool_exp
  workflowStatusMtid: bigint_comparison_exp
  workflowStep: workflow_step_bool_exp
  workflowStepMtid: bigint_comparison_exp
}

# unique or primary key constraints on table "workflow_step_status"
enum workflow_step_status_constraint {
  # unique or primary key constraint
  workflow_step_status_pkey
}

# input type for incrementing integer column in table "workflow_step_status"
input workflow_step_status_inc_input {
  approverMtid: bigint
  count: Int
  countUncut: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowStatusMtid: bigint
  workflowStepMtid: bigint
}

# input type for inserting data into table "workflow_step_status"
input workflow_step_status_insert_input {
  approved: timestamp
  approver: users_obj_rel_insert_input
  approverMtid: bigint
  comment: String
  comment2: String
  completed: Boolean
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  creatorUser: users_obj_rel_insert_input
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastModifierSwitched: users_obj_rel_insert_input
  lastModifierUser: users_obj_rel_insert_input
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  lockerUser: users_obj_rel_insert_input
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowStatus: workflow_status_obj_rel_insert_input
  workflowStatusMtid: bigint
  workflowStep: workflow_step_obj_rel_insert_input
  workflowStepMtid: bigint
}

# aggregate max on columns
type workflow_step_status_max_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowStatusMtid: bigint
  workflowStepMtid: bigint
}

# order by max() on columns of table "workflow_step_status"
input workflow_step_status_max_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  countUncut: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# aggregate min on columns
type workflow_step_status_min_fields {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowStatusMtid: bigint
  workflowStepMtid: bigint
}

# order by min() on columns of table "workflow_step_status"
input workflow_step_status_min_order_by {
  approved: order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  count: order_by
  countUncut: order_by
  created: order_by
  creator: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# response of any mutation on the table "workflow_step_status"
type workflow_step_status_mutation_response {
  # number of affected rows by the mutation
  affected_rows: Int!

  # data of the affected rows by the mutation
  returning: [workflow_step_status!]!
}

# input type for inserting object relation for remote table "workflow_step_status"
input workflow_step_status_obj_rel_insert_input {
  data: workflow_step_status_insert_input!
  on_conflict: workflow_step_status_on_conflict
}

# on conflict condition type for table "workflow_step_status"
input workflow_step_status_on_conflict {
  constraint: workflow_step_status_constraint!
  update_columns: [workflow_step_status_update_column!]!
  where: workflow_step_status_bool_exp
}

# ordering options when selecting data from "workflow_step_status"
input workflow_step_status_order_by {
  approved: order_by
  approver: users_order_by
  approverMtid: order_by
  comment: order_by
  comment2: order_by
  completed: order_by
  count: order_by
  countUncut: order_by
  created: order_by
  creator: order_by
  creatorUser: users_order_by
  deleted: order_by
  deletedDate: order_by
  error: order_by
  labelEng: order_by
  labelHun: order_by
  lastModified: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lastModifierSwitched: users_order_by
  lastModifierUser: users_order_by
  lastRefresh: order_by
  lastTemplateMake: order_by
  lastTouched: order_by
  listPosition: order_by
  locked: order_by
  lockerMtid: order_by
  lockerUser: users_order_by
  mtid: order_by
  oldId: order_by
  oldTimestamp: order_by
  otype: order_by
  prevValid: order_by
  published: order_by
  refreshed: order_by
  status: order_by
  template2Eng: order_by
  template2Hun: order_by
  templateEng: order_by
  templateHun: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatus: workflow_status_order_by
  workflowStatusMtid: order_by
  workflowStep: workflow_step_order_by
  workflowStepMtid: order_by
}

# primary key columns input for table: "workflow_step_status"
input workflow_step_status_pk_columns_input {
  mtid: bigint!
}

# select columns of table "workflow_step_status"
enum workflow_step_status_select_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  completed

  # column name
  count

  # column name
  countUncut

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  workflowStatusMtid

  # column name
  workflowStepMtid
}

# input type for updating data in table "workflow_step_status"
input workflow_step_status_set_input {
  approved: timestamp
  approverMtid: bigint
  comment: String
  comment2: String
  completed: Boolean
  count: Int
  countUncut: Int
  created: timestamp
  creator: bigint
  deleted: Boolean
  deletedDate: timestamp
  error: Int
  labelEng: String
  labelHun: String
  lastModified: timestamp
  lastModifier: bigint
  lastModifierAdmin: bigint
  lastRefresh: timestamp
  lastTemplateMake: timestamp
  lastTouched: timestamp
  listPosition: Int
  locked: timestamp
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  oldTimestamp: timestamp
  otype: String
  prevValid: bigint
  published: Boolean
  refreshed: Boolean
  status: Int
  template2Eng: String
  template2Hun: String
  templateEng: String
  templateHun: String
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowStatusMtid: bigint
  workflowStepMtid: bigint
}

# aggregate stddev on columns
type workflow_step_status_stddev_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowStatusMtid: Float
  workflowStepMtid: Float
}

# order by stddev() on columns of table "workflow_step_status"
input workflow_step_status_stddev_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# aggregate stddev_pop on columns
type workflow_step_status_stddev_pop_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowStatusMtid: Float
  workflowStepMtid: Float
}

# order by stddev_pop() on columns of table "workflow_step_status"
input workflow_step_status_stddev_pop_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# aggregate stddev_samp on columns
type workflow_step_status_stddev_samp_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowStatusMtid: Float
  workflowStepMtid: Float
}

# order by stddev_samp() on columns of table "workflow_step_status"
input workflow_step_status_stddev_samp_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# aggregate sum on columns
type workflow_step_status_sum_fields {
  approverMtid: bigint
  count: Int
  countUncut: Int
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowStatusMtid: bigint
  workflowStepMtid: bigint
}

# order by sum() on columns of table "workflow_step_status"
input workflow_step_status_sum_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# update columns of table "workflow_step_status"
enum workflow_step_status_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  completed

  # column name
  count

  # column name
  countUncut

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  mtid

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  refreshed

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  workflowStatusMtid

  # column name
  workflowStepMtid
}

# aggregate var_pop on columns
type workflow_step_status_var_pop_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowStatusMtid: Float
  workflowStepMtid: Float
}

# order by var_pop() on columns of table "workflow_step_status"
input workflow_step_status_var_pop_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# aggregate var_samp on columns
type workflow_step_status_var_samp_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowStatusMtid: Float
  workflowStepMtid: Float
}

# order by var_samp() on columns of table "workflow_step_status"
input workflow_step_status_var_samp_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# aggregate variance on columns
type workflow_step_status_variance_fields {
  approverMtid: Float
  count: Float
  countUncut: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowStatusMtid: Float
  workflowStepMtid: Float
}

# order by variance() on columns of table "workflow_step_status"
input workflow_step_status_variance_order_by {
  approverMtid: order_by
  count: order_by
  countUncut: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowStatusMtid: order_by
  workflowStepMtid: order_by
}

# aggregate stddev on columns
type workflow_step_stddev_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by stddev() on columns of table "workflow_step"
input workflow_step_stddev_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate stddev_pop on columns
type workflow_step_stddev_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by stddev_pop() on columns of table "workflow_step"
input workflow_step_stddev_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate stddev_samp on columns
type workflow_step_stddev_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by stddev_samp() on columns of table "workflow_step"
input workflow_step_stddev_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate sum on columns
type workflow_step_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  listPosition: Int
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
  workflowMtid: bigint
}

# order by sum() on columns of table "workflow_step"
input workflow_step_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# update columns of table "workflow_step"
enum workflow_step_update_column {
  # column name
  action

  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  description

  # column name
  descriptionEng

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  listPosition

  # column name
  locked

  # column name
  lockerMtid

  # column name
  minimumRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  query

  # column name
  refreshed

  # column name
  sorter

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear

  # column name
  workflowMtid
}

# aggregate var_pop on columns
type workflow_step_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by var_pop() on columns of table "workflow_step"
input workflow_step_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate var_samp on columns
type workflow_step_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by var_samp() on columns of table "workflow_step"
input workflow_step_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate variance on columns
type workflow_step_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  listPosition: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
  workflowMtid: Float
}

# order by variance() on columns of table "workflow_step"
input workflow_step_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  listPosition: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
  workflowMtid: order_by
}

# aggregate sum on columns
type workflow_sum_fields {
  approverMtid: bigint
  creator: bigint
  error: Int
  lastModifier: bigint
  lastModifierAdmin: bigint
  lockerMtid: bigint
  minimumRole: Int
  mtid: bigint
  oldId: Int
  prevValid: bigint
  status: Int
  unhandledTickets: Int
  validFromYear: smallint
  validToYear: smallint
}

# order by sum() on columns of table "workflow"
input workflow_sum_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# update columns of table "workflow"
enum workflow_update_column {
  # column name
  approved

  # column name
  approverMtid

  # column name
  comment

  # column name
  comment2

  # column name
  created

  # column name
  creator

  # column name
  deleted

  # column name
  deletedDate

  # column name
  description

  # column name
  descriptionEng

  # column name
  error

  # column name
  labelEng

  # column name
  labelHun

  # column name
  lastModified

  # column name
  lastModifier

  # column name
  lastModifierAdmin

  # column name
  lastRefresh

  # column name
  lastTemplateMake

  # column name
  lastTouched

  # column name
  locked

  # column name
  lockerMtid

  # column name
  minimumRole

  # column name
  mtid

  # column name
  name

  # column name
  nameEng

  # column name
  oldId

  # column name
  oldTimestamp

  # column name
  otype

  # column name
  prevValid

  # column name
  published

  # column name
  query

  # column name
  recordType

  # column name
  refreshed

  # column name
  requiresList

  # column name
  sorter

  # column name
  status

  # column name
  template2Eng

  # column name
  template2Hun

  # column name
  templateEng

  # column name
  templateHun

  # column name
  unhandledTickets

  # column name
  validFromYear

  # column name
  validToYear
}

# aggregate var_pop on columns
type workflow_var_pop_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_pop() on columns of table "workflow"
input workflow_var_pop_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate var_samp on columns
type workflow_var_samp_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by var_samp() on columns of table "workflow"
input workflow_var_samp_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

# aggregate variance on columns
type workflow_variance_fields {
  approverMtid: Float
  creator: Float
  error: Float
  lastModifier: Float
  lastModifierAdmin: Float
  lockerMtid: Float
  minimumRole: Float
  mtid: Float
  oldId: Float
  prevValid: Float
  status: Float
  unhandledTickets: Float
  validFromYear: Float
  validToYear: Float
}

# order by variance() on columns of table "workflow"
input workflow_variance_order_by {
  approverMtid: order_by
  creator: order_by
  error: order_by
  lastModifier: order_by
  lastModifierAdmin: order_by
  lockerMtid: order_by
  minimumRole: order_by
  mtid: order_by
  oldId: order_by
  prevValid: order_by
  status: order_by
  unhandledTickets: order_by
  validFromYear: order_by
  validToYear: order_by
}

